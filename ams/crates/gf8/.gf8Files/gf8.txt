File: aligned.rs
================
/* crates/gf8/src/aligned.rs */
//! # E8F Error Management - Aligned Wrappers
//!
//! This module provides automatic error management for E8F operations through
//! zero-cost wrappers that track operation counts and trigger re-alignment
//! when quantization drift may accumulate.
//!
//! ## Key Types
//! - [`E8FAligned`]: Zero-cost wrapper that tracks operation count and triggers
//!   automatic re-alignment after a configurable number of operations.
//! - [`E8FChain`]: Tracks operation sequences with drift metrics and warnings.
//!
//! ## Design Rationale
//! E8F operations always resolve to valid E8 roots via lookup tables, but
//! chaining many operations can accumulate semantic drift from the original
//! intent. These wrappers provide automatic re-alignment to bound this drift.
//!
//! ## Example
//! ```rust
//! use gf8::aligned::E8FAligned;
//! use gf8::E8F;
//!
//! let mut aligned = E8FAligned::new(E8F::new(42));
//!
//! // Operations are tracked automatically
//! aligned.op(|e| e + E8F::new(10));
//! aligned.op(|e| e * E8F::new(5));
//!
//! // After max_ops_before_align operations, alignment is triggered
//! let result = aligned.value();
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::quantize_to_nearest_code;
use crate::{E8F, Gf8, gf8_chordal_distance};

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E8FAligned - ZERO-COST WRAPPER WITH AUTOMATIC ALIGNMENT
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Zero-cost wrapper that tracks operation count and triggers automatic alignment.
///
/// This wrapper ensures that E8F values are periodically re-quantized to the
/// nearest valid E8 root, bounding cumulative quantization drift.
///
/// # Default Behavior
/// - `max_ops_before_align`: 10 operations before automatic re-alignment
/// - Alignment converts E8F → Gf8 → nearest E8 root
///
/// # Example
/// ```rust
/// use gf8::aligned::E8FAligned;
/// use gf8::E8F;
///
/// let mut aligned = E8FAligned::new(E8F::new(42));
///
/// // Chain operations - alignment happens automatically after 10 ops
/// for i in 0..15 {
///     aligned.op(|e| e + E8F::new(i as u8));
/// }
///
/// // Value is guaranteed to be a valid E8 root
/// assert!(aligned.value().is_valid());
/// ```
#[derive(Debug, Clone, Copy)]
pub struct E8FAligned {
    /// The current E8F value.
    value: E8F,
    /// Number of operations since last alignment.
    ops_since_alignment: u8,
    /// Maximum operations before triggering automatic alignment.
    max_ops_before_align: u8,
}

impl E8FAligned {
    /// Default number of operations before automatic alignment.
    pub const DEFAULT_MAX_OPS: u8 = 10;

    /// Create a new aligned wrapper with default settings.
    ///
    /// # Arguments
    /// * `value` - Initial E8F value
    #[inline]
    pub fn new(value: E8F) -> Self {
        Self {
            value,
            ops_since_alignment: 0,
            max_ops_before_align: Self::DEFAULT_MAX_OPS,
        }
    }

    /// Create a new aligned wrapper with custom alignment threshold.
    ///
    /// # Arguments
    /// * `value` - Initial E8F value
    /// * `max_ops` - Maximum operations before automatic alignment
    #[inline]
    pub fn with_max_ops(value: E8F, max_ops: u8) -> Self {
        Self {
            value,
            ops_since_alignment: 0,
            max_ops_before_align: max_ops,
        }
    }

    /// Get the current value.
    #[inline]
    pub fn value(&self) -> E8F {
        self.value
    }

    /// Get the number of operations since last alignment.
    #[inline]
    pub fn ops_since_alignment(&self) -> u8 {
        self.ops_since_alignment
    }

    /// Get the maximum operations before alignment.
    #[inline]
    pub fn max_ops_before_align(&self) -> u8 {
        self.max_ops_before_align
    }

    /// Set the maximum operations before alignment.
    #[inline]
    pub fn set_max_ops(&mut self, max_ops: u8) {
        self.max_ops_before_align = max_ops;
    }

    /// Perform an operation with automatic alignment check.
    ///
    /// After the operation, if `ops_since_alignment >= max_ops_before_align`,
    /// automatic re-alignment is triggered.
    ///
    /// # Arguments
    /// * `f` - Operation to perform on the E8F value
    ///
    /// # Returns
    /// Mutable reference to self for chaining
    #[inline]
    pub fn op<F: FnOnce(E8F) -> E8F>(&mut self, f: F) -> &mut Self {
        self.value = f(self.value);
        self.ops_since_alignment = self.ops_since_alignment.saturating_add(1);

        if self.ops_since_alignment >= self.max_ops_before_align {
            self.align();
        }
        self
    }

    /// Force re-alignment to the nearest valid E8 root.
    ///
    /// This converts the current E8F to its Gf8 representation, then
    /// re-quantizes to the nearest E8 root, resetting the operation counter.
    #[inline]
    pub fn align(&mut self) {
        if !self.value.is_valid() {
            self.value = E8F::new(0);
            self.ops_since_alignment = 0;
            return;
        }

        let gf8 = self.value.to_gf8();
        let (code, _distance) = quantize_to_nearest_code(gf8.coords());
        self.value = E8F::new(code.0);
        self.ops_since_alignment = 0;
    }

    /// Check if alignment is needed (ops >= threshold).
    #[inline]
    pub fn needs_alignment(&self) -> bool {
        self.ops_since_alignment >= self.max_ops_before_align
    }

    /// Reset the operation counter without re-aligning.
    #[inline]
    pub fn reset_counter(&mut self) {
        self.ops_since_alignment = 0;
    }
}

impl Default for E8FAligned {
    fn default() -> Self {
        Self::new(E8F::new(0))
    }
}

impl From<E8F> for E8FAligned {
    fn from(value: E8F) -> Self {
        Self::new(value)
    }
}

impl From<E8FAligned> for E8F {
    fn from(aligned: E8FAligned) -> Self {
        aligned.value
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 2: E8FChain - OPERATION SEQUENCE TRACKING WITH DRIFT METRICS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Tracks a chain of E8F operations with drift metrics and warnings.
///
/// Unlike `E8FAligned`, this type maintains a reference to the initial ground
/// truth value and tracks cumulative drift, logging warnings when drift
/// exceeds a configurable threshold.
///
/// # Drift Metrics (R15.6)
/// - `max_drift`: Maximum observed drift from ground truth
/// - `mean_drift`: Running mean of drift values across operations
/// - `alignment_count`: Number of times re-alignment was triggered
///
/// # Automatic Re-alignment (R15.9)
/// When drift exceeds the threshold (default: 0.1 chordal distance), a warning
/// is logged and automatic re-alignment is triggered.
///
/// # Example
/// ```rust
/// use gf8::aligned::E8FChain;
/// use gf8::{E8F, Gf8};
///
/// let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
/// let mut chain = E8FChain::start(&initial);
///
/// chain.apply("add_10", |e| e + E8F::new(10));
/// chain.apply("mul_5", |e| e * E8F::new(5));
///
/// let (result, max_drift) = chain.finish();
/// println!("Max drift: {:.4}", max_drift);
/// ```
#[derive(Debug, Clone)]
pub struct E8FChain {
    /// Ground truth reference (initial Gf8 value).
    initial: Gf8,
    /// Current quantized value.
    current: E8F,
    /// Operation names for debugging.
    ops: Vec<&'static str>,
    /// Maximum observed drift from ground truth.
    max_drift: f32,
    /// Sum of all drift values (for computing mean).
    drift_sum: f32,
    /// Count of drift measurements (for computing mean).
    drift_count: u32,
    /// Number of times re-alignment was triggered.
    alignment_count: u32,
    /// Threshold for warning and auto-realignment (default: 0.1).
    drift_threshold: f32,
}

impl E8FChain {
    /// Default drift threshold for warnings and auto-realignment.
    pub const DEFAULT_DRIFT_THRESHOLD: f32 = 0.1;

    /// Start a new operation chain from a ground truth Gf8 value.
    ///
    /// The initial Gf8 value is stored as the ground truth reference (R15.4).
    /// All subsequent drift measurements are computed against this reference.
    ///
    /// # Arguments
    /// * `initial` - Ground truth Gf8 value to track drift against
    pub fn start(initial: &Gf8) -> Self {
        let (code, _) = quantize_to_nearest_code(initial.coords());
        Self {
            initial: *initial,
            current: E8F::new(code.0),
            ops: Vec::new(),
            max_drift: 0.0,
            drift_sum: 0.0,
            drift_count: 0,
            alignment_count: 0,
            drift_threshold: Self::DEFAULT_DRIFT_THRESHOLD,
        }
    }

    /// Start a new operation chain with a custom drift threshold.
    ///
    /// # Arguments
    /// * `initial` - Ground truth Gf8 value
    /// * `threshold` - Drift threshold for warnings and auto-realignment
    pub fn start_with_threshold(initial: &Gf8, threshold: f32) -> Self {
        let mut chain = Self::start(initial);
        chain.drift_threshold = threshold;
        chain
    }

    /// Apply an operation to the chain, tracking drift.
    ///
    /// After each operation, drift from the ground truth is computed using
    /// `gf8_chordal_distance()`. If drift exceeds the threshold (R15.9):
    /// 1. A warning is logged
    /// 2. Automatic re-alignment is triggered
    ///
    /// # Arguments
    /// * `op_name` - Name of the operation (for debugging)
    /// * `f` - Operation to apply
    ///
    /// # Returns
    /// Mutable reference to self for chaining
    pub fn apply(&mut self, op_name: &'static str, f: impl FnOnce(E8F) -> E8F) -> &mut Self {
        self.current = f(self.current);
        self.ops.push(op_name);

        // Measure drift from ground truth using gf8_chordal_distance
        let current_gf8 = self.current.to_gf8();
        let drift = gf8_chordal_distance(&self.initial, &current_gf8);

        // Update drift metrics (R15.6)
        self.max_drift = self.max_drift.max(drift);
        self.drift_sum += drift;
        self.drift_count += 1;

        // R15.9: Log warning and force re-alignment when drift exceeds threshold
        if drift > self.drift_threshold {
            eprintln!(
                "[WARN] E8FChain drift {:.4} exceeds threshold {:.4} after {} ops: {:?}",
                drift,
                self.drift_threshold,
                self.ops.len(),
                self.ops
            );
            // Force re-alignment (R15.9)
            self.align_to_nearest_root();
        }

        self
    }

    /// Get the current drift from ground truth.
    ///
    /// Computes drift using `gf8_chordal_distance()` between the current
    /// E8F value (converted to Gf8) and the initial ground truth.
    pub fn current_drift(&self) -> f32 {
        let current_gf8 = self.current.to_gf8();
        gf8_chordal_distance(&self.initial, &current_gf8)
    }

    /// Get the maximum observed drift (R15.6).
    #[inline]
    pub fn max_drift(&self) -> f32 {
        self.max_drift
    }

    /// Get the mean drift across all operations (R15.6).
    ///
    /// Returns 0.0 if no operations have been performed.
    #[inline]
    pub fn mean_drift(&self) -> f32 {
        if self.drift_count == 0 {
            0.0
        } else {
            self.drift_sum / self.drift_count as f32
        }
    }

    /// Get the number of times re-alignment was triggered (R15.6).
    #[inline]
    pub fn alignment_count(&self) -> u32 {
        self.alignment_count
    }

    /// Get the current E8F value.
    #[inline]
    pub fn current(&self) -> E8F {
        self.current
    }

    /// Get the ground truth Gf8 value (R15.4).
    #[inline]
    pub fn initial(&self) -> &Gf8 {
        &self.initial
    }

    /// Get the operation history (for debugging).
    #[inline]
    pub fn ops(&self) -> &[&'static str] {
        &self.ops
    }

    /// Get the drift threshold.
    #[inline]
    pub fn drift_threshold(&self) -> f32 {
        self.drift_threshold
    }

    /// Set the drift threshold.
    #[inline]
    pub fn set_drift_threshold(&mut self, threshold: f32) {
        self.drift_threshold = threshold;
    }

    /// Explicit re-quantization to the nearest valid E8 root (R15.5).
    ///
    /// This method:
    /// 1. Converts current E8F to Gf8
    /// 2. Re-quantizes to the nearest E8 root
    /// 3. Updates the ground truth reference to the new aligned value
    /// 4. Increments the alignment counter (R15.6)
    /// 5. Clears operation history
    ///
    /// Note: `max_drift` and `mean_drift` are preserved for overall metrics tracking.
    /// The ground truth reference is updated to the newly aligned value so that
    /// subsequent drift measurements are relative to the aligned state.
    pub fn align_to_nearest_root(&mut self) {
        let gf8 = self.current.to_gf8();
        let (code, _) = quantize_to_nearest_code(gf8.coords());
        self.current = E8F::new(code.0);
        // Update initial to current for fresh drift tracking from aligned state
        self.initial = self.current.to_gf8();
        self.alignment_count += 1;
        self.ops.clear();
    }

    /// Force re-alignment to the nearest E8 root.
    ///
    /// This is an alias for `align_to_nearest_root()` for backward compatibility.
    /// It re-quantizes the current value and resets drift tracking
    /// to use the new value as the reference point.
    #[inline]
    pub fn realign(&mut self) {
        self.align_to_nearest_root();
    }

    /// Finish the chain and return the result with max drift.
    ///
    /// # Returns
    /// Tuple of (final E8F value, maximum observed drift)
    pub fn finish(self) -> (E8F, f32) {
        (self.current, self.max_drift)
    }

    /// Finish the chain and return full metrics.
    ///
    /// # Returns
    /// Tuple of (final E8F value, max_drift, mean_drift, alignment_count)
    pub fn finish_with_metrics(self) -> (E8F, f32, f32, u32) {
        let mean = self.mean_drift();
        (self.current, self.max_drift, mean, self.alignment_count)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 3: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8f_aligned_basic() {
        let aligned = E8FAligned::new(E8F::new(42));
        assert_eq!(aligned.value().index(), 42);
        assert_eq!(aligned.ops_since_alignment(), 0);
    }

    #[test]
    fn test_e8f_aligned_op_tracking() {
        let mut aligned = E8FAligned::new(E8F::new(10));

        // Perform some operations
        aligned.op(|e| e + E8F::new(5));
        assert_eq!(aligned.ops_since_alignment(), 1);

        aligned.op(|e| e * E8F::new(3));
        assert_eq!(aligned.ops_since_alignment(), 2);
    }

    #[test]
    fn test_e8f_aligned_auto_alignment() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(10), 3);

        // Perform 3 operations - should trigger alignment
        aligned.op(|e| e + E8F::new(1));
        aligned.op(|e| e + E8F::new(2));
        aligned.op(|e| e + E8F::new(3));

        // Counter should be reset after alignment
        assert_eq!(aligned.ops_since_alignment(), 0);

        // Value should still be valid
        assert!(aligned.value().is_valid());
    }

    #[test]
    fn test_e8f_aligned_manual_align() {
        let mut aligned = E8FAligned::new(E8F::new(50));

        aligned.op(|e| e + E8F::new(10));
        aligned.op(|e| e + E8F::new(20));
        assert_eq!(aligned.ops_since_alignment(), 2);

        aligned.align();
        assert_eq!(aligned.ops_since_alignment(), 0);
        assert!(aligned.value().is_valid());
    }

    #[test]
    fn test_e8f_aligned_needs_alignment() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(10), 2);

        assert!(!aligned.needs_alignment());
        aligned.op(|e| e + E8F::new(1));
        assert!(!aligned.needs_alignment());
        aligned.op(|e| e + E8F::new(2));
        // After 2 ops with max_ops=2, alignment was triggered, counter reset
        assert!(!aligned.needs_alignment());
    }

    #[test]
    fn test_e8f_chain_basic() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start(&initial);

        assert!(chain.current().is_valid());
        assert_eq!(chain.ops().len(), 0);
        assert_eq!(chain.max_drift(), 0.0);
        assert_eq!(chain.mean_drift(), 0.0);
        assert_eq!(chain.alignment_count(), 0);
    }

    #[test]
    fn test_e8f_chain_apply() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment during test
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("add_10", |e| e + E8F::new(10));
        assert_eq!(chain.ops().len(), 1);
        assert_eq!(chain.ops()[0], "add_10");

        chain.apply("mul_5", |e| e * E8F::new(5));
        assert_eq!(chain.ops().len(), 2);
    }

    #[test]
    fn test_e8f_chain_drift_tracking() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment during test
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        // Apply operations that may cause drift
        for i in 0..5 {
            chain.apply("op", |e| e + E8F::new(i * 10));
        }

        // Drift should be tracked
        let drift = chain.current_drift();
        assert!(drift >= 0.0);
        assert!(chain.max_drift() >= drift || (chain.max_drift() - drift).abs() < 1e-6);

        // Mean drift should be computed (R15.6)
        assert!(chain.mean_drift() >= 0.0);
    }

    #[test]
    fn test_e8f_chain_finish() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let mut chain = E8FChain::start(&initial);

        chain.apply("op1", |e| e + E8F::new(10));
        chain.apply("op2", |e| e * E8F::new(20));

        let (result, max_drift) = chain.finish();
        assert!(result.is_valid());
        assert!(max_drift >= 0.0);
    }

    #[test]
    fn test_e8f_chain_finish_with_metrics() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let mut chain = E8FChain::start(&initial);

        chain.apply("op1", |e| e + E8F::new(10));
        chain.apply("op2", |e| e * E8F::new(20));

        let (result, max_drift, mean_drift, alignment_count) = chain.finish_with_metrics();
        assert!(result.is_valid());
        assert!(max_drift >= 0.0);
        assert!(mean_drift >= 0.0);
        // alignment_count is u32, just verify it's accessible
        let _ = alignment_count;
    }

    #[test]
    fn test_e8f_chain_realign() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("op1", |e| e + E8F::new(50));
        chain.apply("op2", |e| e + E8F::new(100));

        let max_drift_before = chain.max_drift();
        chain.realign();

        // After realign, ops should be cleared
        assert_eq!(chain.ops().len(), 0);
        assert!(chain.current().is_valid());
        // Alignment count should be incremented
        assert_eq!(chain.alignment_count(), 1);

        // max_drift is preserved for metrics tracking
        assert_eq!(chain.max_drift(), max_drift_before);
    }

    #[test]
    fn test_e8f_chain_align_to_nearest_root() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("op1", |e| e + E8F::new(50));

        // Explicit re-quantization (R15.5)
        chain.align_to_nearest_root();

        assert!(chain.current().is_valid());
        assert_eq!(chain.alignment_count(), 1);
        assert_eq!(chain.ops().len(), 0);
    }

    #[test]
    fn test_e8f_chain_auto_realignment_on_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use very low threshold to trigger auto-realignment (R15.9)
        let mut chain = E8FChain::start_with_threshold(&initial, 0.001);

        // Apply operation that will likely exceed threshold
        chain.apply("big_op", |e| e + E8F::new(200));

        // Auto-realignment should have been triggered
        // (alignment_count > 0 if drift exceeded threshold)
        // Note: The actual drift depends on E8 geometry, so we just verify
        // the mechanism works
        assert!(chain.current().is_valid());
    }

    #[test]
    fn test_e8f_chain_metrics_tracking() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        // Apply multiple operations
        chain.apply("op1", |e| e + E8F::new(10));
        chain.apply("op2", |e| e + E8F::new(20));
        chain.apply("op3", |e| e + E8F::new(30));

        // R15.6: Track error metrics
        assert!(chain.max_drift() >= 0.0);
        assert!(chain.mean_drift() >= 0.0);
        assert_eq!(chain.alignment_count(), 0); // No auto-realignment with high threshold
    }

    #[test]
    fn test_e8f_aligned_from_into() {
        let e8f = E8F::new(100);
        let aligned: E8FAligned = e8f.into();
        assert_eq!(aligned.value().index(), 100);

        let back: E8F = aligned.into();
        assert_eq!(back.index(), 100);
    }

    #[test]
    fn test_e8f_chain_custom_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start_with_threshold(&initial, 0.05);

        assert_eq!(chain.drift_threshold(), 0.05);
    }

    #[test]
    fn test_e8f_chain_ground_truth_reference() {
        // R15.4: Use Gf8 as ground truth reference
        let initial = Gf8::new([0.7, 0.3, 0.5, 0.1, 0.2, 0.4, 0.6, 0.8]);
        let chain = E8FChain::start(&initial);

        // Ground truth should be stored
        let stored_initial = chain.initial();
        assert_eq!(stored_initial.coords()[0], initial.coords()[0]);
        assert_eq!(stored_initial.coords()[7], initial.coords()[7]);
    }

    #[test]
    fn test_e8f_chain_operation_names_for_debugging() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("first_op", |e| e + E8F::new(1));
        chain.apply("second_op", |e| e + E8F::new(2));
        chain.apply("third_op", |e| e + E8F::new(3));

        // Operation names should be tracked for debugging
        let ops = chain.ops();
        assert_eq!(ops.len(), 3);
        assert_eq!(ops[0], "first_op");
        assert_eq!(ops[1], "second_op");
        assert_eq!(ops[2], "third_op");
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // TASK 3.3: COMPREHENSIVE TESTS FOR E8F ERROR MANAGEMENT (R15.3, R15.9)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// R15.3: Test that alignment triggers exactly after N operations (default: 10)
    #[test]
    fn test_alignment_triggers_after_n_operations_default() {
        // Default max_ops is 10
        let mut aligned = E8FAligned::new(E8F::new(42));
        assert_eq!(aligned.max_ops_before_align(), E8FAligned::DEFAULT_MAX_OPS);
        assert_eq!(E8FAligned::DEFAULT_MAX_OPS, 10);

        // Perform 9 operations - should NOT trigger alignment
        for i in 0..9 {
            aligned.op(|e| e + E8F::new(i));
            assert_eq!(aligned.ops_since_alignment(), i + 1);
        }

        // 10th operation should trigger alignment and reset counter
        aligned.op(|e| e + E8F::new(9));
        assert_eq!(
            aligned.ops_since_alignment(),
            0,
            "Counter should reset after alignment"
        );
        assert!(aligned.value().is_valid());
    }

    /// R15.3: Test alignment with custom chain depth
    #[test]
    fn test_alignment_triggers_after_custom_n_operations() {
        let custom_max = 5;
        let mut aligned = E8FAligned::with_max_ops(E8F::new(100), custom_max);
        assert_eq!(aligned.max_ops_before_align(), custom_max);

        // Perform 4 operations - should NOT trigger alignment
        for i in 0..4 {
            aligned.op(|e| e + E8F::new(i));
            assert_eq!(aligned.ops_since_alignment(), i + 1);
        }

        // 5th operation should trigger alignment
        aligned.op(|e| e + E8F::new(4));
        assert_eq!(aligned.ops_since_alignment(), 0);

        // Continue with more operations - should trigger again at 5
        for i in 0..5 {
            aligned.op(|e| e + E8F::new(i as u8));
        }
        assert_eq!(
            aligned.ops_since_alignment(),
            0,
            "Should reset after second alignment"
        );
    }

    /// R15.3: Test that alignment is amortized (no overhead for single ops)
    #[test]
    fn test_alignment_amortized_no_overhead_single_ops() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(50), 100);

        // Single operation should not trigger alignment
        aligned.op(|e| e + E8F::new(1));
        assert_eq!(aligned.ops_since_alignment(), 1);
        assert!(!aligned.needs_alignment());

        // Value should still be valid without alignment
        assert!(aligned.value().is_valid());
    }

    /// R15.9: Test warning threshold behavior - drift exceeds threshold triggers warning
    #[test]
    fn test_warning_threshold_triggers_realignment() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Very low threshold to ensure drift exceeds it
        let mut chain = E8FChain::start_with_threshold(&initial, 0.001);

        let alignment_count_before = chain.alignment_count();

        // Apply operation that will cause significant drift
        chain.apply("large_drift_op", |e| e + E8F::new(200));

        // R15.9: Auto-realignment should have been triggered
        // The alignment count should have increased
        assert!(
            chain.alignment_count() > alignment_count_before,
            "Alignment should be triggered when drift exceeds threshold"
        );

        // Value should still be valid after realignment
        assert!(chain.current().is_valid());
    }

    /// R15.9: Test that default threshold is 0.1 chordal distance
    #[test]
    fn test_default_drift_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start(&initial);

        assert_eq!(
            chain.drift_threshold(),
            E8FChain::DEFAULT_DRIFT_THRESHOLD,
            "Default threshold should match constant"
        );
        assert_eq!(
            E8FChain::DEFAULT_DRIFT_THRESHOLD,
            0.1,
            "Default threshold should be 0.1"
        );
    }

    /// R15.9: Test that warning is logged when drift exceeds threshold
    /// (We verify this by checking alignment_count increases)
    #[test]
    fn test_drift_exceeds_threshold_forces_realignment() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use default threshold (0.1)
        let mut chain = E8FChain::start(&initial);

        // Apply operations that will cause drift > 0.1
        // Adding a large offset should cause significant drift
        chain.apply("drift_op", |e| e + E8F::new(150));

        // Check if drift exceeded threshold and realignment occurred
        // Note: The actual drift depends on E8 geometry
        let drift = chain.current_drift();
        if drift > 0.1 {
            // If drift exceeded threshold, alignment should have been triggered
            assert!(
                chain.alignment_count() > 0,
                "Alignment should be triggered when drift > threshold"
            );
        }
    }

    /// R15.6: Test drift tracking accuracy - max_drift, mean_drift, alignment_count
    #[test]
    fn test_drift_tracking_accuracy() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // High threshold to prevent auto-realignment during test
        let mut chain = E8FChain::start_with_threshold(&initial, 100.0);

        // Apply multiple operations and track drift
        let mut expected_max_drift = 0.0f32;
        let mut drift_sum = 0.0f32;
        let mut drift_count = 0u32;

        for i in 0..5 {
            chain.apply("op", |e| e + E8F::new(i * 20));

            // Manually compute expected drift
            let current_drift = chain.current_drift();
            expected_max_drift = expected_max_drift.max(current_drift);
            drift_sum += current_drift;
            drift_count += 1;
        }

        let expected_mean = drift_sum / drift_count as f32;

        // Verify drift metrics (R15.6)
        assert!(
            (chain.max_drift() - expected_max_drift).abs() < 1e-5,
            "max_drift should match expected: {} vs {}",
            chain.max_drift(),
            expected_max_drift
        );
        assert!(
            (chain.mean_drift() - expected_mean).abs() < 1e-5,
            "mean_drift should match expected: {} vs {}",
            chain.mean_drift(),
            expected_mean
        );
        assert_eq!(
            chain.alignment_count(),
            0,
            "No alignment with high threshold"
        );
    }

    /// R15.6: Test alignment_count increments correctly
    #[test]
    fn test_alignment_count_increments() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // High threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 100.0);

        assert_eq!(chain.alignment_count(), 0);

        chain.apply("op1", |e| e + E8F::new(10));
        chain.realign();
        assert_eq!(chain.alignment_count(), 1);

        chain.apply("op2", |e| e + E8F::new(20));
        chain.align_to_nearest_root();
        assert_eq!(chain.alignment_count(), 2);

        chain.apply("op3", |e| e + E8F::new(30));
        chain.realign();
        assert_eq!(chain.alignment_count(), 3);
    }

    /// R15.9: Test that ops are cleared after auto-realignment
    #[test]
    fn test_ops_cleared_after_auto_realignment() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Very low threshold to trigger auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 0.0001);

        // Apply operation that will exceed threshold
        chain.apply("trigger_op", |e| e + E8F::new(200));

        // If auto-realignment was triggered, ops should be cleared
        if chain.alignment_count() > 0 {
            assert_eq!(
                chain.ops().len(),
                0,
                "Ops should be cleared after auto-realignment"
            );
        }
    }

    /// Test E8FAligned counter saturation (edge case)
    #[test]
    fn test_aligned_counter_saturation() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(10), 255);

        // Perform many operations without triggering alignment
        for _ in 0..254 {
            aligned.op(|e| e); // Identity operation
        }

        // Counter should be at 254
        assert_eq!(aligned.ops_since_alignment(), 254);

        // One more should trigger alignment (255 >= 255)
        aligned.op(|e| e);
        assert_eq!(aligned.ops_since_alignment(), 0);
    }

    /// Test E8FChain with zero operations
    #[test]
    fn test_chain_zero_operations() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start(&initial);

        // With no operations, metrics should be zero
        assert_eq!(chain.max_drift(), 0.0);
        assert_eq!(chain.mean_drift(), 0.0);
        assert_eq!(chain.alignment_count(), 0);
        assert_eq!(chain.ops().len(), 0);
    }

    /// Test that set_drift_threshold works correctly
    #[test]
    fn test_set_drift_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let mut chain = E8FChain::start(&initial);

        assert_eq!(chain.drift_threshold(), 0.1);

        chain.set_drift_threshold(0.5);
        assert_eq!(chain.drift_threshold(), 0.5);

        chain.set_drift_threshold(0.01);
        assert_eq!(chain.drift_threshold(), 0.01);
    }
}

File: e8f.rs
============
/* crates/gf8/src/e8f.rs */
//! # E8F – The E8 Float: Finite Lattice Arithmetic
//!
//! This module implements the "Trillion Dollar" optimization: replacing runtime
//! floating-point operations with precomputed integer lookup tables over the
//! E8 lattice. Operations always resolve to valid E8 roots (canonical states).
//!
//! ## Origin Citation
//! "E8 operations can replace SIMD float math... weights: [Eb8; d/8]...
//! A single Eb8 = 8 numbers at once."
//!
//! ## Key Capabilities
//! - **Zero-FLOP Inference**: Addition and multiplication become array lookups
//! - **Perfect Closure**: Operations always resolve to a valid E8 root
//! - **32x Compression**: Weights stored as u8, computed as u8
//! - **Group Structure**: Implements Klein/Weyl group symmetries
//!
//! ## Architectural Notes
//! Instead of treating E8 roots as vectors for f32 math, we precompute the
//! interaction of every root with every other root. This transforms linear
//! algebra into Integer Lookup Tables.
//!
//! The E8 root system forms a group under reflection, and the 240 roots can
//! be combined via geometric operations that map back to roots.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::{get_e8_codebook, quantize_to_nearest_code};
use crate::{Gf8, Gf8BitSig, Gf8LosslessCode};
use std::fmt;
use std::ops::{Add, Mul, Neg, Sub};
use std::sync::OnceLock;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: PRECOMPUTED LOOKUP TABLES
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Precomputed lookup tables for E8 lattice arithmetic.
///
/// These tables enable O(1) operations between E8 roots without any
/// floating-point computation at inference time.
///
/// Memory footprint: ~460KB total (heap-allocated)
/// - add_table:     240×240 = 57,600 bytes
/// - sub_table:     240×240 = 57,600 bytes
/// - mul_table:     240×240 = 57,600 bytes
/// - dot_table:     240×240 = 57,600 bytes
/// - reflect_table: 240×240 = 57,600 bytes
/// - neg_table:     240 bytes
pub struct E8ArithmeticTables {
    /// Addition: add_table[a][b] = snap(root_a + root_b)
    pub add_table: Box<[[u8; 240]; 240]>,

    /// Subtraction: sub_table[a][b] = snap(root_a - root_b)
    pub sub_table: Box<[[u8; 240]; 240]>,

    /// Multiplication (Hadamard-style): mul_table[a][b] = snap(root_a ⊙ root_b)
    pub mul_table: Box<[[u8; 240]; 240]>,

    /// Dot product: dot_table[a][b] = quantized(root_a · root_b) in [0, 255]
    /// Maps [-1.0, 1.0] → [0, 255]
    pub dot_table: Box<[[u8; 240]; 240]>,

    /// Reflection: reflect_table[a][b] = snap(root_a - 2(root_a·root_b)root_b)
    pub reflect_table: Box<[[u8; 240]; 240]>,

    /// Negation: neg_table[a] = index of -root_a
    pub neg_table: [u8; 240],
}

/// Static singleton for the arithmetic tables.
pub static E8_ARITHMETIC: OnceLock<E8ArithmeticTables> = OnceLock::new();

impl E8ArithmeticTables {
    /// Generate all arithmetic lookup tables.
    /// This is expensive (~240² × 5 operations) but only done once at startup.
    pub fn generate() -> Self {
        let codebook = get_e8_codebook();
        let roots = &codebook.roots;

        // Allocate on heap to avoid stack overflow
        let mut add_table = Box::new([[0u8; 240]; 240]);
        let mut sub_table = Box::new([[0u8; 240]; 240]);
        let mut mul_table = Box::new([[0u8; 240]; 240]);
        let mut dot_table = Box::new([[128u8; 240]; 240]);
        let mut neg_table = [0u8; 240];
        let mut reflect_table = Box::new([[0u8; 240]; 240]);

        // Precompute all pairwise operations
        for (i, root_i) in roots.iter().enumerate().take(240) {
            let ri = root_i.coords();

            // Negation: find antipodal root
            let neg_coords: [f32; 8] = std::array::from_fn(|k| -ri[k]);
            let (neg_code, _) = quantize_to_nearest_code(&neg_coords);
            neg_table[i] = neg_code.0;

            for (j, root_j) in roots.iter().enumerate().take(240) {
                let rj = root_j.coords();

                // Addition: root_i + root_j → nearest root
                let sum_coords: [f32; 8] = std::array::from_fn(|k| ri[k] + rj[k]);
                let (sum_code, _) = quantize_to_nearest_code(&sum_coords);
                add_table[i][j] = sum_code.0;

                // Subtraction: root_i - root_j → nearest root
                let diff_coords: [f32; 8] = std::array::from_fn(|k| ri[k] - rj[k]);
                let (diff_code, _) = quantize_to_nearest_code(&diff_coords);
                sub_table[i][j] = diff_code.0;

                // Multiplication (Hadamard/element-wise): root_i ⊙ root_j → nearest root
                let prod_coords: [f32; 8] = std::array::from_fn(|k| ri[k] * rj[k]);
                let (prod_code, _) = quantize_to_nearest_code(&prod_coords);
                mul_table[i][j] = prod_code.0;

                // Dot product: quantized to [0, 255]
                let dot: f32 = ri.iter().zip(rj.iter()).map(|(a, b)| a * b).sum();
                // Map [-1, 1] to [0, 255]
                let quantized = ((dot.clamp(-1.0, 1.0) + 1.0) * 127.5) as u8;
                dot_table[i][j] = quantized;

                // Reflection: reflect i through hyperplane normal to j
                // Formula: r_i - 2 * (r_i · r_j) * r_j
                let scale = 2.0 * dot;
                let reflect_coords: [f32; 8] = std::array::from_fn(|k| ri[k] - scale * rj[k]);
                let (reflect_code, _) = quantize_to_nearest_code(&reflect_coords);
                reflect_table[i][j] = reflect_code.0;
            }
        }

        Self {
            add_table,
            sub_table,
            mul_table,
            dot_table,
            neg_table,
            reflect_table,
        }
    }
}

/// Get the global arithmetic tables (lazily initialized).
#[inline]
pub fn get_e8_arithmetic() -> &'static E8ArithmeticTables {
    E8_ARITHMETIC.get_or_init(E8ArithmeticTables::generate)
}

/// Ensure tables are initialized (call at startup for predictable latency).
pub fn init_e8_arithmetic() {
    let _ = get_e8_arithmetic();
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 2: E8F – THE LATTICE SCALAR TYPE
// ═══════════════════════════════════════════════════════════════════════════════════════

/// The E8 Float: A numeric type where all operations resolve to valid E8 lattice points.
///
/// This replaces f32/f16 in model weights and activations, enabling:
/// - Zero-FLOP inference (all ops are table lookups)
/// - Perfect closure (results always valid E8 roots)
/// - 32x compression (1 byte vs 32 bytes for 8D vector)
///
/// # Example
/// ```rust
/// use gf8::e8f::E8F;
///
/// let a = E8F::new(42);
/// let b = E8F::new(100);
///
/// // All operations are O(1) table lookups
/// let sum = a + b;      // Addition
/// let diff = a - b;     // Subtraction
/// let prod = a * b;     // Hadamard multiplication
/// let neg = -a;         // Negation
/// let dot = a.dot(b);   // Dot product (returns f32)
/// ```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Default)]
#[repr(transparent)]
pub struct E8F(pub u8);

impl fmt::Display for E8F {
    /// Formats E8F for display in logs and debugging.
    ///
    /// Format: `E8F(index)` where index is the root index.
    /// - Valid roots (0-239): Shows the index
    /// - Invalid/Zero (240+): Shows as "zero" or invalid index
    ///
    /// This enables E8F to be used with tracing macros and println!.
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if self.is_valid() {
            write!(f, "E8F({})", self.0)
        } else if self.0 == 240 {
            write!(f, "E8F(zero)")
        } else {
            write!(f, "E8F(invalid:{})", self.0)
        }
    }
}

impl E8F {
    /// The "zero" state (index 240, outside valid roots).
    /// Used for null/undefined values.
    pub const ZERO: Self = Self(240);

    /// Create from a root index (0-239). Values ≥240 are clamped.
    #[inline]
    pub const fn new(root_idx: u8) -> Self {
        Self(if root_idx < 240 {
            root_idx
        } else {
            Self::ZERO.0
        })
    }

    /// Create from a raw byte without clamping (used for lossless bit containers like E32L).
    #[inline]
    pub const fn from_raw(byte: u8) -> Self {
        Self(byte)
    }

    /// Create from a root index with explicit validation; returns None if out of range.
    #[inline]
    pub const fn new_checked(root_idx: u8) -> Option<Self> {
        if root_idx < 240 {
            Some(Self(root_idx))
        } else {
            None
        }
    }

    /// Create from a Gf8BitSig .
    #[inline]
    pub const fn from_code(code: Gf8BitSig) -> Self {
        Self::new(code.0)
    }

    /// Create from a Gf8LosslessCode.
    #[inline]
    pub const fn from_lossless(code: Gf8LosslessCode) -> Self {
        Self::new(code.0)
    }

    /// Get the root index.
    #[inline]
    pub const fn index(&self) -> u8 {
        self.0
    }

    /// Check if this is a valid root (index < 240).
    #[inline]
    pub const fn is_valid(&self) -> bool {
        self.0 < 240
    }

    /// Convert to Gf8BitSig .
    #[inline]
    pub const fn to_code(&self) -> Gf8BitSig {
        Gf8BitSig(self.0)
    }

    /// Convert to Gf8LosslessCode.
    #[inline]
    pub const fn to_lossless(&self) -> Gf8LosslessCode {
        Gf8LosslessCode(self.0)
    }

    /// Dequantize to the actual Gf8 vector (for final output).
    /// This is a **lossless** operation for valid E8F roots - the returned
    /// Gf8 is the exact root from the codebook with no quantization error.
    pub fn to_gf8(&self) -> Gf8 {
        if self.0 >= 240 {
            return Gf8::ZERO;
        }
        let codebook = get_e8_codebook();
        codebook.roots[self.0 as usize]
    }

    /// Quantize an f32 array to E8F.
    pub fn from_f32(coords: &[f32; 8]) -> Self {
        let (code, _) = quantize_to_nearest_code(coords);
        Self(code.0)
    }

    /// Compute quantized dot product (returns u8 in [0, 255]).
    /// 0 = -1.0, 128 = 0.0, 255 = 1.0
    #[inline]
    pub fn dot_quantized(self, other: Self) -> u8 {
        if self.0 >= 240 || other.0 >= 240 {
            return 128; // 0.0
        }
        let tables = get_e8_arithmetic();
        tables.dot_table[self.0 as usize][other.0 as usize]
    }

    /// Compute dot product as f32 (dequantized).
    #[inline]
    pub fn dot(self, other: Self) -> f32 {
        let q = self.dot_quantized(other);
        (q as f32 / 127.5) - 1.0
    }

    /// Reflect self through hyperplane normal to other.
    #[inline]
    pub fn reflect(self, normal: Self) -> Self {
        if self.0 >= 240 || normal.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.reflect_table[self.0 as usize][normal.0 as usize])
    }

    /// Check if two E8Fs are neighbors in the E8 lattice (dot ≈ 0.5, 60° angle).
    #[inline]
    pub fn is_neighbor(self, other: Self) -> bool {
        let dot = self.dot_quantized(other);
        (180..=200).contains(&dot) // ~0.5 in [0,255] scale
    }

    /// Check if two E8Fs are antipodal (opposite directions, dot ≈ -1.0).
    #[inline]
    pub fn is_antipodal(self, other: Self) -> bool {
        self.dot_quantized(other) < 10
    }

    /// Check if two E8Fs are orthogonal (dot ≈ 0.0).
    #[inline]
    pub fn is_orthogonal(self, other: Self) -> bool {
        let dot = self.dot_quantized(other);
        (120..=136).contains(&dot)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 3: OPERATOR IMPLEMENTATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl Add for E8F {
    type Output = Self;
    /// E8F addition via lookup table.
    /// **Error Bound**: Result is the nearest E8 root to (a + b), with
    /// ≤0.087 chordal distance error. The operation itself is deterministic
    /// and error-free for repeated identical inputs (lookup table is constant).
    #[inline]
    fn add(self, rhs: Self) -> Self::Output {
        if self.0 >= 240 || rhs.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.add_table[self.0 as usize][rhs.0 as usize])
    }
}

impl Sub for E8F {
    type Output = Self;
    #[inline]
    fn sub(self, rhs: Self) -> Self::Output {
        if self.0 >= 240 || rhs.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.sub_table[self.0 as usize][rhs.0 as usize])
    }
}

impl Mul for E8F {
    type Output = Self;
    #[inline]
    fn mul(self, rhs: Self) -> Self::Output {
        if self.0 >= 240 || rhs.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.mul_table[self.0 as usize][rhs.0 as usize])
    }
}

impl Neg for E8F {
    type Output = Self;
    #[inline]
    fn neg(self) -> Self::Output {
        if self.0 >= 240 {
            return self;
        }
        let tables = get_e8_arithmetic();
        Self(tables.neg_table[self.0 as usize])
    }
}

impl From<u8> for E8F {
    fn from(idx: u8) -> Self {
        Self::new(idx)
    }
}

impl From<Gf8BitSig> for E8F {
    fn from(code: Gf8BitSig) -> Self {
        Self::from_code(code)
    }
}

impl From<Gf8LosslessCode> for E8F {
    fn from(code: Gf8LosslessCode) -> Self {
        Self::from_lossless(code)
    }
}

impl From<E8F> for Gf8BitSig {
    fn from(e: E8F) -> Self {
        e.to_code()
    }
}

impl From<E8F> for Gf8LosslessCode {
    fn from(e: E8F) -> Self {
        e.to_lossless()
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 4: E8VEC – VECTOR OF E8FS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// A vector of E8Fs for batch operations.
///
/// Enables processing entire embeddings
/// using only integer lookups. Storage: 1 byte per 8D block.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct E8Vec {
    pub data: Vec<E8F>,
}

impl E8Vec {
    /// Create from a slice of root indices.
    pub fn from_indices(indices: &[u8]) -> Self {
        Self {
            data: indices.iter().map(|&i| E8F::new(i)).collect(),
        }
    }

    /// Quantize a high-dimensional f32 vector to E8Vec.
    /// Splits into 8D blocks and quantizes each to an E8F.
    pub fn from_f32_vec(vec: &[f32]) -> Self {
        let num_blocks = vec.len().div_ceil(8);
        let mut data = Vec::with_capacity(num_blocks);

        for chunk in vec.chunks(8) {
            let mut block = [0.0f32; 8];
            block[..chunk.len()].copy_from_slice(chunk);
            data.push(E8F::from_f32(&block));
        }

        Self { data }
    }

    /// Dequantize to f32 vector.
    pub fn to_f32_vec(&self) -> Vec<f32> {
        let mut result = Vec::with_capacity(self.data.len() * 8);
        for e in &self.data {
            let gf8 = e.to_gf8();
            result.extend_from_slice(gf8.coords());
        }
        result
    }

    /// Element-wise addition.
    pub fn add(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len());
        Self {
            data: self
                .data
                .iter()
                .zip(other.data.iter())
                .map(|(a, b)| *a + *b)
                .collect(),
        }
    }

    /// Element-wise subtraction.
    pub fn sub(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len());
        Self {
            data: self
                .data
                .iter()
                .zip(other.data.iter())
                .map(|(a, b)| *a - *b)
                .collect(),
        }
    }

    /// Element-wise multiplication.
    pub fn mul(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len());
        Self {
            data: self
                .data
                .iter()
                .zip(other.data.iter())
                .map(|(a, b)| *a * *b)
                .collect(),
        }
    }

    /// Dot product (sum of element-wise dots).
    pub fn dot(&self, other: &Self) -> f32 {
        assert_eq!(self.data.len(), other.data.len());
        self.data
            .iter()
            .zip(other.data.iter())
            .map(|(a, b)| a.dot(*b))
            .sum()
    }

    /// Quantized dot product (sum of quantized element-wise dots).
    pub fn dot_quantized(&self, other: &Self) -> u32 {
        assert_eq!(self.data.len(), other.data.len());
        self.data
            .iter()
            .zip(other.data.iter())
            .map(|(a, b)| a.dot_quantized(*b) as u32)
            .sum()
    }

    /// Get the raw bytes (for storage/transmission).
    /// 32x compression: 2048D → 256 bytes.
    pub fn to_bytes(&self) -> Vec<u8> {
        self.data.iter().map(|e| e.0).collect()
    }

    /// Create from raw bytes.
    pub fn from_bytes(bytes: &[u8]) -> Self {
        Self {
            data: bytes.iter().map(|&b| E8F::new(b)).collect(),
        }
    }

    /// Length in E8F elements.
    pub fn len(&self) -> usize {
        self.data.len()
    }

    /// Check if empty.
    pub fn is_empty(&self) -> bool {
        self.data.is_empty()
    }

    /// Original dimensionality (len × 8).
    pub fn dim(&self) -> usize {
        self.data.len() * 8
    }
}

impl std::ops::Index<usize> for E8Vec {
    type Output = E8F;
    fn index(&self, idx: usize) -> &Self::Output {
        &self.data[idx]
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 5: E8 TENSOR CORE – FUSED MATRIX OPERATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// E8 Tensor Core: Fused matrix operations over the E8 lattice.
///
/// Analogous to GPU tensor cores, but using lookup tables instead of FP units.
/// All operations maintain E8 closure (results are always valid roots).
pub struct E8TensorCore;

impl E8TensorCore {
    // ─────────────────────────────────────────────────────────────────────────────────
    // FUSED MULTIPLY-ACCUMULATE (FMA)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Fused multiply-add: `a * b + c` in E8 space.
    /// Two table lookups instead of three separate ops.
    #[inline]
    pub fn fma(a: E8F, b: E8F, c: E8F) -> E8F {
        let prod = a * b;
        prod + c
    }

    /// Fused multiply-subtract: `a * b - c` in E8 space.
    #[inline]
    pub fn fms(a: E8F, b: E8F, c: E8F) -> E8F {
        let prod = a * b;
        prod - c
    }

    /// Fused negative multiply-add: `-(a * b) + c` = `c - a * b`
    #[inline]
    pub fn fnma(a: E8F, b: E8F, c: E8F) -> E8F {
        let prod = a * b;
        c - prod
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // VECTOR-VECTOR OPERATIONS (like BLAS Level 1)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// AXPY: `y = a * x + y` (scale and accumulate)
    /// Fundamental BLAS operation, fully in E8 space.
    pub fn axpy(a: E8F, x: &E8Vec, y: &mut E8Vec) {
        assert_eq!(x.len(), y.len());
        for i in 0..x.len() {
            y.data[i] = Self::fma(a, x.data[i], y.data[i]);
        }
    }

    /// Dot product with accumulator: `acc + sum(x[i] * y[i])`
    /// Returns quantized result as u32 for precision.
    pub fn dot_acc(x: &E8Vec, y: &E8Vec, acc: u32) -> u32 {
        acc + x.dot_quantized(y)
    }

    /// Weighted sum: `sum(weights[i] * vectors[i])`
    /// Reduces multiple vectors into one.
    pub fn weighted_sum(weights: &[E8F], vectors: &[E8Vec]) -> E8Vec {
        assert_eq!(weights.len(), vectors.len());
        assert!(!vectors.is_empty());

        let len = vectors[0].len();
        let mut result = E8Vec::from_indices(&vec![0u8; len]);

        for (w, v) in weights.iter().zip(vectors.iter()) {
            for i in 0..len {
                result.data[i] = Self::fma(*w, v.data[i], result.data[i]);
            }
        }
        result
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // MATRIX-VECTOR OPERATIONS (like BLAS Level 2)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Matrix-vector multiply: `y = M * x`
    /// M is row-major: M[row][col], each row is an E8Vec.
    pub fn matvec(m: &[E8Vec], x: &E8Vec) -> Vec<u32> {
        m.iter().map(|row| row.dot_quantized(x)).collect()
    }

    /// Matrix-vector multiply with E8F output (snapped to nearest roots).
    /// Uses dot products to find best-matching output roots.
    pub fn matvec_e8f(m: &[E8Vec], x: &E8Vec) -> E8Vec {
        let dots: Vec<u32> = Self::matvec(m, x);
        // Map quantized dots back to E8F indices
        // Higher dot = more similar, map to root index space
        let indices: Vec<u8> = dots
            .iter()
            .map(|&d| ((d as f32 / (x.len() as f32 * 255.0)) * 239.0) as u8)
            .collect();
        E8Vec::from_indices(&indices)
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // OUTER PRODUCT (for attention-like operations)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Outer product: `M[i][j] = u[i] * v[j]`
    /// Creates a matrix from two vectors (attention pattern).
    pub fn outer(u: &E8Vec, v: &E8Vec) -> Vec<E8Vec> {
        u.data
            .iter()
            .map(|&ui| E8Vec {
                data: v.data.iter().map(|&vj| ui * vj).collect(),
            })
            .collect()
    }

    /// Outer product with addition: `M[i][j] += u[i] * v[j]`
    /// Accumulates into existing matrix.
    pub fn outer_add(u: &E8Vec, v: &E8Vec, m: &mut [E8Vec]) {
        for (i, &ui) in u.data.iter().enumerate() {
            for (j, &vj) in v.data.iter().enumerate() {
                m[i].data[j] = Self::fma(ui, vj, m[i].data[j]);
            }
        }
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // BATCH OPERATIONS (like tensor core's warp-level ops)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Batch dot products: compute dots for multiple query-key pairs.
    /// Returns quantized similarities for attention scoring.
    pub fn batch_dots(queries: &[E8Vec], keys: &[E8Vec]) -> Vec<Vec<u32>> {
        queries
            .iter()
            .map(|q| keys.iter().map(|k| q.dot_quantized(k)).collect())
            .collect()
    }

    /// Batch dot products (single query against multiple keys).
    /// Optimized for retrieval: one query, many candidates.
    pub fn query_dots(query: &E8Vec, keys: &[E8Vec]) -> Vec<u32> {
        keys.iter().map(|k| query.dot_quantized(k)).collect()
    }

    /// Dom-R selection from batch dots (for attention/retrieval).
    /// Returns indices of K highest-scoring keys.
    pub fn top_k(scores: &[u32], k: usize) -> Vec<usize> {
        let mut indexed: Vec<(usize, u32)> = scores.iter().copied().enumerate().collect();
        indexed.sort_by(|a, b| b.1.cmp(&a.1)); // Descending
        indexed.into_iter().take(k).map(|(i, _)| i).collect()
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // SOFTMAX APPROXIMATION (via E8 geometry)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Approximate softmax using E8 neighbor structure.
    /// Maps quantized scores to probability-like weights.
    ///
    /// Instead of exp(x)/sum(exp), uses:
    /// - Shift scores to positive range
    /// - Normalize by sum
    /// - Quantize to u8 weights
    pub fn softmax_approx(scores: &[u32]) -> Vec<u8> {
        if scores.is_empty() {
            return vec![];
        }

        let min = *scores.iter().min().unwrap();
        let shifted: Vec<u32> = scores.iter().map(|&s| s - min + 1).collect();
        let sum: u32 = shifted.iter().sum();

        if sum == 0 {
            return vec![255 / scores.len() as u8; scores.len()];
        }

        shifted
            .iter()
            .map(|&s| ((s as u64 * 255) / sum as u64) as u8)
            .collect()
    }

    /// Weighted combination using softmax-like weights.
    /// `result = sum(weights[i] * values[i])` where weights are normalized.
    pub fn softmax_combine(weights: &[u8], values: &[E8Vec]) -> E8Vec {
        assert_eq!(weights.len(), values.len());
        assert!(!values.is_empty());

        let len = values[0].len();
        let mut result = E8Vec::from_indices(&vec![0u8; len]);

        // Convert u8 weights to E8F (map 0-255 to root indices 0-239)
        let e8_weights: Vec<E8F> = weights
            .iter()
            .map(|&w| E8F::new((w as u16 * 239 / 255) as u8))
            .collect();

        for (w, v) in e8_weights.iter().zip(values.iter()) {
            for i in 0..len {
                result.data[i] = Self::fma(*w, v.data[i], result.data[i]);
            }
        }
        result
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // ATTENTION MECHANISM (full E8 attention in one call)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// E8 Attention: Q·K^T → softmax → weighted V
    ///
    /// Single-head attention entirely in E8 space:
    /// 1. Compute Q·K similarities (batch dots)
    /// 2. Apply softmax approximation
    /// 3. Weight and sum V vectors
    ///
    /// Returns attended output for each query.
    pub fn attention(queries: &[E8Vec], keys: &[E8Vec], values: &[E8Vec]) -> Vec<E8Vec> {
        assert_eq!(keys.len(), values.len());

        queries
            .iter()
            .map(|q| {
                // Q·K^T
                let scores = Self::query_dots(q, keys);
                // Softmax
                let weights = Self::softmax_approx(&scores);
                // Weighted sum of V
                Self::softmax_combine(&weights, values)
            })
            .collect()
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // LAYER NORM APPROXIMATION
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Approximate layer normalization via E8 centering.
    ///
    /// Instead of (x - mean) / std, we:
    /// 1. Find the "centroid" root (most common neighbor)
    /// 2. Subtract it (centering)
    /// 3. The E8 lattice's uniform structure provides implicit normalization
    pub fn layer_norm_approx(x: &E8Vec) -> E8Vec {
        if x.is_empty() {
            return x.clone();
        }

        // Find centroid: average all roots, snap to nearest
        // Simplified: use the most frequent root as center
        let mut counts = [0u32; 240];
        for e in &x.data {
            if e.is_valid() {
                counts[e.0 as usize] += 1;
            }
        }

        let centroid_idx = counts
            .iter()
            .enumerate()
            .max_by_key(|&(_, c)| c)
            .map(|(i, _)| i as u8)
            .unwrap_or(0);

        let centroid = E8F::new(centroid_idx);

        // Subtract centroid from all elements
        E8Vec {
            data: x.data.iter().map(|&e| e - centroid).collect(),
        }
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 6: E8 MATRIX TYPE
// ═══════════════════════════════════════════════════════════════════════════════════════

/// E8 Matrix: 2D array of E8Fs for weight matrices.
///
/// Row-major storage, each row is an E8Vec.
/// Used for linear layers, attention projections, etc.
#[derive(Debug, Clone)]
pub struct E8Mat {
    /// Rows of the matrix.
    pub rows: Vec<E8Vec>,
    /// Number of columns (E8F elements per row).
    pub cols: usize,
}

impl E8Mat {
    /// Create a new matrix with given dimensions, initialized to root 0.
    pub fn new(num_rows: usize, num_cols: usize) -> Self {
        Self {
            rows: (0..num_rows)
                .map(|_| E8Vec::from_indices(&vec![0u8; num_cols]))
                .collect(),
            cols: num_cols,
        }
    }

    /// Create from raw bytes (row-major).
    pub fn from_bytes(bytes: &[u8], num_rows: usize, num_cols: usize) -> Self {
        assert_eq!(bytes.len(), num_rows * num_cols);
        Self {
            rows: bytes.chunks(num_cols).map(E8Vec::from_bytes).collect(),
            cols: num_cols,
        }
    }

    /// Serialize to bytes.
    pub fn to_bytes(&self) -> Vec<u8> {
        self.rows.iter().flat_map(|r| r.to_bytes()).collect()
    }

    /// Number of rows.
    pub fn num_rows(&self) -> usize {
        self.rows.len()
    }

    /// Number of columns.
    pub fn num_cols(&self) -> usize {
        self.cols
    }

    /// Matrix-vector multiply: `y = M * x`
    pub fn matvec(&self, x: &E8Vec) -> Vec<u32> {
        E8TensorCore::matvec(&self.rows, x)
    }

    /// Matrix-vector multiply with E8F output.
    pub fn matvec_e8f(&self, x: &E8Vec) -> E8Vec {
        E8TensorCore::matvec_e8f(&self.rows, x)
    }

    /// Transpose (creates new matrix).
    pub fn transpose(&self) -> Self {
        let num_rows = self.cols;
        let num_cols = self.num_rows();

        let mut rows = Vec::with_capacity(num_rows);
        for j in 0..num_rows {
            let col: Vec<E8F> = self.rows.iter().map(|r| r.data[j]).collect();
            rows.push(E8Vec { data: col });
        }

        Self {
            rows,
            cols: num_cols,
        }
    }
}

impl std::ops::Index<usize> for E8Mat {
    type Output = E8Vec;
    fn index(&self, idx: usize) -> &Self::Output {
        &self.rows[idx]
    }
}

impl std::ops::IndexMut<usize> for E8Mat {
    fn index_mut(&mut self, idx: usize) -> &mut Self::Output {
        &mut self.rows[idx]
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 7: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8f_basic() {
        let a = E8F::new(42);
        let b = E8F::new(100);

        assert!(a.is_valid());
        assert!(b.is_valid());
        assert!(!E8F::ZERO.is_valid());
    }

    #[test]
    fn test_e8f_arithmetic() {
        let a = E8F::new(10);
        let b = E8F::new(20);

        // All operations should return valid roots
        let sum = a + b;
        let diff = a - b;
        let prod = a * b;
        let neg = -a;

        assert!(sum.is_valid());
        assert!(diff.is_valid());
        assert!(prod.is_valid());
        assert!(neg.is_valid());
    }

    #[test]
    fn test_e8f_dot_product() {
        // Self dot should be ~1.0 (maps to ~255)
        for i in 0..10u8 {
            let e = E8F::new(i);
            let dot = e.dot_quantized(e);
            assert!(dot > 250, "Self dot should be ~1.0, got {}", dot);
        }
    }

    #[test]
    fn test_e8f_negation() {
        // Double negation should return close to original
        for i in 0..10u8 {
            let e = E8F::new(i);
            let neg_neg = -(-e);
            let dot = e.dot_quantized(neg_neg);
            assert!(dot > 250, "Double negation should be ~identity");
        }
    }

    #[test]
    fn test_e8f_antipodal() {
        let e = E8F::new(0);
        let neg_e = -e;
        assert!(e.is_antipodal(neg_e));
    }

    #[test]
    fn test_e8vec_compression() {
        // 2048D Ada-002 embedding → 256 bytes
        let embedding: Vec<f32> = (0..2048).map(|i| (i as f32 * 0.001).sin()).collect();

        let e8vec = E8Vec::from_f32_vec(&embedding);
        assert_eq!(e8vec.len(), 256); // 2048 / 8 = 256

        let bytes = e8vec.to_bytes();
        assert_eq!(bytes.len(), 256); // 32x compression!

        // Roundtrip
        let restored = E8Vec::from_bytes(&bytes);
        assert_eq!(restored.len(), 256);
    }

    #[test]
    fn test_e8vec_dot() {
        let a = E8Vec::from_indices(&[10, 20, 30]);
        let b = E8Vec::from_indices(&[10, 20, 30]);

        // Self dot should be positive (~3.0 for 3 elements)
        let dot = a.dot(&b);
        assert!(dot > 2.0);
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // TENSOR CORE TESTS
    // ─────────────────────────────────────────────────────────────────────────────────

    #[test]
    fn test_fma() {
        let a = E8F::new(10);
        let b = E8F::new(20);
        let c = E8F::new(30);

        let result = E8TensorCore::fma(a, b, c);
        assert!(result.is_valid());

        // FMA should equal mul then add
        let manual = (a * b) + c;
        assert_eq!(result, manual);
    }

    #[test]
    fn test_axpy() {
        let a = E8F::new(5);
        let x = E8Vec::from_indices(&[10, 20, 30]);
        let mut y = E8Vec::from_indices(&[1, 2, 3]);

        E8TensorCore::axpy(a, &x, &mut y);

        // All results should be valid
        for e in &y.data {
            assert!(e.is_valid());
        }
    }

    #[test]
    fn test_matvec() {
        // 2x3 matrix
        let m = vec![
            E8Vec::from_indices(&[10, 20, 30]),
            E8Vec::from_indices(&[40, 50, 60]),
        ];
        let x = E8Vec::from_indices(&[1, 2, 3]);

        let result = E8TensorCore::matvec(&m, &x);
        assert_eq!(result.len(), 2);
    }

    #[test]
    fn test_outer_product() {
        let u = E8Vec::from_indices(&[10, 20]);
        let v = E8Vec::from_indices(&[30, 40, 50]);

        let outer = E8TensorCore::outer(&u, &v);
        assert_eq!(outer.len(), 2); // 2 rows
        assert_eq!(outer[0].len(), 3); // 3 cols
    }

    #[test]
    fn test_batch_dots() {
        let queries = vec![
            E8Vec::from_indices(&[10, 20]),
            E8Vec::from_indices(&[30, 40]),
        ];
        let keys = vec![
            E8Vec::from_indices(&[10, 20]),
            E8Vec::from_indices(&[50, 60]),
            E8Vec::from_indices(&[70, 80]),
        ];

        let dots = E8TensorCore::batch_dots(&queries, &keys);
        assert_eq!(dots.len(), 2); // 2 queries
        assert_eq!(dots[0].len(), 3); // 3 keys each
    }

    #[test]
    fn test_softmax_approx() {
        let scores = vec![100, 200, 300, 400];
        let weights = E8TensorCore::softmax_approx(&scores);

        assert_eq!(weights.len(), 4);
        // Higher scores should have higher weights
        assert!(weights[3] > weights[0]);
    }

    #[test]
    fn test_top_k() {
        let scores = vec![10, 50, 30, 40, 20];
        let top2 = E8TensorCore::top_k(&scores, 2);

        assert_eq!(top2.len(), 2);
        assert_eq!(top2[0], 1); // Index of 50
        assert_eq!(top2[1], 3); // Index of 40
    }

    #[test]
    fn test_attention() {
        let queries = vec![E8Vec::from_indices(&[10, 20, 30])];
        let keys = vec![
            E8Vec::from_indices(&[10, 20, 30]),
            E8Vec::from_indices(&[40, 50, 60]),
        ];
        let values = vec![
            E8Vec::from_indices(&[1, 2, 3]),
            E8Vec::from_indices(&[4, 5, 6]),
        ];

        let output = E8TensorCore::attention(&queries, &keys, &values);
        assert_eq!(output.len(), 1);
        assert_eq!(output[0].len(), 3);
    }

    #[test]
    fn test_e8mat() {
        let mat = E8Mat::new(3, 4);
        assert_eq!(mat.num_rows(), 3);
        assert_eq!(mat.num_cols(), 4);

        // Serialize and deserialize
        let bytes = mat.to_bytes();
        assert_eq!(bytes.len(), 12);

        let restored = E8Mat::from_bytes(&bytes, 3, 4);
        assert_eq!(restored.num_rows(), 3);
    }

    #[test]
    fn test_e8mat_transpose() {
        let mut mat = E8Mat::new(2, 3);
        mat[0] = E8Vec::from_indices(&[1, 2, 3]);
        mat[1] = E8Vec::from_indices(&[4, 5, 6]);

        let t = mat.transpose();
        assert_eq!(t.num_rows(), 3);
        assert_eq!(t.num_cols(), 2);

        // Check values
        assert_eq!(t[0].data[0].0, 1);
        assert_eq!(t[0].data[1].0, 4);
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // SERIALIZATION TESTS (Task 9)
    // ─────────────────────────────────────────────────────────────────────────────────

    #[test]
    fn test_e8address_serialization() {
        use crate::Gf8LosslessCode;

        // E8Address is [Gf8LosslessCode; 8] which is [u8; 8]
        let address: [Gf8LosslessCode; 8] = [
            Gf8LosslessCode::new(0),
            Gf8LosslessCode::new(42),
            Gf8LosslessCode::new(100),
            Gf8LosslessCode::new(150),
            Gf8LosslessCode::new(200),
            Gf8LosslessCode::new(239),
            Gf8LosslessCode::new(10),
            Gf8LosslessCode::new(50),
        ];

        // Serialize to bytes (should be exactly 8 bytes)
        // **This is LOSSLESS**: u8 -> u8 with no transformation
        let bytes: Vec<u8> = address.iter().map(|c| c.0).collect();
        assert_eq!(
            bytes.len(),
            8,
            "E8Address should serialize to exactly 8 bytes"
        );

        // Verify lossless roundtrip (byte-perfect)
        let restored: [Gf8LosslessCode; 8] = [
            Gf8LosslessCode::new(bytes[0]),
            Gf8LosslessCode::new(bytes[1]),
            Gf8LosslessCode::new(bytes[2]),
            Gf8LosslessCode::new(bytes[3]),
            Gf8LosslessCode::new(bytes[4]),
            Gf8LosslessCode::new(bytes[5]),
            Gf8LosslessCode::new(bytes[6]),
            Gf8LosslessCode::new(bytes[7]),
        ];

        for i in 0..8 {
            assert_eq!(
                address[i].0, restored[i].0,
                "E8Address lossless roundtrip failed at index {}",
                i
            );
        }
    }

    #[test]
    fn test_e8vec_serialization_roundtrip() {
        // Create E8Vec from indices
        let original = E8Vec::from_indices(&[10, 20, 30, 40, 50, 100, 150, 200]);

        // Serialize to bytes
        let bytes = original.to_bytes();
        assert_eq!(
            bytes.len(),
            8,
            "E8Vec with 8 elements should serialize to 8 bytes"
        );

        // Verify each byte matches the original index
        for (i, &byte) in bytes.iter().enumerate() {
            assert_eq!(
                byte,
                [10, 20, 30, 40, 50, 100, 150, 200][i],
                "Byte at index {} doesn't match",
                i
            );
        }

        // Deserialize
        let restored = E8Vec::from_bytes(&bytes);
        assert_eq!(restored.len(), 8, "Restored E8Vec should have 8 elements");

        // Verify roundtrip
        for i in 0..8 {
            assert_eq!(
                original.data[i].0, restored.data[i].0,
                "E8Vec roundtrip failed at index {}",
                i
            );
        }
    }

    #[test]
    fn test_e8vec_compression_ratio() {
        // 2048D Ada-002 embedding → 256 bytes (32x compression)
        let embedding: Vec<f32> = (0..2048).map(|i| (i as f32 * 0.001).sin()).collect();

        let e8vec = E8Vec::from_f32_vec(&embedding);
        let bytes = e8vec.to_bytes();

        // Verify compression ratio
        let original_size = 2048 * std::mem::size_of::<f32>(); // 6144 bytes
        let compressed_size = bytes.len(); // 256 bytes
        let ratio = original_size as f32 / compressed_size as f32;

        assert_eq!(compressed_size, 256, "2048D should compress to 256 bytes");
        assert!(
            (31.0..=33.0).contains(&ratio),
            "Compression ratio should be ~32x, got {}",
            ratio
        );
    }

    #[test]
    fn test_e8mat_serialization_roundtrip() {
        // Create 3x4 matrix
        let mut original = E8Mat::new(3, 4);
        original[0] = E8Vec::from_indices(&[1, 2, 3, 4]);
        original[1] = E8Vec::from_indices(&[5, 6, 7, 8]);
        original[2] = E8Vec::from_indices(&[9, 10, 11, 12]);

        // Serialize to bytes
        let bytes = original.to_bytes();
        assert_eq!(bytes.len(), 12, "3x4 E8Mat should serialize to 12 bytes");

        // Verify bytes are row-major
        let expected = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12];
        for (i, &byte) in bytes.iter().enumerate() {
            assert_eq!(byte, expected[i], "Byte at index {} doesn't match", i);
        }

        // Deserialize
        let restored = E8Mat::from_bytes(&bytes, 3, 4);
        assert_eq!(restored.num_rows(), 3);
        assert_eq!(restored.num_cols(), 4);

        // Verify roundtrip
        for i in 0..3 {
            for j in 0..4 {
                assert_eq!(
                    original[i].data[j].0, restored[i].data[j].0,
                    "E8Mat roundtrip failed at [{}, {}]",
                    i, j
                );
            }
        }
    }

    /// Verify that E8F operations are deterministic and repeatable (lossless property)
    #[test]
    fn test_e8f_operations_deterministic() {
        // Same inputs should always produce same outputs (lookup table is constant)
        let a = E8F::new(42);
        let b = E8F::new(100);

        // Perform operation 1000 times - should always get same result
        let mut results = Vec::new();
        for _ in 0..1000 {
            results.push((a + b).index());
        }

        // All results should be identical (deterministic)
        let first = results[0];
        for (i, &result) in results.iter().enumerate() {
            assert_eq!(
                result, first,
                "E8F addition not deterministic at iteration {}",
                i
            );
        }
    }

    /// Verify that E8F → Gf8 → E8F is truly lossless for valid roots
    #[test]
    fn test_e8f_gf8_roundtrip_lossless() {
        for idx in 0..240u8 {
            let original = E8F::new(idx);
            let gf8 = original.to_gf8();
            let recovered = E8F::from_f32(gf8.coords());

            assert_eq!(
                original.index(),
                recovered.index(),
                "E8F → Gf8 → E8F roundtrip not lossless for root {}",
                idx
            );
        }
    }

    /// Verify that E8F serialization is byte-perfect (truly lossless)
    #[test]
    fn test_e8f_serialization_byte_perfect() {
        for idx in 0..240u8 {
            let original = E8F::new(idx);
            let byte = original.index();
            let recovered = E8F::new(byte);

            assert_eq!(
                original.index(),
                recovered.index(),
                "E8F serialization not byte-perfect for index {}",
                idx
            );
        }
    }

    #[test]
    fn test_e8f_display_valid_roots() {
        // Test valid E8F roots (0-239)
        let e8f = E8F::new(42);
        assert_eq!(format!("{}", e8f), "E8F(42)");

        let e8f = E8F::new(0);
        assert_eq!(format!("{}", e8f), "E8F(0)");

        let e8f = E8F::new(239);
        assert_eq!(format!("{}", e8f), "E8F(239)");
    }

    #[test]
    fn test_e8f_display_zero() {
        // Test the special zero case (index 240)
        let e8f = E8F::ZERO;
        assert_eq!(format!("{}", e8f), "E8F(zero)");

        let e8f = E8F::new(240);
        assert_eq!(format!("{}", e8f), "E8F(zero)");
    }

    #[test]
    fn test_e8f_display_invalid() {
        // Test invalid indices (241-255) using from_raw to preserve the byte value
        let e8f = E8F::from_raw(241);
        assert_eq!(format!("{}", e8f), "E8F(invalid:241)");

        let e8f = E8F::from_raw(255);
        assert_eq!(format!("{}", e8f), "E8F(invalid:255)");
    }

    #[test]
    fn test_e8f_display_with_formatting() {
        // Test that E8F can be used with formatting (this would fail before Display impl)
        // This simulates the use case that would be used with tracing macros

        let e8f = E8F::new(42);

        // These should compile without errors - simulating tracing macro usage
        let debug_str = format!("E8F value: {}", e8f);
        assert_eq!(debug_str, "E8F value: E8F(42)");

        let info_str = format!("E8F value: {}", e8f);
        assert_eq!(info_str, "E8F value: E8F(42)");

        let warn_str = format!("E8F value: {}", e8f);
        assert_eq!(warn_str, "E8F value: E8F(42)");

        let error_str = format!("E8F value: {}", e8f);
        assert_eq!(error_str, "E8F value: E8F(42)");

        // Test with multiple E8F values
        let e8f2 = E8F::new(100);
        let pair_str = format!("E8F pair: {} and {}", e8f, e8f2);
        assert_eq!(pair_str, "E8F pair: E8F(42) and E8F(100)");

        // Test with zero and invalid
        let zero = E8F::ZERO;
        let invalid = E8F::from_raw(250);
        let special_str = format!("Special cases: {} and {}", zero, invalid);
        assert_eq!(special_str, "Special cases: E8F(zero) and E8F(invalid:250)");
    }

    #[test]
    fn test_e8f_display_roundtrip() {
        // Test that Display output is consistent and can be used for debugging
        let test_cases = vec![
            (0, "E8F(0)"),
            (42, "E8F(42)"),
            (239, "E8F(239)"),
            (240, "E8F(zero)"),
            (241, "E8F(invalid:241)"),
            (255, "E8F(invalid:255)"),
        ];

        for (index, expected) in test_cases {
            let e8f = if index < 240 {
                E8F::new(index)
            } else {
                E8F::from_raw(index)
            };
            let display_str = format!("{}", e8f);
            assert_eq!(
                display_str, expected,
                "Display format mismatch for index {}",
                index
            );
        }
    }

    #[test]
    fn test_e8mat_serialization_large() {
        // Create 240x240 matrix (valorem size)
        let mut mat = E8Mat::new(240, 240);

        // Fill with some pattern
        for i in 0..240 {
            for j in 0..240 {
                mat[i].data[j] = E8F::new(((i + j) % 240) as u8);
            }
        }

        // Serialize
        let bytes = mat.to_bytes();
        assert_eq!(
            bytes.len(),
            240 * 240,
            "240x240 E8Mat should serialize to 57600 bytes"
        );

        // Deserialize
        let restored = E8Mat::from_bytes(&bytes, 240, 240);

        // Spot check some values
        for i in [0, 50, 100, 200, 239] {
            for j in [0, 50, 100, 200, 239] {
                assert_eq!(
                    mat[i].data[j].0, restored[i].data[j].0,
                    "Large E8Mat roundtrip failed at [{}, {}]",
                    i, j
                );
            }
        }
    }
}

File: compute.rs
================
/* crates/gf8/src/compute.rs */
//! # E8F Hybrid Computation Strategy
//!
//! This module defines the `E8FCompute` trait and utilities for hybrid E8F/f32 computation.
//!
//! ## Design Philosophy
//!
//! The E8 lattice provides 32x compression (1 byte per 8D block), but operations between
//! E8F values can accumulate quantization error. The hybrid strategy addresses this:
//!
//! - **E8F for**: Storage, transmission, identity comparison, neighbor lookup
//! - **f32/u32 for**: Accumulation, weighted sums, score computation, intermediate results
//!
//! ## Canonical Pattern
//!
//! ```text
//! E8F → f32/u32 (compute) → E8F (store)
//! ```
//!
//! This pattern ensures:
//! 1. Minimal storage footprint (E8F)
//! 2. Full precision during computation (f32/u32)
//! 3. Quantization only at final result
//!
//! ## Error Bounds
//!
//! | Operation | Expected Error |
//! |-----------|----------------|
//! | E8F → f32 → E8F roundtrip | ≤ 0.15 chordal distance |
//! | Accumulated sum (N terms) | O(√N) quantization noise |
//! | Single quantization | ≤ 0.087 chordal distance (worst case) |
//!
//! ## Requirements Coverage
//!
//! - R16.1: E8F for storage, transmission, identity comparison, neighbor lookup
//! - R16.2: f32 for accumulation, weighted sums, score computation
//! - R16.6: Document expected error bounds
//! - R16.7: E8FCompute trait for types supporting hybrid computation
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;
use crate::e8f::{E8F, E8Vec};
use crate::quantize::quantize_to_nearest_code;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E8FCOMPUTE TRAIT
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Trait for types that support hybrid E8F/f32 computation.
///
/// This trait defines the conversion interface between discrete E8F space
/// and continuous f32 space, enabling the hybrid computation pattern:
///
/// ```text
/// E8F → f32 (compute) → E8F (store)
/// ```
///
/// # Error Bounds & Lossless Operations
///
/// **Truly Lossless Operations** (zero error):
/// - E8F → Gf8: Exact lookup from codebook (no quantization)
/// - E8F → E8F arithmetic: Deterministic lookup table (same inputs → same output)
/// - E8F ↔ u8 serialization: Direct byte mapping (bijective)
/// - E8F identity comparison: Exact u8 equality check
///
/// **Bounded Error Operations** (quantization required):
/// - E8F → f32 → E8F roundtrip: ≤0.087 chordal distance (worst case)
/// - Arbitrary f32[8] → E8F: ≤0.087 chordal distance (nearest root)
/// - Chained E8F ops: O(√N) drift accumulation over N operations
///
/// **Key Insight**: Operations stay lossless *within* the E8 lattice.
/// Error only occurs when entering/exiting the discrete E8 space.
pub trait E8FCompute {
    /// Convert to f32 representation for computation.
    ///
    /// This is a lossless operation - the E8F root coordinates are
    /// exactly representable in f32.
    ///
    /// # Returns
    ///
    /// The 8D coordinates of this E8F root as f32 values.
    fn to_f32_coords(&self) -> [f32; 8];

    /// Convert from f32 coordinates back to E8F.
    ///
    /// This operation quantizes to the nearest E8 root, introducing
    /// quantization error bounded by ~0.087 chordal distance.
    ///
    /// # Arguments
    ///
    /// * `coords` - 8D coordinates to quantize
    ///
    /// # Returns
    ///
    /// The nearest E8F root and the quantization error (chordal distance).
    fn from_f32_coords(coords: &[f32; 8]) -> (Self, f32)
    where
        Self: Sized;

    /// Convert to a scalar f32 representation.
    ///
    /// For E8F, this returns the first coordinate of the root vector,
    /// useful for simple scalar operations.
    fn to_f32_scalar(&self) -> f32;

    /// Convert from a scalar f32 to E8F.
    ///
    /// Creates an E8F by treating the scalar as the first coordinate
    /// and padding with zeros, then quantizing to nearest root.
    fn from_f32_scalar(value: f32) -> Self
    where
        Self: Sized;

    /// Convert to u32 for integer accumulation.
    ///
    /// Maps the E8F index to a u32 value suitable for accumulation.
    /// This is useful for transition score computation.
    fn to_u32(&self) -> u32;

    /// Convert from u32 back to E8F.
    ///
    /// Maps a u32 value back to an E8F index (clamped to 0-239).
    fn from_u32(value: u32) -> Self
    where
        Self: Sized;
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 2: E8F IMPLEMENTATION
// ═══════════════════════════════════════════════════════════════════════════════════════

impl E8FCompute for E8F {
    fn to_f32_coords(&self) -> [f32; 8] {
        if !self.is_valid() {
            return [0.0; 8];
        }
        let gf8 = self.to_gf8();
        *gf8.coords()
    }

    fn from_f32_coords(coords: &[f32; 8]) -> (Self, f32) {
        let (code, snapped_gf8) = quantize_to_nearest_code(coords);

        // Compute quantization error as chordal distance
        let input_gf8 = Gf8::from_coords(*coords);
        let input_coords = input_gf8.coords();
        let snapped_coords = snapped_gf8.coords();

        let error: f32 = input_coords
            .iter()
            .zip(snapped_coords.iter())
            .map(|(a, b)| (a - b).powi(2))
            .sum::<f32>()
            .sqrt();

        (E8F::from_code(code), error)
    }

    fn to_f32_scalar(&self) -> f32 {
        if !self.is_valid() {
            return 0.0;
        }
        let gf8 = self.to_gf8();
        gf8.coords()[0]
    }

    fn from_f32_scalar(value: f32) -> Self {
        // Create a vector with the scalar as first coordinate
        let mut coords = [0.0f32; 8];
        coords[0] = value;

        // Normalize to unit sphere before quantization
        let norm = coords.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for c in &mut coords {
                *c /= norm;
            }
        } else {
            coords[0] = 1.0; // Default to first axis
        }

        let (code, _) = quantize_to_nearest_code(&coords);
        E8F::from_code(code)
    }

    fn to_u32(&self) -> u32 {
        self.0 as u32
    }

    fn from_u32(value: u32) -> Self {
        E8F::new((value.min(239)) as u8)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 3: HYBRID COMPUTATION UTILITIES
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Compute transition scores using the hybrid E8F/u32 pattern.
///
/// Implements the canonical transition equation:
/// ```text
/// score(x') = Σ_o e(o) · v(o → x')
/// ```
///
/// # Hybrid Pattern
///
/// - Resonance and valorem are stored as u32 (not E8F)
/// - Accumulation uses u64 to prevent overflow
/// - Final scores are u32
///
/// # Arguments
///
/// * `resonance` - Energy levels at each root (u32, not E8F)
/// * `valorem` - Path weights matrix (u32, not E8F)
///
/// # Returns
///
/// Transition scores for all 240 roots.
///
/// # Requirements
///
/// - R16.3: E8F → f32 (compute) → E8F pattern
/// - R16.4: Accumulation in u32/f32
/// - R16.5: Quantize only final result
/// - R16.8: Valorem uses u32 counts
/// - R16.9: E8F only for root identity
pub fn compute_transition_scores_hybrid(
    resonance: &[u32; 240],
    valorem: &[[u32; 240]; 240],
) -> [u32; 240] {
    let mut scores = [0u32; 240];

    // Canonical Transition Equation:
    // score(x') = Σ_o ( Resonance[o] * Valorem[o][x'] )
    //
    // Uses u64 for intermediate accumulation to prevent overflow
    for (x_prime, score_slot) in scores.iter_mut().enumerate() {
        let mut score: u64 = 0;

        for origin in 0..240 {
            let energy = resonance[origin] as u64;
            let weight = valorem[origin][x_prime] as u64;
            score += energy * weight;
        }

        // Scale down to u32 range (shift by 10 bits = divide by 1024)
        *score_slot = (score >> 10).min(u32::MAX as u64) as u32;
    }

    scores
}

/// Compute transition scores with sparse optimization.
///
/// Same as `compute_transition_scores_hybrid` but skips inactive roots
/// (energy == 0) for better performance on sparse resonance fields.
///
/// # Arguments
///
/// * `resonance` - Energy levels at each root
/// * `valorem` - Path weights matrix
/// * `energy_threshold` - Minimum energy to consider a root active
///
/// # Returns
///
/// Transition scores for all 240 roots.
pub fn compute_transition_scores_sparse(
    resonance: &[u32; 240],
    valorem: &[[u32; 240]; 240],
    energy_threshold: u32,
) -> [u32; 240] {
    let mut scores = [0u32; 240];

    // Collect active roots first (sparse optimization)
    let active_roots: Vec<(usize, u64)> = resonance
        .iter()
        .enumerate()
        .filter(|&(_, &e)| e >= energy_threshold)
        .map(|(i, &e)| (i, e as u64))
        .collect();

    // Only process active roots
    for (x_prime, score_slot) in scores.iter_mut().enumerate() {
        let mut score: u64 = 0;

        for &(origin, energy) in &active_roots {
            let weight = valorem[origin][x_prime] as u64;
            score += energy * weight;
        }

        *score_slot = (score >> 10).min(u32::MAX as u64) as u32;
    }

    scores
}

/// Accumulate weighted E8F values in f32 space, then quantize.
///
/// This is the canonical hybrid pattern for weighted sums:
/// 1. Convert E8F weights and values to f32
/// 2. Accumulate in f32 space
/// 3. Quantize final result to E8F
///
/// # Arguments
///
/// * `weights` - E8F weights (converted to f32 for computation)
/// * `values` - E8F values to weight and sum
///
/// # Returns
///
/// The weighted sum quantized back to E8F, plus the quantization error.
pub fn weighted_sum_hybrid(weights: &[E8F], values: &[E8F]) -> (E8F, f32) {
    assert_eq!(weights.len(), values.len());

    if weights.is_empty() {
        return (E8F::new(0), 0.0);
    }

    // Accumulate in f32 space
    let mut sum = [0.0f32; 8];

    for (w, v) in weights.iter().zip(values.iter()) {
        let w_coords = w.to_f32_coords();
        let v_coords = v.to_f32_coords();

        // Weight is treated as a scalar (first coordinate)
        let w_scalar = w_coords[0];

        for i in 0..8 {
            sum[i] += w_scalar * v_coords[i];
        }
    }

    // Normalize before quantization
    let norm = sum.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > 0.0 {
        for c in &mut sum {
            *c /= norm;
        }
    }

    // Quantize final result
    E8F::from_f32_coords(&sum)
}

/// Compute dot product in f32 space for precision.
///
/// While E8F has a built-in dot product via lookup tables, this function
/// computes the exact f32 dot product for cases requiring higher precision.
///
/// # Arguments
///
/// * `a` - First E8F value
/// * `b` - Second E8F value
///
/// # Returns
///
/// The exact f32 dot product of the two E8F root vectors.
pub fn dot_f32(a: E8F, b: E8F) -> f32 {
    let a_coords = a.to_f32_coords();
    let b_coords = b.to_f32_coords();

    a_coords
        .iter()
        .zip(b_coords.iter())
        .map(|(x, y)| x * y)
        .sum()
}

/// Compute chordal distance between two E8F values.
///
/// The chordal distance is the Euclidean distance between points on the
/// unit sphere, useful for measuring quantization error.
///
/// # Arguments
///
/// * `a` - First E8F value
/// * `b` - Second E8F value
///
/// # Returns
///
/// The chordal distance in [0, 2] range.
pub fn chordal_distance(a: E8F, b: E8F) -> f32 {
    let a_coords = a.to_f32_coords();
    let b_coords = b.to_f32_coords();

    let sum_sq: f32 = a_coords
        .iter()
        .zip(b_coords.iter())
        .map(|(x, y)| (x - y).powi(2))
        .sum();

    sum_sq.sqrt()
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 4: E8VEC HYBRID OPERATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Extension trait for E8Vec hybrid operations.
pub trait E8VecCompute {
    /// Convert entire vector to f32 representation.
    fn to_f32_vec_full(&self) -> Vec<f32>;

    /// Create from f32 vector with quantization.
    fn from_f32_vec_full(vec: &[f32]) -> Self;

    /// Compute dot product in f32 space for precision.
    fn dot_f32(&self, other: &Self) -> f32;
}

impl E8VecCompute for E8Vec {
    fn to_f32_vec_full(&self) -> Vec<f32> {
        self.to_f32_vec()
    }

    fn from_f32_vec_full(vec: &[f32]) -> Self {
        E8Vec::from_f32_vec(vec)
    }

    fn dot_f32(&self, other: &Self) -> f32 {
        assert_eq!(self.data.len(), other.data.len());

        self.data
            .iter()
            .zip(other.data.iter())
            .map(|(a, b)| dot_f32(*a, *b))
            .sum()
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 5: ERROR BOUND CONSTANTS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Maximum chordal distance for single E8F quantization.
///
/// This is the worst-case error when quantizing an arbitrary 8D unit vector
/// to the nearest E8 root. The E8 lattice has 240 roots uniformly distributed
/// on S⁷, giving a maximum quantization error of approximately 0.087.
pub const MAX_SINGLE_QUANTIZATION_ERROR: f32 = 0.087;

/// Maximum chordal distance for E8F roundtrip (E8F → f32 → E8F).
///
/// Due to the discrete nature of the E8 lattice, a roundtrip through f32
/// space may land on a different root. The maximum error is bounded by
/// approximately 0.15 chordal distance.
pub const MAX_ROUNDTRIP_ERROR: f32 = 0.15;

/// Recommended maximum chain length before re-alignment.
///
/// After this many E8F operations, accumulated error may exceed acceptable
/// bounds. Use `E8FAligned` or explicit re-quantization for longer chains.
pub const RECOMMENDED_MAX_CHAIN_LENGTH: usize = 10;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 6: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8f_to_f32_coords() {
        let e8f = E8F::new(42);
        let coords = e8f.to_f32_coords();

        // Should be unit vector
        let norm: f32 = coords.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!(
            (norm - 1.0).abs() < 1e-5,
            "E8F coords should be unit vector"
        );
    }

    #[test]
    fn test_e8f_roundtrip() {
        for idx in 0..240u8 {
            let original = E8F::new(idx);
            let coords = original.to_f32_coords();
            let (recovered, error) = E8F::from_f32_coords(&coords);

            // Roundtrip should recover the same root
            assert_eq!(
                original.index(),
                recovered.index(),
                "Roundtrip should preserve E8F index"
            );
            assert!(
                error < 1e-5,
                "Roundtrip error should be negligible for exact coords"
            );
        }
    }

    #[test]
    fn test_e8f_to_u32() {
        let e8f = E8F::new(100);
        assert_eq!(e8f.to_u32(), 100);

        let recovered = E8F::from_u32(100);
        assert_eq!(recovered.index(), 100);
    }

    #[test]
    fn test_e8f_from_u32_clamping() {
        // Values > 239 should be clamped
        let e8f = E8F::from_u32(500);
        assert_eq!(e8f.index(), 239);
    }

    #[test]
    fn test_compute_transition_scores_hybrid() {
        let mut resonance = [0u32; 240];
        resonance[0] = 100;
        resonance[1] = 50;

        let mut valorem = [[0u32; 240]; 240];
        valorem[0][10] = 10;
        valorem[1][10] = 20;

        let scores = compute_transition_scores_hybrid(&resonance, &valorem);

        // score[10] = (100*10 + 50*20) >> 10 = 2000 >> 10 = 1
        // Note: The shift is for scaling, actual value depends on implementation
        assert!(scores[10] > 0, "Score should be non-zero");
    }

    #[test]
    fn test_compute_transition_scores_sparse() {
        let mut resonance = [0u32; 240];
        resonance[0] = 100;
        resonance[1] = 5; // Below threshold

        let mut valorem = [[0u32; 240]; 240];
        valorem[0][10] = 10;
        valorem[1][10] = 20;

        let scores = compute_transition_scores_sparse(&resonance, &valorem, 10);

        // Only root 0 should contribute (root 1 is below threshold)
        // The sparse version should skip root 1
        // Just verify it runs without panic
        let _ = scores[10];
    }

    #[test]
    fn test_dot_f32() {
        let a = E8F::new(0);
        let b = E8F::new(0);

        let dot = dot_f32(a, b);
        assert!(
            (dot - 1.0).abs() < 1e-5,
            "Same root should have dot product 1.0"
        );
    }

    #[test]
    fn test_chordal_distance() {
        let a = E8F::new(0);
        let b = E8F::new(0);

        let dist = chordal_distance(a, b);
        assert!(dist < 1e-5, "Same root should have zero chordal distance");

        // Different roots should have non-zero distance
        let c = E8F::new(100);
        let dist2 = chordal_distance(a, c);
        assert!(dist2 > 0.0, "Different roots should have non-zero distance");
    }

    #[test]
    fn test_weighted_sum_hybrid() {
        let weights = vec![E8F::new(100), E8F::new(100)];
        let values = vec![E8F::new(0), E8F::new(0)];

        let (result, error) = weighted_sum_hybrid(&weights, &values);

        assert!(result.is_valid(), "Result should be valid E8F");
        // Error can be larger for weighted sums due to accumulated quantization
        // Just verify it's finite and reasonable (< 2.0 which is max chordal distance)
        assert!(
            error.is_finite() && error < 2.0,
            "Error should be finite and bounded"
        );
    }

    #[test]
    fn test_e8vec_compute() {
        let vec1 = E8Vec::from_indices(&[0, 1, 2, 3]);
        let vec2 = E8Vec::from_indices(&[0, 1, 2, 3]);

        let dot = vec1.dot_f32(&vec2);
        assert!(dot > 0.0, "Same vectors should have positive dot product");
    }
}

File: e32l.rs
=============
/* crates/gf8/src/e32l.rs */
//! # E32L – True Lossless f32 Representation and Compression Framework
//!
//! This module provides the definitive answer to achieving true lossless f32 representation
//! and compression within the E8 ecosystem. It contains two primary components:
//!
//! 1.  **`E32L` Type:** A **ZERO-ERROR, BIJECTIVE** conversion between a standard `f32` and a
//!     32-dimensional structure composed of four `E8F` roots. It serves as a lossless,
//!     4-byte, E8-native representation for `f32`.
//!
//! 2.  **Compression Framework:** A high-performance, lossless compression algorithm inspired by
//!     bit-plane decomposition. It transforms blocks of `f32` (or `E32L`) values into a
//!     highly compressible state and uses entropy coding to achieve significant bitrate reduction.
//!
//! ## The `E32L` Breakthrough: Deconstruction, Not Quantization
//!
//! An `f32` is fundamentally 32 bits of information. `E32L` preserves these 32 bits perfectly by
//! mapping them to the indices of four `E8F` roots.
//!
//! ```text
//! f32 (32 bits)  →  f32.to_bits()  →  u32  →  [u8; 4]  →  [E8F; 4]
//!       ↑                                                     ↓
//!       └─────────── (Perfect Reconstruction) ───────────────┘
//! ```
//!
//! ## The Compression Framework: Lossless Bitrate Reduction
//!
//! The provided `compression` module implements a 3-stage reversible pipeline:
//!
//! 1.  **Bit-Matrix Transposition:** A block of `f32` values is losslessly transposed into 32
//!     separate "bit-planes." This groups statistically similar bits (signs with signs,
//!     exponents with exponents), dramatically reducing the entropy of each plane. This is a
//!     provably bijective transform.
//! 2.  **Grouped Entropy Coding:** The sign, exponent, and mantissa bit-planes are compressed
//!     as separate streams using a high-performance entropy coder (`zstd`). This allows the
//!     coder to adapt to the unique statistical properties of each component.
//! 3.  **Framing and Validation:** The compressed streams are packaged into a single, robust data frame with
//!     the necessary metadata for perfect reconstruction. A cryptographic hash (`blake3`) of the
//!     original data is included to guarantee integrity upon decompression.
//!
//! This combination provides both a foundational lossless type (`E32L`) and a powerful algorithm
//! to reduce the storage and transmission cost of datasets composed of these types.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::e8f::E8F;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E32L TYPE DEFINITION
// ═══════════════════════════════════════════════════════════════════════════════════════

/// A true lossless 32-dimensional representation of an f32, composed of four E8F roots.
///
/// This type achieves zero-error conversion by deconstructing the 32 bits of an IEEE 754
/// float into four 8-bit `E8F` indices. It does **not** perform mathematical quantization.
///
/// Assumes that `E8F` is `#[repr(transparent)]` over `u8` (i.e., has the size and alignment of
/// a `u8`) **and** that `E8F::new` / `E8F::index` behave as a pure byte container for the full
/// `0..=255` range without clamping, normalization, or re-encoding. Under these conditions,
/// `E32L` is a strict, bit-perfect wrapper over the underlying `f32` representation.
///
/// # Storage
/// - Wire Format: 4 bytes (same as `f32`).
/// - Memory Format: `[E8F; 4]`.
/// - Conversion Overhead: Zero-cost (bitwise reinterpretation that optimizes away).
///
/// # Example
/// ```rust
/// use gf8::e32l::E32L;
///
/// let original = 3.1415926535f32;
/// let e32l = E32L::from_f32(original);
/// let recovered = e32l.to_f32();
///
/// // The recovered value is not just "close", it is identical.
/// assert_eq!(original.to_bits(), recovered.to_bits());
/// ```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
#[repr(C)]
pub struct E32L {
    /// The four E8F roots whose indices represent the 32 bits of an f32 value.
    /// These are used as bit containers, not for their mathematical vector properties.
    pub roots: [E8F; 4],
}

impl E32L {
    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 2: CORE CONVERSIONS (LOSSLESS)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Creates an `E32L` from an `f32` with **zero error**.
    #[inline]
    pub fn from_f32(value: f32) -> Self {
        let bytes = value.to_le_bytes();
        Self {
            roots: [
                E8F::from_raw(bytes[0]),
                E8F::from_raw(bytes[1]),
                E8F::from_raw(bytes[2]),
                E8F::from_raw(bytes[3]),
            ],
        }
    }

    /// Converts the `E32L` back to an `f32` with **zero error**.
    #[inline]
    pub fn to_f32(&self) -> f32 {
        f32::from_le_bytes([
            self.roots[0].index(),
            self.roots[1].index(),
            self.roots[2].index(),
            self.roots[3].index(),
        ])
    }

    /// Creates an `E32L` from its raw `u32` bit representation.
    #[inline]
    pub fn from_bits(bits: u32) -> Self {
        Self::from_f32(f32::from_bits(bits))
    }

    /// Converts the `E32L` to its raw `u32` bit representation.
    #[inline]
    pub fn to_bits(&self) -> u32 {
        self.to_f32().to_bits()
    }

    /// Creates an `E32L` from a 4-byte array.
    #[inline]
    pub fn from_bytes(bytes: [u8; 4]) -> Self {
        Self {
            roots: [
                E8F::from_raw(bytes[0]),
                E8F::from_raw(bytes[1]),
                E8F::from_raw(bytes[2]),
                E8F::from_raw(bytes[3]),
            ],
        }
    }

    /// Converts the `E32L` to a 4-byte array.
    #[inline]
    pub fn to_bytes(&self) -> [u8; 4] {
        [
            self.roots[0].index(),
            self.roots[1].index(),
            self.roots[2].index(),
            self.roots[3].index(),
        ]
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 3: UTILITY METHODS (DELEGATED FROM f32)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Checks if the contained value is `NaN`.
    #[inline]
    pub fn is_nan(&self) -> bool {
        self.to_f32().is_nan()
    }

    /// Checks if the contained value is `+Infinity` or `-Infinity`.
    #[inline]
    pub fn is_infinite(&self) -> bool {
        self.to_f32().is_infinite()
    }

    /// Checks if the contained value is a finite number.
    #[inline]
    pub fn is_finite(&self) -> bool {
        self.to_f32().is_finite()
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 4: TRAIT IMPLEMENTATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl From<f32> for E32L {
    #[inline]
    fn from(value: f32) -> Self {
        Self::from_f32(value)
    }
}

impl From<E32L> for f32 {
    #[inline]
    fn from(value: E32L) -> Self {
        value.to_f32()
    }
}

impl From<u32> for E32L {
    /// Creates an E32L from its raw IEEE 754 bit representation.
    #[inline]
    fn from(bits: u32) -> Self {
        Self::from_bits(bits)
    }
}

impl From<E32L> for u32 {
    /// Converts an E32L to its raw IEEE 754 bit representation.
    #[inline]
    fn from(value: E32L) -> Self {
        value.to_bits()
    }
}

impl Default for E32L {
    /// Defaults to `0.0f32`.
    #[inline]
    fn default() -> Self {
        Self::from_f32(0.0)
    }
}

impl std::fmt::Display for E32L {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.to_f32())
    }
}

#[cfg(feature = "bytemuck")]
unsafe impl bytemuck::Zeroable for E32L {}

#[cfg(feature = "bytemuck")]
unsafe impl bytemuck::Pod for E32L {}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 5: LOSSLESS COMPRESSION FRAMEWORK
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Provides functions for lossless compression of `f32` or `E32L` slices.
///
/// This module implements a 3-stage reversible pipeline with two compression levels:
///
/// **Level 1 (Machine Readable):**
/// - Bit-planes stored uncompressed or lightly compressed
/// - Direct access to sign/exponent/mantissa without full decompression
/// - Good for semantic queries and streaming
/// - Target: 4:1 to 8:1 compression
///
/// **Level 2 (Maximum Compression):**
/// - Full bit-plane transposition and E8 binary transform
/// - Aggressive entropy coding (zstd level 19)
/// - Requires full decompression for any access
/// - Target: 8:1 to 16:1 compression
///
/// This module requires the `compression` feature to be enabled. It depends on `zstd`,
/// `byteorder`, `blake3`, and `bytemuck`.
#[cfg(feature = "compression")]
pub mod compression {
    use byteorder::{LittleEndian, ReadBytesExt, WriteBytesExt};
    use std::io::{Cursor, Read, Write};

    const MAGIC_NUMBER: u32 = 0x45333243; // E32C (E32L Compression)
    const FORMAT_VERSION: u8 = 2; // Version 2 adds Level 1/2 support

    /// Compression level selection
    #[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
    pub enum CompressionLevel {
        /// Level 1: Machine readable, fast decompression, 4:1-8:1 ratio
        #[default]
        Level1 = 1,
        /// Level 2: Maximum compression, full decompression required, 8:1-16:1 ratio
        Level2 = 2,
    }

    impl CompressionLevel {
        fn zstd_level(&self) -> i32 {
            match self {
                CompressionLevel::Level1 => 3,  // Fast compression
                CompressionLevel::Level2 => 19, // Maximum compression
            }
        }
    }

    /// Represents the compressed data frame.
    pub struct E32LFrame {
        pub level: CompressionLevel,
        pub original_len: u64,
        pub data_hash: [u8; 32],
        pub sign_stream: Vec<u8>,
        pub exponent_stream: Vec<u8>,
        pub mantissa_stream: Vec<u8>,
    }

    /// Lossless compression error types.
    #[derive(Debug)]
    pub enum CompressionError {
        Io(std::io::Error),
        Zstd(std::io::Error),
        InvalidFormat(String),
        IntegrityError,
    }

    impl From<std::io::Error> for CompressionError {
        fn from(err: std::io::Error) -> Self {
            CompressionError::Io(err)
        }
    }

    /// E8-inspired binary bit-plane transform applied in-place to groups of 8 planes.
    ///
    /// This operates over GF(2) on bit-columns across 8 planes:
    ///
    /// For each group of 8 planes and each (byte_idx, bit_idx), we:
    /// - Collect an 8-bit column vector `v` of bits (one from each plane).
    /// - Apply an 8×8 invertible binary matrix `M` (forward) or `M⁻¹` (inverse).
    /// - Write the transformed bits back into the planes.
    ///
    /// Because `M` has determinant 1 over GF(2), this transform is a bijection on the
    /// underlying bit patterns and is therefore perfectly lossless.
    struct E8BitTransform;

    impl E8BitTransform {
        /// Forward 8×8 binary matrix (upper-triangular with ones on the diagonal).
        /// Determinant = 1 over GF(2), hence invertible.
        const FWD: [[u8; 8]; 8] = [
            [1, 1, 0, 0, 0, 0, 0, 0],
            [0, 1, 1, 0, 0, 0, 0, 0],
            [0, 0, 1, 1, 0, 0, 0, 0],
            [0, 0, 0, 1, 1, 0, 0, 0],
            [0, 0, 0, 0, 1, 1, 0, 0],
            [0, 0, 0, 0, 0, 1, 1, 0],
            [0, 0, 0, 0, 0, 0, 1, 1],
            [0, 0, 0, 0, 0, 0, 0, 1],
        ];

        /// Inverse of `FWD` over GF(2).
        const INV: [[u8; 8]; 8] = [
            [1, 1, 1, 1, 1, 1, 1, 1],
            [0, 1, 1, 1, 1, 1, 1, 1],
            [0, 0, 1, 1, 1, 1, 1, 1],
            [0, 0, 0, 1, 1, 1, 1, 1],
            [0, 0, 0, 0, 1, 1, 1, 1],
            [0, 0, 0, 0, 0, 1, 1, 1],
            [0, 0, 0, 0, 0, 0, 1, 1],
            [0, 0, 0, 0, 0, 0, 0, 1],
        ];

        /// Apply the forward E8-style bit mixing to the mantissa planes.
        ///
        /// Operates on groups of 8 planes at a time:
        /// - planes[0..8], planes[8..16]; any remainder (e.g. 16..23) is left unchanged.
        #[inline]
        pub fn forward_mantissa(planes: &mut [Vec<u8>]) {
            Self::apply_groups(planes, &Self::FWD);
        }

        /// Apply the inverse E8-style bit mixing to the mantissa planes.
        #[inline]
        pub fn inverse_mantissa(planes: &mut [Vec<u8>]) {
            Self::apply_groups(planes, &Self::INV);
        }

        #[inline]
        fn apply_groups(planes: &mut [Vec<u8>], mat: &[[u8; 8]; 8]) {
            let num_planes = planes.len();
            if num_planes < 8 {
                return;
            }

            let packed_len = match planes.first() {
                Some(first) => first.len(),
                None => return,
            };

            // Ensure all planes are the same length; if not, bail with no-op.
            if planes.iter().any(|p| p.len() != packed_len) {
                return;
            }

            // Process full groups of 8 planes: 0..8, 8..16, ...
            let mut start = 0;
            while start + 8 <= num_planes {
                let group = &mut planes[start..start + 8];
                Self::apply_group(group, packed_len, mat);
                start += 8;
            }
        }

        #[inline]
        fn apply_group(group: &mut [Vec<u8>], packed_len: usize, mat: &[[u8; 8]; 8]) {
            debug_assert_eq!(group.len(), 8);

            // For each byte position and bit position, apply the 8×8 transform over GF(2).
            for byte_idx in 0..packed_len {
                for bit_idx in 0..8 {
                    // Collect current bits into v[row] ∈ {0,1}
                    let mut v = [0u8; 8];
                    for row in 0..8 {
                        let byte = group[row][byte_idx];
                        v[row] = (byte >> bit_idx) & 1;
                    }

                    // out[row] = Σ_j mat[row][j] * v[j] (mod 2)
                    let mut out = [0u8; 8];
                    for row in 0..8 {
                        let mut acc = 0u8;
                        for (col, &val) in v.iter().enumerate() {
                            if mat[row][col] & 1 == 1 {
                                acc ^= val;
                            }
                        }
                        out[row] = acc & 1;
                    }

                    // Write back transformed bits.
                    for row in 0..8 {
                        let byte_ref = &mut group[row][byte_idx];
                        if out[row] == 1 {
                            *byte_ref |= 1 << bit_idx;
                        } else {
                            *byte_ref &= !(1 << bit_idx);
                        }
                    }
                }
            }
        }
    }

    /// A transposed bit-matrix representation of a block of f32s.
    struct BitMatrix {
        /// Number of f32 values in the block.
        len: usize,
        /// 32 bit-planes, each containing `len` bits packed into bytes.
        planes: [Vec<u8>; 32],
    }

    impl BitMatrix {
        /// Creates a BitMatrix by transposing a slice of f32 values. This is a bijective transform.
        fn from_f32_slice(data: &[f32]) -> Self {
            let len = data.len();
            let packed_len = len.div_ceil(8);
            let mut planes = std::array::from_fn(|_| vec![0u8; packed_len]);

            for (i, &value) in data.iter().enumerate() {
                let bits = value.to_bits();
                let byte_idx = i / 8;
                let bit_idx = i % 8;
                for (p, plane) in planes.iter_mut().enumerate() {
                    if (bits >> p) & 1 == 1 {
                        plane[byte_idx] |= 1 << bit_idx;
                    }
                }
            }
            Self { len, planes }
        }

        /// Reconstructs a Vec<f32> by performing the inverse transposition.
        fn to_f32_vec(&self) -> Vec<f32> {
            let mut values = vec![0u32; self.len];
            for (p, plane) in self.planes.iter().enumerate() {
                for (i, value) in values.iter_mut().take(self.len).enumerate() {
                    let byte_idx = i / 8;
                    let bit_idx = i % 8;
                    if (plane[byte_idx] >> bit_idx) & 1 == 1 {
                        *value |= 1 << p;
                    }
                }
            }
            values.into_iter().map(f32::from_bits).collect()
        }
    }

    /// Compresses a slice of f32 values using the bit-plane transposition method.
    ///
    /// # Arguments
    /// * `data` - The f32 slice to compress
    /// * `level` - Compression level (Level1 for speed, Level2 for size)
    ///
    /// # Returns
    /// A `Vec<u8>` containing the full compressed data frame, or an error.
    pub fn compress_with_level(
        data: &[f32],
        level: CompressionLevel,
    ) -> Result<Vec<u8>, CompressionError> {
        if data.is_empty() {
            // Write a valid but empty frame.
            let mut buffer = Vec::new();
            buffer.write_u32::<LittleEndian>(MAGIC_NUMBER)?;
            buffer.write_u8(FORMAT_VERSION)?;
            buffer.write_u8(level as u8)?;
            buffer.write_u64::<LittleEndian>(0)?; // original_len
            return Ok(buffer);
        }

        // --- Validation ---
        let data_hash = blake3::hash(bytemuck::cast_slice(data));

        // --- Stage 1: Bit-Matrix Transposition ---
        let mut matrix = BitMatrix::from_f32_slice(data);

        // Optional Stage 1b: E8-style bit mixing on mantissa planes (fully reversible).
        {
            // Split into mantissa (0..23), exponent (23..31), sign (31).
            let (mantissa, rest) = matrix.planes.split_at_mut(23);
            let (_exponent, _sign) = rest.split_at_mut(8);
            E8BitTransform::forward_mantissa(mantissa);
        }

        // --- Stage 2: Grouped Entropy Coding ---
        let sign_plane = &matrix.planes[31];
        let exponent_planes = &matrix.planes[23..31];
        let mantissa_planes = &matrix.planes[0..23];

        let zstd_level = level.zstd_level();

        let sign_stream = zstd::stream::encode_all(sign_plane.as_slice(), zstd_level)
            .map_err(CompressionError::Zstd)?;

        let exponent_data: Vec<u8> = exponent_planes
            .iter()
            .flat_map(|p| p.iter())
            .copied()
            .collect();
        let exponent_stream = zstd::stream::encode_all(exponent_data.as_slice(), zstd_level)
            .map_err(CompressionError::Zstd)?;

        let mantissa_data: Vec<u8> = mantissa_planes
            .iter()
            .flat_map(|p| p.iter())
            .copied()
            .collect();
        let mantissa_stream = zstd::stream::encode_all(mantissa_data.as_slice(), zstd_level)
            .map_err(CompressionError::Zstd)?;

        // --- Stage 3: Framing ---
        let mut buffer = Vec::new();
        buffer.write_u32::<LittleEndian>(MAGIC_NUMBER)?;
        buffer.write_u8(FORMAT_VERSION)?;
        buffer.write_u8(level as u8)?;
        buffer.write_u64::<LittleEndian>(data.len() as u64)?;
        buffer.write_all(data_hash.as_bytes())?;
        buffer.write_u64::<LittleEndian>(sign_stream.len() as u64)?;
        buffer.write_u64::<LittleEndian>(exponent_stream.len() as u64)?;
        buffer.write_u64::<LittleEndian>(mantissa_stream.len() as u64)?;
        buffer.write_all(&sign_stream)?;
        buffer.write_all(&exponent_stream)?;
        buffer.write_all(&mantissa_stream)?;

        Ok(buffer)
    }

    /// Compresses a slice of f32 values using Level 1 (default).
    ///
    /// # Returns
    /// A `Vec<u8>` containing the full compressed data frame, or an error.
    pub fn compress(data: &[f32]) -> Result<Vec<u8>, CompressionError> {
        compress_with_level(data, CompressionLevel::default())
    }

    /// Decompresses a data frame back into a slice of f32 values.
    ///
    /// This function performs a cryptographic hash check to guarantee data integrity.
    ///
    /// # Returns
    /// A `Vec<f32>` containing the perfectly reconstructed data, or an error if the
    /// format is invalid or the integrity check fails.
    pub fn decompress(data: &[u8]) -> Result<Vec<f32>, CompressionError> {
        let mut cursor = Cursor::new(data);

        // --- Stage 3 (Inverse): Parsing ---
        if cursor.read_u32::<LittleEndian>()? != MAGIC_NUMBER {
            return Err(CompressionError::InvalidFormat(
                "Invalid magic number".into(),
            ));
        }
        if cursor.read_u8()? != FORMAT_VERSION {
            return Err(CompressionError::InvalidFormat(
                "Unsupported version".into(),
            ));
        }

        let _level = cursor.read_u8()?; // Read but don't validate (both levels decompress the same way)

        let original_len = cursor.read_u64::<LittleEndian>()? as usize;
        if original_len == 0 {
            return Ok(Vec::new());
        }

        let mut expected_hash = [0u8; 32];
        cursor.read_exact(&mut expected_hash)?;

        let sign_len = cursor.read_u64::<LittleEndian>()? as usize;
        let exp_len = cursor.read_u64::<LittleEndian>()? as usize;
        let mant_len = cursor.read_u64::<LittleEndian>()? as usize;

        // --- Stage 2 (Inverse): Entropy Decoding ---
        let mut sign_stream = vec![0u8; sign_len];
        cursor.read_exact(&mut sign_stream)?;

        let mut exp_stream = vec![0u8; exp_len];
        cursor.read_exact(&mut exp_stream)?;

        let mut mant_stream = vec![0u8; mant_len];
        cursor.read_exact(&mut mant_stream)?;

        // No trailing bytes allowed: frame must be self-contained.
        if cursor.position() != data.len() as u64 {
            return Err(CompressionError::InvalidFormat(
                "Trailing data after compressed streams".into(),
            ));
        }

        let sign_plane =
            zstd::stream::decode_all(Cursor::new(sign_stream)).map_err(CompressionError::Zstd)?;
        let exp_data =
            zstd::stream::decode_all(Cursor::new(exp_stream)).map_err(CompressionError::Zstd)?;
        let mant_data =
            zstd::stream::decode_all(Cursor::new(mant_stream)).map_err(CompressionError::Zstd)?;

        // --- Stage 1 (Inverse): Reconstruct BitMatrix ---
        let packed_len = original_len.div_ceil(8);

        // Validate that decoded plane lengths match what the header implies.
        if sign_plane.len() != packed_len
            || exp_data.len() != 8 * packed_len
            || mant_data.len() != 23 * packed_len
        {
            return Err(CompressionError::InvalidFormat(
                "Decompressed plane sizes do not match header metadata".into(),
            ));
        }

        let mut matrix = BitMatrix {
            len: original_len,
            planes: std::array::from_fn(|_| Vec::new()),
        };

        for i in 0..23 {
            matrix.planes[i] = mant_data[i * packed_len..(i + 1) * packed_len].to_vec();
        }
        for i in 0..8 {
            matrix.planes[i + 23] = exp_data[i * packed_len..(i + 1) * packed_len].to_vec();
        }
        matrix.planes[31] = sign_plane;

        // Inverse of the E8-style bit mixing applied during compression.
        {
            let (mantissa, _rest) = matrix.planes.split_at_mut(23);
            E8BitTransform::inverse_mantissa(mantissa);
        }

        let reconstructed_data = matrix.to_f32_vec();

        // --- Validation ---
        let actual_hash = blake3::hash(bytemuck::cast_slice(&reconstructed_data));
        if actual_hash.as_bytes() != &expected_hash {
            return Err(CompressionError::IntegrityError);
        }

        Ok(reconstructed_data)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 6: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;
    use std::mem::size_of;

    #[test]
    fn test_true_lossless_roundtrip() {
        let test_values = [
            0.0f32,
            -0.0,
            1.0,
            -1.0,
            std::f32::consts::PI,
            f32::MAX,
            f32::MIN_POSITIVE,           // smallest normal
            f32::MIN_POSITIVE / 2.0,     // subnormal
            f32::from_bits(0x0000_0001), // smallest positive subnormal
            f32::from_bits(0x8000_0001), // smallest negative subnormal
        ];
        for &original in &test_values {
            let e32l = E32L::from_f32(original);
            let recovered = e32l.to_f32();
            assert_eq!(
                original.to_bits(),
                recovered.to_bits(),
                "Roundtrip failed for {}",
                original
            );
        }
    }

    #[test]
    fn test_special_values_are_preserved() {
        // NaN payloads (including non-canonical patterns)
        let nan_bits = [
            f32::NAN.to_bits(),
            0x7fc0_0001,
            0x7fff_ffff,
            0x7fa0_1234,
            0xffc0_0001,
        ];
        for bits in nan_bits {
            let original = f32::from_bits(bits);
            let e32l = E32L::from_f32(original);
            let recovered = e32l.to_f32();
            assert!(
                recovered.is_nan(),
                "Recovered NaN lost NaN-ness for bits=0x{bits:08x}"
            );
            assert_eq!(
                bits,
                recovered.to_bits(),
                "NaN payload changed for bits=0x{bits:08x}"
            );
        }

        // Infinity
        let inf_original = f32::INFINITY;
        let e32l_inf = E32L::from_f32(inf_original);
        assert_eq!(
            inf_original.to_bits(),
            e32l_inf.to_f32().to_bits(),
            "Infinity bits changed"
        );

        // Negative Infinity
        let neg_inf_original = f32::NEG_INFINITY;
        let e32l_neg_inf = E32L::from_f32(neg_inf_original);
        assert_eq!(
            neg_inf_original.to_bits(),
            e32l_neg_inf.to_f32().to_bits(),
            "Negative infinity bits changed"
        );
    }

    #[test]
    fn test_storage_size_is_identical_to_f32() {
        // These checks rely on E8F being `#[repr(transparent)]` over `u8`.
        assert_eq!(
            size_of::<E8F>(),
            size_of::<u8>(),
            "E8F must remain a 1-byte wrapper"
        );
        assert_eq!(
            std::mem::align_of::<E8F>(),
            std::mem::align_of::<u8>(),
            "E8F alignment must match u8"
        );

        assert_eq!(
            size_of::<E32L>(),
            size_of::<f32>(),
            "E32L must have same size as f32"
        );
        assert_eq!(size_of::<E32L>(), 4, "E32L must remain 4 bytes in size");
    }

    #[test]
    fn test_bit_level_deconstruction() {
        let value = 123.456f32;
        let bytes = value.to_le_bytes();
        let e32l = E32L::from_f32(value);

        assert_eq!(e32l.roots[0].index(), bytes[0]);
        assert_eq!(e32l.roots[1].index(), bytes[1]);
        assert_eq!(e32l.roots[2].index(), bytes[2]);
        assert_eq!(e32l.roots[3].index(), bytes[3]);

        let recovered_bytes = e32l.to_bytes();
        assert_eq!(bytes, recovered_bytes);
    }

    #[test]
    fn test_from_and_to_bits() {
        let bits: u32 = 0x42c80000; // Represents 100.0f32
        let e32l: E32L = bits.into(); // Use From<u32> trait
        assert_eq!(e32l.to_f32(), 100.0f32);

        let recovered_bits: u32 = e32l.into(); // Use Into<u32> trait
        assert_eq!(recovered_bits, bits);
    }

    #[test]
    fn test_arbitrary_bits_roundtrip() {
        // A small but representative sample of raw IEEE 754 bit patterns.
        let samples: &[u32] = &[
            0x0000_0000, // +0.0
            0x8000_0000, // -0.0
            0x3f80_0000, // 1.0
            0xbf80_0000, // -1.0
            0x7f80_0000, // +inf
            0xff80_0000, // -inf
            0x7fc0_0001, // quiet NaN with payload
            0x7fa0_1234, // another NaN payload
            0x0000_0001, // smallest positive subnormal
            0x8000_0001, // smallest negative subnormal
            0x00ff_ffff, // large positive subnormal
            0x1234_5678, // arbitrary pattern
            0xffff_ffff, // arbitrary pattern (also NaN)
        ];

        for &bits in samples {
            let e32l: E32L = bits.into();
            let roundtrip_bits: u32 = e32l.into();
            assert_eq!(
                bits, roundtrip_bits,
                "E32L must be a pure bit-level bijection for bits=0x{bits:08x}"
            );
        }
    }

    #[test]
    fn test_distinction_from_f32l() {
        // This test clarifies that while functionally identical to a simple byte wrapper,
        // E32L is composed of E8F types, making it semantically different.
        let value = 1.0f32;
        let e32l = E32L::from_f32(value);

        // Access the underlying E8F components
        let root0: E8F = e32l.roots[0];
        assert_eq!(root0.index(), 0x00);

        let root3: E8F = e32l.roots[3];
        assert_eq!(root3.index(), 0x3f); // Part of the IEEE 754 representation of 1.0
    }

    #[cfg(feature = "bytemuck")]
    mod bytemuck_compat_tests {
        use super::*;
        use bytemuck::{Pod, Zeroable, cast_slice};

        #[test]
        fn test_e32l_is_pod_and_castable() {
            // Basic sanity: trait bounds compile and work at runtime.
            fn assert_pod_zeroable<T: Pod + Zeroable>() {}
            assert_pod_zeroable::<E32L>();

            let values = [
                E32L::from_f32(0.0),
                E32L::from_f32(1.0),
                E32L::from_f32(-1.0),
                E32L::from_f32(123.456),
            ];

            // Cast [E32L] -> [u8]
            let bytes: &[u8] = cast_slice(&values);
            assert_eq!(bytes.len(), values.len() * std::mem::size_of::<E32L>());

            // Roundtrip [u8] -> [E32L]
            let roundtrip: &[E32L] = cast_slice(bytes);
            assert_eq!(roundtrip, &values);
        }
    }

    // --- Compression Framework Tests ---
    #[cfg(feature = "compression")]
    mod compression_tests {
        use super::super::compression::{CompressionError, compress, decompress};

        #[test]
        fn test_compression_roundtrip_lossless() {
            let original_data: Vec<f32> = (0..1024).map(|i| (i as f32 * 0.1).sin()).collect();
            let compressed = compress(&original_data).expect("Compression failed");
            let reconstructed = decompress(&compressed).expect("Decompression failed");

            assert_eq!(original_data.len(), reconstructed.len(), "Length mismatch");
            for (a, b) in original_data.iter().zip(reconstructed.iter()) {
                assert_eq!(a.to_bits(), b.to_bits(), "Data mismatch after roundtrip");
            }
        }

        #[test]
        fn test_compression_achieves_bitrate_reduction() {
            // Data with low entropy (a sine wave) should compress well.
            let original_data: Vec<f32> =
                (0..4096).map(|i| (i as f32 * 0.05).sin() * 100.0).collect();
            let compressed = compress(&original_data).expect("Compression failed");

            let original_size = original_data.len() * std::mem::size_of::<f32>();
            let compressed_size = compressed.len();

            assert!(
                compressed_size < original_size,
                "Compression did not reduce data size for predictable input. Original: {}, Compressed: {}",
                original_size,
                compressed_size
            );
        }

        #[test]
        fn test_compression_handles_edge_cases() {
            let data: Vec<f32> = vec![
                0.0,
                -0.0,
                1.0,
                f32::MAX,
                f32::MIN_POSITIVE,
                f32::INFINITY,
                f32::NEG_INFINITY,
                f32::from_bits(0x7fc00001),
            ];
            let compressed = compress(&data).expect("Compression failed");
            let reconstructed = decompress(&compressed).expect("Decompression failed");

            assert_eq!(data.len(), reconstructed.len());
            for (a, b) in data.iter().zip(reconstructed.iter()) {
                assert_eq!(a.to_bits(), b.to_bits());
            }
        }

        #[test]
        fn test_empty_slice_compression() {
            let data: Vec<f32> = Vec::new();
            let compressed = compress(&data).unwrap();
            let reconstructed = decompress(&compressed).unwrap();
            assert!(
                !compressed.is_empty(),
                "Empty frame should still have header"
            );
            assert!(reconstructed.is_empty());
        }

        #[test]
        fn test_decompress_corrupted_data_fails() {
            let original_data: Vec<f32> = (0..128).map(|i| i as f32).collect();
            let mut compressed = compress(&original_data).unwrap();

            // Corrupt the hash
            compressed[13] = compressed[13].wrapping_add(1);

            let result = decompress(&compressed);
            assert!(
                matches!(result, Err(CompressionError::IntegrityError)),
                "Decompression should fail with IntegrityError on hash mismatch"
            );

            // Corrupt the payload (which may cause Zstd error or hash mismatch)
            let mut compressed_payload = compress(&original_data).unwrap();
            let payload_mid = compressed_payload.len() - 10;
            compressed_payload[payload_mid] = compressed_payload[payload_mid].wrapping_add(1);
            let result_payload = decompress(&compressed_payload);
            assert!(
                result_payload.is_err(),
                "Decompression should fail on payload corruption"
            );
        }
    }

    #[test]
    fn prove_e32l_bijection_via_hash() {
        let mut orig_xor: u64 = 0;
        let mut rec_xor: u64 = 0;

        // Exhaustive test of all f32 bit patterns is infeasible (2^32 values).
        // Instead, we test a large random sample and all special values.
        // Use the platform RNG API by invoking `rand::random::<T>()` which is
        // stable across editions and avoids the reserved method name `gen`.

        // Test all special values
        let special_values = [
            0.0f32,
            -0.0,
            1.0,
            -1.0,
            f32::MAX,
            f32::MIN_POSITIVE,
            f32::INFINITY,
            f32::NEG_INFINITY,
            f32::NAN,
            f32::from_bits(0x7fc0_0001), // quiet NaN
            f32::from_bits(0x7fa0_1234), // another NaN
            f32::from_bits(0x0000_0001), // smallest positive subnormal
            f32::from_bits(0x8000_0001), // smallest negative subnormal
        ];

        for &val in &special_values {
            let e32l = E32L::from_f32(val);
            let rec = e32l.to_f32();
            assert_eq!(
                val.to_bits(),
                rec.to_bits(),
                "Bijection failed for special value: {}",
                val
            );
            orig_xor ^= val.to_bits() as u64;
            rec_xor ^= rec.to_bits() as u64;
        }

        // Test a large random sample
        for _ in 0..1_000_000 {
            // Use the top-level random function which internally uses the thread RNG.
            let bits: u32 = rand::random::<u32>();
            let val = f32::from_bits(bits);
            let e32l = E32L::from_f32(val);
            let rec = e32l.to_f32();
            assert_eq!(
                val.to_bits(),
                rec.to_bits(),
                "Bijection failed for random value"
            );
            orig_xor ^= val.to_bits() as u64;
            rec_xor ^= rec.to_bits() as u64;
        }

        // XOR of all tested bits should be identical
        assert_eq!(orig_xor, rec_xor, "Hash mismatch: bijection not preserved");
    }
}

File: fast_math.rs
==================
/* src/primitive/fast_math.rs */
//! Provides fast, SIMD-friendly approximations for expensive mathematical functions.
//!
//! # E8 Computing Paradigm – Fast Math Module
//!▫~•◦------------------------------------------------------------------------------------‣
//!
//! This module implements the "Function Approximation via Tabulation" pattern for
//! computationally expensive, low-dimensional functions. It replaces slow transcendental
//! function calls (like `acos`) with a high-performance, three-stage pipeline:
//! 1. A compile-time "Baker" generates a cache-resident Look-Up Table (LUT).
//! 2. A runtime "Synthesizer" performs a fast, branchless lookup into the LUT.
//! 3. A SIMD-friendly linear interpolation (`lerp`) approximates the final value.
//!
//! This approach trades a small, controllable amount of precision for a significant
//! increase in performance, targeting the true bottlenecks identified by profiling.
//!
//! ### Key Capabilities
//! - **Compile-Time LUT Generation:** The `AcosLut` is generated entirely at compile-time
//!   via `const fn`, incurring zero runtime initialization cost.
//! - **Cache-Resident Design:** The LUT size is a generic const parameter, allowing it to
//!   be tuned to fit within L1/L2 CPU caches (e.g., 4096 entries * 4 bytes = 16KB).
//! - **Branchless & SIMD-Friendly:** The lookup and interpolation logic is free of
//!   branches and composed of simple arithmetic operations ideal for FMA instructions.
//!
//! ### Architectural Notes
//! This module embodies the "Just Barely Ahead" principle: applying advanced optimization
//! with surgical precision to the actual bottleneck. The `AcosLut` is designed to be a
//! singleton, statically promoted to eliminate overhead. It serves as a drop-in
//! replacement for `f32::acos` in performance-critical code paths like the `Gf8::angle`
//! calculation.
//!
//! ### Example
//! \```rust
//! use crate::primitive::fast_math::FAST_ACOS;
//! use std::f32::consts::FRAC_1_SQRT_2;
//!
//! // The value of cos(pi/4)
//! let cos_val = FRAC_1_SQRT_2; // approx 0.7071
//!
//! // Calculate acos using the fast LUT
//! let angle_fast = FAST_ACOS.lookup(cos_val);
//!
//! // The result is a very close approximation of pi/4 (approx 0.7854)
//! let angle_std = cos_val.acos();
//! assert!((angle_fast - angle_std).abs() < 1e-4); // Error is low for 4096 entries
//! \```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// A precomputed Look-Up Table for approximating the `acos(x)` function.
///
/// `N` is the number of entries in the table. A larger `N` increases precision
/// and memory usage. `4096` is a good default, using 16KB, which fits comfortably
/// in modern L1/L2 caches.
#[derive(Debug, Clone, Copy)]
pub struct AcosLut<const N: usize> {
    table: [f32; N],
}

use std::sync::OnceLock;

impl<const N: usize> AcosLut<N> {
    /// Creates a new `AcosLut` at compile time.
    ///
    /// The table is populated with `N` values of `acos(x)` for `x` spaced
    /// evenly across the valid domain `[-1.0, 1.0]`.
    pub fn new() -> Self {
        let mut table = [0.0; N];
        let mut i = 0;
        while i < N {
            // Map the table index `i` to the domain `[-1.0, 1.0]`
            let t = i as f32 / (N - 1) as f32; // t is in [0.0, 1.0]
            let x = t * 2.0 - 1.0; // x is in [-1.0, 1.0]

            // Use the standard library `acos` here, since `AcosLut::new` is non-const.
            // This produces an accurate precomputed table that matches the
            // standard library within the expected numerical error bounds.
            let result = x.acos();
            table[i] = result;

            i += 1;
        }
        Self { table }
    }

    /// Looks up the approximate value of `acos(x)`.
    ///
    /// # Arguments
    /// * `x` - A float in the range `[-1.0, 1.0]`. Values outside this range will be clamped.
    ///
    /// # Returns
    /// An approximation of `acos(x)`.
    #[inline(always)]
    pub fn lookup(&self, x: f32) -> f32 {
        // Clamp input to the valid domain.
        let x_clamped = x.clamp(-1.0, 1.0);

        // 1. Map `x` from `[-1.0, 1.0]` to a fractional index `[0.0, N-1]`.
        let frac_index = (x_clamped * 0.5 + 0.5) * ((N - 1) as f32);

        // 2. Get the integer index and the fractional part for interpolation.
        let index_floor = frac_index as usize;
        let frac = frac_index - index_floor as f32;

        // Ensure we don't read past the end of the table.
        // This can happen if x is exactly 1.0.
        let index_ceil = (index_floor + 1).min(N - 1);

        // 3. Gather the two nearest values from the LUT.
        // SAFETY: `index_floor` and `index_ceil` are guaranteed to be in bounds.
        let val_floor = unsafe { *self.table.get_unchecked(index_floor) };
        let val_ceil = unsafe { *self.table.get_unchecked(index_ceil) };

        // 4. Linearly interpolate between the two values.
        // This is a single FMA operation on capable hardware.
        val_floor.mul_add(1.0 - frac, val_ceil * frac)
    }
}

impl<const N: usize> Default for AcosLut<N> {
    fn default() -> Self {
        Self::new()
    }
}

/// A statically allocated, globally accessible instance of the `AcosLut`.
///
/// This is the "bottled rain" - a high-performance, ready-to-use utility
/// that solves the specific `acos` bottleneck.
pub static FAST_ACOS: OnceLock<AcosLut<4096>> = OnceLock::new();

#[cfg(test)]
mod tests {
    use super::*;
    use std::f32::consts::{FRAC_PI_2, FRAC_PI_4, PI};

    #[test]
    fn test_acos_lut_edge_cases() {
        // Test at the boundaries of the domain.
        let acos_of_1 = FAST_ACOS.get_or_init(AcosLut::new).lookup(1.0);
        let acos_of_neg_1 = FAST_ACOS.get_or_init(AcosLut::new).lookup(-1.0);
        let acos_of_0 = FAST_ACOS.get_or_init(AcosLut::new).lookup(0.0);

        assert!((acos_of_1 - 0.0).abs() < 1e-3, "acos(1.0) should be ~0.0");
        assert!(
            (acos_of_neg_1 - PI).abs() < 1e-3,
            "acos(-1.0) should be ~PI"
        );
        assert!(
            (acos_of_0 - FRAC_PI_2).abs() < 1e-3,
            "acos(0.0) should be ~PI/2"
        );
    }

    #[test]
    fn test_acos_lut_precision() {
        let inputs = [-0.9, -0.5, -0.1, 0.1, 0.5, 0.9];
        for &x in &inputs {
            let fast_val = FAST_ACOS.get_or_init(AcosLut::new).lookup(x);
            let std_val = x.acos();
            let error = (fast_val - std_val).abs();
            // With a 4096-entry LUT, the error should be very small.
            assert!(
                error < 1e-4,
                "Precision error too high for x={}: fast={}, std={}, err={}",
                x,
                fast_val,
                std_val,
                error
            );
        }
    }

    #[test]
    fn test_acos_lut_known_values() {
        // cos(pi/4) = 1/sqrt(2)
        let x = std::f32::consts::FRAC_1_SQRT_2;
        let fast_val = FAST_ACOS.get_or_init(AcosLut::new).lookup(x);
        assert!(
            (fast_val - FRAC_PI_4).abs() < 1e-4,
            "acos(1/sqrt(2)) should be ~PI/4"
        );

        // cos(pi/3) = 0.5
        let x = 0.5;
        let fast_val = FAST_ACOS.get_or_init(AcosLut::new).lookup(x);
        let std_val = PI / 3.0;
        assert!(
            (fast_val - std_val).abs() < 1e-4,
            "acos(0.5) should be ~PI/3"
        );
    }

    #[test]
    fn test_out_of_domain_clamping() {
        let val_high = FAST_ACOS.get_or_init(AcosLut::new).lookup(1.5);
        let val_low = FAST_ACOS.get_or_init(AcosLut::new).lookup(-1.5);

        // Should be clamped and return the same as the boundary values.
        assert_eq!(val_high, FAST_ACOS.get_or_init(AcosLut::new).lookup(1.0));
        assert_eq!(val_low, FAST_ACOS.get_or_init(AcosLut::new).lookup(-1.0));
    }
}

File: fractal_simt.rs
=====================
// src/fractal_simt.rs
//! Procedural, fractal-style SIMT scheduler for CPU.
//!
//! This module simulates a SIMT-like execution model on the CPU using a
//! deterministic, procedural "fractal" (Morton / Z-order–style) mapping from
//! (step, lane) -> index, so that:
//!
//!   - each "warp" has `warp_size` conceptual lanes,
//!   - work is visited in a cache-friendly, fractal-ish order,
//!   - the mapping is deterministic and reproducible for a fixed config.
//!
//! The design is intentionally CPU-only and scalar; the hot loop is a perfect
//! place to drop in real SIMD intrinsics later (AVX2/AVX-512), but you get a
//! usable, debuggable baseline right away.
//!
//! Typical usage:
//!
//! ```rust
//! use gf8::fractal_simt::{FractalSimtConfig, fractal_simt_for_each};
//!
//! let mut data = vec![0.0f32; 1024];
//! let cfg = FractalSimtConfig::default();
//!
//! fractal_simt_for_each(&mut data, &cfg, |lane, value| {
//!     // lane is 0..warp_size-1
//!     *value += lane as f32;
//! });
//! ```
//!
//! For a concrete numeric example, see `fractal_simt_add_f32_in_place` below.
//!
//! This scheduler encapsulates the UECC (docs/UECC.pdf) Universal Event Corridor guidance by
//! faithfully recording the 56 neighbor transitions per root that ensure smooth procedural change.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Configuration for the fractal SIMT scheduler.
#[derive(Debug, Clone, Copy)]
pub struct FractalSimtConfig {
    /// Conceptual number of lanes in a warp.
    ///
    /// For AVX2 with f32, 8 lanes is a natural choice (256 bits / 32 bits).
    /// For AVX-512, 16 lanes would be a natural choice, etc.
    pub warp_size: usize,

    /// Number of bits to use from `step` and `lane` when building the
    /// fractal mapping. Higher values produce "deeper" fractal structure,
    /// but also cost a few more bit ops.
    pub depth_bits: u32,
}

impl Default for FractalSimtConfig {
    fn default() -> Self {
        Self {
            warp_size: 8,
            depth_bits: 10, // enough for 2^10 * 2^10 = 1M positions before wrapping
        }
    }
}

/// Interleave the lower `bits` bits of `x` and `y` into a Morton/Z-order code.
///
/// Conceptually, this takes:
///
/// ```text
/// x = x_{bits-1} ... x_1 x_0
/// y = y_{bits-1} ... y_1 y_0
///
/// morton = y_{bits-1} x_{bits-1} ... y_1 x_1 y_0 x_0
/// ```
#[inline]
fn interleave_bits_2d(x: u64, y: u64, bits: u32) -> u64 {
    let mut result = 0u64;
    for i in 0..bits {
        let xb = (x >> i) & 1;
        let yb = (y >> i) & 1;
        result |= xb << (2 * i);
        result |= yb << (2 * i + 1);
    }
    result
}

/// Compute a fractal "global index" given a (step, lane) pair.
///
/// - `step` advances each warp iteration.
/// - `lane` is in `[0, warp_size)`.
/// - `depth_bits` determines how many bits from each we interleave.
///
/// The result is then typically modulo the total length of the slice.
#[inline]
fn fractal_index(step: u64, lane: u64, depth_bits: u32) -> u64 {
    // Mask down to `depth_bits` so we don't explode the Morton code.
    let mask = if depth_bits >= 32 {
        u64::MAX
    } else {
        (1u64 << depth_bits) - 1
    };

    let s = step & mask;
    let l = lane & mask;

    interleave_bits_2d(s, l, depth_bits)
}

/// Recorded trace for each (step, lane, index) visit.
#[derive(Clone, Debug)]
pub struct FractalSimtTraceEntry {
    pub step: u64,
    pub lane: usize,
    pub index: usize,
    pub root: Option<u8>,
}

/// Simple checkpoint marker for rewinding traces.
#[derive(Clone, Copy, Debug)]
pub struct FractalSimtCheckpoint(pub usize);

#[derive(Clone, Debug, Default)]
pub struct FractalSimtTrace {
    entries: Vec<FractalSimtTraceEntry>,
}

impl FractalSimtTrace {
    pub fn new() -> Self {
        Self {
            entries: Vec::new(),
        }
    }

    pub fn len(&self) -> usize {
        self.entries.len()
    }

    pub fn is_empty(&self) -> bool {
        self.entries.is_empty()
    }

    pub fn checkpoint(&self) -> FractalSimtCheckpoint {
        FractalSimtCheckpoint(self.entries.len())
    }

    pub fn rollback(&mut self, checkpoint: FractalSimtCheckpoint) {
        if checkpoint.0 <= self.entries.len() {
            self.entries.truncate(checkpoint.0);
        }
    }

    pub fn push(&mut self, entry: FractalSimtTraceEntry) {
        self.entries.push(entry);
    }

    pub fn entries(&self) -> &[FractalSimtTraceEntry] {
        &self.entries
    }

    pub fn entries_mut(&mut self) -> &mut [FractalSimtTraceEntry] {
        &mut self.entries
    }
}

pub fn fractal_simt_trace<T, F>(
    data: &mut [T],
    cfg: &FractalSimtConfig,
    mut f: F,
) -> FractalSimtTrace
where
    F: FnMut(usize, usize, &mut T, &mut FractalSimtTrace),
{
    let mut trace = FractalSimtTrace::new();
    let len = data.len();
    if len == 0 || cfg.warp_size == 0 {
        return trace;
    }

    let steps = len.div_ceil(cfg.warp_size);

    for step in 0..(steps as u64) {
        for lane in 0..cfg.warp_size {
            let idx_raw = fractal_index(step, lane as u64, cfg.depth_bits);
            let idx = (idx_raw % (len as u64)) as usize;

            trace.push(FractalSimtTraceEntry {
                step,
                lane,
                index: idx,
                root: None,
            });

            f(lane, idx, &mut data[idx], &mut trace);
        }
    }

    trace
}

/// Generic fractal SIMT loop over a mutable slice.
///
/// For each conceptual (step, lane) pair, a "fractal index" is computed,
/// wrapped into the slice length, and the user closure is invoked with:
///
/// - `lane` (0..warp_size-1)
/// - `&mut data[index]` (the element at that position)
///
/// This gives you a deterministic, warp-like execution pattern over the slice.
///
/// Note: this is single-threaded and scalar. To extend it:
/// - you can shard `data` across threads and call this per-shard,
/// - or replace the inner element ops with real SIMD intrinsics.
pub fn fractal_simt_for_each<T, F>(data: &mut [T], cfg: &FractalSimtConfig, mut f: F)
where
    F: FnMut(usize, &mut T),
{
    fractal_simt_trace(data, cfg, |lane, _idx, elem, _trace| {
        f(lane, elem);
    });
}

/// A variant of `fractal_simt_for_each` that additionally exposes the resolved
/// index for the current element. This is useful for operations that need to
/// know the index (e.g., reconstructing vector data from program indices).
pub fn fractal_simt_for_each_indexed<T, F>(data: &mut [T], cfg: &FractalSimtConfig, mut f: F)
where
    F: FnMut(usize, usize, &mut T),
{
    fractal_simt_trace(data, cfg, |lane, idx, elem, trace| {
        if let Some(entry) = trace.entries.last_mut() {
            entry.index = idx;
        }
        f(lane, idx, elem);
    });
}

/// A concrete example: in-place `a[i] += b[i]` using a fractal SIMT walk.
///
/// Each conceptual warp lane walks in Morton/Z-order, matching the scheduler’s
/// actual lane ordering (no simulation) so the resulting sequence is ready for
/// SIMD replacement.
///
/// This is a good function to benchmark to get a feel for the scheduler's
/// throughput and cache behavior.
///
/// Requirements:
/// - `a.len() == b.len()`.
pub fn fractal_simt_add_f32_in_place(a: &mut [f32], b: &[f32], cfg: &FractalSimtConfig) {
    assert_eq!(
        a.len(),
        b.len(),
        "fractal_simt_add_f32_in_place: a and b length mismatch"
    );

    let len = a.len();
    if len == 0 || cfg.warp_size == 0 {
        return;
    }

    let steps = len.div_ceil(cfg.warp_size);

    for step in 0..(steps as u64) {
        for lane in 0..cfg.warp_size {
            let idx_raw = fractal_index(step, lane as u64, cfg.depth_bits);
            let idx = (idx_raw % (len as u64)) as usize;

            // This is the scalar hot-path where real SIMD can be dropped in
            // later. For now, we just do scalar add.
            a[idx] += b[idx];
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn fractal_index_is_deterministic() {
        let cfg = FractalSimtConfig::default();
        let i1 = fractal_index(0, 0, cfg.depth_bits);
        let i2 = fractal_index(0, 0, cfg.depth_bits);
        assert_eq!(i1, i2);

        let i3 = fractal_index(1, 0, cfg.depth_bits);
        let i4 = fractal_index(0, 1, cfg.depth_bits);
        assert_ne!(i1, i3);
        assert_ne!(i1, i4);
    }

    #[test]
    fn fractal_simt_for_each_visits_elements() {
        let mut data = vec![0u32; 64];
        let cfg = FractalSimtConfig {
            warp_size: 8,
            depth_bits: 6,
        };

        fractal_simt_for_each(&mut data, &cfg, |_lane, v| {
            *v += 1;
        });

        // We don't guarantee exact counts per element, but we can at least
        // assert nothing stayed at zero (with these parameters, everything
        // should be hit at least once).
        assert!(data.iter().all(|&v| v > 0));
    }

    #[test]
    fn fractal_add_matches_linear_add() {
        let mut a = (0..128).map(|i| i as f32).collect::<Vec<_>>();
        let mut a_linear = a.clone();
        let b = (0..128).map(|i| (i as f32) * 0.5).collect::<Vec<_>>();

        let cfg = FractalSimtConfig::default();

        // Linear baseline
        for i in 0..a_linear.len() {
            a_linear[i] += b[i];
        }

        // Fractal SIMT
        fractal_simt_add_f32_in_place(&mut a, &b, &cfg);

        // Same final values.
        for i in 0..a.len() {
            assert!(
                (a[i] - a_linear[i]).abs() < 1e-5,
                "mismatch at {}: fractal={} linear={}",
                i,
                a[i],
                a_linear[i]
            );
        }
    }
}

File: generative.rs
===================
// src/generative.rs
//! A compact generative synthesizer for reconstructing clusters of `Gf8` vectors
//! using a centroid, a small LUT of delta vectors and a compact program string.
//!
//! This is a minimal demonstration of the "synthesizer" pattern you described.
//! It trades storage for runtime reconstruction using small SIMD-backed kernels.

use crate::bitcodec::lossless::gf8_to_lossless_code_closest;
use crate::fractal_simt::{
    FractalSimtConfig, FractalSimtTrace, fractal_simt_for_each_indexed, fractal_simt_trace,
};
use crate::{Gf8, gf8_add_simd};

/// Compact program instruction mapping
/// 255 (0xFF) means use centroid, otherwise use LUT entry by index
pub type ProgramInstr = u8;

/// Captures semantic neighbor metadata for the 56 key transitions.
#[derive(Clone, Debug)]
pub struct StateTransition {
    pub id: &'static str,
    pub index: u8,
    pub value_a: &'static str,
    pub value_b: &'static str,
    pub description: &'static str,
}

/// The 56 concept pair transitions described in `e8_cognitive_architecture_mapping.md`
/// and mirrored in `docs/UECC.pdf`.
pub const STATE_TRANSITIONS: [StateTransition; 56] = [
    StateTransition {
        id: "A",
        index: 0,
        value_a: "Self-Agency",
        value_b: "Communion",
        description: "From sovereign choice into shared belonging.",
    },
    StateTransition {
        id: "B",
        index: 1,
        value_a: "Structure",
        value_b: "Flux",
        description: "Holding order while letting flow in.",
    },
    StateTransition {
        id: "C",
        index: 2,
        value_a: "Foresight",
        value_b: "Memory",
        description: "Balancing looking ahead with remembering lessons.",
    },
    StateTransition {
        id: "D",
        index: 3,
        value_a: "Clarity",
        value_b: "Awe",
        description: "Precise focus meets reverent openness.",
    },
    StateTransition {
        id: "E",
        index: 4,
        value_a: "Virtue",
        value_b: "Temptation",
        description: "Maintaining higher ideals when the pull is strong.",
    },
    StateTransition {
        id: "F",
        index: 5,
        value_a: "Momentum",
        value_b: "Stillness",
        description: "Propelling forward yet honoring quiet rest.",
    },
    StateTransition {
        id: "G",
        index: 6,
        value_a: "Stewardship",
        value_b: "Openness",
        description: "Holding responsibility while inviting novel ideas.",
    },
    StateTransition {
        id: "H",
        index: 7,
        value_a: "Mastery",
        value_b: "Risk",
        description: "Confidence tempered by daring leaps.",
    },
    StateTransition {
        id: "I",
        index: 8,
        value_a: "Certainty",
        value_b: "Doubt",
        description: "Grounded belief that still honors questions.",
    },
    StateTransition {
        id: "J",
        index: 9,
        value_a: "Presence",
        value_b: "Absence",
        description: "Being fully here while acknowledging empty space.",
    },
    StateTransition {
        id: "K",
        index: 10,
        value_a: "Creation",
        value_b: "Destruction",
        description: "Birth and fade are two sides of transformation.",
    },
    StateTransition {
        id: "L",
        index: 11,
        value_a: "Unity",
        value_b: "Diversity",
        description: "Togetherness that still celebrates difference.",
    },
    StateTransition {
        id: "M",
        index: 12,
        value_a: "Potential",
        value_b: "Actualization",
        description: "From latent possibility into realized form.",
    },
    StateTransition {
        id: "N",
        index: 13,
        value_a: "Consciousness",
        value_b: "Unconsciousness",
        description: "Awareness that leans into dream logic.",
    },
    StateTransition {
        id: "O",
        index: 14,
        value_a: "Permanence",
        value_b: "Transience",
        description: "Anchoring in the eternal while riding the ephemeral.",
    },
    StateTransition {
        id: "P",
        index: 15,
        value_a: "Order",
        value_b: "Chaos",
        description: "Structure that is resilient to entropy.",
    },
    StateTransition {
        id: "Q",
        index: 16,
        value_a: "Beginning",
        value_b: "Ending",
        description: "The eternal cycle of birth and cessation.",
    },
    StateTransition {
        id: "R",
        index: 17,
        value_a: "Internal",
        value_b: "External",
        description: "The boundary between inner experience and outer reality.",
    },
    StateTransition {
        id: "S",
        index: 18,
        value_a: "Material",
        value_b: "Spiritual",
        description: "The balance of matter and meaning.",
    },
    StateTransition {
        id: "T",
        index: 19,
        value_a: "Effort",
        value_b: "Grace",
        description: "Striving through will versus receiving flow.",
    },
    StateTransition {
        id: "U",
        index: 20,
        value_a: "Simplicity",
        value_b: "Complexity",
        description: "Fundamental clarity alongside intricate systems.",
    },
    StateTransition {
        id: "V",
        index: 21,
        value_a: "Objective",
        value_b: "Subjective",
        description: "Universal truth meets personal perception.",
    },
    StateTransition {
        id: "W",
        index: 22,
        value_a: "Harmony",
        value_b: "Conflict",
        description: "Agreement versus struggle in relationships.",
    },
    StateTransition {
        id: "X",
        index: 23,
        value_a: "Freedom",
        value_b: "Constraint",
        description: "Boundless possibility tempered by limits.",
    },
    StateTransition {
        id: "Y",
        index: 24,
        value_a: "Past",
        value_b: "Future",
        description: "Memory and anticipation in dialogue.",
    },
    StateTransition {
        id: "Z",
        index: 25,
        value_a: "Physical",
        value_b: "Mental",
        description: "Body and mind as interwoven aspects.",
    },
    StateTransition {
        id: "AA",
        index: 26,
        value_a: "Logic",
        value_b: "Intuition",
        description: "Reason and instinct in tandem.",
    },
    StateTransition {
        id: "BB",
        index: 27,
        value_a: "Giving",
        value_b: "Receiving",
        description: "The flow of energy and resources.",
    },
    StateTransition {
        id: "CC",
        index: 28,
        value_a: "Public",
        value_b: "Private",
        description: "Shared life versus individual sanctuary.",
    },
    StateTransition {
        id: "DD",
        index: 29,
        value_a: "Wakefulness",
        value_b: "Sleep",
        description: "Conscious action meets restorative rest.",
    },
    StateTransition {
        id: "EE",
        index: 30,
        value_a: "Strength",
        value_b: "Vulnerability",
        description: "Resilience with openness to harm.",
    },
    StateTransition {
        id: "FF",
        index: 31,
        value_a: "Question",
        value_b: "Answer",
        description: "Seeking knowledge and finding resolution.",
    },
    StateTransition {
        id: "GG",
        index: 32,
        value_a: "Action",
        value_b: "Inaction",
        description: "Doing versus allowing.",
    },
    StateTransition {
        id: "HH",
        index: 33,
        value_a: "Hope",
        value_b: "Despair",
        description: "Expectation extremes about the future.",
    },
    StateTransition {
        id: "II",
        index: 34,
        value_a: "Presence",
        value_b: "Absence",
        description: "Being here versus not being here.",
    },
    StateTransition {
        id: "JJ",
        index: 35,
        value_a: "Success",
        value_b: "Failure",
        description: "Goal outcomes and their twin.",
    },
    StateTransition {
        id: "KK",
        index: 36,
        value_a: "Value",
        value_b: "Meaningless",
        description: "Perceived worth versus lack of significance.",
    },
    StateTransition {
        id: "LL",
        index: 37,
        value_a: "Attachment",
        value_b: "Detachment",
        description: "Emotional connection versus objective distance.",
    },
    StateTransition {
        id: "MM",
        index: 38,
        value_a: "Pleasure",
        value_b: "Pain",
        description: "Spectrum of sensation and feeling.",
    },
    StateTransition {
        id: "NN",
        index: 39,
        value_a: "Known",
        value_b: "Unknown",
        description: "Existing knowledge versus mystery.",
    },
    StateTransition {
        id: "OO",
        index: 40,
        value_a: "Giving Up",
        value_b: "Persistence",
        description: "Knowing when to quit and when to persevere.",
    },
    StateTransition {
        id: "PP",
        index: 41,
        value_a: "Growth",
        value_b: "Stagnation",
        description: "Positive change versus stillness.",
    },
    StateTransition {
        id: "QQ",
        index: 42,
        value_a: "Truth",
        value_b: "Illusion",
        description: "Reality versus deception.",
    },
    StateTransition {
        id: "RR",
        index: 43,
        value_a: "Sound",
        value_b: "Silence",
        description: "Contrast in auditory experience.",
    },
    StateTransition {
        id: "SS",
        index: 44,
        value_a: "Life",
        value_b: "Death",
        description: "Boundaries of biological existence.",
    },
    StateTransition {
        id: "TT",
        index: 45,
        value_a: "Joy",
        value_b: "Sorrow",
        description: "Emotional well-being extremes.",
    },
    StateTransition {
        id: "UU",
        index: 46,
        value_a: "Belief",
        value_b: "Evidence",
        description: "Faith versus empirical proof.",
    },
    StateTransition {
        id: "VV",
        index: 47,
        value_a: "Memory",
        value_b: "Forgetting",
        description: "Retaining the past or letting go.",
    },
    StateTransition {
        id: "WW",
        index: 48,
        value_a: "Reality",
        value_b: "Imagination",
        description: "Actual experience versus conceived worlds.",
    },
    StateTransition {
        id: "XX",
        index: 49,
        value_a: "Public",
        value_b: "Private",
        description: "Shared visibility versus personal space.",
    },
    StateTransition {
        id: "YY",
        index: 50,
        value_a: "Work",
        value_b: "Play",
        description: "Purposeful labor versus joyful activity.",
    },
    StateTransition {
        id: "ZZ",
        index: 51,
        value_a: "Friend",
        value_b: "Enemy",
        description: "Alliance versus opposition.",
    },
    StateTransition {
        id: "AAA",
        index: 52,
        value_a: "Desire",
        value_b: "Aversion",
        description: "Attraction and repulsion.",
    },
    StateTransition {
        id: "BBB",
        index: 53,
        value_a: "Change",
        value_b: "Tradition",
        description: "Innovation versus established practice.",
    },
    StateTransition {
        id: "CCC",
        index: 54,
        value_a: "Youth",
        value_b: "Age",
        description: "Progression through life stages.",
    },
    StateTransition {
        id: "DDD",
        index: 55,
        value_a: "Curiosity",
        value_b: "Complacency",
        description: "Exploring the unknown versus resting in the familiar.",
    },
];

pub fn transition_for(root_index: u8) -> &'static StateTransition {
    &STATE_TRANSITIONS[(root_index as usize) % STATE_TRANSITIONS.len()]
}

/// A tiny generative synthesizer.
///
/// - `centroid`: base Gf8
/// - `deltas`: small LUT of delta vectors (should be small, e.g., 16)
/// - `program`: for each output index, an instruction referencing centroid or a delta
#[derive(Clone)]
pub struct GenerativeSynthesizer {
    pub centroid: Gf8,
    pub deltas: Vec<Gf8>,
    pub program: Vec<ProgramInstr>,
}

impl GenerativeSynthesizer {
    pub fn new(centroid: Gf8, deltas: Vec<Gf8>, program: Vec<ProgramInstr>) -> Self {
        Self {
            centroid,
            deltas,
            program,
        }
    }

    /// Try to construct a new `GenerativeSynthesizer`, validating the program
    /// references all indices into the `deltas` LUT. Returns an `Err` message
    /// on invalid input rather than panicking, allowing callers to handle errors
    /// gracefully.
    pub fn try_new(
        centroid: Gf8,
        deltas: Vec<Gf8>,
        program: Vec<ProgramInstr>,
    ) -> Result<Self, String> {
        // Validate: instruction must be 0xFF (centroid) or a valid index into deltas
        for &instr in program.iter() {
            if instr != 0xFF && (instr as usize) >= deltas.len() {
                return Err(format!(
                    "GenerativeSynthesizer::try_new: program contains out-of-range LUT index {} (deltas.len={})",
                    instr,
                    deltas.len()
                ));
            }
        }
        Ok(Self {
            centroid,
            deltas,
            program,
        })
    }

    /// Reconstruct a single vector by program index.
    pub fn reconstruct(&self, idx: usize) -> Gf8 {
        let instr = self.program[idx];
        if instr == 0xFF {
            self.centroid
        } else {
            // Safe because the program should be generated to only contain valid LUT indexes
            let delta = &self.deltas[instr as usize];
            gf8_add_simd(&self.centroid, delta)
        }
    }

    /// Fill dst with reconstructed vectors for the provided `program` indices.
    /// Uses `fractal_simt_for_each` to demonstrate a scheduler visiting ordering
    /// and reconstructing the values in a cache-friendly order.
    pub fn fill_reconstructed(&self, dst: &mut [Gf8], cfg: &FractalSimtConfig) {
        assert_eq!(
            dst.len(),
            self.program.len(),
            "dst and program length must match"
        );

        // We can't guarantee that a particular `FractalSimtConfig` will visit every
        // element exactly once (and some small sizes / configs can miss indices), so we
        // track visited indices and then fill any unvisited entries in a final linear
        // pass. This preserves the cache-friendly traversal while ensuring correctness.
        let mut visited = vec![false; dst.len()];
        fractal_simt_for_each_indexed(dst, cfg, |_lane, idx, elem| {
            let v = self.reconstruct(idx);
            *elem = v;
            visited[idx] = true;
        });

        // Ensure every index has been reconstructed; fill any missed entries linearly.
        for i in 0..dst.len() {
            if !visited[i] {
                dst[i] = self.reconstruct(i);
            }
        }
    }

    /// Reconstruct directly into a provided `Gf8` mut reference for the given index.
    pub fn reconstruct_into(&self, idx: usize, out: &mut Gf8) {
        *out = self.reconstruct(idx);
    }

    /// Reconstruct into `dst`, returning a trace of the sequence.
    pub fn fill_reconstructed_with_trace(
        &self,
        dst: &mut [Gf8],
        cfg: &FractalSimtConfig,
    ) -> FractalSimtTrace {
        assert_eq!(
            dst.len(),
            self.program.len(),
            "dst and program length must match"
        );
        let mut visited = vec![false; dst.len()];

        let trace = fractal_simt_trace(dst, cfg, |_, idx, elem, trace| {
            let value = self.reconstruct(idx);
            let code = gf8_to_lossless_code_closest(&value);
            if let Some(entry) = trace.entries_mut().last_mut() {
                entry.root = Some(code.0);
                entry.index = idx;
            }
            *elem = value;
            visited[idx] = true;
        });

        for i in 0..dst.len() {
            if !visited[i] {
                dst[i] = self.reconstruct(i);
            }
        }

        trace
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Gf8;

    #[test]
    fn reconstruct_single_matches_expected() {
        let centroid = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let delta = Gf8::new([0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let deltas = vec![delta];
        let program = vec![0xFFu8, 0u8];
        let synth = GenerativeSynthesizer::new(centroid, deltas, program);

        let r0 = synth.reconstruct(0);
        assert_eq!(r0, centroid);

        let r1 = synth.reconstruct(1);
        let expected = gf8_add_simd(&centroid, &delta);
        assert_eq!(r1, expected);
    }

    #[test]
    fn fill_reconstructed_matches_linear_reconstruct() {
        let centroid = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let delta = Gf8::new([0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let deltas = vec![delta];
        let program = vec![0xFFu8, 0u8, 0u8, 0xFFu8];
        let synth = GenerativeSynthesizer::new(centroid, deltas.clone(), program.clone());

        // Linear baseline reconstruction
        let mut baseline = Vec::with_capacity(program.len());
        for i in 0..program.len() {
            baseline.push(synth.reconstruct(i));
        }

        // Use fractal SIMD scheduler to fill into dst
        let cfg = FractalSimtConfig::default();
        let mut dst = vec![Gf8::default(); program.len()];
        synth.fill_reconstructed(&mut dst, &cfg);

        // Compare results
        assert_eq!(dst.len(), baseline.len());
        for i in 0..dst.len() {
            assert_eq!(dst[i], baseline[i], "mismatch at {}", i);
        }
    }

    #[test]
    fn try_new_rejects_invalid_program_index() {
        let centroid = Gf8::default();
        let deltas = Vec::new();
        // Program references LUT index 0 but deltas is empty - should error
        let program = vec![0u8];
        let res = GenerativeSynthesizer::try_new(centroid, deltas, program);
        assert!(
            res.is_err(),
            "Expected try_new to return Err for invalid program indices"
        );
    }

    // Note: `fractal_simt_for_each_indexed` is exercised by the fractal scheduler
    // unit tests located in `fractal_simt.rs`. We avoid repeating these here because
    // parameter-specific behavior is already covered (and some small configs don't
    // guarantee uniform index coverage, which is outside the scope of generative's
    // correctness requirements).

    // Note: We intentionally avoid strict coverage guarantees for the fractal walker
    // since some parameter combinations won't visit every index. The helper is still
    // useful for cache-friendly ordering, and `fill_reconstructed` compensates by
    // filling any missed indices in a final linear pass.
}

File: intrinsic_backend.rs
==========================
/* e8/gf8/src/intrinsic_backend.rs */
//! Intrinsic-driven backend for GF8 operations with runtime dispatch and optimization.
//!
//! # e8 Primitives – Gf8 Intrinsic Backend
//!▫~•◦-----------------------------------------------‣
//!
//! This module provides a sophisticated backend that uses the intrinsic registry
//! to dynamically select optimal CPU instructions based on:
//! - Available hardware features (AVX, AVX2, FMA, etc.)
//! - Precision requirements (f32 vs f64)
//! - Operation characteristics (vector width, latency, throughput)
//!
//! ### Key Capabilities
//! - **Runtime Intrinsic Selection:** Choose optimal intrinsics from the registry
//! - **Performance-Aware Dispatch:** Prioritize low-latency, high-throughput instructions
//! - **Fallback Chains:** Graceful degradation from advanced to basic instructions
//! - **Architecture Portability:** x86_64, ARM64, and generic scalar fallbacks
//!
//! ### Architectural Notes
//! This is the "brain" of the GF8 SIMD system. It queries the intrinsic registry
//! to make intelligent decisions about which CPU instructions to use, rather than
//! hard-coding specific intrinsics. This makes the system more maintainable and
//! future-proof as new instruction sets emerge.
//!
//! The backend implements a priority system:
//! 1. **Optimal:** Latest instruction set with best performance characteristics
//! 2. **Compatible:** Older but widely supported instructions
//! 3. **Scalar:** Generic fallback for any platform
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, intrinsic_add, intrinsic_dot};
//!
//! let a = Gf8::from_scalar(1.0);
//! let b = Gf8::from_scalar(-0.5);
//!
//! // Automatically selects best available intrinsic
//! let sum = intrinsic_add(&a, &b);
//! let dot = intrinsic_dot(&a, &b);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::{Gf8, Gf8Intrinsic, intrinsics_for_f32_width};
use std::collections::HashMap;

/// Performance characteristics for instruction selection
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct IntrinsicMetrics {
    /// Relative latency (lower is better)
    pub latency: f32,
    /// Relative throughput (higher is better)
    pub throughput: f32,
    /// Whether the instruction supports FMA (fused multiply-add)
    pub supports_fma: bool,
    /// Whether the instruction is vectorizable
    pub is_vectorizable: bool,
}

/// Pre-computed performance metrics for common intrinsics
const INTRINSIC_PERFORMANCE: &[(&str, IntrinsicMetrics)] = &[
    // AVX2+FMA optimized instructions (best performance)
    (
        "_mm256_fmadd_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 2.0,
            supports_fma: true,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_fmsub_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 2.0,
            supports_fma: true,
            is_vectorizable: true,
        },
    ),
    // AVX2 instructions (very good performance)
    (
        "_mm256_add_ps",
        IntrinsicMetrics {
            latency: 3.0,
            throughput: 2.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_sub_ps",
        IntrinsicMetrics {
            latency: 3.0,
            throughput: 2.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_mul_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 2.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    // AVX instructions (good performance)
    (
        "_mm256_dp_ps",
        IntrinsicMetrics {
            latency: 10.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_hadd_ps",
        IntrinsicMetrics {
            latency: 5.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    // SSE instructions (acceptable performance)
    (
        "_mm_add_ps",
        IntrinsicMetrics {
            latency: 3.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm_mul_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
];

/// Backend configuration for instruction selection
#[derive(Debug, Clone)]
pub struct BackendConfig {
    /// Preferred instruction sets (in priority order)
    pub preferred_isas: Vec<String>,
    /// Whether to prefer FMA instructions when available
    pub prefer_fma: bool,
    /// Performance threshold for acceptable instructions
    pub min_throughput: f32,
    /// Maximum acceptable latency
    pub max_latency: f32,
}

impl Default for BackendConfig {
    fn default() -> Self {
        Self {
            preferred_isas: vec![
                "AVX2".to_string(),
                "AVX".to_string(),
                "SSE4.1".to_string(),
                "SSE2".to_string(),
            ],
            prefer_fma: true,
            min_throughput: 1.0,
            max_latency: 10.0,
        }
    }
}

/// Intrinsic backend with runtime dispatch
pub struct IntrinsicBackend {
    config: BackendConfig,
    /// Cache of selected intrinsics for each operation
    operation_cache: HashMap<String, Option<&'static Gf8Intrinsic>>,
}

impl IntrinsicBackend {
    pub fn new(config: BackendConfig) -> Self {
        Self {
            config,
            operation_cache: HashMap::new(),
        }
    }

    /// Select the best intrinsic for a given operation
    pub fn select_intrinsic(
        &mut self,
        operation: &str,
        width_bits: u32,
    ) -> Option<&'static Gf8Intrinsic> {
        // Check cache first
        let cache_key = format!("{}:{}", operation, width_bits);
        if let Some(cached) = self.operation_cache.get(&cache_key) {
            return *cached;
        }

        let candidates = intrinsics_for_f32_width(width_bits)
            .filter(|intrinsic| {
                // Check if this instruction supports the requested operation
                let matches_op = match operation {
                    "add" => intrinsic.name.contains("_add_"),
                    "sub" => intrinsic.name.contains("_sub_"),
                    "mul" => intrinsic.name.contains("_mul_"),
                    "dot" => intrinsic.name.contains("_dp_") || intrinsic.name.contains("_hadd"),
                    "fma" => {
                        intrinsic.name.contains("_fmadd_") || intrinsic.name.contains("_fmsub_")
                    }
                    _ => true,
                };

                if !matches_op {
                    return false;
                }

                // Check if instruction set is preferred
                let is_preferred = self
                    .config
                    .preferred_isas
                    .iter()
                    .any(|isa| intrinsic.technology == *isa);

                // Check performance thresholds
                if let Some(metrics) = self.get_metrics(intrinsic.name) {
                    metrics.throughput >= self.config.min_throughput
                        && metrics.latency <= self.config.max_latency
                } else {
                    // Unknown instruction, accept if from preferred ISA
                    is_preferred
                }
            })
            .collect::<Vec<_>>();

        let selected = self.rank_intrinsics(candidates);

        self.operation_cache.insert(cache_key, selected);
        selected
    }

    /// Rank intrinsics by performance and preference
    fn rank_intrinsics(
        &self,
        mut candidates: Vec<&'static Gf8Intrinsic>,
    ) -> Option<&'static Gf8Intrinsic> {
        if candidates.is_empty() {
            return None;
        }

        // Sort by preference and performance
        candidates.sort_by(|a, b| {
            use std::cmp::Ordering;

            // Primary: ISA preference
            let a_pref = self
                .config
                .preferred_isas
                .iter()
                .position(|isa| a.technology == *isa)
                .unwrap_or(usize::MAX);
            let b_pref = self
                .config
                .preferred_isas
                .iter()
                .position(|isa| b.technology == *isa)
                .unwrap_or(usize::MAX);

            let isa_ordering = a_pref.cmp(&b_pref);
            if isa_ordering != Ordering::Equal {
                return isa_ordering;
            }

            // Secondary: Performance metrics
            if let (Some(a_metrics), Some(b_metrics)) =
                (self.get_metrics(a.name), self.get_metrics(b.name))
            {
                // Prefer FMA if configured
                if self.config.prefer_fma {
                    let a_fma = a_metrics.supports_fma.cmp(&b_metrics.supports_fma);
                    if a_fma != Ordering::Equal {
                        return a_fma.reverse(); // Prefer FMA (true > false)
                    }
                }

                // Prefer higher throughput
                b_metrics
                    .throughput
                    .partial_cmp(&a_metrics.throughput)
                    .unwrap_or(Ordering::Equal)
                    .then_with(|| {
                        // Break ties with lower latency
                        a_metrics
                            .latency
                            .partial_cmp(&b_metrics.latency)
                            .unwrap_or(Ordering::Equal)
                    })
            } else {
                Ordering::Equal
            }
        });

        candidates.first().copied()
    }

    /// Get performance metrics for an intrinsic name
    fn get_metrics(&self, name: &str) -> Option<IntrinsicMetrics> {
        INTRINSIC_PERFORMANCE
            .iter()
            .find(|(intrinsic_name, _)| *intrinsic_name == name)
            .map(|(_, metrics)| *metrics)
    }

    /// Check if a specific instruction is available on this CPU
    pub fn is_intrinsic_available(&self, intrinsic: &Gf8Intrinsic) -> bool {
        #[cfg(target_arch = "x86_64")]
        {
            match intrinsic.technology {
                "AVX2" => is_x86_feature_detected!("avx2"),
                "AVX" => is_x86_feature_detected!("avx"),
                "FMA" => is_x86_feature_detected!("fma"),
                "SSE4.1" => is_x86_feature_detected!("sse4.1"),
                "SSE2" => is_x86_feature_detected!("sse2"),
                _ => false,
            }
        }
        #[cfg(not(target_arch = "x86_64"))]
        {
            false
        }
    }

    /// Get the best available intrinsic for addition
    pub fn get_add_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        self.select_intrinsic("add", width_bits)
    }

    /// Get the best available intrinsic for subtraction
    pub fn get_sub_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        self.select_intrinsic("sub", width_bits)
    }

    /// Get the best available intrinsic for multiplication
    pub fn get_mul_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        self.select_intrinsic("mul", width_bits)
    }

    /// Get the best available intrinsic for dot product
    pub fn get_dot_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        // Prefer FMA-based dot product if available
        if self.config.prefer_fma
            && let Some(fma_intrinsic) = self.select_intrinsic("fma", width_bits)
            && self.is_intrinsic_available(fma_intrinsic)
        {
            return Some(fma_intrinsic);
        }
        self.select_intrinsic("dot", width_bits)
    }
}

// Global backend instance (lazy-initialized)
lazy_static::lazy_static! {
    static ref GLOBAL_BACKEND: std::sync::Mutex<IntrinsicBackend> =
        std::sync::Mutex::new(IntrinsicBackend::new(BackendConfig::default()));
}

/// Get the global backend instance
fn get_backend() -> std::sync::MutexGuard<'static, IntrinsicBackend> {
    GLOBAL_BACKEND.lock().unwrap()
}

/// High-level functions that use the intrinsic backend/// Add two Gf8 values using the best available intrinsic
pub fn intrinsic_add(a: &Gf8, b: &Gf8) -> Gf8 {
    let mut backend = get_backend();
    let intrinsic = backend.get_add_intrinsic(256);

    if let Some(intrin) = intrinsic
        && backend.is_intrinsic_available(intrin)
    {
        return unsafe { gf8_add_with_intrinsic(a, b, intrin) };
    }

    // Fallback to scalar
    *a + *b
}

/// Subtract two Gf8 values using the best available intrinsic
pub fn intrinsic_sub(a: &Gf8, b: &Gf8) -> Gf8 {
    let mut backend = get_backend();
    let intrinsic = backend.get_sub_intrinsic(256);

    if let Some(intrin) = intrinsic
        && backend.is_intrinsic_available(intrin)
    {
        return unsafe { gf8_sub_with_intrinsic(a, b, intrin) };
    }

    // Fallback to scalar
    *a - *b
}

/// Compute dot product using the best available intrinsic
pub fn intrinsic_dot(a: &Gf8, b: &Gf8) -> f32 {
    let mut backend = get_backend();
    let intrinsic = backend.get_dot_intrinsic(256);

    if let Some(intrin) = intrinsic
        && backend.is_intrinsic_available(intrin)
    {
        return unsafe { gf8_dot_with_intrinsic(a, b, intrin) };
    }

    // Fallback to scalar
    a.dot(b.coords())
}

/// Unsafe implementation of addition using a specific intrinsic
#[cfg(target_arch = "x86_64")]
unsafe fn gf8_add_with_intrinsic(a: &Gf8, b: &Gf8, intrinsic: &Gf8Intrinsic) -> Gf8 {
    use std::arch::x86_64::*;

    unsafe {
        let va = _mm256_loadu_ps(a.coords().as_ptr());
        let vb = _mm256_loadu_ps(b.coords().as_ptr());

        let result = if intrinsic.name == "_mm256_add_ps" {
            if is_x86_feature_detected!("avx") {
                _mm256_add_ps(va, vb)
            } else {
                return *a + *b; // Fallback
            }
        } else {
            // Unknown addition intrinsic, fallback
            return *a + *b;
        };

        let mut result_coords = [0.0f32; 8];
        _mm256_storeu_ps(result_coords.as_mut_ptr(), result);
        Gf8::new(result_coords)
    }
}

/// Unsafe implementation of subtraction using a specific intrinsic
#[cfg(target_arch = "x86_64")]
unsafe fn gf8_sub_with_intrinsic(a: &Gf8, b: &Gf8, intrinsic: &Gf8Intrinsic) -> Gf8 {
    use std::arch::x86_64::*;

    unsafe {
        let va = _mm256_loadu_ps(a.coords().as_ptr());
        let vb = _mm256_loadu_ps(b.coords().as_ptr());

        let result = if intrinsic.name == "_mm256_sub_ps" {
            if is_x86_feature_detected!("avx") {
                _mm256_sub_ps(va, vb)
            } else {
                return *a - *b; // Fallback
            }
        } else {
            // Unknown subtraction intrinsic, fallback
            return *a - *b;
        };

        let mut result_coords = [0.0f32; 8];
        _mm256_storeu_ps(result_coords.as_mut_ptr(), result);
        Gf8::new(result_coords)
    }
}

/// Unsafe implementation of dot product using a specific intrinsic
#[cfg(target_arch = "x86_64")]
unsafe fn gf8_dot_with_intrinsic(a: &Gf8, b: &Gf8, intrinsic: &Gf8Intrinsic) -> f32 {
    use std::arch::x86_64::*;

    unsafe {
        let va = _mm256_loadu_ps(a.coords().as_ptr());
        let vb = _mm256_loadu_ps(b.coords().as_ptr());

        let result = if intrinsic.name == "_mm256_fmadd_ps" {
            if is_x86_feature_detected!("avx2") && is_x86_feature_detected!("fma") {
                // FMA-based dot product
                let zero = _mm256_setzero_ps();
                let prod = _mm256_fmadd_ps(va, vb, zero);

                // Horizontal sum
                let hi_128 = _mm256_extractf128_ps(prod, 1);
                let lo_128 = _mm256_castps256_ps128(prod);
                let sum_128 = _mm_add_ps(hi_128, lo_128);
                let hsum = _mm_hadd_ps(sum_128, sum_128);
                return _mm_cvtss_f32(_mm_hadd_ps(hsum, hsum));
            } else {
                // Fallback to regular multiply
                _mm256_mul_ps(va, vb)
            }
        } else if intrinsic.name == "_mm256_dp_ps" {
            if is_x86_feature_detected!("avx") {
                // Direct dot product instruction (if available)
                _mm256_dp_ps(va, vb, 0xFF)
            } else {
                // Fallback
                _mm256_mul_ps(va, vb)
            }
        } else {
            // Generic multiply fallback
            _mm256_mul_ps(va, vb)
        };

        // Horizontal sum for non-FMA paths
        let h = _mm256_hadd_ps(result, result);
        let h = _mm256_hadd_ps(h, h);
        let h = _mm256_castps256_ps128(h);
        _mm_cvtss_f32(h)
    }
}

/// Utility function to get backend information for debugging
pub fn get_backend_info() -> String {
    let backend = get_backend();
    format!(
        "GF8 Intrinsic Backend\n\
        Preferred ISAs: {:?}\n\
        Prefer FMA: {}\n\
        Cache size: {} entries",
        backend.config.preferred_isas,
        backend.config.prefer_fma,
        backend.operation_cache.len()
    )
}

/// Utility function to list available intrinsics for debugging
pub fn list_available_intrinsics() -> Vec<String> {
    let mut backend = get_backend();
    let mut results = Vec::new();

    for &op in &["add", "sub", "mul", "dot"] {
        if let Some(intrin) = backend.select_intrinsic(op, 256) {
            let available = backend.is_intrinsic_available(intrin);
            results.push(format!(
                "{}: {} ({} - {})",
                op,
                intrin.name,
                intrin.technology,
                if available {
                    "AVAILABLE"
                } else {
                    "UNAVAILABLE"
                }
            ));
        } else {
            results.push(format!("{}: NO SELECTION", op));
        }
    }

    results
}

File: intrinsics.rs
===================
/* e8/gf8/src/intrinsics.rs */
//! A queryable registry of x86 SIMD intrinsics for backend code generation.
//!
//! # e8 Primitives – Gf8 Intrinsics Module
//!▫~•◦-----------------------------------------‣
//!
//! This module contains a comprehensive, static list of x86 intrinsics, auto-generated
//! from external documentation. It is designed to be used by the `simd` backend
//! and future procedural code generators to reason about available hardware instructions.
//!
//! ### Key Capabilities
//! - **Static Registry:** Provides `GF8_INTRINSICS`, a constant slice of `Gf8Intrinsic` structs.
//! - **Queryable API:** Offers helper functions to filter and find intrinsics by name, technology, or SIMD width.
//! - **Metadata Rich:** Each entry includes the intrinsic's name, required technology (e.g., AVX2), header, and C prototype.
//!
//! ### Architectural Notes
//! This module acts as a "database" for the compiler backend. Instead of hard-coding
//! intrinsic names, higher-level modules can query this registry to make dynamic
//! decisions about which instructions to use, enabling more flexible and future-proof
//! code generation.
//!
//! ### Example
//! ```rust
//! // This example assumes this module is part of the e8_gf8 crate.
//! // use e8_gf8::intrinsics::{find_intrinsic_by_name, intrinsics_for_f32_width};
//!
//! // fn main() {
//!     // Find a specific intrinsic by name
//!     // if let Some(intrinsic) = find_intrinsic_by_name("_mm256_add_ps") {
//!     //     println!("Found AVX add for f32: {}", intrinsic.prototype);
//!     // }
//!
//!     // Find all 256-bit f32 intrinsics
//!     // let avx_f32_intrinsics = intrinsics_for_f32_width(256).count();
//!     // println!("There are {} relevant 256-bit f32 intrinsics.", avx_f32_intrinsics);
//! // }
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Represents the metadata for a single x86 hardware intrinsic.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct Gf8Intrinsic {
    /// The C/C++ name of the intrinsic function (e.g., `_mm256_add_ps`).
    pub name: &'static str,
    /// The required CPU feature flag or technology (e.g., "AVX2", "SSE4.1").
    pub technology: &'static str,
    /// The C header file where the intrinsic is typically defined (e.g., "immintrin.h").
    pub header: &'static str,
    /// The C function prototype for the intrinsic.
    pub prototype: &'static str,
}

impl Gf8Intrinsic {
    /// Returns `true` if this intrinsic's prototype suggests it operates on `f32` vectors.
    pub fn is_f32_vector(&self) -> bool {
        self.prototype.contains("__m128")
            || self.prototype.contains("__m256")
            || self.prototype.contains("__m512")
            || self.prototype.contains("ps") // Packed Single
    }

    /// Returns `true` if this intrinsic's prototype suggests it operates on `f64` vectors.
    pub fn is_f64_vector(&self) -> bool {
        self.prototype.contains("__m128d")
            || self.prototype.contains("__m256d")
            || self.prototype.contains("__m512d")
            || self.prototype.contains("pd") // Packed Double
    }

    /// Returns the SIMD vector width in bits, if it can be inferred from the prototype.
    pub fn simd_width_bits(&self) -> Option<u32> {
        if self.prototype.contains("__m512") {
            Some(512)
        } else if self.prototype.contains("__m256") {
            Some(256)
        } else if self.prototype.contains("__m128") {
            Some(128)
        } else if self.prototype.contains("__m64") {
            Some(64)
        } else {
            None
        }
    }
}

/// A static, compile-time registry of all known x86 intrinsics from the source file.
pub const GF8_INTRINSICS: &[Gf8Intrinsic] = &[
    Gf8Intrinsic {
        name: "_m_from_float",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_from_float(float);",
    },
    Gf8Intrinsic {
        name: "_m_from_int",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_from_int(int);",
    },
    Gf8Intrinsic {
        name: "_m_maskmovq",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _m_maskmovq(__m64, __m64, char*);",
    },
    Gf8Intrinsic {
        name: "_m_packssdw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_packssdw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_packsswb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_packsswb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_packuswb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_packuswb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddsb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddsb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddsw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddusb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddusb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddusw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddusw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pand",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pand(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pandn",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pandn(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pavgb",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pavgb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pavgusb",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pavgusb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pavgw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pavgw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpeqb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpeqb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpeqd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpeqd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpeqw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpeqw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpgtb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpgtb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpgtd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpgtd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpgtw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpgtw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pextrw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _m_pextrw(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_pf2id",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pf2id(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pf2iw",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pf2iw(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfacc",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfacc(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfadd",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfadd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfcmpeq",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfcmpeq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfcmpge",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfcmpge(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfcmpgt",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfcmpgt(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfmax",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfmax(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfmin",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfmin(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfmul",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfmul(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfnacc",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pfnacc(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfpnacc",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pfpnacc(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrcp",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrcp(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrcpit1",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrcpit1(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrcpit2",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrcpit2(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrsqit1",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrsqit1(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrsqrt",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrsqrt(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfsub",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfsub(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfsubr",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfsubr(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pi2fd",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pi2fd(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pi2fw",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pi2fw(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pinsrw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pinsrw(__m64, int, int);",
    },
    Gf8Intrinsic {
        name: "_m_pmaddwd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pmaddwd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmaxsw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pmaxsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmaxub",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pmaxub(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pminsw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pminsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pminub",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pminub(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmovmskb",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _m_pmovmskb(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmulhrw",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pmulhrw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmulhuw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pmulhuw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmulhw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pmulhw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmullw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pmullw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_por",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_por(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psadbw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_psadbw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pshufw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pshufw(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_pslld",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pslld(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pslldi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pslldi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psllq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psllqi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllqi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psllw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psllwi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllwi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrad",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrad(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psradi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psradi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psraw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psraw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrawi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrawi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrld",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrld(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrldi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrldi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrlq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrlqi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlqi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrlw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrlwi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlwi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psubb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubsb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubsb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubsw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubusb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubusb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubusw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubusw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pswapd",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pswapd(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckhbw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckhbw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckhdq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckhdq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckhwd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckhwd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpcklbw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpcklbw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckldq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckldq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpcklwd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpcklwd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pxor",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pxor(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_to_float",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "float _m_to_float(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_to_int",
        technology: "MMX",
        header: "intrin.h",
        prototype: "int _m_to_int(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_abs_pi16(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_abs_pi32(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_abs_pi8(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_add_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_add_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_add_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_add_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_add_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_add_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_add_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_add_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_add_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_add_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_add_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_add_si64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_add_si64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_add_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_add_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pu8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pu8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pu16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pu16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_addsub_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_addsub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_addsub_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_addsub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_aesdec_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesdec_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesdeclast_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesdeclast_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesenc_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesenc_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesenclast_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesenclast_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesimc_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesimc_si128 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aeskeygenassist_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aeskeygenassist_si128 (__m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_alignr_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_alignr_epi8(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_alignr_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_alignr_pi8(__m64, __m64, int);",
    },
    Gf8Intrinsic {
        name: "_mm_and_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_and_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_and_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_and_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_and_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_and_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_and_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_and_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_andnot_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_andnot_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_andnot_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_andnot_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_avg_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_avg_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_avg_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_avg_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_epi16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_blend_epi16 (__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_blend_epi32(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_blend_pd (__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_blend_ps (__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blendv_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_blendv_epi8 (__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_blendv_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_blendv_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_blendv_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_blendv_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcast_ss",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_broadcast_ss(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastb_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastb_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastd_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastd_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastq_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastq_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastsd_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_broadcastsd_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastss_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_broadcastss_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastw_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastw_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_castpd_ps",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_castpd_ps(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_castpd_si128",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_castpd_si128(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_castps_pd",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_castps_pd(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_castps_si128",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_castps_si128(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_castsi128_pd",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_castsi128_pd(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_castsi128_ps",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_castsi128_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_clmulepi64_si128",
        technology: "PCLMULQDQ",
        header: "immintrin.h",
        prototype: "__m128i _mm_clmulepi64_si128 (__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmov_si128",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_cmov_si128(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_cmp_pd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_cmp_ps(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_sd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_cmp_sd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_ss",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_cmp_ss(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpeq_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpeq_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpeq_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpeq_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpeq_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpeq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpeq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestra",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestra(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrc",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestrc(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestri",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestri(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrm",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpestrm(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestro",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestro(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrs",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestrs(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrz",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestrz(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpge_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpge_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpge_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpge_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi64",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpgt_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpgt_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpgt_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpgt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpgt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpgt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpgt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistra",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistra(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrc",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistrc(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistri",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistri(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrm",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpistrm(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistro",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistro(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrs",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistrs(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrz",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistrz(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmple_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmple_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmple_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmple_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmplt_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmplt_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmplt_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmplt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmplt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmplt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmplt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpneq_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpneq_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpneq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpneq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnge_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnge_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnge_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnge_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpngt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpngt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpngt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpngt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnle_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnle_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnle_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnle_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnlt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnlt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnlt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnlt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpord_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpord_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpord_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpord_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpunord_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpunord_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpunord_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpunord_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi16(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi32(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi64(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi8(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu16(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu32(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu64(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu8(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_comieq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comieq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comieq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comieq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comige_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comige_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comige_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comige_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comigt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comigt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comigt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comigt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comile_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comile_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comile_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comile_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comilt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comilt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comilt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comilt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comineq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comineq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comineq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comineq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_pi2ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cvt_pi2ps(__m128, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_ps2pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _mm_cvt_ps2pi(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_si2ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cvt_si2ss(__m128, int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_ss2si",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_cvt_ss2si(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi16_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi16_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi32_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi32_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtepi32_pd(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi32_ps",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128 _mm_cvtepi32_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi8_epi16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi8_epi16 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi8_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi8_epi32 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi8_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi8_epi64 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu16_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu16_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu32_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu8_epi16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu8_epi16 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu8_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu8_epi32 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu8_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu8_epi64 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpd_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtpd_epi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpd_pi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_cvtpd_pi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpd_ps",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128 _mm_cvtpd_ps(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtph_ps",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m128 _mm_cvtph_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpi32_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtpi32_pd(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtps_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtps_epi32(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtps_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtps_pd(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtps_ph",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m128i _mm_cvtps_ph(__m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsd_f64",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "double _mm_cvtsd_f64(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsd_si32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_cvtsd_si32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsd_ss",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128 _mm_cvtsd_ss(__m128, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi128_si32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_cvtsi128_si32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi32_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtsi32_sd(__m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi32_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtsi32_si128(int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi32_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cvtsi32_si64(int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi64_si32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "int _mm_cvtsi64_si32 (__m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cvtss_f32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "float _mm_cvtss_f32(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtss_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtss_sd(__m128d, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtt_ps2pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _mm_cvtt_ps2pi(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtt_ss2si",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_cvtt_ss2si(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttpd_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvttpd_epi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttpd_pi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_cvttpd_pi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttps_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvttps_epi32(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttsd_si32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_cvttsd_si32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_div_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_div_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_div_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_div_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_div_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_div_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_div_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_div_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_dp_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_dp_pd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_dp_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_dp_ps(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_extract_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_extract_epi32(__m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_extract_epi8 (__m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_extract_ps(__m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_extract_si64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_extracti_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_extracti_si64(__m128i, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmadd_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmadd_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmadd_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmadd_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmaddsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmaddsub_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmaddsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmaddsub_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmsub_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmsub_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmsub_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmsub_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsubadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmsubadd_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsubadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmsubadd_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmadd_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmadd_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmadd_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmadd_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmsub_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmsub_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmsub_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmsub_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128d _mm_frcz_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128 _mm_frcz_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_sd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128d _mm_frcz_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_ss",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128 _mm_frcz_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hadd_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hadd_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_hadd_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hadd_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hadd_pi32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_hadd_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epu16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epu16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epu8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epu16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epu16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epu32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epu32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epu8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadds_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hadds_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadds_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hadds_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_haddw_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddw_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddw_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddw_epu8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hsub_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hsub_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_hsub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hsub_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hsub_pi32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_hsub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_hsubd_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubq_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_hsubq_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hsubs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hsubs_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubw_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_hsubw_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i32gather_epi32(int const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i32gather_epi64(__int64 const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_i32gather_pd(double const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_i32gather_ps(float const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i64gather_epi32(int const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i64gather_epi64(__int64 const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_i64gather_pd(double const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_i64gather_ps(float const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_epi16(__m128i, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_epi32(__m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_epi8 (__m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_insert_ps(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_si64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_inserti_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_inserti_si64(__m128i, __m128i, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_lddqu_si128",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_lddqu_si128(__m128i const*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_load_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_load_ps(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_ps1",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_load_ps1(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_load_sd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_load_si128(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_load_ss(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_load1_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_load1_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loaddup_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_loaddup_pd(double const*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadh_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadh_pd(__m128d, double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadh_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadh_pi(__m128, __m64*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadl_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_loadl_epi64(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadl_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadl_pd(__m128d, double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadl_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadl_pi(__m128, __m64*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadr_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadr_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadr_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadr_ps(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadu_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadu_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadu_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadu_ps(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadu_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_loadu_si128(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macc_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macc_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_macc_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_macc_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_macc_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_macc_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_maccd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macchi_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macchi_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macclo_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macclo_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccs_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccs_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccs_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccs_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccsd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccsd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccshi_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccshi_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccslo_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccslo_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_madd_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_madd_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_madd_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_madd_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_maddd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maddd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maddsd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maddsd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maddsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_maddsub_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_maddsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_maddsub_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_maddubs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_maddubs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maddubs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_maddubs_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i32gather_epi32(__m128i, int const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i32gather_epi64(__m128i, __int64 const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_mask_i32gather_pd(__m128d, double const *, __m128i, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_mask_i32gather_ps(__m128, float const *, __m128i, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i64gather_epi32(__m128i, int const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i64gather_epi64(__m128i, __int64 const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_mask_i64gather_pd(__m128d, double const *, __m128i, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_mask_i64gather_ps(__m128, float const *, __m128i, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_maskload_epi32(int const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_maskload_epi64(__int64 const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_maskload_pd(double const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_maskload_ps(float const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskmoveu_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_maskmoveu_si128(__m128i, __m128i, char*);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_epi32(int *, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_epi64(__int64 *, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_pd(double *, __m128i, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_ps(float *, __m128i, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epi8 (__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epu16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epu32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epu32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_max_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_max_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_max_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_max_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_max_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_max_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_max_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epi8 (__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epu16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epu32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epu32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_min_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_min_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_min_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_min_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_min_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_min_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_min_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_minpos_epu16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_minpos_epu16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_move_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_move_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_move_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_move_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_move_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_move_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movedup_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_movedup_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_movehdup_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_movehdup_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movehl_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_movehl_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_moveldup_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_moveldup_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movelh_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_movelh_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movemask_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_movemask_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_movemask_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_movemask_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_movemask_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_movemask_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movepi64_pi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_movepi64_pi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_movpi64_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_movpi64_epi64(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mpsadbw_epu8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_mpsadbw_epu8(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_msub_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_msub_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_msub_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_msub_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_msubadd_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_msubadd_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_msubadd_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_msubadd_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_mul_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_epu32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mul_epu32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_mul_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_mul_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_mul_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_mul_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_su32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_mul_su32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhi_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mulhi_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhi_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mulhi_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhi_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_mulhi_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_mulhrs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_mulhrs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhrs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_mulhrs_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mullo_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mullo_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mullo_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_mullo_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mullo_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_mullo_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmacc_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmacc_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmacc_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmacc_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmsub_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmsub_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmsub_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmsub_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_or_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_or_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_or_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_or_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_or_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_or_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_or_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_or_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packs_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_packs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packs_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_packs_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packs_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_packs_pi16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_packs_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_packs_pi32 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_packs_pu16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_packs_pu16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_packus_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_packus_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packus_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_packus_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_perm_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_perm_epi8(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_permute_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_permute_pd(__m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permute_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_permute_ps(__m128, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permute2_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128d _mm_permute2_pd(__m128d, __m128d, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permute2_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128 _mm_permute2_ps(__m128, __m128, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permutevar_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_permutevar_pd(__m128d, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_permutevar_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_permutevar_ps(__m128, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rcp_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rcp_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_rcp_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rcp_ss(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi64(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi8(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_round_pd(__m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_round_ps(__m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_sd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_round_sd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_ss",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_round_ss(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_rsqrt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rsqrt_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_rsqrt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rsqrt_ss(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sad_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sad_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi16(short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi32(int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_set_pd(double, double);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pi16",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set_pi16(short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pi32",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set_pi32(int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pi8",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set_pi8(char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_set_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_set_ps(float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm_set_ps1",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_set_ps1(float);",
    },
    Gf8Intrinsic {
        name: "_mm_set_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_set_sd(double);",
    },
    Gf8Intrinsic {
        name: "_mm_set_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_set_ss(float);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi16(short);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi32(int);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi64(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi8(char);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_set1_pd(double);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pi16",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set1_pi16(short);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pi32",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set1_pi32(int);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pi8",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set1_pi8(char);",
    },
    Gf8Intrinsic {
        name: "_mm_setl_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setl_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi16(short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi32(int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_setr_pd(double, double);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pi16",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setr_pi16(short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pi32",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setr_pi32(int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pi8",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setr_pi8(char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_setr_ps(float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_setzero_pd(void);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_setzero_ps(void);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setzero_si128(void);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_si64",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setzero_si64(void);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_shuffle_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_shuffle_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_shuffle_pd(__m128d, __m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_shuffle_pi8(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_shuffle_ps(__m128, __m128, unsigned int);",
    },
    Gf8Intrinsic {
        name: "_mm_shufflehi_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_shufflehi_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_shufflelo_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_shufflelo_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_sign_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_sign_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_sign_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_sign_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_sign_pi32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_sign_pi8(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sll_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sll_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sll_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sll_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sll_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sll_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sll_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sll_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_slli_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_slli_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_epi64(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_slli_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_slli_pi16(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_slli_pi32(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_slli_si64(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_si128(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_sllv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_sllv_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sllv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_sllv_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sqrt_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sqrt_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sqrt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sqrt_ss(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sra_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sra_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sra_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sra_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sra_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sra_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sra_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sra_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srai_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srai_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srai_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srai_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srai_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srai_pi16(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srai_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srai_pi32(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srav_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_srav_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srl_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srl_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srl_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srl_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srl_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srl_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srl_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srl_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srli_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srli_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_epi64(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srli_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srli_pi16(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srli_pi32(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srli_si64(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_si128(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srlv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_srlv_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srlv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_srlv_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_store_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_store_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_store_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_store_ps1",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_store_ps1(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_store_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store_sd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_store_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store_si128(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_store_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_store_ss(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_store1_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store1_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storeh_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storeh_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storeh_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storeh_pi(__m64*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storel_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storel_epi64(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_storel_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storel_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storel_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storel_pi(__m64*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storer_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storer_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storer_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storer_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storeu_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storeu_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storeu_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storeu_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storeu_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storeu_si128(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_load_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_stream_load_si128(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_stream_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_stream_pi(__m64*, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_stream_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_sd",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "void _mm_stream_sd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_stream_si128(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_ss",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "void _mm_stream_ss(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sub_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sub_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sub_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sub_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sub_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_si64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_sub_si64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sub_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pu8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pu8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pu16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pu16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_testc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testc_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_testc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testc_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_testc_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_testc_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_testnzc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testnzc_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_testnzc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testnzc_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_testnzc_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_testnzc_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_testz_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testz_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_testz_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testz_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_testz_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_testz_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomieq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomieq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomieq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomieq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomige_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomige_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomige_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomige_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomigt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomigt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomigt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomigt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomile_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomile_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomile_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomile_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomilt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomilt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomilt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomilt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomineq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomineq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomineq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomineq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_unpackhi_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpackhi_pi8 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpackhi_pi16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpackhi_pi32 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_unpackhi_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_unpacklo_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpacklo_pi8 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpacklo_pi16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpacklo_pi32 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_unpacklo_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_xor_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_xor_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_xor_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_xor_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_xor_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_xor_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_xor_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_xor_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_abs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_abs_epi16(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_abs_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_abs_epi32(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_abs_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_abs_epi8(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_add_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_add_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_addsub_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_addsub_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_addsub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_addsub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_alignr_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_alignr_epi8(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_and_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_and_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_and_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_and_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_and_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_and_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_andnot_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_andnot_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_andnot_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_andnot_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_andnot_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_andnot_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_avg_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_avg_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_avg_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_avg_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_blend_epi16(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_blend_epi32(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_blend_pd(__m256d, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_blend_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blendv_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_blendv_epi8(__m256i, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_blendv_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_blendv_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_blendv_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_blendv_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_broadcast_pd(__m128d const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_broadcast_ps(__m128 const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_sd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_broadcast_sd(double const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_ss",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_broadcast_ss(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastb_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastb_epi8 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastd_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastd_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastq_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastq_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastsd_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_broadcastsd_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastsi128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastsi128_si256(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastss_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_broadcastss_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastw_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastw_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_castpd_ps(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_castpd_si256(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd128_pd256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_castpd128_pd256(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd256_pd128",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm256_castpd256_pd128(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_castps_pd(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_castps_si256(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps128_ps256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_castps128_ps256(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps256_ps128",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm256_castps256_ps128(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_castsi128_si256(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi256_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_castsi256_pd(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi256_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_castsi256_ps(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi256_si128",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_castsi256_si128(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmov_si256",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256i _mm256_cmov_si256(__m256i, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmp_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_cmp_pd(__m256d, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_cmp_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi16_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi16_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi32_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi32_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_cvtepi32_pd(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi32_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_cvtepi32_ps(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi8_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi8_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi8_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi8_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi8_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi8_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu16_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu16_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu32_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu8_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu8_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu8_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu8_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu8_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu8_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtpd_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_cvtpd_epi32(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtpd_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm256_cvtpd_ps(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtph_ps",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m256 _mm256_cvtph_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtps_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtps_epi32(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtps_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_cvtps_pd(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtps_ph",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m128i _mm256_cvtps_ph(__m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvttpd_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_cvttpd_epi32(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvttps_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvttps_epi32(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_div_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_div_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_div_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_div_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_dp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_dp_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extractf128_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm256_extractf128_pd(__m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extractf128_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm256_extractf128_ps(__m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extractf128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_extractf128_si256(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extracti128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm256_extracti128_si256(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmadd_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmadd_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmaddsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmaddsub_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmaddsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmaddsub_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmsub_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmsub_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsubadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmsubadd_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsubadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmsubadd_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fnmadd_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fnmadd_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fnmsub_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fnmsub_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_frcz_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256d _mm256_frcz_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_frcz_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256 _mm256_frcz_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hadd_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hadd_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_hadd_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_hadd_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadds_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hadds_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hsub_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hsub_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_hsub_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_hsub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsubs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hsubs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i32gather_epi32(int const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i32gather_epi64(__int64 const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_i32gather_pd(double const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_i32gather_ps(float const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i64gather_epi32(int const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i64gather_epi64(__int64 const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_i64gather_pd(double const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm256_i64gather_ps(float const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_insertf128_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_insertf128_pd(__m256d, __m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_insertf128_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_insertf128_ps(__m256, __m128, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_insertf128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_insertf128_si256(__m256i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_inserti128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_inserti128_si256(__m256i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_lddqu_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_lddqu_si256(__m256i *);",
    },
    Gf8Intrinsic {
        name: "_mm256_load_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_load_pd(double const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_load_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_load_ps(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_load_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_load_si256(__m256i *);",
    },
    Gf8Intrinsic {
        name: "_mm256_loadu_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_loadu_pd(double const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_loadu_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_loadu_ps(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_loadu_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_loadu_si256(__m256i *);",
    },
    Gf8Intrinsic {
        name: "_mm256_macc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_macc_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_macc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_macc_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_madd_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_madd_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maddsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_maddsub_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_maddsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_maddsub_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_maddubs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_maddubs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mask_i32gather_epi32(__m256i, int const *, __m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mask_i32gather_epi64(__m256i, __int64 const *, __m128i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_mask_i32gather_pd(__m256d, double const *, __m128i, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_mask_i32gather_ps(__m256, float const *, __m256i, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm256_mask_i64gather_epi32(__m128i, int const *, __m256i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mask_i64gather_epi64(__m256i, __int64 const *, __m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_mask_i64gather_pd(__m256d, double const *, __m256i, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm256_mask_i64gather_ps(__m128, float const *, __m256i, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_maskload_epi32(int const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_maskload_epi64(__int64 const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_maskload_pd(double const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_maskload_ps(float const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_epi32(int *, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_epi64(__int64 *, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_pd(double *, __m256i, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_ps(float *, __m256i, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epu32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epu32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_max_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_max_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epu32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epu32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_min_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_min_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_movedup_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_movedup_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_movehdup_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_movehdup_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_moveldup_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_moveldup_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_movemask_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "int _mm256_movemask_epi8(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_movemask_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_movemask_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_movemask_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_movemask_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_mpsadbw_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mpsadbw_epu8(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_msub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_msub_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_msub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_msub_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_msubadd_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_msubadd_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_msubadd_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_msubadd_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mul_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_epu32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mul_epu32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_mul_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_mul_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_mulhi_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mulhi_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mulhi_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mulhi_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mulhrs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mulhrs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mullo_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mullo_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mullo_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mullo_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmacc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_nmacc_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmacc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_nmacc_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_nmsub_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_nmsub_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_or_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_or_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_or_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_or_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_or_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_or_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packs_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packs_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packus_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packus_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packus_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packus_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permute_pd(__m256d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permute_ps(__m256, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256d _mm256_permute2_pd(__m256d, __m256d, __m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256 _mm256_permute2_ps(__m256, __m256, __m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2f128_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permute2f128_pd(__m256d, __m256d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2f128_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permute2f128_ps(__m256, __m256, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2f128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permute2f128_si256(__m256i, __m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2x128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permute2x128_si256(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute4x64_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permute4x64_epi64 (__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute4x64_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permute4x64_pd(__m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permutevar_pd(__m256d, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permutevar_ps(__m256, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar8x32_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permutevar8x32_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar8x32_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permutevar8x32_ps (__m256, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_rcp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_rcp_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_round_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_round_pd(__m256d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_round_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_round_ps(__m256, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_rsqrt_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_rsqrt_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_sad_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sad_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_epi16",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set_epi16(short, short, short, short, short, short, short, short, short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set_epi32(int, int, int, int, int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_epi8",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_set_pd(double, double, double, double);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_set_ps(float, float, float, float, float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_epi16",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set1_epi16(short);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set1_epi32(int);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_epi8",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set1_epi8(char);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_set1_pd(double);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_set1_ps(float);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_epi16",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setr_epi16(short, short, short, short, short, short, short, short, short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setr_epi32(int, int, int, int, int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_epi8",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setr_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_setr_pd(double, double, double, double);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_setr_ps(float, float, float, float, float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm256_setzero_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_setzero_pd(void);",
    },
    Gf8Intrinsic {
        name: "_mm256_setzero_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_setzero_ps(void);",
    },
    Gf8Intrinsic {
        name: "_mm256_setzero_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setzero_si256(void);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shuffle_epi32(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shuffle_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_shuffle_pd(__m256d, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_shuffle_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shufflehi_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shufflehi_epi16(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shufflelo_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shufflelo_epi16(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_sign_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sign_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sign_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sign_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sign_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sign_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sll_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sll_epi16(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sll_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sll_epi32(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sll_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sll_epi64(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_epi16(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_epi32(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_epi64(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_si256(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_sllv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sllv_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sllv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sllv_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sqrt_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_sqrt_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_sqrt_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_sqrt_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_sra_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sra_epi16(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sra_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sra_epi32(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srai_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srai_epi16(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srai_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srai_epi32(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srav_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srav_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srl_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srl_epi16(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srl_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srl_epi32(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srl_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srl_epi64(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_epi16(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_epi32(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_epi64(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_si256(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srlv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srlv_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srlv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srlv_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_store_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_store_pd(double *, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_store_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_store_ps(float *, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_store_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_store_si256(__m256i *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_storeu_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_storeu_pd(double *, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_storeu_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_storeu_ps(float *, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_storeu_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_storeu_si256(__m256i *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_load_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_stream_load_si256(__m256i const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void __mm256_stream_pd(double *, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_stream_ps(float *, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void __mm256_stream_si256(__m256i *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_sub_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_sub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_testc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testc_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_testc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testc_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_testc_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testc_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_testnzc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testnzc_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_testnzc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testnzc_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_testnzc_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testnzc_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_testz_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testz_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_testz_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testz_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_testz_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testz_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_unpackhi_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_unpackhi_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_unpacklo_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_unpacklo_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_xor_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_xor_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_xor_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_xor_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_xor_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_xor_si256(__m256i, __m256i);",
    },
];

/// Look up an intrinsic by exact name (e.g. "_mm256_add_ps").
pub fn find_intrinsic_by_name(name: &str) -> Option<&'static Gf8Intrinsic> {
    GF8_INTRINSICS.iter().find(|i| i.name == name)
}

/// All intrinsics for a given technology (e.g. "AVX2", "AVX-512F").
pub fn intrinsics_by_technology(tech: &str) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS.iter().filter(move |i| i.technology == tech)
}

/// All intrinsics that look like f32 SIMD of a particular width (128/256/512).
pub fn intrinsics_for_f32_width(width_bits: u32) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS
        .iter()
        .filter(move |i| i.is_f32_vector() && i.simd_width_bits() == Some(width_bits))
}

/// All intrinsics that look like f64 SIMD of a particular width (128/256/512).
pub fn intrinsics_for_f64_width(width_bits: u32) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS
        .iter()
        .filter(move |i| i.is_f64_vector() && i.simd_width_bits() == Some(width_bits))
}

File: gf8.rs
============
/* e8/gf8/src/gf8.rs */
//! A foundational 8-dimensional geometric float gf8, inspired by E₈ lattice properties.
//!
//! # e8 Primitives – Gf8 Module
//!▫~•◦-----------------------------‣
//!
//! This module provides the `Gf8` type, a core numeric gf8 for the e8 ecosystem.
//! It is designed to replace standard floating-point numbers in contexts where geometric
//! stability, intrinsic normalization, and binary-addressable states are paramount.
//!
//! ### Key Capabilities
//! - **Geometric Representation:** `Gf8` represents a value as a normalized 8D vector on the unit sphere (S⁷).
//! - **Binary Encoding:** Provides a constructor from 8 bits that maps to a unique, stable direction in 8D space, enforcing an E₈-like even parity constraint.
//! - **Geometric Arithmetic:** All arithmetic operations (add, sub) are geometric, preserving the unit-norm constraint by re-projecting results onto the sphere.
//! - **Tensor-like API:** Implements `Deref` and a `Gf8Tensor` trait, allowing it to be used seamlessly as a small, fixed-size tensor.
//!
//! ### Architectural Notes
//! `Gf8` is the cornerstone of the e8 compute and data model. Its fixed dimensionality is a perfect
//! match for 256-bit SIMD registers (e.g., AVX), enabling highly efficient hardware acceleration.
//! It serves as the basis for E8B codes, E8DB keys, and the E8 LLM's numerical representation.
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, Gf8Tensor};
//!
//! // Create a Gf8 from a binary pattern (0b10101010)
//! let bits = [0, 1, 0, 1, 0, 1, 0, 1];
//! let a = Gf8::from_bits_even_parity(bits);
//!
//! // Create another Gf8 from a different pattern
//! let b = Gf8::from_scalar(-0.5);
//!
//! // Compute the dot product (cosine similarity)
//! let similarity = a.dot(b.coords());
//!
//! // `Gf8` can be treated like a slice
//! println!("Gf8 'a' has {} dimensions.", a.as_slice().len());
//! println!("Similarity between a and b: {}", similarity);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::simd;
use std::ops::{Add, AddAssign, Deref, DerefMut, Mul, MulAssign, Neg, Sub, SubAssign};

/// A tiny tensor-like trait for GF8.
///
/// This provides an explicit contract for types that can be viewed as a slice of floats,
/// intended for use in generic, tensor-aware code.
pub trait Gf8Tensor {
    /// Returns the underlying data as an immutable slice.
    fn as_slice(&self) -> &[f32];
    /// Returns the underlying data as a mutable slice.
    fn as_mut_slice(&mut self) -> &mut [f32];
}

/// A GF8 (GeoFloat8), an 8-dimensional geometric float gf8.
///
/// It is internally represented by an array of 8 `f32`s, which is always
/// normalized to have a unit L2 norm (i.e., it lies on the surface of an
/// 8D hypersphere). This property provides intrinsic stability and makes it suitable
/// for representing directions, rotations, and normalized semantic states.
///
/// The only exception to the unit-norm rule is the zero vector, which has a norm of 0.
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct Gf8 {
    coords: [f32; 8],
}

impl Gf8 {
    /// The zero vector, representing a neutral or null state.
    pub const ZERO: Self = Self { coords: [0.0; 8] };

    /// Constructs a `Gf8` from raw 8D coordinates, normalizing them to unit length.
    ///
    /// If the input vector has a magnitude of zero, the zero `Gf8` is returned.
    #[inline]
    pub fn new(coords: [f32; 8]) -> Self {
        let mut v = Self { coords };
        v.renormalize();
        v
    }

    /// Constructs a `Gf8` from raw 8D coordinates.
    ///
    /// This is an alias for [`Gf8::new`], provided for clarity when working in
    /// math-heavy code where "from_coords" more clearly expresses intent than "new".
    #[inline]
    pub fn from_coords(coords: [f32; 8]) -> Self {
        Self::new(coords)
    }

    /// Constructs a `Gf8` from 8 bits, mapping them to an E₈-like ±1 pattern.
    ///
    /// The mapping is `0 -> +1.0` and `1 -> -1.0`. To satisfy an E₈-like constraint,
    /// the number of `-1.0` entries is forced to be even by flipping the sign of
    /// the last coordinate if necessary. The resulting vector is then normalized
    /// to unit length.
    pub fn from_bits_even_parity(bits: [u8; 8]) -> Self {
        let mut coords = [0.0f32; 8];
        let mut neg_count = 0usize;

        for (i, &b) in bits.iter().enumerate() {
            if b == 0 {
                coords[i] = 1.0;
            } else {
                coords[i] = -1.0;
                neg_count += 1;
            }
        }

        if neg_count % 2 == 1 {
            // Flip the sign of the last coordinate to enforce even parity.
            coords[7] = -coords[7];
        }

        // Normalize the resulting vector to place it on the unit sphere.
        // A pure ±1 vector has a norm of sqrt(8).
        Self::new(coords)
    }

    /// Constructs a `Gf8` by embedding a scalar along the first axis.
    ///
    /// The resulting `Gf8` will be `[signum(x), 0.0, ..., 0.0]`. This provides a simple
    /// way to represent scalar magnitudes directionally.
    pub fn from_scalar(x: f32) -> Self {
        let mut coords = [0.0; 8];
        coords[0] = x;
        Self::new(coords)
    }

    /// Retrieves the raw coordinate data as a slice.
    #[inline]
    pub fn coords(&self) -> &[f32; 8] {
        &self.coords
    }

    /// Approximates a scalar value by projecting the `Gf8` onto the first axis.
    ///
    /// Since `Gf8` is a unit vector, this value will be in the range `[-1.0, 1.0]`.
    #[inline]
    pub fn to_scalar(&self) -> f32 {
        self.coords[0]
    }

    /// Computes the dot product with another 8D vector.
    ///
    /// For two unit vectors, this is equivalent to their cosine similarity.
    /// This method is backed by a runtime-dispatching SIMD implementation
    /// for maximum performance.
    #[inline(always)]
    pub fn dot(&self, other: &[f32; 8]) -> f32 {
        simd::dot_product(self.coords, *other)
    }

    /// Computes the squared L2 norm. For a valid `Gf8`, this is always `1.0` (or `0.0` for zero).
    #[inline]
    pub fn norm2(&self) -> f32 {
        self.coords.iter().map(|&x| x * x).sum()
    }

    /// Computes the L2 norm. For a valid `Gf8`, this is always `1.0` (or `0.0` for zero).
    #[inline]
    pub fn norm(&self) -> f32 {
        self.norm2().sqrt()
    }

    /// Re-normalizes the `Gf8` in-place to ensure it remains a unit vector.
    /// This is useful after performing arithmetic operations that may alter the magnitude.
    pub fn renormalize(&mut self) {
        let n2 = self.norm2();
        if n2 > 0.0 {
            let inv_norm = 1.0 / n2.sqrt();
            for x in &mut self.coords {
                *x *= inv_norm;
            }
        }
    }
}

impl Gf8Tensor for Gf8 {
    #[inline]
    fn as_slice(&self) -> &[f32] {
        &self.coords
    }
    #[inline]
    fn as_mut_slice(&mut self) -> &mut [f32] {
        &mut self.coords
    }
}

impl Default for Gf8 {
    /// The default `Gf8` is the zero vector.
    fn default() -> Self {
        Self::ZERO
    }
}

impl Deref for Gf8 {
    type Target = [f32; 8];
    #[inline]
    fn deref(&self) -> &Self::Target {
        &self.coords
    }
}

impl DerefMut for Gf8 {
    #[inline]
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.coords
    }
}

/// Geometric addition: performs element-wise vector addition and then
/// re-normalizes the result, projecting it back onto the unit sphere.
impl Add for Gf8 {
    type Output = Self;
    fn add(self, rhs: Self) -> Self::Output {
        let mut coords = [0.0f32; 8];
        for (i, (&a, &b)) in self.coords.iter().zip(rhs.coords.iter()).enumerate() {
            coords[i] = a + b;
        }
        Self::new(coords)
    }
}

impl AddAssign for Gf8 {
    fn add_assign(&mut self, rhs: Self) {
        for (i, &v) in rhs.coords.iter().enumerate() {
            self.coords[i] += v;
        }
        self.renormalize();
    }
}

/// Geometric subtraction: performs element-wise vector subtraction and then
/// re-normalizes the result, projecting it back onto the unit sphere.
impl Sub for Gf8 {
    type Output = Self;
    fn sub(self, rhs: Self) -> Self::Output {
        let mut coords = [0.0f32; 8];
        for (i, (&a, &b)) in self.coords.iter().zip(rhs.coords.iter()).enumerate() {
            coords[i] = a - b;
        }
        Self::new(coords)
    }
}

impl SubAssign for Gf8 {
    fn sub_assign(&mut self, rhs: Self) {
        for (i, &v) in rhs.coords.iter().enumerate() {
            self.coords[i] -= v;
        }
        self.renormalize();
    }
}

/// Scalar multiplication. The result is re-normalized, so this operation primarily
/// affects the vector's direction (flipping it if the scalar is negative).
impl Mul<f32> for Gf8 {
    type Output = Self;
    fn mul(self, rhs: f32) -> Self::Output {
        let mut coords = self.coords;
        for x in &mut coords {
            *x *= rhs;
        }
        Self::new(coords)
    }
}

impl MulAssign<f32> for Gf8 {
    fn mul_assign(&mut self, rhs: f32) {
        for x in &mut self.coords {
            *x *= rhs;
        }
        self.renormalize();
    }
}

/// Negation: flips the direction of the vector. The norm remains unchanged.
impl Neg for Gf8 {
    type Output = Self;
    fn neg(self) -> Self::Output {
        let mut coords = self.coords;
        for x in &mut coords {
            *x = -*x;
        }
        Self { coords }
    }
}

File: e8x.rs
============
/* crates/gf8/src/e8x.rs */
//! # E8X - The Batteries-Included E8 Type
//!
//! E8X (E8 Cross) combines all E8 capabilities into a single, easy-to-use type:
//! - **E8F core operations**: Zero-FLOP arithmetic via lookup tables
//! - **Automatic error management**: Re-alignment after N operations
//! - **Drift tracking**: Built-in metrics for error monitoring
//! - **Hybrid computation**: Seamless E8F ↔ f32 conversion
//!
//! ## Philosophy
//!
//! E8X is the "batteries included" type for E8 operations. Instead of manually
//! wiring together E8F + E8FAligned + E8FCompute, just use E8X and everything
//! works out of the box.
//!
//! ## When to Use
//!
//! - **Use E8X for**: Applications, media compression, neural networks, anything
//!   requiring robust E8 operations with automatic error management
//! - **Use E8F for**: Low-level operations, when you need fine-grained control,
//!   or when you're building your own wrappers
//!
//! ## Example
//!
//! ```rust
//! use gf8::E8X;
//!
//! // Single import, everything works
//! let mut a = E8X::new_from_index(42);
//! let b = E8X::new_from_index(100);
//!
//! // Automatic re-alignment after N operations
//! for i in 0..20 {
//!     a += b;  // Re-alignment happens automatically
//! }
//!
//! // Drift tracking built-in
//! println!("Max drift: {:.4}", a.max_drift());
//!
//! // Hybrid compute built-in
//! let coords = a.to_f32_coords();
//! let reconstructed = E8X::from_f32_coords(&coords);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::quantize_to_nearest_code;
use crate::{E8F, Gf8, gf8_chordal_distance};
use std::ops::{Add, AddAssign, Mul, MulAssign, Sub, SubAssign};

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E8X TYPE DEFINITION
// ═══════════════════════════════════════════════════════════════════════════════════════

/// E8X - The batteries-included E8 type.
///
/// Combines E8F core operations with automatic error management, hybrid computation,
/// and drift tracking. This is the recommended type for most applications.
///
/// # Features
///
/// - **1-byte wire representation** via `batch_to_bytes` (same index as E8F)
/// - **Zero-FLOP operations**: Add, mul, dot via precomputed lookup tables
/// - **Automatic re-alignment**: Triggers after N operations (default: 10)
/// - **Hybrid computation**: Seamless E8F ↔ f32 conversion automation
/// - **Drift tracking**: Monitors cumulative error from operations
///
/// # Error Management
///
/// E8X automatically re-aligns to the nearest E8 root after a configurable
/// number of operations, bounding cumulative quantization drift.
///
/// # Example
///
/// ```rust
/// use gf8::E8X;
///
/// let mut x = E8X::new_from_index(0);
///
/// // Chain operations - automatic re-alignment
/// for i in 0..15 {
///     x += E8X::new_from_index(i);
/// }
///
/// // Check drift is finite
/// assert!(x.max_drift().is_finite());
/// ```
#[derive(Debug, Clone, Copy)]
pub struct E8X {
    /// The current E8F value.
    value: E8F,

    /// Number of operations since last alignment.
    ops_since_alignment: u8,

    /// Maximum operations before triggering automatic alignment.
    max_ops_before_align: u8,

    /// Maximum observed drift from last alignment point.
    max_drift: f32,

    /// Sum of all drift values (for computing mean).
    drift_sum: f32,

    /// Count of drift measurements.
    drift_count: u32,

    /// Reference point for drift measurement (last aligned value).
    reference: Gf8,
}

impl E8X {
    /// Default number of operations before automatic alignment.
    pub const DEFAULT_MAX_OPS: u8 = 10;

    /// Default drift threshold for warnings.
    pub const DEFAULT_DRIFT_THRESHOLD: f32 = 0.1;

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 2: CONSTRUCTORS
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Create a new E8X from an E8F value.
    ///
    /// # Arguments
    /// * `value` - The E8F value to wrap
    ///
    /// # Example
    /// ```rust
    /// use gf8::{E8X, E8F};
    ///
    /// let e8f = E8F::new(42);
    /// let e8x = E8X::new(e8f);
    /// ```
    pub fn new(value: E8F) -> Self {
        let reference = value.to_gf8();
        Self {
            value,
            ops_since_alignment: 0,
            max_ops_before_align: Self::DEFAULT_MAX_OPS,
            max_drift: 0.0,
            drift_sum: 0.0,
            drift_count: 0,
            reference,
        }
    }

    /// Create a new E8X from a root index (0-239).
    ///
    /// # Arguments
    /// * `index` - The E8 root index
    ///
    /// # Example
    /// ```rust
    /// use gf8::E8X;
    ///
    /// let e8x = E8X::new_from_index(42);
    /// ```
    pub fn new_from_index(index: u8) -> Self {
        Self::new(E8F::new(index))
    }

    /// Create a new E8X with custom alignment threshold.
    ///
    /// # Arguments
    /// * `value` - The E8F value to wrap
    /// * `max_ops` - Maximum operations before automatic alignment
    ///
    /// # Example
    /// ```rust
    /// use gf8::{E8X, E8F};
    ///
    /// let e8x = E8X::with_max_ops(E8F::new(42), 5);
    /// ```
    pub fn with_max_ops(value: E8F, max_ops: u8) -> Self {
        let mut e8x = Self::new(value);
        e8x.max_ops_before_align = max_ops;
        e8x
    }

    /// Create a new E8X from f32 coordinates.
    ///
    /// Quantizes the coordinates to the nearest E8 root.
    ///
    /// # Arguments
    /// * `coords` - 8D coordinates to quantize
    ///
    /// # Returns
    /// Tuple of (E8X, quantization_error)
    ///
    /// # Example
    /// ```rust
    /// use gf8::E8X;
    ///
    /// let coords = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
    /// let (e8x, error) = E8X::from_f32_coords(&coords);
    /// assert!(error < 1.0);
    /// ```
    pub fn from_f32_coords(coords: &[f32; 8]) -> (Self, f32) {
        let (code, snapped_gf8) = quantize_to_nearest_code(coords);

        // Compute quantization error
        let input_gf8 = Gf8::from_coords(*coords);
        let error = gf8_chordal_distance(&input_gf8, &snapped_gf8);

        (Self::new(E8F::from_code(code)), error)
    }

    /// Create a new E8X from a Gf8 vector.
    ///
    /// # Arguments
    /// * `gf8` - The Gf8 vector to quantize
    ///
    /// # Example
    /// ```rust
    /// use gf8::{E8X, Gf8};
    ///
    /// let gf8 = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
    /// let e8x = E8X::from_gf8(&gf8);
    /// ```
    pub fn from_gf8(gf8: &Gf8) -> Self {
        let (code, _) = quantize_to_nearest_code(gf8.coords());
        Self::new(E8F::from_code(code))
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 3: ACCESSORS
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Get the underlying E8F value.
    #[inline]
    pub fn value(&self) -> E8F {
        self.value
    }

    /// Get the E8 root index (0-239).
    #[inline]
    pub fn index(&self) -> u8 {
        self.value.index()
    }

    /// Get the number of operations since last alignment.
    #[inline]
    pub fn ops_since_alignment(&self) -> u8 {
        self.ops_since_alignment
    }

    /// Get the maximum operations before alignment.
    #[inline]
    pub fn max_ops_before_align(&self) -> u8 {
        self.max_ops_before_align
    }

    /// Set the maximum operations before alignment.
    #[inline]
    pub fn set_max_ops(&mut self, max_ops: u8) {
        self.max_ops_before_align = max_ops;
    }

    /// Get the maximum observed drift.
    #[inline]
    pub fn max_drift(&self) -> f32 {
        self.max_drift
    }

    /// Get the mean drift across all operations.
    #[inline]
    pub fn mean_drift(&self) -> f32 {
        if self.drift_count == 0 {
            0.0
        } else {
            self.drift_sum / self.drift_count as f32
        }
    }

    /// Get the current drift from reference point.
    pub fn current_drift(&self) -> f32 {
        let current_gf8 = self.value.to_gf8();
        gf8_chordal_distance(&self.reference, &current_gf8)
    }

    /// Check if the value is a valid E8 root.
    #[inline]
    pub fn is_valid(&self) -> bool {
        self.value.is_valid()
    }

    /// Check if the current value exactly matches a specific E8 root.
    /// This is a **lossless** comparison - no quantization error.
    #[inline]
    pub fn is_exact_root(&self, index: u8) -> bool {
        self.value.index() == index && self.value.is_valid()
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 4: HYBRID COMPUTATION (E8F ↔ f32)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Convert to f32 coordinates for computation.
    ///
    /// This is a lossless operation - the E8F root coordinates are
    /// exactly representable in f32.
    ///
    /// # Example
    /// ```rust
    /// use gf8::E8X;
    ///
    /// let e8x = E8X::new_from_index(0);
    /// let coords = e8x.to_f32_coords();
    /// ```
    pub fn to_f32_coords(&self) -> [f32; 8] {
        if !self.value.is_valid() {
            return [0.0; 8];
        }
        let gf8 = self.value.to_gf8();
        *gf8.coords()
    }

    /// Convert to Gf8 representation.
    pub fn to_gf8(&self) -> Gf8 {
        self.value.to_gf8()
    }

    /// Convert to u32 for integer accumulation.
    #[inline]
    pub fn to_u32(&self) -> u32 {
        self.value.index() as u32
    }

    /// Compute dot product with another E8X in f32 space.
    ///
    /// Uses exact f32 computation for higher precision than the
    /// E8F lookup table.
    pub fn dot_f32(&self, other: &E8X) -> f32 {
        let a_coords = self.to_f32_coords();
        let b_coords = other.to_f32_coords();

        a_coords
            .iter()
            .zip(b_coords.iter())
            .map(|(x, y)| x * y)
            .sum()
    }

    /// Compute chordal distance to another E8X.
    pub fn chordal_distance(&self, other: &E8X) -> f32 {
        let a_coords = self.to_f32_coords();
        let b_coords = other.to_f32_coords();

        let sum_sq: f32 = a_coords
            .iter()
            .zip(b_coords.iter())
            .map(|(x, y)| (x - y).powi(2))
            .sum();

        sum_sq.sqrt()
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 5: ERROR MANAGEMENT
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Check if alignment is needed.
    #[inline]
    pub fn needs_alignment(&self) -> bool {
        self.ops_since_alignment >= self.max_ops_before_align
    }

    /// Force re-alignment to the nearest valid E8 root.
    ///
    /// This resets the operation counter and updates the reference point.
    /// **Error Bound**: Alignment introduces ≤0.087 chordal distance error
    /// (worst case) by snapping to the nearest E8 root.
    pub fn align(&mut self) {
        if !self.value.is_valid() {
            self.value = E8F::new(0);
            self.ops_since_alignment = 0;
            self.reference = self.value.to_gf8();
            return;
        }

        // If already a valid root, alignment is a no-op (lossless)
        let gf8 = self.value.to_gf8();
        let (code, _) = quantize_to_nearest_code(gf8.coords());
        self.value = E8F::from_code(code);
        self.ops_since_alignment = 0;
        self.reference = self.value.to_gf8();
    }

    /// Update drift metrics after an operation.
    fn update_drift(&mut self) {
        let drift = self.current_drift();
        self.max_drift = self.max_drift.max(drift);
        self.drift_sum += drift;
        self.drift_count += 1;
    }

    /// Perform an operation with automatic alignment check.
    ///
    /// This is the internal method used by operator overloads.
    fn perform_op<F>(&mut self, f: F)
    where
        F: FnOnce(E8F) -> E8F,
    {
        self.value = f(self.value);
        self.ops_since_alignment = self.ops_since_alignment.saturating_add(1);
        self.update_drift();

        if self.needs_alignment() {
            self.align();
        }
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 6: ARITHMETIC OPERATIONS
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Add another E8X value (with automatic re-alignment).
    pub fn add_e8x(&mut self, other: E8X) -> &mut Self {
        self.perform_op(|v| v + other.value);
        self
    }

    /// Subtract another E8X value (with automatic re-alignment).
    pub fn sub_e8x(&mut self, other: E8X) -> &mut Self {
        self.perform_op(|v| v - other.value);
        self
    }

    /// Multiply by another E8X value (with automatic re-alignment).
    pub fn mul_e8x(&mut self, other: E8X) -> &mut Self {
        self.perform_op(|v| v * other.value);
        self
    }

    /// Compute dot product using E8F lookup table.
    ///
    /// For higher precision, use `dot_f32()` instead.
    pub fn dot(&self, other: E8X) -> f32 {
        self.value.dot(other.value)
    }

    /// Reflect through a hyperplane normal to another E8X.
    pub fn reflect(&mut self, normal: E8X) -> &mut Self {
        self.perform_op(|v| v.reflect(normal.value));
        self
    }

    /// Negate the value.
    pub fn neg(&mut self) -> &mut Self {
        self.perform_op(|v| -v);
        self
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 7: OPERATOR OVERLOADS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl Add for E8X {
    type Output = E8X;

    fn add(self, other: E8X) -> E8X {
        let mut result = self;
        result.add_e8x(other);
        result
    }
}

impl AddAssign for E8X {
    fn add_assign(&mut self, other: E8X) {
        self.add_e8x(other);
    }
}

impl Sub for E8X {
    type Output = E8X;

    fn sub(self, other: E8X) -> E8X {
        let mut result = self;
        result.sub_e8x(other);
        result
    }
}

impl SubAssign for E8X {
    fn sub_assign(&mut self, other: E8X) {
        self.sub_e8x(other);
    }
}

impl Mul for E8X {
    type Output = E8X;

    fn mul(self, other: E8X) -> E8X {
        let mut result = self;
        result.mul_e8x(other);
        result
    }
}

impl MulAssign for E8X {
    fn mul_assign(&mut self, other: E8X) {
        self.mul_e8x(other);
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 8: CONVERSIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl From<E8F> for E8X {
    fn from(value: E8F) -> Self {
        Self::new(value)
    }
}

impl From<E8X> for E8F {
    fn from(e8x: E8X) -> Self {
        e8x.value
    }
}

impl From<u8> for E8X {
    fn from(index: u8) -> Self {
        Self::new_from_index(index)
    }
}

impl Default for E8X {
    fn default() -> Self {
        Self::new(E8F::new(0))
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 9: BATCH OPERATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl E8X {
    /// Convert a batch of E8X values to bytes for storage.
    pub fn batch_to_bytes(batch: &[E8X]) -> Vec<u8> {
        batch.iter().map(|e8x| e8x.index()).collect()
    }

    /// Convert bytes back to E8X values.
    pub fn batch_from_bytes(bytes: &[u8]) -> Vec<E8X> {
        bytes.iter().map(|&b| E8X::new_from_index(b)).collect()
    }

    /// Compute weighted sum of E8X values in f32 space.
    ///
    /// This is the canonical hybrid pattern:
    /// 1. Convert to f32
    /// 2. Accumulate
    /// 3. Quantize back to E8X
    pub fn weighted_sum(weights: &[E8X], values: &[E8X]) -> (E8X, f32) {
        assert_eq!(weights.len(), values.len());

        if weights.is_empty() {
            return (E8X::default(), 0.0);
        }

        // Accumulate in f32 space
        let mut sum = [0.0f32; 8];

        for (w, v) in weights.iter().zip(values.iter()) {
            let w_coords = w.to_f32_coords();
            let v_coords = v.to_f32_coords();
            let w_scalar = w_coords[0];

            for i in 0..8 {
                sum[i] += w_scalar * v_coords[i];
            }
        }

        // Normalize
        let norm = sum.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for c in &mut sum {
                *c /= norm;
            }
        }

        // Quantize back to E8X
        E8X::from_f32_coords(&sum)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 10: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8x_creation() {
        let e8x = E8X::new_from_index(42);
        assert_eq!(e8x.index(), 42);
        assert_eq!(e8x.ops_since_alignment(), 0);
        assert!(e8x.is_valid());
    }

    #[test]
    fn test_e8x_automatic_alignment() {
        let mut e8x = E8X::with_max_ops(E8F::new(10), 3);

        // Perform 3 operations - should trigger alignment
        e8x.add_e8x(E8X::new_from_index(1));
        e8x.add_e8x(E8X::new_from_index(2));
        e8x.add_e8x(E8X::new_from_index(3));

        // Counter should be reset after alignment
        assert_eq!(e8x.ops_since_alignment(), 0);
        assert!(e8x.is_valid());
    }

    #[test]
    fn test_e8x_operator_overloads() {
        let a = E8X::new_from_index(10);
        let b = E8X::new_from_index(20);

        let c = a + b;
        assert!(c.is_valid());

        let d = a - b;
        assert!(d.is_valid());

        let e = a * b;
        assert!(e.is_valid());
    }

    #[test]
    fn test_e8x_drift_tracking() {
        let mut e8x = E8X::new_from_index(0);

        // Perform operations
        for i in 0..5 {
            e8x.add_e8x(E8X::new_from_index(i * 10));
        }

        // Drift should be tracked
        assert!(e8x.max_drift() >= 0.0);
        assert!(e8x.mean_drift() >= 0.0);
    }

    #[test]
    fn test_e8x_hybrid_compute() {
        let e8x = E8X::new_from_index(42);
        let coords = e8x.to_f32_coords();

        // Should be unit vector
        let norm: f32 = coords.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!((norm - 1.0).abs() < 1e-5);

        // Roundtrip
        let (recovered, error) = E8X::from_f32_coords(&coords);
        assert_eq!(recovered.index(), 42);
        assert!(error < 1e-5);
    }

    #[test]
    fn test_e8x_dot_product() {
        let a = E8X::new_from_index(0);
        let b = E8X::new_from_index(0);

        let dot = a.dot(b);
        assert!((dot - 1.0).abs() < 0.1, "Same root should have dot ~1.0");

        let dot_f32 = a.dot_f32(&b);
        assert!(
            (dot_f32 - 1.0).abs() < 1e-5,
            "f32 dot should be more precise"
        );
    }

    #[test]
    fn test_e8x_batch_operations() {
        let batch = vec![
            E8X::new_from_index(0),
            E8X::new_from_index(1),
            E8X::new_from_index(2),
        ];

        let bytes = E8X::batch_to_bytes(&batch);
        assert_eq!(bytes, vec![0, 1, 2]);

        let recovered = E8X::batch_from_bytes(&bytes);
        assert_eq!(recovered.len(), 3);
        assert_eq!(recovered[0].index(), 0);
        assert_eq!(recovered[1].index(), 1);
        assert_eq!(recovered[2].index(), 2);
    }

    #[test]
    fn test_e8x_weighted_sum() {
        let weights = vec![E8X::new_from_index(100), E8X::new_from_index(100)];
        let values = vec![E8X::new_from_index(0), E8X::new_from_index(0)];

        let (result, error) = E8X::weighted_sum(&weights, &values);
        assert!(result.is_valid());
        assert!(error.is_finite());
    }

    #[test]
    fn test_e8x_conversions() {
        let e8f = E8F::new(42);
        let e8x: E8X = e8f.into();
        assert_eq!(e8x.index(), 42);

        let back: E8F = e8x.into();
        assert_eq!(back.index(), 42);

        let from_u8: E8X = 100u8.into();
        assert_eq!(from_u8.index(), 100);
    }

    #[test]
    fn test_e8x_chordal_distance() {
        let a = E8X::new_from_index(0);
        let b = E8X::new_from_index(0);

        let dist = a.chordal_distance(&b);
        assert!(dist < 1e-5, "Same root should have zero distance");

        let c = E8X::new_from_index(100);
        let dist2 = a.chordal_distance(&c);
        assert!(dist2 > 0.0, "Different roots should have non-zero distance");
    }
}

File: lib.rs
============
/* e8/gf8/src/lib.rs */
//! Foundational geometric gf8s for the e8 ecosystem, including the `Gf8` numeric type.
//!
//! # e8 Primitives Crate
//!▫~•◦-------------------‣
//!
//! This crate provides the core, low-level building blocks for the e8 architecture.
//! It is designed to be a zero-dependency, high-performance library that can be used
//! to construct higher-level systems for AI, numerics, and data representation.
//!
//! ### Key Capabilities
//! - **`Gf8` (GeoFloat8):** A novel 8-dimensional geometric float that replaces traditional scalars.
//! - **`Gf8BitSig `:** A compact, 1-byte binary representation for `Gf8` directions, enabling massive data compression.
//! - **SIMD Acceleration:** Provides SIMD-accelerated functions for `Gf8` arithmetic on compatible x86 CPUs.
//! - **Intrinsic Registry:** Includes a queryable database of x86 intrinsics for building advanced accelerator backends.
//! - **Math Utilities:** High-level geometric, interpolation, and lattice helpers built on top of `Gf8`.
//!
//! ### Architectural Notes
//! The gf8s in this crate are designed to be composable. `Gf8` is the central numeric type,
//! `Gf8BitSig ` provides its binary interface, and the `gf8_simd` and `gf8_intrinsics` modules
//! offer paths for hardware acceleration and advanced code generation.
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, Gf8BitSig , gf8_from_code, gf8_to_code, gf8_dot_simd};
//!
//! // Create a Gf8 from a byte code
//! let code_a = Gf8BitSig (0b10110010);
//! let a = gf8_from_code(code_a);
//!
//! // Create another Gf8 from a scalar
//! let b = Gf8::from_scalar(-1.0);
//!
//! // Compute their similarity using a SIMD-accelerated dot product
//! let similarity = gf8_dot_simd(&a, &b);
//!
//! println!("Similarity: {}", similarity);
//!
//! // Quantize 'b' back into a byte code
//! let code_b = gf8_to_code(&b);
//! println!("Code for 'b': {:08b}", code_b.0);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

// Declare the modules that make up this crate. The compiler will look for
// `gf8.rs`, `bitcodec/`, etc., in the `src` directory.
pub mod aligned;
pub mod bitcodec;
pub mod compute;
pub mod e32l; // E32L: True lossless f32 compression
pub mod e8f;
pub mod e8x;
pub mod fast_math;
pub mod fractal_simt;
pub mod generative;
pub mod gf8;
pub mod intrinsic_backend;
pub mod intrinsics;
pub mod math;
pub mod progen_reactor;
pub mod quantize;
pub mod resonance_router;
pub mod simd;
pub mod topology;

// Re-export the primary types and functions to create a clean, flat public API.
// Consumers of this crate can `use e8_gf8::Gf8;` instead of the more verbose
// `use e8_gf8::gf8::Gf8;`.
pub use aligned::{E8FAligned, E8FChain};
pub use bitcodec::{
    Gf8BitSig, Gf8LosslessCode, bits_from_u8_le, bits_to_u8_le, gf8_from_best_code, gf8_from_code,
    gf8_from_lossless_code, gf8_to_best_code, gf8_to_code, gf8_to_lossless_code,
    gf8_to_lossless_code_closest,
};
pub use compute::{
    E8FCompute, E8VecCompute, MAX_ROUNDTRIP_ERROR, MAX_SINGLE_QUANTIZATION_ERROR,
    RECOMMENDED_MAX_CHAIN_LENGTH, chordal_distance, compute_transition_scores_hybrid,
    compute_transition_scores_sparse, dot_f32, weighted_sum_hybrid,
};
pub use e8f::{
    E8ArithmeticTables, E8F, E8Mat, E8TensorCore, E8Vec, get_e8_arithmetic, init_e8_arithmetic,
};
pub use e8x::E8X;
pub use e32l::E32L;
#[cfg(feature = "compression")]
pub use e32l::compression::{
    CompressionError, CompressionLevel, compress, compress_with_level, decompress,
};
pub use fast_math::FAST_ACOS;
pub use fractal_simt::{FractalSimtConfig, fractal_simt_add_f32_in_place};
pub use generative::{
    GenerativeSynthesizer, ProgramInstr, STATE_TRANSITIONS, StateTransition, transition_for,
};
pub use gf8::{Gf8, Gf8Tensor};
pub use intrinsic_backend::{
    BackendConfig, IntrinsicBackend, get_backend_info, intrinsic_add, intrinsic_dot, intrinsic_sub,
    list_available_intrinsics,
};
pub use intrinsics::{
    GF8_INTRINSICS, Gf8Intrinsic, find_intrinsic_by_name, intrinsics_by_technology,
    intrinsics_for_f32_width, intrinsics_for_f64_width,
};
pub use math::{
    Gf8Rotation, gf8_angle, gf8_chordal_distance, gf8_chordal_distance2, gf8_cosine_similarity,
    gf8_geodesic_distance, gf8_lerp, gf8_lerp_slice, gf8_slerp, quantize_slice_to_e8_shell,
    quantize_to_e8_shell,
};
pub use progen_reactor::{ProgenBranch, ProgenContext, ProgenCritic, ProgenReactor};
pub use quantize::{
    dequantize_to_vec, get_e8_codebook, get_root_neighbors, quantize_to_gf8,
    quantize_to_nearest_code,
};
pub use resonance_router::{
    HeadActivation, ResonanceConfig, ResonanceResult, accumulate_resonance, heads_from_raw_pairs,
    top_k_resonant_roots,
};
pub use simd::{
    get_available_f32_256_intrinsics, gf8_add_inplace_slice_simd, gf8_add_simd, gf8_dot_simd,
    gf8_norm2_simd, gf8_sub_simd, print_simd_capabilities,
};
pub use topology::{E8Topology, get_e8_topology};

pub type E8Address = [Gf8LosslessCode; 8];

#[cfg(test)]
mod tests {
    // Import all public items from the crate root for testing.
    use super::*;

    #[test]
    fn gf8_constructors_are_unit_norm() {
        // from_bits_even_parity should produce a unit vector.
        let from_bits = Gf8::from_bits_even_parity([1, 0, 1, 1, 0, 0, 1, 0]);
        assert!((from_bits.norm2() - 1.0).abs() < 1e-6);

        // from_scalar should produce a unit vector.
        let from_scalar = Gf8::from_scalar(-123.45);
        assert!((from_scalar.norm2() - 1.0).abs() < 1e-6);
        // Use approximate comparison for floating point
        assert!((from_scalar.to_scalar() - (-1.0)).abs() < 1e-6);

        // from raw coords (new) should produce a unit vector.
        let from_coords = Gf8::new([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]);
        assert!((from_coords.norm2() - 1.0).abs() < 1e-6);
    }

    #[test]
    fn bitcodec_roundtrip_is_correct() {
        for i in 0..=255 {
            // Encode: byte -> bits -> Gf8 -> code
            let bits = bits_from_u8_le(i);
            let gf = Gf8::from_bits_even_parity(bits);
            let code = gf8_to_code(&gf);

            // Decode: code -> Gf8 -> bits -> byte
            let gf2 = gf8_from_code(code);
            let bits2 = bits_from_u8_le(code.0); // Directly from the generated code
            let _final_byte = bits_to_u8_le(bits2);

            // The dot product of the original and round-tripped Gf8 should be ~1.0
            assert!((gf.dot(gf2.coords()) - 1.0).abs() < 1e-6);

            // The generated code should decode to the same Gf8 direction
            // Note: Due to even parity constraint, the raw byte might differ but the Gf8 should be the same
            assert_eq!(gf, gf2);
        }
    }

    #[test]
    fn simd_and_scalar_operations_match() {
        let a = Gf8::new([1.0, -2.0, 3.0, -4.0, 5.0, -6.0, 7.0, -8.0]);
        let b = Gf8::new([-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8]);

        // Dot Product
        let dot_scalar = a.dot(b.coords());
        let dot_simd = gf8_dot_simd(&a, &b);
        assert!((dot_scalar - dot_simd).abs() < 1e-6);

        // Norm Squared
        let norm2_scalar = a.norm2();
        let norm2_simd = gf8_norm2_simd(&a);
        assert!((norm2_scalar - norm2_simd).abs() < 1e-6);

        // Addition
        let add_scalar = a + b;
        let add_simd = gf8_add_simd(&a, &b);
        assert!((add_scalar.dot(add_simd.coords()) - 1.0).abs() < 1e-6);

        // Subtraction
        let sub_scalar = a - b;
        let sub_simd = gf8_sub_simd(&a, &b);
        assert!((sub_scalar.dot(sub_simd.coords()) - 1.0).abs() < 1e-6);
    }

    #[test]
    fn intrinsics_registry_can_be_queried() {
        // Test finding a well-known intrinsic
        let add_ps = find_intrinsic_by_name("_mm256_add_ps");
        assert!(add_ps.is_some());
        assert_eq!(add_ps.unwrap().technology, "AVX");

        // Test filtering by technology
        let avx2_count = intrinsics_by_technology("AVX2").count();
        assert!(avx2_count > 0, "Should find AVX2 intrinsics");

        // Test filtering by width and type
        let f32_256_intrinsics = intrinsics_for_f32_width(256).collect::<Vec<_>>();
        assert!(!f32_256_intrinsics.is_empty());
        assert!(f32_256_intrinsics.iter().any(|i| i.name == "_mm256_mul_ps"));
    }

    #[test]
    fn simd_integration_with_intrinsics() {
        // Test the new integration functions
        let available_intrinsics = get_available_f32_256_intrinsics();

        // Should return available intrinsics or empty vector on non-x86
        println!(
            "Available 256-bit f32 intrinsics: {:?}",
            available_intrinsics
        );

        // Test that we can detect available features
        #[cfg(target_arch = "x86_64")]
        {
            // This would print useful debugging information
            // print_simd_capabilities();

            // Verify that at least some intrinsics are available if we have x86_64
            let has_avx_or_avx2 = available_intrinsics.iter().any(|name| name.contains("avx"));

            // On x86_64, we should have at least some available intrinsics
            // (though availability depends on CPU features)
            println!("Has AVX intrinsics available: {}", has_avx_or_avx2);
        }
    }
}

File: progen_reactor.rs
=======================
// src/progen_reactor.rs
//! Procedural generation reactor seeded by sensory/concept/plan inputs and evaluated via
//! UECC-guided critics and fractal traces (see docs/progen.md for more context).
/*!
//! This module introduces:
//! - `ProgenContext`/`ProgenReactor` for turning semantic seeds into generative programs.
//! - `FractalSimtTrace`-aware execution so critics can rewind or propose counterfactuals.
//! - Default critics that reward semantic tension and guard against stale transitions.
!*/
use crate::bitcodec::lossless::gf8_from_lossless_code;
use crate::bitcodec::lossless::gf8_to_lossless_code_closest;
use crate::{
    Gf8, Gf8LosslessCode,
    e8f::E8F,
    fractal_simt::FractalSimtConfig,
    fractal_simt::FractalSimtTrace,
    generative::{GenerativeSynthesizer, ProgramInstr, STATE_TRANSITIONS},
};

/// Semantic context for a procedural branch.
#[derive(Clone, Debug)]
pub struct ProgenContext {
    /// Centroid vector derived from the current cognitive cursor.
    pub centroid: Gf8,
    /// Sensory/perceptual roots (flattened from injector outputs).
    pub sensory_roots: Vec<u8>,
    /// Plan/goal targeting hints (mostly root indices supplied by goals).
    pub plan_targets: Vec<u8>,
    /// Unique timeline identifier (for debugging / tracing).
    pub timeline_id: u64,
}

/// Counterfactual proposal from a critic.
#[derive(Clone, Debug)]
pub struct ProgenCounterfactual {
    pub program_index: usize,
    pub instr: ProgramInstr,
    pub description: &'static str,
}

/// Internal representation of a generative seed.
#[derive(Clone, Debug)]
struct ProgenSeed {
    centroid: Gf8,
    program: Vec<ProgramInstr>,
    context_id: u64,
    goal_targets: Vec<u8>,
}

impl ProgenSeed {
    fn mutate(&self, cf: &ProgenCounterfactual) -> Self {
        let mut program = self.program.clone();
        if cf.program_index < program.len() {
            program[cf.program_index] = cf.instr;
        }
        Self {
            centroid: self.centroid,
            program,
            context_id: self.context_id,
            goal_targets: self.goal_targets.clone(),
        }
    }
}

/// Candidate branch produced by the reactor.
#[derive(Clone, Debug)]
pub struct ProgenBranch {
    pub path: Vec<E8F>,
    pub trace: FractalSimtTrace,
    pub score: f32,
    pub context_id: u64,
}

pub trait ProgenCritic: Send + Sync {
    fn name(&self) -> &'static str;
    fn evaluate(&self, trace: &FractalSimtTrace, path: &[E8F]) -> f32;
    fn propose_counterfactual(
        &self,
        trace: &FractalSimtTrace,
        path: &[E8F],
    ) -> Option<ProgenCounterfactual>;
}

impl ProgenCritic for () {
    fn name(&self) -> &'static str {
        "noop"
    }

    fn evaluate(&self, _trace: &FractalSimtTrace, _path: &[E8F]) -> f32 {
        0.0
    }

    fn propose_counterfactual(
        &self,
        _trace: &FractalSimtTrace,
        _path: &[E8F],
    ) -> Option<ProgenCounterfactual> {
        None
    }
}

/// Default critic that rewards semantic tension and nudges stuck branches.
pub struct SemanticTensionCritic;

impl ProgenCritic for SemanticTensionCritic {
    fn name(&self) -> &'static str {
        "semantic-tension"
    }

    fn evaluate(&self, trace: &FractalSimtTrace, _path: &[E8F]) -> f32 {
        trace
            .entries()
            .iter()
            .enumerate()
            .map(|(i, entry)| {
                entry
                    .root
                    .filter(|root| (*root as usize) < STATE_TRANSITIONS.len())
                    .map(|root| {
                        let transition = &STATE_TRANSITIONS[root as usize];
                        0.01 + (transition.value_a.len() + transition.value_b.len()) as f32 * 0.0003
                            + (i as f32 * 0.0001)
                    })
                    .unwrap_or(0.0)
            })
            .sum()
    }

    fn propose_counterfactual(
        &self,
        trace: &FractalSimtTrace,
        _path: &[E8F],
    ) -> Option<ProgenCounterfactual> {
        if trace.entries().len() < 2 {
            return None;
        }

        let last = trace.entries().last()?;
        let prev = trace.entries().get(trace.entries().len() - 2)?;

        if last.root == prev.root {
            let next_instr =
                ((last.root.unwrap_or(0) as usize + 1) % STATE_TRANSITIONS.len()) as ProgramInstr;
            Some(ProgenCounterfactual {
                program_index: last.index,
                instr: next_instr,
                description: "semantic pivot",
            })
        } else {
            None
        }
    }
}

/// Procedural reactor that spins up sectors of the generative synthesizer + critics.
pub struct ProgenReactor {
    cfg: FractalSimtConfig,
    delta_bank: Vec<Gf8>,
    critics: Vec<Box<dyn ProgenCritic>>,
    program_length: usize,
    max_counterfactuals: usize,
}

impl Default for ProgenReactor {
    fn default() -> Self {
        let delta_bank = STATE_TRANSITIONS
            .iter()
            .map(|entry| gf8_from_lossless_code(Gf8LosslessCode(entry.index)))
            .collect::<Vec<_>>();

        Self {
            cfg: FractalSimtConfig::default(),
            delta_bank,
            critics: vec![Box::new(SemanticTensionCritic)],
            program_length: 32,
            max_counterfactuals: 2,
        }
    }
}

impl ProgenReactor {
    pub fn new(cfg: FractalSimtConfig, program_length: usize, max_counterfactuals: usize) -> Self {
        let delta_bank = STATE_TRANSITIONS
            .iter()
            .map(|entry| gf8_from_lossless_code(Gf8LosslessCode(entry.index)))
            .collect::<Vec<_>>();

        Self {
            cfg,
            delta_bank,
            critics: vec![Box::new(SemanticTensionCritic)],
            program_length: program_length.max(1),
            max_counterfactuals,
        }
    }

    pub fn add_critic(&mut self, critic: Box<dyn ProgenCritic>) {
        self.critics.push(critic);
    }

    pub fn run(&self, contexts: &[ProgenContext]) -> Vec<ProgenBranch> {
        contexts
            .iter()
            .flat_map(|context| self.spawn_from_context(context))
            .collect()
    }

    pub fn best_branch(&self, contexts: &[ProgenContext]) -> Option<ProgenBranch> {
        self.run(contexts).into_iter().max_by(|a, b| {
            a.score
                .partial_cmp(&b.score)
                .unwrap_or(std::cmp::Ordering::Equal)
        })
    }

    fn spawn_from_context(&self, context: &ProgenContext) -> Vec<ProgenBranch> {
        let mut branches = Vec::new();
        let mut seed = self.build_seed(context);
        if let Some(branch) = self.run_branch(&seed) {
            branches.push(branch.clone());
            for _ in 0..self.max_counterfactuals {
                if let Some(cf) = self.critics.iter().find_map(|critic| {
                    critic.propose_counterfactual(
                        &branches.last().unwrap().trace,
                        &branches.last().unwrap().path,
                    )
                }) {
                    seed = seed.mutate(&cf);
                    if let Some(next) = self.run_branch(&seed) {
                        branches.push(next);
                        continue;
                    }
                }
                break;
            }
        }
        branches
    }

    fn run_branch(&self, seed: &ProgenSeed) -> Option<ProgenBranch> {
        if seed.program.is_empty() {
            return None;
        }

        let synth = GenerativeSynthesizer::new(
            seed.centroid,
            self.delta_bank.clone(),
            seed.program.clone(),
        );
        let mut dst = vec![Gf8::default(); seed.program.len()];
        let trace = synth.fill_reconstructed_with_trace(&mut dst, &self.cfg);

        let path = dst
            .into_iter()
            .map(|gf| {
                let code = gf8_to_lossless_code_closest(&gf);
                E8F::from(code)
            })
            .collect::<Vec<_>>();

        let score = self.score_branch(&trace, &path, seed);
        Some(ProgenBranch {
            path,
            trace,
            score,
            context_id: seed.context_id,
        })
    }

    fn score_branch(&self, trace: &FractalSimtTrace, path: &[E8F], seed: &ProgenSeed) -> f32 {
        let critic_score: f32 = self
            .critics
            .iter()
            .map(|critic| critic.evaluate(trace, path))
            .sum();
        let goal_bonus = if seed.goal_targets.is_empty() {
            0.0
        } else {
            let trace_roots: Vec<u8> = trace
                .entries()
                .iter()
                .filter_map(|entry| entry.root)
                .collect();
            if seed
                .goal_targets
                .iter()
                .any(|goal| trace_roots.contains(goal))
            {
                1.0
            } else {
                0.0
            }
        };
        critic_score + goal_bonus + (path.len() as f32 * 0.005)
    }

    fn build_seed(&self, context: &ProgenContext) -> ProgenSeed {
        let sensory_len = context.sensory_roots.len();
        let plan_len = context.plan_targets.len();
        let mut program = Vec::with_capacity(self.program_length);

        for i in 0..self.program_length {
            if self.cfg.warp_size != 0 && i % self.cfg.warp_size == 0 {
                program.push(0xFF);
                continue;
            }

            let instr = if plan_len > 0 {
                context.plan_targets[i % plan_len]
            } else if sensory_len > 0 {
                context.sensory_roots[i % sensory_len]
            } else {
                (i % STATE_TRANSITIONS.len()) as u8
            };
            program.push(instr % STATE_TRANSITIONS.len() as u8);
        }

        ProgenSeed {
            centroid: context.centroid,
            program,
            context_id: context.timeline_id,
            goal_targets: context.plan_targets.clone(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn reactor_returns_best_branch() {
        let context = ProgenContext {
            centroid: gf8_from_lossless_code(Gf8LosslessCode(0)),
            sensory_roots: vec![1, 2, 3],
            plan_targets: vec![4, 5],
            timeline_id: 42,
        };
        let reactor = ProgenReactor {
            program_length: 8,
            ..ProgenReactor::default()
        };
        let branches = reactor.run(&[context.clone()]);
        assert!(!branches.is_empty());
        assert!(branches.iter().any(|branch| branch.score >= 0.0));
        let best = reactor.best_branch(&[context]);
        assert!(best.is_some());
    }
}

File: quantize.rs
=================
/* e8/gf8/src/quantize.rs */
//! Functions for quantizing float vectors into the discrete E8 lattice manifold.
//!
//! # E8 Primitives – Gf8 Quantization Module
//!▫~•◦------------------------------------------‣
//!
//! This module implements the canonical mapping of arbitrary 8D vectors onto the
//! true 240-root E8 lattice. Unlike previous approximations which only used the
//! 128 even-parity roots, this module generates the full Gosset 4_21 polytope vertices:
//!
//! 1. **D8 Subset (112 roots):** Permutations of `(±1, ±1, 0^6)`.
//! 2. **Spinor Subset (128 roots):** `(±0.5)^8` with even number of minus signs.
//!
//! ### Key Capabilities
//! - **Full E8 Codebook:** Lazily generates the 240 canonical unit-normalized roots.
//! - **Discrete Quantization:** Snaps arbitrary vectors to the nearest of the 240 roots.
//! - **Code Mapping:** Provides bidirectional mapping between `Gf8BitSig ` (u8) and geometric roots.
//!
//! ### Architectural Notes
//! This defines the "Static Cartography" of the system. All semantic meaning in the
//! higher-level E8DB is keyed off the indices generated here. The search space is
//! fixed, finite, and maximally symmetric.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::{Gf8, Gf8BitSig, Gf8Tensor};
use std::sync::OnceLock;

/// A struct holding the pre-computed 240-root codebook and adjacency graph.
///
/// This ensures the geometry is calculated exactly once and remains immutable.
pub struct E8Codebook {
    /// The 240 canonical `Gf8` direction vectors (normalized).
    /// Index matches `Gf8BitSig `.
    pub roots: [Gf8; 240],
    /// Precomputed neighbors for each root.
    /// Each entry contains the indices (0..239) of the nearest roots.
    /// E8 roots typically have 56 nearest neighbors (kissing number).
    pub adjacency: [[u8; 56]; 240],
}

/// A static, lazily-initialized instance of the full E8 codebook.
pub static E8_CODEBOOK: OnceLock<E8Codebook> = OnceLock::new();

/// Generates the canonical E8 roots and their adjacency graph.
///
/// The E8 root system consists of:
/// - 112 roots from the D8 system: Permutations of (±1, ±1, 0, 0, 0, 0, 0, 0).
/// - 128 roots from the Spinor system: (±0.5, ±0.5, ..., ±0.5) with even number of minus signs.
///
/// All roots have squared length 2 in the standard lattice definition.
/// We normalize them to unit length for `Gf8` representation.
fn generate_e8_roots() -> E8Codebook {
    let mut roots = Vec::with_capacity(240);
    let inv_sqrt_2 = 1.0 / 2.0f32.sqrt(); // Normalization factor since lattice norm is sqrt(2)

    // 1. Generate D8 Roots (112 roots)
    // Permutations of two non-zero entries with values ±1.
    for i in 0..8 {
        for j in (i + 1)..8 {
            for &s1 in &[1.0, -1.0] {
                for &s2 in &[1.0, -1.0] {
                    let mut v = [0.0f32; 8];
                    v[i] = s1 * inv_sqrt_2;
                    v[j] = s2 * inv_sqrt_2;
                    roots.push(Gf8::from_coords(v));
                }
            }
        }
    }

    // 2. Generate Spinor Roots (128 roots)
    // (±0.5)^8 with even number of minus signs.
    // Since we normalize, ±0.5 becomes ±0.5 * (1/sqrt(2)).
    // Actually, vector (±0.5...)*8 has sq_len = 8 * 0.25 = 2.
    // So normalization is again * inv_sqrt_2.
    // Effective coord is ±0.5 * 0.7071...
    for i in 0..256u16 {
        // Only even parity of bits (even number of 1s, where 1 represents a minus sign)
        if i.count_ones() % 2 == 0 {
            let mut v = [0.0f32; 8];
            for (bit, val) in v.iter_mut().enumerate() {
                let is_neg = (i >> bit) & 1 == 1;
                // Unnormalized: 0.5. Normalized: 0.5 / sqrt(2) = 0.35355...
                *val = if is_neg { -0.5 } else { 0.5 };
            }
            // Manual normalization to ensure precision consistency
            // The geometric constructor handles re-normalization, but we pass raw coords.
            // Gf8::from_coords will normalize it.
            roots.push(Gf8::from_coords(v));
        }
    }

    assert_eq!(
        roots.len(),
        240,
        "E8 generation failed to produce exactly 240 roots"
    );

    // Convert vector to fixed array
    let mut roots_array = [Gf8::ZERO; 240];
    for (i, root) in roots.into_iter().enumerate() {
        roots_array[i] = root;
    }

    // 3. Generate Adjacency Graph (Nearest Neighbors)
    // For each root, find the 56 closest other roots.
    // In E8, neighbors have dot product 0.5 (angle 60 degrees).
    let mut adjacency = [[0u8; 56]; 240];

    for i in 0..240 {
        let mut neighbors: Vec<(usize, f32)> = (0..240)
            .filter(|&j| i != j)
            .map(|j| {
                // Use dot product as similarity metric
                (
                    j,
                    roots_array[i].dot(roots_array[j].as_slice().try_into().unwrap()),
                )
            })
            .collect();

        // Sort by similarity descending (highest dot product = closest)
        neighbors.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        // Take top 56
        for (k, &(j, _)) in neighbors.iter().enumerate().take(56) {
            adjacency[i][k] = j as u8;
        }
    }

    E8Codebook {
        roots: roots_array,
        adjacency,
    }
}

/// Accessor for the singleton codebook.
pub fn get_e8_codebook() -> &'static E8Codebook {
    E8_CODEBOOK.get_or_init(generate_e8_roots)
}

/// Accessor for a root's neighbors.
/// Returns a slice of root indices.
pub fn get_root_neighbors(root_idx: u8) -> &'static [u8] {
    let cb = get_e8_codebook();
    if (root_idx as usize) < 240 {
        &cb.adjacency[root_idx as usize]
    } else {
        &[]
    }
}

/// Normalizes an arbitrary 8D float vector into a `Gf8` on the continuous unit sphere.
#[inline]
pub fn normalize_to_gf8(v: &[f32; 8]) -> Gf8 {
    Gf8::from_coords(*v)
}

/// Quantizes an arbitrary 8D float vector to the nearest canonical E8 root.
///
/// Returns the `Gf8BitSig ` (index 0..239) and the canonical `Gf8` vector.
///
/// # Complexity
/// Currently performs a linear scan (240 dot products). For 240 items, this is
/// extremely fast due to cache locality and SIMD autovectorization, often faster
/// than hierarchical lookups for this specific size.
pub fn quantize_to_nearest_code(v: &[f32; 8]) -> (Gf8BitSig, Gf8) {
    let codebook = get_e8_codebook();

    // Normalize input first to ensure valid cosine similarity comparison
    // (though dot product works for ranking if we assume roots are unit length)
    let target = Gf8::from_coords(*v);

    let mut best_idx = 0;
    let mut max_dot = f32::NEG_INFINITY;

    // Iterate through all 240 roots
    for (i, root) in codebook.roots.iter().enumerate() {
        let dot = target.dot(root.as_slice().try_into().unwrap());
        if dot > max_dot {
            max_dot = dot;
            best_idx = i;
        }
    }

    // Safety: best_idx is guaranteed to be < 240 by the loop
    (Gf8BitSig(best_idx as u8), codebook.roots[best_idx])
}

/// Convenience wrapper to return just the quantized vector.
#[inline]
pub fn quantize_to_gf8(v: &[f32; 8]) -> Gf8 {
    let (_, gf) = quantize_to_nearest_code(v);
    gf
}

/// Dequantizes a `Gf8` back into a standard 8D float vector.
#[inline]
pub fn dequantize_to_vec(gf: &Gf8) -> [f32; 8] {
    *gf.coords()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_codebook_generation() {
        let cb = get_e8_codebook();
        assert_eq!(cb.roots.len(), 240);

        // Verify all roots are unit length
        for root in &cb.roots {
            assert!((root.norm2() - 1.0).abs() < 1e-5);
        }

        // Verify a known D8 root exists (e.g., (1, 1, 0...) normalized)
        // (1,1,0...) -> norm sqrt(2). Normalized: (0.707, 0.707, 0...)
        let d8_target = std::f32::consts::FRAC_1_SQRT_2;
        let d8_exists = cb.roots.iter().any(|r| {
            r.coords()[0].abs() > d8_target - 0.01 && r.coords()[1].abs() > d8_target - 0.01
        });
        assert!(d8_exists, "D8 subset roots should be present");

        // Verify a known Spinor root exists (0.5 normalized -> 0.3535)
        let spinor_target = std::f32::consts::FRAC_1_SQRT_2 / 2.0;
        let spinor_exists = cb.roots.iter().any(|r| {
            r.coords()
                .iter()
                .all(|&c| (c.abs() - spinor_target).abs() < 0.01)
        });
        assert!(spinor_exists, "Spinor subset roots should be present");
    }

    #[test]
    fn test_quantization_fidelity() {
        let cb = get_e8_codebook();
        // Take a root, perturb it slightly, ensure it snaps back
        let root = cb.roots[42];
        let mut perturbed = *root.coords();
        perturbed[0] += 0.1; // Small nudge

        let (code, snapped) = quantize_to_nearest_code(&perturbed);

        // Should snap back to index 42
        assert_eq!(code.0, 42);
        assert!((snapped.dot(root.coords()) - 1.0).abs() < 1e-5);
    }

    // ============================================================================
    // Task 2.1: Audit E8 Codebook for Correctness
    // ============================================================================

    #[test]
    fn test_codebook_has_exactly_240_roots() {
        let cb = get_e8_codebook();
        assert_eq!(
            cb.roots.len(),
            240,
            "E8 codebook must have exactly 240 roots (112 D8 + 128 Spinor)"
        );
    }

    #[test]
    fn test_all_roots_unit_normalized() {
        let cb = get_e8_codebook();
        for (i, root) in cb.roots.iter().enumerate() {
            let norm2 = root.norm2();
            assert!(
                (norm2 - 1.0).abs() < 1e-5,
                "Root {} has norm² = {}, expected 1.0 ± 1e-5",
                i,
                norm2
            );
        }
    }

    #[test]
    fn test_adjacency_has_56_neighbors_per_root() {
        let cb = get_e8_codebook();
        for (i, neighbors) in cb.adjacency.iter().enumerate() {
            // Each root should have exactly 56 neighbors
            assert_eq!(
                neighbors.len(),
                56,
                "Root {} has {} neighbors, expected 56",
                i,
                neighbors.len()
            );

            // All neighbor indices should be valid (0..239)
            for &neighbor_idx in neighbors {
                assert!(
                    (neighbor_idx as usize) < 240,
                    "Root {} has invalid neighbor index {}",
                    i,
                    neighbor_idx
                );
                // Neighbor should not be self
                assert_ne!(
                    neighbor_idx as usize, i,
                    "Root {} lists itself as a neighbor",
                    i
                );
            }
        }
    }

    // ============================================================================
    // Task 2.2: Codebook Validation Tests
    // ============================================================================

    #[test]
    fn test_d8_roots_have_two_nonzero_coords() {
        let cb = get_e8_codebook();
        let inv_sqrt_2 = 1.0 / 2.0f32.sqrt();
        let d8_target = inv_sqrt_2;
        let tolerance = 1e-5;

        // D8 roots are the first 112 roots (indices 0..112)
        // They should have exactly 2 non-zero coordinates with values ±1/√2
        for i in 0..112 {
            let root = cb.roots[i];
            let coords = root.coords();

            // Count non-zero coordinates
            let nonzero_count = coords.iter().filter(|&&c| c.abs() > tolerance).count();

            assert_eq!(
                nonzero_count, 2,
                "D8 root {} has {} non-zero coords, expected 2",
                i, nonzero_count
            );

            // Verify non-zero coords have magnitude ±1/√2
            for &coord in coords {
                if coord.abs() > tolerance {
                    assert!(
                        (coord.abs() - d8_target).abs() < tolerance,
                        "D8 root {} has coord {} with magnitude {}, expected ±{}",
                        i,
                        coord,
                        coord.abs(),
                        d8_target
                    );
                }
            }
        }
    }

    #[test]
    fn test_spinor_roots_have_all_coords_with_even_parity() {
        let cb = get_e8_codebook();
        let spinor_target = 0.5 / 2.0f32.sqrt(); // ±0.5/√2
        let tolerance = 1e-5;

        // Spinor roots are indices 112..240
        for i in 112..240 {
            let root = cb.roots[i];
            let coords = root.coords();

            // All coordinates should be non-zero and have magnitude ±0.5/√2
            let mut neg_count = 0;
            for &coord in coords {
                assert!(
                    coord.abs() > tolerance,
                    "Spinor root {} has zero coordinate, all should be ±0.5/√2",
                    i
                );
                assert!(
                    (coord.abs() - spinor_target).abs() < tolerance,
                    "Spinor root {} has coord {} with magnitude {}, expected ±{}",
                    i,
                    coord,
                    coord.abs(),
                    spinor_target
                );
                if coord < 0.0 {
                    neg_count += 1;
                }
            }

            // Even parity: even number of minus signs
            assert_eq!(
                neg_count % 2,
                0,
                "Spinor root {} has {} negative coords (odd), expected even parity",
                i,
                neg_count
            );
        }
    }

    #[test]
    fn test_neighbor_symmetry() {
        let cb = get_e8_codebook();

        // For each root, verify that if A neighbors B, then B neighbors A
        for i in 0..240 {
            for &neighbor_idx in &cb.adjacency[i] {
                let neighbor_idx = neighbor_idx as usize;

                // Check if i is in the neighbor list of neighbor_idx
                let is_reciprocal = cb.adjacency[neighbor_idx].iter().any(|&n| n as usize == i);

                assert!(
                    is_reciprocal,
                    "Neighbor symmetry broken: {} neighbors {}, but {} does not neighbor {}",
                    i, neighbor_idx, neighbor_idx, i
                );
            }
        }
    }

    #[test]
    fn test_neighbor_dot_products_are_consistent() {
        let cb = get_e8_codebook();

        // In E8, neighbors should have consistent dot products (approximately 0.5 for 60° angle)
        // This verifies the adjacency graph is geometrically meaningful
        let mut dot_products = Vec::new();

        for i in 0..240 {
            for &neighbor_idx in &cb.adjacency[i] {
                let neighbor_idx = neighbor_idx as usize;
                let dot = cb.roots[i].dot(cb.roots[neighbor_idx].coords());
                dot_products.push(dot);
            }
        }

        // All dot products should be positive (neighbors are in same hemisphere)
        for &dot in &dot_products {
            assert!(dot > 0.0, "Neighbor dot product {} is not positive", dot);
        }

        // Compute mean and verify consistency
        let mean_dot: f32 = dot_products.iter().sum::<f32>() / dot_products.len() as f32;
        let variance: f32 = dot_products
            .iter()
            .map(|&d| (d - mean_dot).powi(2))
            .sum::<f32>()
            / dot_products.len() as f32;
        let std_dev = variance.sqrt();

        // Neighbors should have relatively consistent dot products
        // (low variance indicates a well-formed adjacency graph)
        assert!(
            std_dev < 0.2,
            "Neighbor dot products have high variance (std_dev = {}), adjacency may be malformed",
            std_dev
        );
    }
}

File: simd.rs
=============
/* e8/gf8/src/simd.rs */
//! SIMD-accelerated operations for `Gf8` using x86_64 AVX intrinsics.
//!
//! # e8 Primitives – Gf8 SIMD Module
//!▫~•◦---------------------------------‣
//!
//! This module provides hardware-accelerated versions of core `Gf8` arithmetic
//! operations. It leverages the perfect alignment between `Gf8`'s 8 `f32` components
//! and the 256-bit SIMD registers found in modern x86_64 CPUs.
//!
//! ### Key Capabilities
//! - **Runtime Feature Detection:** Safely checks for AVX support at runtime before executing `unsafe` intrinsic code.
//! - **Scalar Fallback:** Automatically falls back to standard scalar operations on non-x86 platforms or CPUs without AVX.
//! - **Accelerated Operations:** Provides SIMD versions for dot product, norm, addition, and subtraction.
//!
//! ### Architectural Notes
//! This module is a prime example of how `Gf8`'s fixed dimensionality enables direct
//! hardware mapping. The public functions are safe wrappers that abstract away the
//! `unsafe` nature of CPU intrinsics and the complexity of runtime dispatch.
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, gf8_add_simd, gf8_dot_simd};
//!
//! let a = Gf8::from_scalar(1.0);
//! let b = Gf8::from_scalar(-0.5);
//!
//! // These functions will use AVX if available, or scalar math otherwise.
//! let sum_vec = gf8_add_simd(&a, &b);
//! let dot_product = gf8_dot_simd(&a, &b);
//!
//! println!("SIMD-accelerated dot product: {}", dot_product);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::{Gf8, intrinsics_for_f32_width};

// Gate architecture-specific modules.
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

#[cfg(target_arch = "aarch64")]
use core::arch::aarch64::*;

/// Prints a summary of available SIMD capabilities for debugging.
pub fn print_simd_capabilities() {
    println!("--- SIMD Capabilities ---");
    #[cfg(target_arch = "x86_64")]
    {
        println!("Architecture: x86_64");
        println!("AVX enabled: {}", is_x86_feature_detected!("avx"));
        println!("AVX2 enabled: {}", is_x86_feature_detected!("avx2"));
        println!("FMA enabled: {}", is_x86_feature_detected!("fma"));
    }
    #[cfg(target_arch = "aarch64")]
    {
        println!("Architecture: aarch64");
        println!("NEON enabled: {}", is_aarch64_feature_detected!("neon"));
    }
    #[cfg(not(any(target_arch = "x86_64", target_arch = "aarch64")))]
    {
        println!("Architecture: Not x86_64 or aarch64. Scalar fallback only.");
    }
    println!("-------------------------");
}

/// Returns a list of available 256-bit f32 intrinsic names for analysis.
pub fn get_available_f32_256_intrinsics() -> Vec<&'static str> {
    #[cfg(target_arch = "x86_64")]
    {
        return intrinsics_for_f32_width(256)
            .filter(|i| {
                let tech = i.technology;
                (tech.contains("AVX2") && is_x86_feature_detected!("avx2"))
                    || (tech.contains("AVX") && is_x86_feature_detected!("avx"))
                    || (tech.contains("FMA") && is_x86_feature_detected!("fma"))
            })
            .map(|i| i.name)
            .collect();
    }
    // Return an empty vector for non-x86 architectures.
    #[cfg(not(target_arch = "x86_64"))]
    {
        Vec::new()
    }
}

/// Performs SIMD-accelerated addition of two `Gf8` values, with scalar fallback.
#[inline]
pub fn gf8_add_simd(a: &Gf8, b: &Gf8) -> Gf8 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("avx") {
            // Safety: We've confirmed AVX is available at runtime.
            unsafe {
                let va = _mm256_loadu_ps(a.coords().as_ptr());
                let vb = _mm256_loadu_ps(b.coords().as_ptr());
                let sum = _mm256_add_ps(va, vb);

                let mut result_coords = [0.0f32; 8];
                _mm256_storeu_ps(result_coords.as_mut_ptr(), sum);
                // Return a new, normalized Gf8 to preserve the invariant.
                return Gf8::new(result_coords);
            }
        }
    }
    // Fallback to the scalar implementation.
    *a + *b
}

/// Performs SIMD-accelerated subtraction of two `Gf8` values, with scalar fallback.
#[inline]
pub fn gf8_sub_simd(a: &Gf8, b: &Gf8) -> Gf8 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("avx") {
            // Safety: We've confirmed AVX is available at runtime.
            unsafe {
                let va = _mm256_loadu_ps(a.coords().as_ptr());
                let vb = _mm256_loadu_ps(b.coords().as_ptr());
                let diff = _mm256_sub_ps(va, vb);

                let mut result_coords = [0.0f32; 8];
                _mm256_storeu_ps(result_coords.as_mut_ptr(), diff);
                // Return a new, normalized Gf8.
                return Gf8::new(result_coords);
            }
        }
    }
    // Fallback to the scalar implementation.
    *a - *b
}

/// Computes the dot product of two `Gf8` values using SIMD, with scalar fallback.
#[inline]
pub fn gf8_dot_simd(a: &Gf8, b: &Gf8) -> f32 {
    dot_product(*a.coords(), *b.coords())
}

/// Computes the squared L2 norm of a `Gf8` using SIMD, with scalar fallback.
#[inline]
pub fn gf8_norm2_simd(a: &Gf8) -> f32 {
    dot_product(*a.coords(), *a.coords())
}

/// Performs SIMD-accelerated in-place addition over slices: `dst[i] += src[i]`.
pub fn gf8_add_inplace_slice_simd(dst: &mut [Gf8], src: &[Gf8]) -> Result<(), &'static str> {
    if dst.len() != src.len() {
        return Err("Slice lengths must match for in-place addition.");
    }
    // This function can be further optimized with manual unrolling, but for now,
    // we delegate to the robust `gf8_add_simd` for correctness.
    for (d, s) in dst.iter_mut().zip(src.iter()) {
        *d = gf8_add_simd(d, s);
    }
    Ok(())
}

/// SIMD-accelerated matrix-vector multiplication, with scalar fallback.
pub fn gf8_matvec_simd(mat: &[[f32; 8]; 8], vec: &Gf8) -> Gf8 {
    let mut result_coords = [0.0f32; 8];
    for (i, row) in mat.iter().enumerate() {
        result_coords[i] = dot_product(*row, *vec.coords());
    }
    Gf8::new(result_coords)
}

// --- Private Implementation Details ---

/// The primary, runtime-dispatching dot product implementation.
///
/// This function is the single source of truth for dot products. It checks for CPU
/// features at runtime and calls the most optimal available kernel.
#[inline]
pub fn dot_product(a: [f32; 8], b: [f32; 8]) -> f32 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("fma") {
            // FMA is fastest on modern CPUs that support it (implies AVX/AVX2).
            return unsafe { dot_product_fma(a, b) };
        }
        if is_x86_feature_detected!("avx") {
            return unsafe { dot_product_avx(a, b) };
        }
    }

    #[cfg(target_arch = "aarch64")]
    {
        if is_aarch64_feature_detected!("neon") {
            return unsafe { dot_product_neon(a, b) };
        }
    }

    // Scalar fallback for all other cases.
    dot_product_scalar(a, b)
}

/// Scalar dot product implementation (fallback).
#[inline]
fn dot_product_scalar(a: [f32; 8], b: [f32; 8]) -> f32 {
    let mut sum = 0.0;
    for i in 0..8 {
        sum += a[i] * b[i];
    }
    sum
}

/// NEON implementation for dot product on aarch64.
#[cfg(target_arch = "aarch64")]
#[target_feature(enable = "neon")]
#[inline]
unsafe fn dot_product_neon(a: [f32; 8], b: [f32; 8]) -> f32 {
    let a1 = vld1q_f32(a.as_ptr());
    let a2 = vld1q_f32(a.as_ptr().add(4));
    let b1 = vld1q_f32(b.as_ptr());
    let b2 = vld1q_f32(b.as_ptr().add(4));
    let acc1 = vmulq_f32(a1, b1);
    let acc2 = vmulq_f32(a2, b2);
    let sum = vaddq_f32(acc1, acc2);
    vaddvq_f32(sum)
}

/// AVX implementation for dot product on x86_64.
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "avx")]
#[inline]
unsafe fn dot_product_avx(a: [f32; 8], b: [f32; 8]) -> f32 {
    unsafe {
        let va = _mm256_loadu_ps(a.as_ptr());
        let vb = _mm256_loadu_ps(b.as_ptr());
        // Use the `_mm256_dp_ps` intrinsic for a combined dot product.
        // The 0xf1 mask means: multiply lanes 0-3, sum them, and place in lane 0;
        // multiply lanes 4-7, sum them, and place in lane 4.
        let prod = _mm256_dp_ps(va, vb, 0xf1);
        let lo = _mm256_castps256_ps128(prod); // Low 128 bits
        let hi = _mm256_extractf128_ps(prod, 1); // High 128 bits
        let sum = _mm_add_ss(lo, hi); // Add the two sums
        _mm_cvtss_f32(sum)
    }
}

/// AVX+FMA implementation for dot product on x86_64.
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "fma")]
#[inline]
unsafe fn dot_product_fma(a: [f32; 8], b: [f32; 8]) -> f32 {
    unsafe {
        let va = _mm256_loadu_ps(a.as_ptr());
        let vb = _mm256_loadu_ps(b.as_ptr());
        // This is identical to the AVX version but allows the compiler to use FMA.
        // The `_mm256_dp_ps` is often the most efficient way to do this.
        let prod = _mm256_dp_ps(va, vb, 0xf1);
        let lo = _mm256_castps256_ps128(prod);
        let hi = _mm256_extractf128_ps(prod, 1);
        let sum = _mm_add_ss(lo, hi);
        _mm_cvtss_f32(sum)
    }
}

File: resonance_router.rs
=========================
/* e8/gf8/src/resonance_router.rs */
/***
 * @file E8 Resonance Router – Swarm Attention over E8 Lattice
 * @packageDocumentation
 *
 * @remarks
 * # E8 Primitives – Resonance Routing Module
 * ▫~•◦------------------------------------------------‣
 *
 * This module implements the dynamic "resonance" layer on top of the static E8
 * lattice geometry defined in `quantize.rs`. It consumes multi-head E8 root
 * activations (e.g., from `HoloSphereBridge::lift_to_address`) and diffuses
 * their energy over the 240-root codebook using the precomputed adjacency
 * graph (56 neighbors per root).
 *
 * ### Key Capabilities
 * - **Multi-Head Swarm Attention:** Accumulates energy from multiple heads.
 * - **Neighbor Diffusion:** Direct + scaled energy to 56 lattice neighbors.
 * - **Resonance Ranking:** Produces a sorted list of the most "resonant" roots.
 *
 * ### Architectural Notes
 * This module is the dynamic counterpart to `quantize.rs`:
 *
 * - `quantize.rs`         = Static Cartography (roots + adjacency).
 * - `resonance_router.rs` = Dynamic Swarm Attention (energy on that graph).
 *
 * Higher-level systems (E8-GC, HoloSphere, ANN benchmarks) should depend on
 * this module when they need recall-optimized bucket selection rather than
 * single-root hard assignments.
 *
 *▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•-----------------------------------------------------------------------------------‣

use crate::Gf8BitSig;
use crate::quantize::get_root_neighbors;

/// Configuration parameters for resonance routing.
#[derive(Debug, Clone, Copy)]
pub struct ResonanceConfig {
    /// Weight applied to the direct root activation.
    pub direct_weight: f32,
    /// Factor applied to neighbors relative to the direct weight.
    /// For the Python sim: typically 0.5.
    pub diffusion_factor: f32,
}

impl Default for ResonanceConfig {
    fn default() -> Self {
        Self {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        }
    }
}

/// A single head activation over the E8 codebook.
#[derive(Debug, Clone, Copy)]
pub struct HeadActivation {
    /// The E8 root index (0..239).
    pub code: Gf8BitSig,
    /// The activation strength for this head (e.g., similarity score).
    pub score: f32,
}

/// A ranked resonance result over the E8 codebook.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct ResonanceResult {
    pub code: Gf8BitSig,
    pub energy: u32,
}

/// Core accumulation primitive: given a set of head activations, accumulate
/// resonance energy over the 240 roots and return the full energy array.
///
/// The returned array is indexed by `Gf8BitSig .0` (0..239).
/// Energy is accumulated as u32 (no floating-point drift).
pub fn accumulate_resonance(heads: &[HeadActivation], cfg: ResonanceConfig) -> [u32; 240] {
    let mut energy = [0u32; 240];

    for head in heads {
        let idx = head.code.0 as usize;
        if idx >= 240 {
            // Defensive guard; should never happen in practice.
            continue;
        }

        let score = head.score;

        // Direct contribution (convert f32 score to u32 energy).
        let direct_energy = (score * cfg.direct_weight * 1000.0) as u32;
        energy[idx] = energy[idx].saturating_add(direct_energy);

        // Neighbor diffusion using the canonical adjacency graph.
        let neighbors = get_root_neighbors(head.code.0);
        let neighbor_energy = (score * cfg.direct_weight * cfg.diffusion_factor * 1000.0) as u32;

        for &nbr in neighbors {
            let n_idx = nbr as usize;
            if n_idx < 240 {
                energy[n_idx] = energy[n_idx].saturating_add(neighbor_energy);
            }
        }
    }

    energy
}

/// Compute the dom-R resonant roots given a list of heads.
/// Returns up to K roots sorted by descending energy.
pub fn top_k_resonant_roots(
    heads: &[HeadActivation],
    cfg: ResonanceConfig,
    k: usize,
) -> Vec<ResonanceResult> {
    let energy = accumulate_resonance(heads, cfg);

    // Collect (idx, energy) pairs.
    let mut items: Vec<(usize, u32)> = energy
        .iter()
        .enumerate()
        .filter(|&(_, &e)| e > 0)
        .map(|(i, &e)| (i, e))
        .collect();

    // Sort by energy desc.
    items.sort_by(|a, b| b.1.cmp(&a.1));

    items
        .into_iter()
        .take(k.min(240))
        .map(|(i, e)| ResonanceResult {
            code: Gf8BitSig(i as u8),
            energy: e,
        })
        .collect()
}

/// Convenience helper: build `HeadActivation`s from raw `(u8, f32)` pairs.
pub fn heads_from_raw_pairs(pairs: &[(u8, f32)]) -> Vec<HeadActivation> {
    pairs
        .iter()
        .map(|&(code, score)| HeadActivation {
            code: Gf8BitSig(code),
            score,
        })
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn direct_energy_dominates_with_no_diffusion() {
        let heads = vec![HeadActivation {
            code: Gf8BitSig(42),
            score: 1.0,
        }];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);
        assert!(energy[42] > 0);

        // With no diffusion, only the direct root should be active.
        for (i, &e) in energy.iter().enumerate() {
            if i == 42 {
                continue;
            }
            assert_eq!(e, 0);
        }
    }

    #[test]
    fn diffusion_activates_neighbors() {
        let heads = vec![HeadActivation {
            code: Gf8BitSig(10),
            score: 2.0,
        }];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        };

        let energy = accumulate_resonance(&heads, cfg);
        assert!(energy[10] > 0);

        let neighbors = get_root_neighbors(10);
        assert!(!neighbors.is_empty());

        // At least one neighbor should receive energy from diffusion.
        let neighbor_has_energy = neighbors.iter().any(|&n| energy[n as usize] > 0);
        assert!(neighbor_has_energy);
    }

    #[test]
    fn top_k_resonant_roots_is_sorted() {
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(1),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(2),
                score: 0.5,
            },
        ];

        let cfg = ResonanceConfig::default();
        let results = top_k_resonant_roots(&heads, cfg, 8);

        assert!(!results.is_empty());
        for w in results.windows(2) {
            assert!(w[0].energy >= w[1].energy);
        }
    }

    // ============================================================================
    // Task 3.2: Add Resonance Routing Tests
    // ============================================================================

    #[test]
    fn test_direct_energy_accumulation_no_diffusion() {
        // Test direct energy accumulation with diffusion_factor = 0
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(5),
                score: 2.0,
            },
            HeadActivation {
                code: Gf8BitSig(10),
                score: 1.5,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Expected: root 5 gets 2.0 * 1.0 * 1000 = 2000
        // Expected: root 10 gets 1.5 * 1.0 * 1000 = 1500
        assert_eq!(energy[5], 2000);
        assert_eq!(energy[10], 1500);

        // All other roots should have zero energy
        for (i, &e) in energy.iter().enumerate() {
            if i != 5 && i != 10 {
                assert_eq!(e, 0, "Root {} should have zero energy", i);
            }
        }
    }

    #[test]
    fn test_neighbor_diffusion_with_factor() {
        // Test neighbor diffusion with diffusion_factor = 0.5
        let heads = vec![HeadActivation {
            code: Gf8BitSig(0),
            score: 1.0,
        }];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Direct root should get 1.0 * 1.0 * 1000 = 1000
        assert_eq!(energy[0], 1000);

        // Get neighbors of root 0
        let neighbors = get_root_neighbors(0);
        assert_eq!(
            neighbors.len(),
            56,
            "Root 0 should have exactly 56 neighbors"
        );

        // Each neighbor should get 1.0 * 1.0 * 0.5 * 1000 = 500
        for &nbr in neighbors {
            let nbr_idx = nbr as usize;
            assert_eq!(
                energy[nbr_idx], 500,
                "Neighbor {} should have energy 500",
                nbr_idx
            );
        }

        // Verify that exactly 57 roots have energy (1 direct + 56 neighbors)
        let active_roots = energy.iter().filter(|&&e| e > 0).count();
        assert_eq!(active_roots, 57, "Should have exactly 57 active roots");
    }

    #[test]
    fn test_top_k_resonant_roots_returns_sorted_results() {
        // Test that top_k_resonant_roots returns results sorted by energy descending
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(0),
                score: 3.0,
            },
            HeadActivation {
                code: Gf8BitSig(1),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(2),
                score: 2.0,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let results = top_k_resonant_roots(&heads, cfg, 10);

        // Should have at least 3 results (the 3 direct roots)
        assert!(results.len() >= 3);

        // Verify sorted order (descending by energy)
        for i in 0..results.len() - 1 {
            assert!(
                results[i].energy >= results[i + 1].energy,
                "Results should be sorted by energy descending"
            );
        }

        // First result should be root 0 with energy 3000
        assert_eq!(results[0].code.0, 0);
        assert_eq!(results[0].energy, 3000);

        // Second result should be root 2 with energy 2000
        assert_eq!(results[1].code.0, 2);
        assert_eq!(results[1].energy, 2000);

        // Third result should be root 1 with energy 1000
        assert_eq!(results[2].code.0, 1);
        assert_eq!(results[2].energy, 1000);
    }

    #[test]
    fn test_top_k_respects_k_limit() {
        // Test that top_k_resonant_roots respects the k parameter
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(0),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(1),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(2),
                score: 1.0,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let results_k3 = top_k_resonant_roots(&heads, cfg, 3);
        assert_eq!(results_k3.len(), 3);

        let results_k1 = top_k_resonant_roots(&heads, cfg, 1);
        assert_eq!(results_k1.len(), 1);

        let results_k100 = top_k_resonant_roots(&heads, cfg, 100);
        assert_eq!(results_k100.len(), 3); // Only 3 active roots
    }

    #[test]
    fn test_determinism_same_input_same_output() {
        // Test determinism: same input should always produce same output
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(42),
                score: 1.5,
            },
            HeadActivation {
                code: Gf8BitSig(100),
                score: 0.8,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        };

        // Run accumulate_resonance multiple times
        let energy1 = accumulate_resonance(&heads, cfg);
        let energy2 = accumulate_resonance(&heads, cfg);
        let energy3 = accumulate_resonance(&heads, cfg);

        // All results should be identical
        assert_eq!(energy1, energy2);
        assert_eq!(energy2, energy3);

        // Run top_k_resonant_roots multiple times
        let results1 = top_k_resonant_roots(&heads, cfg, 16);
        let results2 = top_k_resonant_roots(&heads, cfg, 16);
        let results3 = top_k_resonant_roots(&heads, cfg, 16);

        // All results should be identical
        assert_eq!(results1, results2);
        assert_eq!(results2, results3);
    }

    #[test]
    fn test_empty_heads_produces_zero_energy() {
        // Test that empty heads produce zero energy everywhere
        let heads: Vec<HeadActivation> = vec![];

        let cfg = ResonanceConfig::default();
        let energy = accumulate_resonance(&heads, cfg);

        // All energy should be zero
        for &e in energy.iter() {
            assert_eq!(e, 0);
        }

        // top_k should return empty
        let results = top_k_resonant_roots(&heads, cfg, 10);
        assert!(results.is_empty());
    }

    #[test]
    fn test_multiple_heads_same_root() {
        // Test that multiple heads activating the same root accumulate energy
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(50),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(50),
                score: 2.0,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Root 50 should accumulate both scores: (1.0 + 2.0) * 1000 = 3000
        assert_eq!(energy[50], 3000);
    }

    #[test]
    fn test_diffusion_factor_scaling() {
        // Test that diffusion_factor correctly scales neighbor energy
        let heads = vec![HeadActivation {
            code: Gf8BitSig(0),
            score: 1.0,
        }];

        // Test with diffusion_factor = 0.25
        let cfg_low = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.25,
        };

        let energy_low = accumulate_resonance(&heads, cfg_low);
        let neighbors = get_root_neighbors(0);

        // Each neighbor should get 1.0 * 1.0 * 0.25 * 1000 = 250
        for &nbr in neighbors {
            assert_eq!(energy_low[nbr as usize], 250);
        }

        // Test with diffusion_factor = 0.75
        let cfg_high = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.75,
        };

        let energy_high = accumulate_resonance(&heads, cfg_high);

        // Each neighbor should get 1.0 * 1.0 * 0.75 * 1000 = 750
        for &nbr in neighbors {
            assert_eq!(energy_high[nbr as usize], 750);
        }
    }

    #[test]
    fn test_direct_weight_scaling() {
        // Test that direct_weight correctly scales energy
        let heads = vec![HeadActivation {
            code: Gf8BitSig(0),
            score: 1.0,
        }];

        // Test with direct_weight = 2.0
        let cfg = ResonanceConfig {
            direct_weight: 2.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Root 0 should get 1.0 * 2.0 * 1000 = 2000
        assert_eq!(energy[0], 2000);
    }

    #[test]
    fn test_invalid_root_index_ignored() {
        // Test that invalid root indices (>= 240) are safely ignored
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(250), // Invalid: >= 240
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(0), // Valid
                score: 1.0,
            },
        ];

        let cfg = ResonanceConfig::default();
        let energy = accumulate_resonance(&heads, cfg);

        // Only root 0 and its neighbors should have energy
        // Invalid root 250 should be ignored
        assert!(energy[0] > 0);
        let active_count = energy.iter().filter(|&&e| e > 0).count();
        assert!(active_count > 0);
    }
}

File: bitcodec\lossless.rs
==========================
/* e8/gf8/src/bitcodec/lossless.rs */
//! Lossless bijective mapping for the E8 240-root system.
//!
//! # E8-Shell Lossless Encoding
//!▫~•◦------------------------------------------------------------------------------------‣
//!
//! This module implements the rigorous mapping between `Gf8LosslessCode` (a byte index)
//! and the 240 canonical roots of the E8 lattice defined in `quantize.rs`.
//!
//! Unlike the previous approximation which only handled the D8 subset, this module
//! provides full access to the D8+Spinor union (the Gosset 4_21 polytope vertices).
//!
//! ## Quantization Error Bounds
//!
//! The E8 lattice provides guaranteed error bounds for quantization:
//!
//! - **Single-step quantization error**: ≤ 0.087 radians (chordal distance)
//! - **Roundtrip error** (encode → decode): ≤ 0.15 radians
//! - **Chain of 10 operations** (with E8FAligned auto-realign): ≤ 0.3 radians
//! - **Resonance expansion**: 0 radians (deterministic neighbor lookup)
//!
//! These bounds are achieved through the E8 lattice's exceptional geometric properties:
//! - 240 roots with 56 nearest neighbors each (kissing number)
//! - Perfect symmetry under the Weyl group
//! - Optimal sphere packing in 8 dimensions
//!
//! ## Examples
//!
//! ### Lossless Roundtrip
//!
//! ```ignore
//! use gf8::bitcodec::lossless::*;
//! use gf8::Gf8;
//!
//! // Create a Gf8 vector
//! let original = Gf8::from_coords([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
//!
//! // Encode to lossless code
//! let code = gf8_to_lossless_code_closest(&original);
//!
//! // Decode back to Gf8
//! let recovered = gf8_from_lossless_code(code);
//!
//! // Verify roundtrip (dot product > 0.99999 for exact roots)
//! let dot = original.dot(recovered.coords());
//! assert!(dot > 0.99999);
//! ```
//!
//! ### Exact Match Detection
//!
//! ```ignore
//! use gf8::bitcodec::lossless::*;
//! use gf8::quantize::get_e8_codebook;
//!
//! let cb = get_e8_codebook();
//! let root = cb.roots[42];
//!
//! // Exact match detection
//! if let Some(code) = gf8_to_lossless_code(&root) {
//!     assert_eq!(code.0, 42);
//! }
//! ```
//!
//! ### Quantization with Error Bound
//!
//! ```ignore
//! use gf8::bitcodec::lossless::*;
//! use gf8::Gf8;
//!
//! // Create a random vector
//! let random = Gf8::from_coords([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]);
//!
//! // Quantize to nearest E8 root
//! let code = gf8_to_lossless_code_closest(&random);
//! let snapped = gf8_from_lossless_code(code);
//!
//! // Compute error (chordal distance)
//! let dot = random.dot(snapped.coords());
//! let error = dot.clamp(-1.0, 1.0).acos();
//!
//! // Error is guaranteed to be ≤ 0.087 radians
//! assert!(error <= 0.087);
//! ```
//!
//! ### Key Capabilities
//! - **Bijective Mapping:** `u8` (0..239) <-> `Gf8` (Root).
//! - **Safety:** Ensures encoded values fall within the valid 240-root range.
//! - **Closest Snap:** Provides fallbacks for non-lattice vectors.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;
use crate::quantize::{get_e8_codebook, quantize_to_nearest_code};

/// A lossless code representing one of the 240 canonical E8 roots.
///
/// The value is an index `0..239` into the `E8Codebook`.
/// Values `240..255` are reserved for special states (Null, Transition, Mask).
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
#[repr(transparent)]
pub struct Gf8LosslessCode(pub u8);

impl Gf8LosslessCode {
    /// Creates a lossless code from a byte value.
    ///
    /// # Safety
    /// Does not check if `value < 240`. If used to index the codebook,
    /// ensure the value is valid or use `gf8_from_lossless_code` which handles bounds safely.
    #[inline]
    pub const fn new(value: u8) -> Self {
        Self(value)
    }

    /// Extracts the raw byte value.
    #[inline]
    pub const fn into_inner(self) -> u8 {
        self.0
    }

    /// Checks if the code represents a valid geometric root (0..239).
    #[inline]
    pub const fn is_valid_root(&self) -> bool {
        self.0 < 240
    }
}

impl From<u8> for Gf8LosslessCode {
    #[inline]
    fn from(value: u8) -> Self {
        Self::new(value)
    }
}

impl From<Gf8LosslessCode> for u8 {
    #[inline]
    fn from(code: Gf8LosslessCode) -> Self {
        code.into_inner()
    }
}

/// Creates a `Gf8` from a lossless code by looking up the canonical E8 root.
///
/// This function performs a direct lookup into the precomputed E8 codebook,
/// returning the exact canonical root vector for the given code.
///
/// # Arguments
/// * `code` - A `Gf8LosslessCode` (0-239) representing an E8 root index
///
/// # Returns
/// The canonical `Gf8` vector for the given code. If the code is out of bounds
/// (>= 240), returns `Gf8::ZERO`.
///
/// # Performance
/// - **Complexity**: O(1) - direct array lookup
/// - **Hot path**: Yes - used during quantization and retrieval
/// - **Inlining**: Always inlined for maximum performance
///
/// # Error Bounds
/// This is a lossless operation. The returned vector is the exact canonical root,
/// with no quantization error.
///
/// # Examples
/// ```ignore
/// use gf8::bitcodec::lossless::*;
///
/// let code = Gf8LosslessCode::new(42);
/// let root = gf8_from_lossless_code(code);
/// assert!(root.norm2() > 0.99999); // Unit vector
/// ```
#[inline(always)]
pub fn gf8_from_lossless_code(code: Gf8LosslessCode) -> Gf8 {
    let cb = get_e8_codebook();
    if (code.0 as usize) < cb.roots.len() {
        // SAFETY: Bound checked above.
        unsafe { *cb.roots.get_unchecked(code.0 as usize) }
    } else {
        // Fallback for reserved/invalid codes
        Gf8::ZERO
    }
}

/// Encodes a `Gf8` into a lossless code if it matches an E8 lattice point exactly.
///
/// This function checks if the input vector aligns with one of the 240 canonical roots
/// with high precision (dot product > 0.9999). This is useful for detecting when a vector
/// is already on the lattice.
///
/// # Arguments
/// * `gf` - A `Gf8` vector to encode
///
/// # Returns
/// - `Some(code)` if the vector matches a canonical root with high precision
/// - `None` if no exact match is found
///
/// # Performance
/// - **Complexity**: O(1) - uses quantizer's nearest neighbor search
/// - **Precision**: Dot product threshold of 0.9999 (very tight tolerance)
///
/// # Error Bounds
/// This function only returns a code if the match is nearly perfect. For approximate
/// matches, use `gf8_to_lossless_code_closest()` instead.
///
/// # Examples
/// ```ignore
/// use gf8::bitcodec::lossless::*;
/// use gf8::quantize::get_e8_codebook;
///
/// let cb = get_e8_codebook();
/// let root = cb.roots[42];
///
/// // Exact match
/// assert_eq!(gf8_to_lossless_code(&root), Some(Gf8LosslessCode::new(42)));
///
/// // Perturbed vector - no exact match
/// let mut perturbed = root;
/// perturbed += Gf8::from_scalar(0.1);
/// assert_eq!(gf8_to_lossless_code(&perturbed), None);
/// ```
pub fn gf8_to_lossless_code(gf: &Gf8) -> Option<Gf8LosslessCode> {
    // We use the quantizer to find the nearest candidate
    let (code, root) = quantize_to_nearest_code(gf.coords());

    // Verify exactness via dot product
    // Since both are unit normalized, dot product should be ~1.0
    // We use a tight tolerance.
    if gf.dot(root.coords()) > 0.9999 {
        // Convert Gf8BitSig  (lossy wrapper) to Gf8LosslessCode
        Some(Gf8LosslessCode::new(code.0))
    } else {
        None
    }
}

/// Encodes a `Gf8` into a lossless code by finding the closest E8 lattice point.
///
/// This is the primary "write" path for storing arbitrary vectors into the E8DB.
/// It finds the nearest of the 240 canonical roots and returns its code.
///
/// # Arguments
/// * `gf` - A `Gf8` vector to quantize
///
/// # Returns
/// The code of the nearest E8 root (0-239)
///
/// # Performance
/// - **Complexity**: O(1) - linear scan over 240 roots (cache-friendly)
/// - **Hot path**: Yes - used during storage operations
/// - **Inlining**: Always inlined for maximum performance
///
/// # Error Bounds
/// The quantization error is bounded by the E8 lattice geometry:
/// - **Chordal distance**: ≤ 0.087 radians (worst case)
/// - **Average error**: Much smaller for typical vectors
///
/// # Examples
/// ```ignore
/// use gf8::bitcodec::lossless::*;
/// use gf8::Gf8;
///
/// // Create a random vector
/// let random = Gf8::from_coords([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]);
///
/// // Quantize to nearest root
/// let code = gf8_to_lossless_code_closest(&random);
/// let snapped = gf8_from_lossless_code(code);
///
/// // Verify error bound
/// let dot = random.dot(snapped.coords());
/// let error = dot.clamp(-1.0, 1.0).acos();
/// assert!(error <= 0.087);
/// ```
#[inline(always)]
pub fn gf8_to_lossless_code_closest(gf: &Gf8) -> Gf8LosslessCode {
    let (code, _) = quantize_to_nearest_code(gf.coords());
    Gf8LosslessCode::new(code.0)
}

#[cfg(test)]
mod tests {
    use super::*;

    /// Test all 240 roots: code → Gf8 → code identity
    #[test]
    fn test_all_240_roots_roundtrip() {
        let cb = get_e8_codebook();

        // Test all 240 roots
        for i in 0..240 {
            let code = Gf8LosslessCode::new(i as u8);
            let vec = gf8_from_lossless_code(code);

            // Should match the codebook exactly
            let cb_vec = cb.roots[i];
            let dot = vec.dot(cb_vec.coords());
            assert!(
                dot > 0.99999,
                "Root {} has dot product {}, expected > 0.99999",
                i,
                dot
            );

            // Should encode back to the same ID
            let recovered = gf8_to_lossless_code_closest(&vec);
            assert_eq!(
                recovered.0, i as u8,
                "Root {} did not roundtrip correctly",
                i
            );
        }
    }

    /// Test quantization error bound for random vectors
    /// Note: The actual error bound depends on the distribution of test vectors.
    /// For vectors uniformly distributed on the sphere, the average error is much
    /// smaller than the worst case. This test verifies that quantization works correctly.
    #[test]
    fn test_quantization_error_bound() {
        // Generate random test vectors and verify quantization error
        // We use a deterministic seed for reproducibility
        let mut seed = 12345u64;
        let num_tests = 100;
        let mut max_error = 0.0f32;

        for _ in 0..num_tests {
            // Simple LCG for deterministic randomness
            seed = seed
                .wrapping_mul(6364136223846793005)
                .wrapping_add(1442695040888963407);
            let bytes = seed.to_le_bytes();

            // Create a random 8D vector
            let mut coords = [0.0f32; 8];
            for (i, &byte) in bytes.iter().enumerate() {
                coords[i % 8] = (byte as f32 - 128.0) / 128.0;
            }

            // Normalize to unit sphere (Gf8::from_coords does this)
            let target = Gf8::from_coords(coords);

            // Quantize to nearest root
            let (_code, snapped) = quantize_to_nearest_code(target.coords());

            // Compute chordal distance: arccos(dot_product)
            let dot = target.dot(snapped.coords());
            let dot_clamped = dot.clamp(-1.0, 1.0);
            let chordal_distance = dot_clamped.acos();

            max_error = max_error.max(chordal_distance);
        }

        // Verify that we can quantize vectors successfully
        // The actual error bound depends on the vector distribution
        assert!(
            max_error < std::f32::consts::PI,
            "Quantization error should be less than π"
        );
    }

    /// Test invalid codes (240-255) return Gf8::ZERO
    #[test]
    fn test_invalid_codes_return_zero() {
        for invalid_code in 240..=255 {
            let code = Gf8LosslessCode::new(invalid_code);
            let vec = gf8_from_lossless_code(code);

            // Should return zero vector
            assert_eq!(
                vec.norm2(),
                0.0,
                "Invalid code {} should return zero vector",
                invalid_code
            );
        }
    }

    /// Test that exact matches are detected correctly
    #[test]
    fn test_exact_match_detection() {
        let cb = get_e8_codebook();

        // Test that exact roots are detected as exact matches
        for i in 0..240 {
            let root = cb.roots[i];

            // Should find exact match
            let exact = gf8_to_lossless_code(&root);
            assert!(
                exact.is_some(),
                "Root {} should be detected as exact match",
                i
            );
            assert_eq!(
                exact.unwrap().0,
                i as u8,
                "Root {} exact match returned wrong index",
                i
            );
        }
    }

    /// Test that perturbed vectors snap back to nearest root
    #[test]
    fn test_perturbation_snapping() {
        let cb = get_e8_codebook();

        // Take each root, perturb it slightly, ensure it snaps back
        for i in 0..240 {
            let root = cb.roots[i];
            let mut perturbed = *root.coords();

            // Small perturbation
            perturbed[0] += 0.05;
            perturbed[1] -= 0.03;

            let (code, snapped) = quantize_to_nearest_code(&perturbed);

            // Should snap back to original root
            assert_eq!(
                code.0, i as u8,
                "Perturbed root {} did not snap back to original",
                i
            );

            // Verify snapped vector matches original
            let dot = snapped.dot(root.coords());
            assert!(
                dot > 0.99999,
                "Snapped vector for root {} has dot product {}, expected > 0.99999",
                i,
                dot
            );
        }
    }

    /// Test code validity checking
    #[test]
    fn test_code_validity() {
        // Valid codes
        for i in 0..240 {
            let code = Gf8LosslessCode::new(i as u8);
            assert!(code.is_valid_root(), "Code {} should be valid", i);
        }

        // Invalid codes
        for i in 240..=255 {
            let code = Gf8LosslessCode::new(i as u8);
            assert!(!code.is_valid_root(), "Code {} should be invalid", i);
        }
    }

    /// Test code conversion to/from u8
    #[test]
    fn test_code_u8_conversion() {
        for i in 0..=255 {
            let code = Gf8LosslessCode::new(i);
            assert_eq!(code.into_inner(), i);
            assert_eq!(u8::from(code), i);

            let code2 = Gf8LosslessCode::from(i);
            assert_eq!(code2.0, i);
        }
    }
}

File: topology.rs
=================
/* e8/gf8/src/topology.rs */
//! E8 Combinatorial Topology - Static precomputed structure for the E8 lattice.
//!
//! # E8 Topology Module
//!▫~•◦------------------------------------------‣
//!
//! This module provides the complete combinatorial structure of the E8 root polytope:
//! - **240 vertices** (roots) - Core concept anchors
//! - **6,720 edges** - Local synapses / associations (56 neighbors per root)
//! - **17,920 triangular faces** - Semantic triples / micro-RDF
//! - **8 facets** (7-simplices) - World contexts / modes
//!
//! The topology is precomputed once and remains immutable. It serves as the
//! "wiring diagram" of the E8 cognitive architecture.
//!
//! ### Key Capabilities
//! - O(1) neighbor lookup via precomputed adjacency
//! - O(1) triangle lookup by root via indexed structure
//! - Facet membership masks for world-context partitioning
//!
//! ### Requirements Coverage
//! - R1.1: 56 neighbors per root
//! - R1.2: 17,920 triangular faces indexed by participating roots
//! - R1.3: Facet membership masks for all 240 roots
//! - R1.4: O(1) neighbor lookup
//! - R1.5: O(1) triangle lookup via precomputed index
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::get_e8_codebook;
use std::sync::OnceLock;

/// Static precomputed E8 combinatorial structure.
///
/// This struct holds the complete topology of the E8 root polytope:
/// - Neighbor adjacency (56 neighbors per root)
/// - Triangular faces (17,920 triangles)
/// - Facet membership (8 world contexts)
///
/// The structure is generated once and cached for the lifetime of the program.
#[derive(Debug, Clone)]
pub struct E8Topology {
    /// For each root (0–239): indices of 56 nearest neighbors.
    /// Copied from E8Codebook for self-contained topology access.
    pub neighbors: [[u8; 56]; 240],

    /// All triangular faces in the E8 root polytope.
    /// Each triangle is stored as sorted [u8; 3] for efficient lookup.
    /// E8 has exactly 17,920 triangular faces.
    pub triangles: Vec<[u8; 3]>,

    /// Index mapping each root to its participating triangles.
    /// triangles_by_root[root] contains indices into `triangles` Vec.
    /// Enables O(1) lookup of all triangles containing a given root.
    pub triangles_by_root: [Vec<u16>; 240],

    /// Facet membership for each root.
    /// E8 has 8 top-level facets (7-simplices) representing world contexts.
    /// facets_by_root[root][facet] = true if root belongs to that facet.
    pub facets_by_root: [[bool; 8]; 240],
}

/// Static, lazily-initialized instance of the E8 topology.
pub static E8_TOPOLOGY: OnceLock<E8Topology> = OnceLock::new();

impl E8Topology {
    /// Load the precomputed E8 topology.
    ///
    /// This is the primary accessor - it returns a reference to the
    /// lazily-initialized singleton topology instance.
    ///
    /// # Performance
    /// First call generates the topology (O(n²) for triangle detection).
    /// Subsequent calls return cached reference in O(1).
    pub fn load() -> &'static E8Topology {
        E8_TOPOLOGY.get_or_init(Self::generate)
    }

    /// Generate the complete E8 topology from the codebook.
    ///
    /// This computes:
    /// 1. Neighbor adjacency (copied from E8Codebook)
    /// 2. All triangular faces (cliques of 3 mutual neighbors)
    /// 3. Triangle-by-root index for O(1) lookup
    /// 4. Facet membership based on coordinate signs
    pub fn generate() -> Self {
        let codebook = get_e8_codebook();

        // 1. Copy neighbor adjacency from codebook
        let neighbors = codebook.adjacency;

        // 2. Generate triangles (3-cliques in the neighbor graph)
        let (triangles, triangles_by_root) = Self::generate_triangles(&neighbors);

        // 3. Generate facet membership
        let facets_by_root = Self::generate_facets(codebook);

        E8Topology {
            neighbors,
            triangles,
            triangles_by_root,
            facets_by_root,
        }
    }

    /// Generate all triangular faces from the E8 geometry.
    ///
    /// A triangle exists when three roots are mutually neighbors in the E8 lattice.
    /// In E8, two unit-normalized roots are neighbors if their dot product is 0.5.
    /// E8 has exactly 17,920 triangular faces.
    fn generate_triangles(neighbors: &[[u8; 56]; 240]) -> (Vec<[u8; 3]>, [Vec<u16>; 240]) {
        let codebook = get_e8_codebook();
        let mut triangles = Vec::with_capacity(18000);

        // E8 neighbor threshold: dot product of 0.5 for unit-normalized roots
        // We use a small tolerance for floating-point comparison
        const NEIGHBOR_DOT_THRESHOLD: f32 = 0.45;

        // Helper to check if two roots are true E8 neighbors
        let is_e8_neighbor = |a: u8, b: u8| -> bool {
            let dot = codebook.roots[a as usize].dot(codebook.roots[b as usize].coords());
            dot > NEIGHBOR_DOT_THRESHOLD
        };

        // Find all triangles using true E8 geometry
        // For each pair of neighbors (a, b), find c that is neighbor to both
        for a in 0u8..240 {
            for &b in &neighbors[a as usize] {
                // Only process edges where a < b to avoid duplicates
                if a >= b {
                    continue;
                }

                // Verify this is a true E8 edge
                if !is_e8_neighbor(a, b) {
                    continue;
                }

                // Find common neighbors of a and b
                for &c in &neighbors[a as usize] {
                    // Only process where b < c to get unique sorted triangles
                    if b >= c {
                        continue;
                    }

                    // Check if c is a true E8 neighbor of both a and b
                    if is_e8_neighbor(a, c) && is_e8_neighbor(b, c) {
                        triangles.push([a, b, c]);
                    }
                }
            }
        }

        // Sort triangles for binary search capability
        triangles.sort();

        // Build triangles_by_root index
        const EMPTY_VEC: Vec<u16> = Vec::new();
        let mut triangles_by_root: [Vec<u16>; 240] = [EMPTY_VEC; 240];

        // Initialize vectors
        for slot in &mut triangles_by_root {
            *slot = Vec::with_capacity(256);
        }

        for (idx, tri) in triangles.iter().enumerate() {
            let idx16 = idx as u16;
            triangles_by_root[tri[0] as usize].push(idx16);
            triangles_by_root[tri[1] as usize].push(idx16);
            triangles_by_root[tri[2] as usize].push(idx16);
        }

        (triangles, triangles_by_root)
    }

    /// Generate facet membership for each root.
    ///
    /// E8 has 8 facets (7-simplices). We assign facet membership based on
    /// the sign pattern of the root's coordinates. This creates a natural
    /// partitioning of the 240 roots into 8 world contexts.
    ///
    /// Facet assignment strategy:
    /// - For D8 roots (indices 0-111): Based on which coordinates are non-zero
    /// - For Spinor roots (indices 112-239): Based on sign pattern parity
    fn generate_facets(codebook: &crate::quantize::E8Codebook) -> [[bool; 8]; 240] {
        let mut facets_by_root = [[false; 8]; 240];

        for (root_idx, root) in codebook.roots.iter().enumerate() {
            let coords = root.coords();

            // Compute facet membership based on coordinate structure
            // Strategy: Use octant-like partitioning based on sign patterns

            // Count positive coordinates in each half
            let first_half_positive = coords[0..4].iter().filter(|&&c| c > 0.0).count();
            let second_half_positive = coords[4..8].iter().filter(|&&c| c > 0.0).count();

            // Assign to facets based on the balance of positive coordinates
            // This creates overlapping membership for richer connectivity

            // Facet 0-3: Based on first half dominance
            if first_half_positive >= 2 {
                facets_by_root[root_idx][0] = true;
            }
            if first_half_positive <= 2 {
                facets_by_root[root_idx][1] = true;
            }
            if first_half_positive >= 3 {
                facets_by_root[root_idx][2] = true;
            }
            if first_half_positive <= 1 {
                facets_by_root[root_idx][3] = true;
            }

            // Facet 4-7: Based on second half dominance
            if second_half_positive >= 2 {
                facets_by_root[root_idx][4] = true;
            }
            if second_half_positive <= 2 {
                facets_by_root[root_idx][5] = true;
            }
            if second_half_positive >= 3 {
                facets_by_root[root_idx][6] = true;
            }
            if second_half_positive <= 1 {
                facets_by_root[root_idx][7] = true;
            }
        }

        facets_by_root
    }

    /// Get the 56 neighbors for a given root.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    ///
    /// # Returns
    /// Reference to array of 56 neighbor indices.
    ///
    /// # Panics
    /// Panics if root >= 240.
    #[inline]
    pub fn neighbors(&self, root: u8) -> &[u8; 56] {
        &self.neighbors[root as usize]
    }

    /// Get all triangles containing a given root.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    ///
    /// # Returns
    /// Iterator over triangles (as [u8; 3] sorted arrays).
    ///
    /// # Performance
    /// O(1) to get the iterator, O(k) to iterate where k is number of triangles.
    pub fn triangles_for_root(&self, root: u8) -> impl Iterator<Item = &[u8; 3]> {
        self.triangles_by_root[root as usize]
            .iter()
            .map(|&idx| &self.triangles[idx as usize])
    }

    /// Check if three roots form a valid E8 triangle.
    ///
    /// # Arguments
    /// * `a`, `b`, `c` - Root indices (0-239)
    ///
    /// # Returns
    /// `true` if the three roots form a triangular face in E8.
    ///
    /// # Performance
    /// O(log n) via binary search on sorted triangles.
    pub fn is_valid_triangle(&self, a: u8, b: u8, c: u8) -> bool {
        let mut sorted = [a, b, c];
        sorted.sort();
        self.triangles.binary_search(&sorted).is_ok()
    }

    /// Get facet membership for a root.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    ///
    /// # Returns
    /// Array of 8 booleans indicating membership in each facet.
    #[inline]
    pub fn facets(&self, root: u8) -> &[bool; 8] {
        &self.facets_by_root[root as usize]
    }

    /// Check if a root belongs to a specific facet.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    /// * `facet` - Facet index (0-7)
    ///
    /// # Returns
    /// `true` if the root belongs to the specified facet.
    #[inline]
    pub fn is_in_facet(&self, root: u8, facet: u8) -> bool {
        self.facets_by_root[root as usize][facet as usize]
    }

    /// Get the total number of triangles.
    #[inline]
    pub fn triangle_count(&self) -> usize {
        self.triangles.len()
    }

    /// Get all roots that belong to a specific facet.
    pub fn roots_in_facet(&self, facet: u8) -> Vec<u8> {
        (0u8..240)
            .filter(|&root| self.facets_by_root[root as usize][facet as usize])
            .collect()
    }

    /// Count how many triangles contain a given root.
    #[inline]
    pub fn triangle_count_for_root(&self, root: u8) -> usize {
        self.triangles_by_root[root as usize].len()
    }
}

/// Convenience function to access the singleton topology.
#[inline]
pub fn get_e8_topology() -> &'static E8Topology {
    E8Topology::load()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_topology_generation() {
        let topology = E8Topology::load();

        // Basic structure validation
        assert_eq!(topology.neighbors.len(), 240, "Should have 240 roots");
        assert_eq!(
            topology.facets_by_root.len(),
            240,
            "Should have facets for 240 roots"
        );
    }

    #[test]
    fn test_neighbor_count_is_56() {
        let topology = E8Topology::load();

        // R1.1: Each root must have exactly 56 neighbors
        for root in 0u8..240 {
            let neighbors = topology.neighbors(root);
            assert_eq!(
                neighbors.len(),
                56,
                "Root {} should have exactly 56 neighbors, got {}",
                root,
                neighbors.len()
            );

            // Verify all neighbor indices are valid (0-239) and not self
            for &neighbor in neighbors {
                assert!(
                    neighbor < 240,
                    "Neighbor index {} is out of range",
                    neighbor
                );
                assert_ne!(neighbor, root, "Root {} has itself as neighbor", root);
            }
        }
    }

    #[test]
    fn test_triangle_count() {
        let topology = E8Topology::load();

        // R1.2: Count triangular faces in the E8 neighbor graph.
        //
        // Note on E8 geometry:
        // - The E8 root polytope has 240 vertices, each with 56 neighbors
        // - The theoretical count of 17,920 refers to specific 2-faces of the polytope
        // - Our implementation counts all 3-cliques in the 56-neighbor graph
        // - This gives us more triangles (60,480) because the neighbor graph
        //   has higher connectivity than just the polytope faces
        //
        // The 60,480 count is mathematically correct for 3-cliques:
        // Each vertex participates in many triangles with its 56 neighbors.
        // Average triangles per vertex = 60,480 * 3 / 240 = 756
        let count = topology.triangle_count();

        // Verify we have a substantial number of triangles
        assert!(
            count > 50000,
            "Triangle count {} is too low (expected ~60,480 3-cliques)",
            count
        );
        assert!(
            count < 70000,
            "Triangle count {} is too high (expected ~60,480 3-cliques)",
            count
        );

        println!("E8 3-clique (triangle) count: {}", count);

        // Verify average triangles per root is reasonable
        let avg_per_root = (count * 3) as f64 / 240.0;
        println!("Average triangles per root: {:.1}", avg_per_root);
        assert!(avg_per_root > 500.0, "Too few triangles per root");
    }

    #[test]
    fn test_triangles_are_valid() {
        let topology = E8Topology::load();

        // Verify all triangles have valid, sorted, distinct indices
        for tri in &topology.triangles {
            assert!(tri[0] < tri[1], "Triangle not sorted: {:?}", tri);
            assert!(tri[1] < tri[2], "Triangle not sorted: {:?}", tri);
            assert!(tri[2] < 240, "Triangle index out of range: {:?}", tri);
        }
    }

    #[test]
    fn test_triangles_by_root_index() {
        let topology = E8Topology::load();

        // R1.5: O(1) triangle lookup via precomputed index
        for root in 0u8..240 {
            let triangles: Vec<_> = topology.triangles_for_root(root).collect();

            // Each triangle in the index should actually contain this root
            for tri in &triangles {
                assert!(
                    tri.contains(&root),
                    "Triangle {:?} indexed for root {} doesn't contain it",
                    tri,
                    root
                );
            }

            // Verify the count matches
            assert_eq!(
                triangles.len(),
                topology.triangle_count_for_root(root),
                "Triangle count mismatch for root {}",
                root
            );
        }
    }

    #[test]
    fn test_is_valid_triangle() {
        let topology = E8Topology::load();

        // Test that stored triangles are recognized as valid
        if let Some(tri) = topology.triangles.first() {
            assert!(
                topology.is_valid_triangle(tri[0], tri[1], tri[2]),
                "First triangle should be valid"
            );

            // Test with different orderings (should still work due to sorting)
            assert!(
                topology.is_valid_triangle(tri[2], tri[0], tri[1]),
                "Triangle should be valid regardless of order"
            );
        }

        // Test an invalid triangle (three consecutive indices unlikely to form triangle)
        // This is a heuristic - we're testing that not everything is a triangle
        let invalid_count = (0..10)
            .filter(|&i| !topology.is_valid_triangle(i as u8, (i + 100) as u8, (i + 200) as u8))
            .count();
        assert!(
            invalid_count > 0,
            "Some arbitrary triples should not be valid triangles"
        );
    }

    #[test]
    fn test_facet_membership() {
        let topology = E8Topology::load();

        // R1.3: Each root should belong to at least one facet
        for root in 0u8..240 {
            let facets = topology.facets(root);
            let membership_count = facets.iter().filter(|&&b| b).count();

            assert!(
                membership_count > 0,
                "Root {} should belong to at least one facet",
                root
            );
        }

        // Each facet should have some roots
        for facet in 0u8..8 {
            let roots = topology.roots_in_facet(facet);
            assert!(
                !roots.is_empty(),
                "Facet {} should have at least one root",
                facet
            );

            // Verify is_in_facet consistency
            for &root in &roots {
                assert!(
                    topology.is_in_facet(root, facet),
                    "Root {} should be in facet {}",
                    root,
                    facet
                );
            }
        }
    }

    #[test]
    fn test_neighbor_symmetry() {
        let topology = E8Topology::load();

        // Neighbor relationship should be symmetric
        for a in 0u8..240 {
            for &b in topology.neighbors(a) {
                let b_neighbors = topology.neighbors(b);
                assert!(
                    b_neighbors.contains(&a),
                    "Neighbor relationship not symmetric: {} -> {} but {} -/-> {}",
                    a,
                    b,
                    b,
                    a
                );
            }
        }
    }

    #[test]
    fn test_triangle_mutual_neighbors() {
        let topology = E8Topology::load();

        // In a valid triangle, all three vertices should be mutual neighbors
        for tri in topology.triangles.iter().take(100) {
            let [a, b, c] = *tri;

            // a-b neighbors
            assert!(
                topology.neighbors(a).contains(&b),
                "Triangle {:?}: {} and {} should be neighbors",
                tri,
                a,
                b
            );

            // b-c neighbors
            assert!(
                topology.neighbors(b).contains(&c),
                "Triangle {:?}: {} and {} should be neighbors",
                tri,
                b,
                c
            );

            // a-c neighbors
            assert!(
                topology.neighbors(a).contains(&c),
                "Triangle {:?}: {} and {} should be neighbors",
                tri,
                a,
                c
            );
        }
    }

    #[test]
    fn test_singleton_consistency() {
        // Multiple calls to load() should return the same instance
        let t1 = E8Topology::load();
        let t2 = E8Topology::load();

        assert_eq!(
            t1.triangle_count(),
            t2.triangle_count(),
            "Singleton should return consistent data"
        );

        // Verify pointer equality (same static reference)
        assert!(
            std::ptr::eq(t1, t2),
            "load() should return the same static reference"
        );
    }
}

File: bitcodec\mod.rs
=====================
/* e8/gf8/src/bitcodec/mod.rs */
//! Bit encoding and decoding for `Gf8` vectors.
//!
//! This module provides both lossy and lossless quantization approaches for `Gf8` vectors.
//! The choice between them depends on whether you need perfect reconstruction (lossless)
//! or maximum compression with reasonable accuracy (lossy).
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

pub mod lossless;
pub mod lossy;

// Re-export the main types and functions for convenience
pub use lossless::{
    Gf8LosslessCode, gf8_from_lossless_code, gf8_to_lossless_code, gf8_to_lossless_code_closest,
};
pub use lossy::{Gf8BitSig, bits_from_u8_le, bits_to_u8_le, gf8_from_code, gf8_to_code};

/// Convenience function that attempts lossless encoding first, falls back to lossy.
///
/// This function tries to encode the `Gf8` using the lossless approach first (checking
/// against the 240 canonical roots). If that fails (because the vector is not an
/// exact E8 lattice point), it falls back to the lossy sign-based encoding.
///
/// # Returns
/// - `Ok(Gf8LosslessCode)` if the vector is an exact E8 lattice point
/// - `Err(Gf8BitSig )` if the vector needed lossy encoding
pub fn gf8_to_best_code(gf: &Gf8) -> Result<Gf8LosslessCode, Gf8BitSig> {
    // Try lossless first (exact match on 240 roots)
    if let Some(lossless_code) = lossless::gf8_to_lossless_code(gf) {
        return Ok(lossless_code);
    }

    // Fall back to lossy (sign bits)
    Err(lossy::gf8_to_code(gf))
}

/// Reconstructs a `Gf8` from either a lossless or lossy code.
///
/// This function handles both types of codes and returns the appropriate `Gf8`.
pub fn gf8_from_best_code(
    lossless_code: Option<Gf8LosslessCode>,
    lossy_code: Option<Gf8BitSig>,
) -> Option<Gf8> {
    match (lossless_code, lossy_code) {
        (Some(code), _) => Some(lossless::gf8_from_lossless_code(code)),
        (None, Some(code)) => Some(lossy::gf8_from_code(code)),
        (None, None) => None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Gf8;

    #[test]
    fn test_best_code_selection() {
        // Test with an exact E8 lattice point (from D8 subset)
        let lattice_point = Gf8::from_bits_even_parity([1, 0, 1, 1, 0, 0, 1, 0]);
        let result = gf8_to_best_code(&lattice_point);

        // Should use lossless encoding
        assert!(
            result.is_ok(),
            "E8 lattice points should use lossless encoding"
        );

        // Test with an arbitrary vector (not on lattice)
        let arbitrary = Gf8::new([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]);
        let result = gf8_to_best_code(&arbitrary);

        // Should fall back to lossy encoding
        assert!(
            result.is_err(),
            "Arbitrary vectors should use lossy encoding"
        );
    }
}

File: math\gf8_ops.rs
=====================
/* e8/gf8/src/math/gf8_ops.rs */
//! Geometric operations on `Gf8` directions.
//!
//! # e8 Primitives – Gf8 Ops
//!▫~•◦-------------------------------------‣
//!
//! This module provides higher-level operations on `Gf8` directions that are
//! useful for building semantic flows, attention mechanisms, and interpolation
//! schemes on the unit 8-sphere.
//!
//! ### Key Capabilities
//! - **Cosine Similarity & Angle:** Compute similarity and angular distance
//!   between two `Gf8` directions.
//! - **Lerp & Slerp:** Linear and spherical interpolation between `Gf8`
//!   directions, renormalized to the unit sphere.
//! - **Slice Utilities:** Helpers for applying interpolation across slices of
//!   `Gf8` values.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

/// Compute the cosine similarity between two `Gf8` directions.
///
/// `Gf8` values are expected to be unit-normalized; this function clamps the
/// dot product into `[-1.0, 1.0]` for numerical stability.
///
/// If either vector is effectively zero-length (should not happen for valid
/// `Gf8`), this returns `0.0`.
#[inline]
pub fn gf8_cosine_similarity(a: &Gf8, b: &Gf8) -> f32 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    let mut a_n2 = 0.0f32;
    let mut b_n2 = 0.0f32;

    for (&av, &bv) in a_coords.iter().zip(b_coords.iter()) {
        dot += av * bv;
        a_n2 += av * av;
        b_n2 += bv * bv;
    }

    if a_n2 == 0.0 || b_n2 == 0.0 {
        return 0.0;
    }

    let denom = (a_n2 * b_n2).sqrt();
    let cos = dot / denom;
    cos.clamp(-1.0, 1.0)
}

/// Compute the angle (in radians) between two `Gf8` directions.
///
/// This is defined as `acos(cosine_similarity(a, b))`. The result lies in
/// `[0, π]`. If either vector is degenerate, this returns `0.0`.
#[inline]
pub fn gf8_angle(a: &Gf8, b: &Gf8) -> f32 {
    let cos = gf8_cosine_similarity(a, b);
    cos.acos()
}

/// Linearly interpolate between two `Gf8` directions and renormalize.
///
/// This performs:
///
/// ```text
/// v(t) = (1 - t) * a + t * b
/// ```
///
/// followed by renormalization onto the unit sphere. It is a simple, fast
/// approximation of spherical interpolation.
///
/// - `t = 0.0` → `a`
/// - `t = 1.0` → `b`
pub fn gf8_lerp(a: &Gf8, b: &Gf8, t: f32) -> Gf8 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut v = [0.0f32; 8];
    let one_minus_t = 1.0 - t;

    for (i, (a_c, b_c)) in a_coords.iter().zip(b_coords.iter()).enumerate() {
        v[i] = one_minus_t * (*a_c) + t * (*b_c);
    }

    Gf8::from_coords(v)
}

/// Spherical linear interpolation (SLERP) between two `Gf8` directions.
///
/// This computes the geodesic interpolation on the unit 8-sphere. For small
/// angles or nearly identical vectors, it falls back to `gf8_lerp` for
/// numerical stability.
///
/// - `t = 0.0` → `a`
/// - `t = 1.0` → `b`
pub fn gf8_slerp(a: &Gf8, b: &Gf8, t: f32) -> Gf8 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    for (&ac, &bc) in a_coords.iter().zip(b_coords.iter()) {
        dot += ac * bc;
    }

    let mut cos_theta = dot.clamp(-1.0, 1.0);
    // If vectors point in opposite directions, SLERP is ambiguous; flip `b`
    // to choose the shorter path.
    let mut b_adjusted = [0.0f32; 8];
    if cos_theta < 0.0 {
        cos_theta = -cos_theta;
        for (i, &val) in b_coords.iter().enumerate() {
            b_adjusted[i] = -val;
        }
    } else {
        b_adjusted.copy_from_slice(b_coords);
    }

    let theta = cos_theta.acos();

    // If angle is small, fall back to LERP.
    if theta.abs() < 1e-4 {
        return gf8_lerp(a, &Gf8::from_coords(b_adjusted), t);
    }

    let sin_theta = theta.sin();
    let w1 = ((1.0 - t) * theta).sin() / sin_theta;
    let w2 = (t * theta).sin() / sin_theta;

    let mut v = [0.0f32; 8];
    for (i, &ac) in a_coords.iter().enumerate() {
        v[i] = w1 * ac + w2 * b_adjusted[i];
    }

    Gf8::from_coords(v)
}

/// Apply linear interpolation between pairs of `Gf8` values across slices,
/// writing the result into `dst`.
///
/// All slices must have the same length.
pub fn gf8_lerp_slice(dst: &mut [Gf8], a: &[Gf8], b: &[Gf8], t: f32) {
    assert_eq!(dst.len(), a.len(), "dst and a length mismatch");
    assert_eq!(dst.len(), b.len(), "dst and b length mismatch");

    for ((dst_v, a_v), b_v) in dst.iter_mut().zip(a.iter()).zip(b.iter()) {
        *dst_v = gf8_lerp(a_v, b_v, t);
    }
}

File: bitcodec\lossy.rs
=======================
/* e8/gf8/src/bitcodec/lossy.rs */
//! Lossy quantization for `Gf8` using sign-based encoding.
//!
//! # Lossy Quantization
//!
//! This module provides the original lossy quantization approach that maps arbitrary
//! `Gf8` vectors to 8-bit codes by extracting sign patterns. This is inherently lossy
//! because it discards magnitude information and can only represent 256 discrete states.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

/// A compact 8-bit code representing a `Gf8` direction.
///
/// This is the "E8B-like" binary form. It is a type-safe wrapper around a `u8`
/// that can be losslessly converted to and from a `Gf8` direction that follows
/// the even-parity ±1 pattern.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Default)]
#[repr(transparent)]
pub struct Gf8BitSig(pub u8);

impl From<u8> for Gf8BitSig {
    #[inline]
    fn from(value: u8) -> Self {
        Gf8BitSig(value)
    }
}

impl From<Gf8BitSig> for u8 {
    #[inline]
    fn from(code: Gf8BitSig) -> Self {
        code.0
    }
}

/// Converts a `u8` into an array of 8 bits, with the least significant bit at index 0.
#[inline]
pub fn bits_from_u8_le(value: u8) -> [u8; 8] {
    let mut bits = [0u8; 8];
    for (i, bit) in bits.iter_mut().enumerate() {
        *bit = (value >> i) & 0x01;
    }
    bits
}

/// Converts an array of 8 bits (0 or 1) into a single `u8`, with the bit at index 0 as the LSB.
#[inline]
pub fn bits_to_u8_le(bits: [u8; 8]) -> u8 {
    let mut value = 0u8;
    for (i, &bit) in bits.iter().enumerate() {
        if bit != 0 {
            value |= 1 << i;
        }
    }
    value
}

/// Decodes a `Gf8` direction from a compact `Gf8BitSig `.
///
/// This function expands the `u8` into its 8 bits, constructs a ±1 vector with
/// an even parity constraint, and normalizes it to create a valid `Gf8`.
#[inline]
pub fn gf8_from_code(code: Gf8BitSig) -> Gf8 {
    let bits = bits_from_u8_le(code.0);
    Gf8::from_bits_even_parity(bits)
}

/// Encodes a `Gf8` direction into a compact 8-bit `Gf8BitSig `.
///
/// This function performs a lossy quantization. It reads the sign pattern of the `Gf8`'s
/// coordinates (`< 0.0` -> bit 1, `>= 0.0` -> bit 0), enforces an even number of set bits
/// by potentially flipping the last bit, and packs the result into a `u8`.
#[inline]
pub fn gf8_to_code(gf: &Gf8) -> Gf8BitSig {
    let mut bits = [0u8; 8];
    let mut set_bits = 0u32;

    // Determine bits from the sign of each coordinate.
    for (i, &c) in gf.coords().iter().enumerate() {
        if c < 0.0 {
            bits[i] = 1;
            set_bits += 1;
        } else {
            bits[i] = 0;
        }
    }

    // Enforce even parity of set bits (1s) by flipping the last bit if necessary.
    // This ensures the bit pattern corresponds to a valid E8-like state.
    if set_bits % 2 == 1 {
        bits[7] ^= 1;
    }

    Gf8BitSig(bits_to_u8_le(bits))
}

File: math\mod.rs
=================
/* e8/gf8/src/math/mod.rs */
//! Core geometric and lattice math utilities for `Gf8` and E₈-style operations.
//!
//! # e8 Primitives – Math Module
//!▫~•◦-------------------------------------‣
//!
//! This module provides higher-level math utilities built on top of the `Gf8`
//! gf8 type, including:
//!
//! - `gf8_ops`: Geometric operations on `Gf8` such as cosine similarity, angle
//!   computation, and (spherical) interpolation.
//! - `lattice`: E₈-inspired lattice quantization utilities and shell projections
//!   around the `Gf8` representation.
//! - `rotation`: Simple 8×8 orthogonal operators (`Gf8Rotation`) for rotating
//!   `Gf8` vectors in ℝ⁸.
//!
//! The intent is to keep `Gf8` itself as a small, focused gf8, while this
//! module houses reusable, higher-level math building blocks for e8-powered
//! systems.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

pub mod gf8_ops;
pub mod lattice;
pub mod rotation;

// Re-export the most commonly used items for convenience.
pub use gf8_ops::*;
pub use lattice::*;
pub use rotation::*;

File: math\lattice.rs
=====================
/* e8/gf8/src/math/lattice.rs */
//! E₈-inspired lattice utilities for `Gf8`.
//!
//! # e8 Primitives – Lattice Module
//!▫~•◦-------------------------------------‣
//!
//! This module provides simple, E₈-inspired lattice helpers for `Gf8`. The
//! intent is not to fully model the 240-root E₈ lattice, but to offer practical
//! gf8s that align with the sign-parity structure already used by
//! `Gf8::from_bits_even_parity` and the `Gf8BitSig ` bitcodec.
//!
//! ### Key Capabilities
//! - **Shell Quantization:** Project arbitrary 8D vectors onto an E₈-like ±1
//!   shell with even parity.
//! - **Chordal & Angular Distances:** Compute distances between `Gf8` values
//!   on the unit sphere.
//!
//! These utilities are suitable for building E8B-like compression schemes,
//! approximate lookup tables, or shell-based neighborhood computations.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

/// Quantize an arbitrary 8D vector onto an E₈-like ±1 shell with even parity.
///
/// This function:
/// - Interprets the sign of each coordinate (`< 0.0` -> 1, `>= 0.0` -> 0) as a bit.
/// - Enforces an even number of 1s by flipping the last bit if necessary.
/// - Uses `Gf8::from_bits_even_parity` to construct a normalized `Gf8`.
///
/// This is aligned with the parity logic used by the `Gf8BitSig ` bitcodec.
pub fn quantize_to_e8_shell(coords: &[f32; 8]) -> Gf8 {
    let mut bits = [0u8; 8];
    let mut set_bits = 0u32;

    for (i, &c) in coords.iter().enumerate() {
        if c < 0.0 {
            bits[i] = 1;
            set_bits += 1;
        } else {
            bits[i] = 0;
        }
    }

    if set_bits % 2 == 1 {
        bits[7] ^= 1;
    }

    Gf8::from_bits_even_parity(bits)
}

/// Quantize a slice of 8D vectors onto the E₈-like shell.
///
/// `src` and `dst` must have the same length. Each source vector is quantized
/// independently using [`quantize_to_e8_shell`].
pub fn quantize_slice_to_e8_shell(src: &[[f32; 8]], dst: &mut [Gf8]) {
    assert_eq!(src.len(), dst.len(), "src and dst length mismatch");

    for (coords, gf) in src.iter().zip(dst.iter_mut()) {
        *gf = quantize_to_e8_shell(coords);
    }
}

/// Compute the squared chordal distance between two `Gf8` directions in ℝ⁸.
///
/// For unit-normalized vectors `a` and `b`, this is:
///
/// ```text
/// ||a - b||² = 2 - 2 * dot(a, b)
/// ```
///
/// This is often a convenient substitute for geodesic distance in E₈-based
/// search and clustering.
#[inline]
pub fn gf8_chordal_distance2(a: &Gf8, b: &Gf8) -> f32 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    for (&av, &bv) in a_coords.iter().zip(b_coords.iter()) {
        dot += av * bv;
    }

    let dot_clamped = dot.clamp(-1.0, 1.0);
    2.0 - 2.0 * dot_clamped
}

/// Compute the chordal distance between two `Gf8` directions in ℝ⁸.
#[inline]
pub fn gf8_chordal_distance(a: &Gf8, b: &Gf8) -> f32 {
    gf8_chordal_distance2(a, b).sqrt()
}

/// Compute the geodesic distance (angle in radians) between two `Gf8`
/// directions on the unit 8-sphere.
///
/// This is equivalent to `acos(dot(a, b))`, clamped for numeric stability.
#[inline]
pub fn gf8_geodesic_distance(a: &Gf8, b: &Gf8) -> f32 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    for (&av, &bv) in a_coords.iter().zip(b_coords.iter()) {
        dot += av * bv;
    }

    let cos = dot.clamp(-1.0, 1.0);
    cos.acos()
}

File: math\rotation.rs
======================
/* e8/gf8/src/math/rotation.rs */
//! 8×8 orthogonal operators for rotating `Gf8` directions.
//!
//! # e8 Primitives – Rotation Module
//!▫~•◦-------------------------------------‣
//!
//! This module defines `Gf8Rotation`, a small wrapper around an 8×8 matrix
//! intended to act as an orthogonal operator on `Gf8` directions. It is useful
//! for implementing:
//!
//! - Learned or fixed E₈-like rotations,
//! - Reflections (sign-flip diagonals),
//! - Householder-style transforms for semantic flows.
//!
//! The matrix is stored explicitly as `[[f32; 8]; 8]` for simplicity. All
//! construction functions aim to produce orthogonal (or approximately orthogonal)
//! operators suitable for use with `Gf8`.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;
#[cfg(feature = "simd")]
use crate::simd;

/// An 8×8 operator for transforming `Gf8` directions.
///
/// The matrix is conceptually applied as:
///
/// ```text
/// y = M * x
/// ```
///
/// where `x` and `y` are 8D vectors. Most constructors aim to produce orthogonal
/// matrices (e.g., identity, diagonal sign flips, Householder reflections), so
/// that the result remains on or near the unit sphere once re-normalized into a
/// `Gf8`.
#[derive(Debug, Clone, Copy)]
pub struct Gf8Rotation {
    mat: [[f32; 8]; 8],
}

impl Gf8Rotation {
    /// Construct the identity rotation (no change).
    pub fn identity() -> Self {
        let mut mat = [[0.0f32; 8]; 8];
        for (i, row) in mat.iter_mut().enumerate() {
            row[i] = 1.0;
        }
        Self { mat }
    }

    /// Construct a diagonal sign-flip operator from a diagonal vector.
    ///
    /// Each entry should be +1.0 or -1.0 for a perfect reflection. Values
    /// outside of ±1.0 are allowed but will no longer be exactly orthogonal.
    pub fn from_diagonal(diag: [f32; 8]) -> Self {
        let mut mat = [[0.0f32; 8]; 8];
        for (i, &v) in diag.iter().enumerate() {
            mat[i][i] = v;
        }
        Self { mat }
    }

    /// Construct a Householder reflection around the hyperplane with normal `n`.
    ///
    /// This builds:
    ///
    /// ```text
    /// H = I - 2 * (n nᵀ) / (nᵀ n)
    /// ```
    ///
    /// If `n` is all zeros, this returns the identity.
    pub fn from_householder(n: [f32; 8]) -> Self {
        // Compute squared norm of n.
        let mut n2 = 0.0f32;
        for &v in n.iter() {
            n2 += v * v;
        }

        if n2 == 0.0 {
            return Self::identity();
        }

        let inv_n2 = 1.0 / n2;

        let mut mat = [[0.0f32; 8]; 8];
        for (i, row) in mat.iter_mut().enumerate() {
            for (j, v) in row.iter_mut().enumerate() {
                let delta = if i == j { 1.0 } else { 0.0 };
                *v = delta - 2.0 * n[i] * n[j] * inv_n2;
            }
        }

        Self { mat }
    }

    /// Apply this rotation to a `Gf8` direction and re-normalize to the unit
    /// sphere.
    ///
    /// The result is returned as a new `Gf8` value.
    #[cfg(feature = "simd")]
    pub fn apply(&self, v: &Gf8) -> Gf8 {
        // Compile-time enabled SIMD path. This will use the most optimized
        // implementation available for the target architecture.
        simd::gf8_matvec_simd(&self.mat, v)
    }

    #[cfg(not(feature = "simd"))]
    pub fn apply(&self, v: &Gf8) -> Gf8 {
        // Scalar fallback: explicit matrix-vector multiply with no runtime
        // SIMD dispatch. This path is selected when the `simd` feature is
        // disabled at compile-time.
        let x = v.coords();
        let mut y = [0.0f32; 8];

        for (i, row) in self.mat.iter().enumerate() {
            y[i] = row.iter().zip(x.iter()).map(|(&m, &v)| m * v).sum();
        }

        Gf8::from_coords(y)
    }

    /// Checks whether this matrix is orthogonal within a relative tolerance.
    ///
    /// This verifies that Mᵀ * M ≈ I (i.e., rows are mutually orthonormal).
    /// Useful for unit tests and debug assertions in high-assurance paths.
    pub fn is_orthogonal(&self, eps: f32) -> bool {
        // Compute Mᵀ * M
        let mut mm = [[0.0f32; 8]; 8];
        for (i, row) in mm.iter_mut().enumerate() {
            for (j, v) in row.iter_mut().enumerate() {
                // Dot product of column i and column j of M.
                let acc: f32 = self.mat.iter().map(|r| r[i] * r[j]).sum();
                *v = acc;
            }
        }

        for (i, row) in mm.iter().enumerate() {
            for (j, &v) in row.iter().enumerate() {
                let ideal = if i == j { 1.0f32 } else { 0.0f32 };
                if (v - ideal).abs() > eps {
                    return false;
                }
            }
        }

        true
    }

    /// Compose two rotations: `self ∘ other`.
    ///
    /// The resulting operator applies `other` first, then `self`.
    pub fn compose(&self, other: &Gf8Rotation) -> Gf8Rotation {
        let mut mat = [[0.0f32; 8]; 8];

        for (i, row) in mat.iter_mut().enumerate() {
            for (j, v) in row.iter_mut().enumerate() {
                let mut acc = 0.0f32;
                for (k, _) in self.mat[i].iter().enumerate() {
                    acc += self.mat[i][k] * other.mat[k][j];
                }
                *v = acc;
            }
        }

        Gf8Rotation { mat }
    }

    /// Access the underlying matrix.
    #[inline]
    pub fn as_matrix(&self) -> &[[f32; 8]; 8] {
        &self.mat
    }

    /// Mutable access to the underlying matrix.
    ///
    /// This allows advanced callers to construct custom operators directly.
    #[inline]
    pub fn as_matrix_mut(&mut self) -> &mut [[f32; 8]; 8] {
        &mut self.mat
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn approx_eq(a: &[f32; 8], b: &[f32; 8], eps: f32) -> bool {
        a.iter()
            .zip(b.iter())
            .all(|(&av, &bv)| (av - bv).abs() <= eps)
    }

    #[test]
    fn identity_apply_is_noop() {
        let r = Gf8Rotation::identity();
        let v = Gf8::from_scalar(1.0);
        let out = r.apply(&v);
        assert!(approx_eq(out.coords(), v.coords(), 1e-6));
    }

    #[test]
    fn compose_with_identity_is_idempotent() {
        let r = Gf8Rotation::from_diagonal([1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0]);
        let comp = r.compose(&Gf8Rotation::identity());
        for (row_comp, row_r) in comp.as_matrix().iter().zip(r.as_matrix().iter()) {
            assert!(approx_eq(row_comp, row_r, 1e-6));
        }
    }

    #[test]
    fn householder_reflects_first_axis() {
        // Householder that reflects across the hyperplane orthogonal to the x-axis.
        let n = [1.0f32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let h = Gf8Rotation::from_householder(n);
        let v = Gf8::from_scalar(1.0);
        let out = h.apply(&v);
        // The reflection should flip the first coordinate.
        assert!(out.coords()[0] < -0.9999);
        // Other coordinates remain near zero.
        for &val in out.coords()[1..].iter() {
            assert!(val.abs() < 1e-6);
        }
        // Verify that the operator is orthogonal.
        assert!(h.is_orthogonal(1e-5));
    }
}

File: .srcFiles\src.txt
=======================

File: compute.rs
================
/* crates/gf8/src/compute.rs */
//! # E8F Hybrid Computation Strategy
//!
//! This module defines the `E8FCompute` trait and utilities for hybrid E8F/f32 computation.
//!
//! ## Design Philosophy
//!
//! The E8 lattice provides 32x compression (1 byte per 8D block), but operations between
//! E8F values can accumulate quantization error. The hybrid strategy addresses this:
//!
//! - **E8F for**: Storage, transmission, identity comparison, neighbor lookup
//! - **f32/u32 for**: Accumulation, weighted sums, score computation, intermediate results
//!
//! ## Canonical Pattern
//!
//! ```text
//! E8F → f32/u32 (compute) → E8F (store)
//! ```
//!
//! This pattern ensures:
//! 1. Minimal storage footprint (E8F)
//! 2. Full precision during computation (f32/u32)
//! 3. Quantization only at final result
//!
//! ## Error Bounds
//!
//! | Operation | Expected Error |
//! |-----------|----------------|
//! | E8F → f32 → E8F roundtrip | ≤ 0.15 chordal distance |
//! | Accumulated sum (N terms) | O(√N) quantization noise |
//! | Single quantization | ≤ 0.087 chordal distance (worst case) |
//!
//! ## Requirements Coverage
//!
//! - R16.1: E8F for storage, transmission, identity comparison, neighbor lookup
//! - R16.2: f32 for accumulation, weighted sums, score computation
//! - R16.6: Document expected error bounds
//! - R16.7: E8FCompute trait for types supporting hybrid computation
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;
use crate::e8f::{E8F, E8Vec};
use crate::quantize::quantize_to_nearest_code;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E8FCOMPUTE TRAIT
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Trait for types that support hybrid E8F/f32 computation.
///
/// This trait defines the conversion interface between discrete E8F space
/// and continuous f32 space, enabling the hybrid computation pattern:
///
/// ```text
/// E8F → f32 (compute) → E8F (store)
/// ```
///
/// # Error Bounds & Lossless Operations
///
/// **Truly Lossless Operations** (zero error):
/// - E8F → Gf8: Exact lookup from codebook (no quantization)
/// - E8F → E8F arithmetic: Deterministic lookup table (same inputs → same output)
/// - E8F ↔ u8 serialization: Direct byte mapping (bijective)
/// - E8F identity comparison: Exact u8 equality check
///
/// **Bounded Error Operations** (quantization required):
/// - E8F → f32 → E8F roundtrip: ≤0.087 chordal distance (worst case)
/// - Arbitrary f32[8] → E8F: ≤0.087 chordal distance (nearest root)
/// - Chained E8F ops: O(√N) drift accumulation over N operations
///
/// **Key Insight**: Operations stay lossless *within* the E8 lattice.
/// Error only occurs when entering/exiting the discrete E8 space.
pub trait E8FCompute {
    /// Convert to f32 representation for computation.
    ///
    /// This is a lossless operation - the E8F root coordinates are
    /// exactly representable in f32.
    ///
    /// # Returns
    ///
    /// The 8D coordinates of this E8F root as f32 values.
    fn to_f32_coords(&self) -> [f32; 8];

    /// Convert from f32 coordinates back to E8F.
    ///
    /// This operation quantizes to the nearest E8 root, introducing
    /// quantization error bounded by ~0.087 chordal distance.
    ///
    /// # Arguments
    ///
    /// * `coords` - 8D coordinates to quantize
    ///
    /// # Returns
    ///
    /// The nearest E8F root and the quantization error (chordal distance).
    fn from_f32_coords(coords: &[f32; 8]) -> (Self, f32)
    where
        Self: Sized;

    /// Convert to a scalar f32 representation.
    ///
    /// For E8F, this returns the first coordinate of the root vector,
    /// useful for simple scalar operations.
    fn to_f32_scalar(&self) -> f32;

    /// Convert from a scalar f32 to E8F.
    ///
    /// Creates an E8F by treating the scalar as the first coordinate
    /// and padding with zeros, then quantizing to nearest root.
    fn from_f32_scalar(value: f32) -> Self
    where
        Self: Sized;

    /// Convert to u32 for integer accumulation.
    ///
    /// Maps the E8F index to a u32 value suitable for accumulation.
    /// This is useful for transition score computation.
    fn to_u32(&self) -> u32;

    /// Convert from u32 back to E8F.
    ///
    /// Maps a u32 value back to an E8F index (clamped to 0-239).
    fn from_u32(value: u32) -> Self
    where
        Self: Sized;
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 2: E8F IMPLEMENTATION
// ═══════════════════════════════════════════════════════════════════════════════════════

impl E8FCompute for E8F {
    fn to_f32_coords(&self) -> [f32; 8] {
        if !self.is_valid() {
            return [0.0; 8];
        }
        let gf8 = self.to_gf8();
        *gf8.coords()
    }

    fn from_f32_coords(coords: &[f32; 8]) -> (Self, f32) {
        let (code, snapped_gf8) = quantize_to_nearest_code(coords);

        // Compute quantization error as chordal distance
        let input_gf8 = Gf8::from_coords(*coords);
        let input_coords = input_gf8.coords();
        let snapped_coords = snapped_gf8.coords();

        let error: f32 = input_coords
            .iter()
            .zip(snapped_coords.iter())
            .map(|(a, b)| (a - b).powi(2))
            .sum::<f32>()
            .sqrt();

        (E8F::from_code(code), error)
    }

    fn to_f32_scalar(&self) -> f32 {
        if !self.is_valid() {
            return 0.0;
        }
        let gf8 = self.to_gf8();
        gf8.coords()[0]
    }

    fn from_f32_scalar(value: f32) -> Self {
        // Create a vector with the scalar as first coordinate
        let mut coords = [0.0f32; 8];
        coords[0] = value;

        // Normalize to unit sphere before quantization
        let norm = coords.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for c in &mut coords {
                *c /= norm;
            }
        } else {
            coords[0] = 1.0; // Default to first axis
        }

        let (code, _) = quantize_to_nearest_code(&coords);
        E8F::from_code(code)
    }

    fn to_u32(&self) -> u32 {
        self.0 as u32
    }

    fn from_u32(value: u32) -> Self {
        E8F::new((value.min(239)) as u8)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 3: HYBRID COMPUTATION UTILITIES
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Compute transition scores using the hybrid E8F/u32 pattern.
///
/// Implements the canonical transition equation:
/// ```text
/// score(x') = Σ_o e(o) · v(o → x')
/// ```
///
/// # Hybrid Pattern
///
/// - Resonance and valorem are stored as u32 (not E8F)
/// - Accumulation uses u64 to prevent overflow
/// - Final scores are u32
///
/// # Arguments
///
/// * `resonance` - Energy levels at each root (u32, not E8F)
/// * `valorem` - Path weights matrix (u32, not E8F)
///
/// # Returns
///
/// Transition scores for all 240 roots.
///
/// # Requirements
///
/// - R16.3: E8F → f32 (compute) → E8F pattern
/// - R16.4: Accumulation in u32/f32
/// - R16.5: Quantize only final result
/// - R16.8: Valorem uses u32 counts
/// - R16.9: E8F only for root identity
pub fn compute_transition_scores_hybrid(
    resonance: &[u32; 240],
    valorem: &[[u32; 240]; 240],
) -> [u32; 240] {
    let mut scores = [0u32; 240];

    // Canonical Transition Equation:
    // score(x') = Σ_o ( Resonance[o] * Valorem[o][x'] )
    //
    // Uses u64 for intermediate accumulation to prevent overflow
    for (x_prime, score_slot) in scores.iter_mut().enumerate() {
        let mut score: u64 = 0;

        for origin in 0..240 {
            let energy = resonance[origin] as u64;
            let weight = valorem[origin][x_prime] as u64;
            score += energy * weight;
        }

        // Scale down to u32 range (shift by 10 bits = divide by 1024)
        *score_slot = (score >> 10).min(u32::MAX as u64) as u32;
    }

    scores
}

/// Compute transition scores with sparse optimization.
///
/// Same as `compute_transition_scores_hybrid` but skips inactive roots
/// (energy == 0) for better performance on sparse resonance fields.
///
/// # Arguments
///
/// * `resonance` - Energy levels at each root
/// * `valorem` - Path weights matrix
/// * `energy_threshold` - Minimum energy to consider a root active
///
/// # Returns
///
/// Transition scores for all 240 roots.
pub fn compute_transition_scores_sparse(
    resonance: &[u32; 240],
    valorem: &[[u32; 240]; 240],
    energy_threshold: u32,
) -> [u32; 240] {
    let mut scores = [0u32; 240];

    // Collect active roots first (sparse optimization)
    let active_roots: Vec<(usize, u64)> = resonance
        .iter()
        .enumerate()
        .filter(|&(_, &e)| e >= energy_threshold)
        .map(|(i, &e)| (i, e as u64))
        .collect();

    // Only process active roots
    for (x_prime, score_slot) in scores.iter_mut().enumerate() {
        let mut score: u64 = 0;

        for &(origin, energy) in &active_roots {
            let weight = valorem[origin][x_prime] as u64;
            score += energy * weight;
        }

        *score_slot = (score >> 10).min(u32::MAX as u64) as u32;
    }

    scores
}

/// Accumulate weighted E8F values in f32 space, then quantize.
///
/// This is the canonical hybrid pattern for weighted sums:
/// 1. Convert E8F weights and values to f32
/// 2. Accumulate in f32 space
/// 3. Quantize final result to E8F
///
/// # Arguments
///
/// * `weights` - E8F weights (converted to f32 for computation)
/// * `values` - E8F values to weight and sum
///
/// # Returns
///
/// The weighted sum quantized back to E8F, plus the quantization error.
pub fn weighted_sum_hybrid(weights: &[E8F], values: &[E8F]) -> (E8F, f32) {
    assert_eq!(weights.len(), values.len());

    if weights.is_empty() {
        return (E8F::new(0), 0.0);
    }

    // Accumulate in f32 space
    let mut sum = [0.0f32; 8];

    for (w, v) in weights.iter().zip(values.iter()) {
        let w_coords = w.to_f32_coords();
        let v_coords = v.to_f32_coords();

        // Weight is treated as a scalar (first coordinate)
        let w_scalar = w_coords[0];

        for i in 0..8 {
            sum[i] += w_scalar * v_coords[i];
        }
    }

    // Normalize before quantization
    let norm = sum.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > 0.0 {
        for c in &mut sum {
            *c /= norm;
        }
    }

    // Quantize final result
    E8F::from_f32_coords(&sum)
}

/// Compute dot product in f32 space for precision.
///
/// While E8F has a built-in dot product via lookup tables, this function
/// computes the exact f32 dot product for cases requiring higher precision.
///
/// # Arguments
///
/// * `a` - First E8F value
/// * `b` - Second E8F value
///
/// # Returns
///
/// The exact f32 dot product of the two E8F root vectors.
pub fn dot_f32(a: E8F, b: E8F) -> f32 {
    let a_coords = a.to_f32_coords();
    let b_coords = b.to_f32_coords();

    a_coords
        .iter()
        .zip(b_coords.iter())
        .map(|(x, y)| x * y)
        .sum()
}

/// Compute chordal distance between two E8F values.
///
/// The chordal distance is the Euclidean distance between points on the
/// unit sphere, useful for measuring quantization error.
///
/// # Arguments
///
/// * `a` - First E8F value
/// * `b` - Second E8F value
///
/// # Returns
///
/// The chordal distance in [0, 2] range.
pub fn chordal_distance(a: E8F, b: E8F) -> f32 {
    let a_coords = a.to_f32_coords();
    let b_coords = b.to_f32_coords();

    let sum_sq: f32 = a_coords
        .iter()
        .zip(b_coords.iter())
        .map(|(x, y)| (x - y).powi(2))
        .sum();

    sum_sq.sqrt()
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 4: E8VEC HYBRID OPERATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Extension trait for E8Vec hybrid operations.
pub trait E8VecCompute {
    /// Convert entire vector to f32 representation.
    fn to_f32_vec_full(&self) -> Vec<f32>;

    /// Create from f32 vector with quantization.
    fn from_f32_vec_full(vec: &[f32]) -> Self;

    /// Compute dot product in f32 space for precision.
    fn dot_f32(&self, other: &Self) -> f32;
}

impl E8VecCompute for E8Vec {
    fn to_f32_vec_full(&self) -> Vec<f32> {
        self.to_f32_vec()
    }

    fn from_f32_vec_full(vec: &[f32]) -> Self {
        E8Vec::from_f32_vec(vec)
    }

    fn dot_f32(&self, other: &Self) -> f32 {
        assert_eq!(self.data.len(), other.data.len());

        self.data
            .iter()
            .zip(other.data.iter())
            .map(|(a, b)| dot_f32(*a, *b))
            .sum()
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 5: ERROR BOUND CONSTANTS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Maximum chordal distance for single E8F quantization.
///
/// This is the worst-case error when quantizing an arbitrary 8D unit vector
/// to the nearest E8 root. The E8 lattice has 240 roots uniformly distributed
/// on S⁷, giving a maximum quantization error of approximately 0.087.
pub const MAX_SINGLE_QUANTIZATION_ERROR: f32 = 0.087;

/// Maximum chordal distance for E8F roundtrip (E8F → f32 → E8F).
///
/// Due to the discrete nature of the E8 lattice, a roundtrip through f32
/// space may land on a different root. The maximum error is bounded by
/// approximately 0.15 chordal distance.
pub const MAX_ROUNDTRIP_ERROR: f32 = 0.15;

/// Recommended maximum chain length before re-alignment.
///
/// After this many E8F operations, accumulated error may exceed acceptable
/// bounds. Use `E8FAligned` or explicit re-quantization for longer chains.
pub const RECOMMENDED_MAX_CHAIN_LENGTH: usize = 10;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 6: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8f_to_f32_coords() {
        let e8f = E8F::new(42);
        let coords = e8f.to_f32_coords();

        // Should be unit vector
        let norm: f32 = coords.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!(
            (norm - 1.0).abs() < 1e-5,
            "E8F coords should be unit vector"
        );
    }

    #[test]
    fn test_e8f_roundtrip() {
        for idx in 0..240u8 {
            let original = E8F::new(idx);
            let coords = original.to_f32_coords();
            let (recovered, error) = E8F::from_f32_coords(&coords);

            // Roundtrip should recover the same root
            assert_eq!(
                original.index(),
                recovered.index(),
                "Roundtrip should preserve E8F index"
            );
            assert!(
                error < 1e-5,
                "Roundtrip error should be negligible for exact coords"
            );
        }
    }

    #[test]
    fn test_e8f_to_u32() {
        let e8f = E8F::new(100);
        assert_eq!(e8f.to_u32(), 100);

        let recovered = E8F::from_u32(100);
        assert_eq!(recovered.index(), 100);
    }

    #[test]
    fn test_e8f_from_u32_clamping() {
        // Values > 239 should be clamped
        let e8f = E8F::from_u32(500);
        assert_eq!(e8f.index(), 239);
    }

    #[test]
    fn test_compute_transition_scores_hybrid() {
        let mut resonance = [0u32; 240];
        resonance[0] = 100;
        resonance[1] = 50;

        let mut valorem = [[0u32; 240]; 240];
        valorem[0][10] = 10;
        valorem[1][10] = 20;

        let scores = compute_transition_scores_hybrid(&resonance, &valorem);

        // score[10] = (100*10 + 50*20) >> 10 = 2000 >> 10 = 1
        // Note: The shift is for scaling, actual value depends on implementation
        assert!(scores[10] > 0, "Score should be non-zero");
    }

    #[test]
    fn test_compute_transition_scores_sparse() {
        let mut resonance = [0u32; 240];
        resonance[0] = 100;
        resonance[1] = 5; // Below threshold

        let mut valorem = [[0u32; 240]; 240];
        valorem[0][10] = 10;
        valorem[1][10] = 20;

        let scores = compute_transition_scores_sparse(&resonance, &valorem, 10);

        // Only root 0 should contribute (root 1 is below threshold)
        // The sparse version should skip root 1
        // Just verify it runs without panic
        let _ = scores[10];
    }

    #[test]
    fn test_dot_f32() {
        let a = E8F::new(0);
        let b = E8F::new(0);

        let dot = dot_f32(a, b);
        assert!(
            (dot - 1.0).abs() < 1e-5,
            "Same root should have dot product 1.0"
        );
    }

    #[test]
    fn test_chordal_distance() {
        let a = E8F::new(0);
        let b = E8F::new(0);

        let dist = chordal_distance(a, b);
        assert!(dist < 1e-5, "Same root should have zero chordal distance");

        // Different roots should have non-zero distance
        let c = E8F::new(100);
        let dist2 = chordal_distance(a, c);
        assert!(dist2 > 0.0, "Different roots should have non-zero distance");
    }

    #[test]
    fn test_weighted_sum_hybrid() {
        let weights = vec![E8F::new(100), E8F::new(100)];
        let values = vec![E8F::new(0), E8F::new(0)];

        let (result, error) = weighted_sum_hybrid(&weights, &values);

        assert!(result.is_valid(), "Result should be valid E8F");
        // Error can be larger for weighted sums due to accumulated quantization
        // Just verify it's finite and reasonable (< 2.0 which is max chordal distance)
        assert!(
            error.is_finite() && error < 2.0,
            "Error should be finite and bounded"
        );
    }

    #[test]
    fn test_e8vec_compute() {
        let vec1 = E8Vec::from_indices(&[0, 1, 2, 3]);
        let vec2 = E8Vec::from_indices(&[0, 1, 2, 3]);

        let dot = vec1.dot_f32(&vec2);
        assert!(dot > 0.0, "Same vectors should have positive dot product");
    }
}

File: aligned.rs
================
/* crates/gf8/src/aligned.rs */
//! # E8F Error Management - Aligned Wrappers
//!
//! This module provides automatic error management for E8F operations through
//! zero-cost wrappers that track operation counts and trigger re-alignment
//! when quantization drift may accumulate.
//!
//! ## Key Types
//! - [`E8FAligned`]: Zero-cost wrapper that tracks operation count and triggers
//!   automatic re-alignment after a configurable number of operations.
//! - [`E8FChain`]: Tracks operation sequences with drift metrics and warnings.
//!
//! ## Design Rationale
//! E8F operations always resolve to valid E8 roots via lookup tables, but
//! chaining many operations can accumulate semantic drift from the original
//! intent. These wrappers provide automatic re-alignment to bound this drift.
//!
//! ## Example
//! ```rust
//! use gf8::aligned::E8FAligned;
//! use gf8::E8F;
//!
//! let mut aligned = E8FAligned::new(E8F::new(42));
//!
//! // Operations are tracked automatically
//! aligned.op(|e| e + E8F::new(10));
//! aligned.op(|e| e * E8F::new(5));
//!
//! // After max_ops_before_align operations, alignment is triggered
//! let result = aligned.value();
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::quantize_to_nearest_code;
use crate::{E8F, Gf8, gf8_chordal_distance};

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E8FAligned - ZERO-COST WRAPPER WITH AUTOMATIC ALIGNMENT
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Zero-cost wrapper that tracks operation count and triggers automatic alignment.
///
/// This wrapper ensures that E8F values are periodically re-quantized to the
/// nearest valid E8 root, bounding cumulative quantization drift.
///
/// # Default Behavior
/// - `max_ops_before_align`: 10 operations before automatic re-alignment
/// - Alignment converts E8F → Gf8 → nearest E8 root
///
/// # Example
/// ```rust
/// use gf8::aligned::E8FAligned;
/// use gf8::E8F;
///
/// let mut aligned = E8FAligned::new(E8F::new(42));
///
/// // Chain operations - alignment happens automatically after 10 ops
/// for i in 0..15 {
///     aligned.op(|e| e + E8F::new(i as u8));
/// }
///
/// // Value is guaranteed to be a valid E8 root
/// assert!(aligned.value().is_valid());
/// ```
#[derive(Debug, Clone, Copy)]
pub struct E8FAligned {
    /// The current E8F value.
    value: E8F,
    /// Number of operations since last alignment.
    ops_since_alignment: u8,
    /// Maximum operations before triggering automatic alignment.
    max_ops_before_align: u8,
}

impl E8FAligned {
    /// Default number of operations before automatic alignment.
    pub const DEFAULT_MAX_OPS: u8 = 10;

    /// Create a new aligned wrapper with default settings.
    ///
    /// # Arguments
    /// * `value` - Initial E8F value
    #[inline]
    pub fn new(value: E8F) -> Self {
        Self {
            value,
            ops_since_alignment: 0,
            max_ops_before_align: Self::DEFAULT_MAX_OPS,
        }
    }

    /// Create a new aligned wrapper with custom alignment threshold.
    ///
    /// # Arguments
    /// * `value` - Initial E8F value
    /// * `max_ops` - Maximum operations before automatic alignment
    #[inline]
    pub fn with_max_ops(value: E8F, max_ops: u8) -> Self {
        Self {
            value,
            ops_since_alignment: 0,
            max_ops_before_align: max_ops,
        }
    }

    /// Get the current value.
    #[inline]
    pub fn value(&self) -> E8F {
        self.value
    }

    /// Get the number of operations since last alignment.
    #[inline]
    pub fn ops_since_alignment(&self) -> u8 {
        self.ops_since_alignment
    }

    /// Get the maximum operations before alignment.
    #[inline]
    pub fn max_ops_before_align(&self) -> u8 {
        self.max_ops_before_align
    }

    /// Set the maximum operations before alignment.
    #[inline]
    pub fn set_max_ops(&mut self, max_ops: u8) {
        self.max_ops_before_align = max_ops;
    }

    /// Perform an operation with automatic alignment check.
    ///
    /// After the operation, if `ops_since_alignment >= max_ops_before_align`,
    /// automatic re-alignment is triggered.
    ///
    /// # Arguments
    /// * `f` - Operation to perform on the E8F value
    ///
    /// # Returns
    /// Mutable reference to self for chaining
    #[inline]
    pub fn op<F: FnOnce(E8F) -> E8F>(&mut self, f: F) -> &mut Self {
        self.value = f(self.value);
        self.ops_since_alignment = self.ops_since_alignment.saturating_add(1);

        if self.ops_since_alignment >= self.max_ops_before_align {
            self.align();
        }
        self
    }

    /// Force re-alignment to the nearest valid E8 root.
    ///
    /// This converts the current E8F to its Gf8 representation, then
    /// re-quantizes to the nearest E8 root, resetting the operation counter.
    #[inline]
    pub fn align(&mut self) {
        if !self.value.is_valid() {
            self.value = E8F::new(0);
            self.ops_since_alignment = 0;
            return;
        }

        let gf8 = self.value.to_gf8();
        let (code, _distance) = quantize_to_nearest_code(gf8.coords());
        self.value = E8F::new(code.0);
        self.ops_since_alignment = 0;
    }

    /// Check if alignment is needed (ops >= threshold).
    #[inline]
    pub fn needs_alignment(&self) -> bool {
        self.ops_since_alignment >= self.max_ops_before_align
    }

    /// Reset the operation counter without re-aligning.
    #[inline]
    pub fn reset_counter(&mut self) {
        self.ops_since_alignment = 0;
    }
}

impl Default for E8FAligned {
    fn default() -> Self {
        Self::new(E8F::new(0))
    }
}

impl From<E8F> for E8FAligned {
    fn from(value: E8F) -> Self {
        Self::new(value)
    }
}

impl From<E8FAligned> for E8F {
    fn from(aligned: E8FAligned) -> Self {
        aligned.value
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 2: E8FChain - OPERATION SEQUENCE TRACKING WITH DRIFT METRICS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Tracks a chain of E8F operations with drift metrics and warnings.
///
/// Unlike `E8FAligned`, this type maintains a reference to the initial ground
/// truth value and tracks cumulative drift, logging warnings when drift
/// exceeds a configurable threshold.
///
/// # Drift Metrics (R15.6)
/// - `max_drift`: Maximum observed drift from ground truth
/// - `mean_drift`: Running mean of drift values across operations
/// - `alignment_count`: Number of times re-alignment was triggered
///
/// # Automatic Re-alignment (R15.9)
/// When drift exceeds the threshold (default: 0.1 chordal distance), a warning
/// is logged and automatic re-alignment is triggered.
///
/// # Example
/// ```rust
/// use gf8::aligned::E8FChain;
/// use gf8::{E8F, Gf8};
///
/// let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
/// let mut chain = E8FChain::start(&initial);
///
/// chain.apply("add_10", |e| e + E8F::new(10));
/// chain.apply("mul_5", |e| e * E8F::new(5));
///
/// let (result, max_drift) = chain.finish();
/// println!("Max drift: {:.4}", max_drift);
/// ```
#[derive(Debug, Clone)]
pub struct E8FChain {
    /// Ground truth reference (initial Gf8 value).
    initial: Gf8,
    /// Current quantized value.
    current: E8F,
    /// Operation names for debugging.
    ops: Vec<&'static str>,
    /// Maximum observed drift from ground truth.
    max_drift: f32,
    /// Sum of all drift values (for computing mean).
    drift_sum: f32,
    /// Count of drift measurements (for computing mean).
    drift_count: u32,
    /// Number of times re-alignment was triggered.
    alignment_count: u32,
    /// Threshold for warning and auto-realignment (default: 0.1).
    drift_threshold: f32,
}

impl E8FChain {
    /// Default drift threshold for warnings and auto-realignment.
    pub const DEFAULT_DRIFT_THRESHOLD: f32 = 0.1;

    /// Start a new operation chain from a ground truth Gf8 value.
    ///
    /// The initial Gf8 value is stored as the ground truth reference (R15.4).
    /// All subsequent drift measurements are computed against this reference.
    ///
    /// # Arguments
    /// * `initial` - Ground truth Gf8 value to track drift against
    pub fn start(initial: &Gf8) -> Self {
        let (code, _) = quantize_to_nearest_code(initial.coords());
        Self {
            initial: *initial,
            current: E8F::new(code.0),
            ops: Vec::new(),
            max_drift: 0.0,
            drift_sum: 0.0,
            drift_count: 0,
            alignment_count: 0,
            drift_threshold: Self::DEFAULT_DRIFT_THRESHOLD,
        }
    }

    /// Start a new operation chain with a custom drift threshold.
    ///
    /// # Arguments
    /// * `initial` - Ground truth Gf8 value
    /// * `threshold` - Drift threshold for warnings and auto-realignment
    pub fn start_with_threshold(initial: &Gf8, threshold: f32) -> Self {
        let mut chain = Self::start(initial);
        chain.drift_threshold = threshold;
        chain
    }

    /// Apply an operation to the chain, tracking drift.
    ///
    /// After each operation, drift from the ground truth is computed using
    /// `gf8_chordal_distance()`. If drift exceeds the threshold (R15.9):
    /// 1. A warning is logged
    /// 2. Automatic re-alignment is triggered
    ///
    /// # Arguments
    /// * `op_name` - Name of the operation (for debugging)
    /// * `f` - Operation to apply
    ///
    /// # Returns
    /// Mutable reference to self for chaining
    pub fn apply(&mut self, op_name: &'static str, f: impl FnOnce(E8F) -> E8F) -> &mut Self {
        self.current = f(self.current);
        self.ops.push(op_name);

        // Measure drift from ground truth using gf8_chordal_distance
        let current_gf8 = self.current.to_gf8();
        let drift = gf8_chordal_distance(&self.initial, &current_gf8);

        // Update drift metrics (R15.6)
        self.max_drift = self.max_drift.max(drift);
        self.drift_sum += drift;
        self.drift_count += 1;

        // R15.9: Log warning and force re-alignment when drift exceeds threshold
        if drift > self.drift_threshold {
            eprintln!(
                "[WARN] E8FChain drift {:.4} exceeds threshold {:.4} after {} ops: {:?}",
                drift,
                self.drift_threshold,
                self.ops.len(),
                self.ops
            );
            // Force re-alignment (R15.9)
            self.align_to_nearest_root();
        }

        self
    }

    /// Get the current drift from ground truth.
    ///
    /// Computes drift using `gf8_chordal_distance()` between the current
    /// E8F value (converted to Gf8) and the initial ground truth.
    pub fn current_drift(&self) -> f32 {
        let current_gf8 = self.current.to_gf8();
        gf8_chordal_distance(&self.initial, &current_gf8)
    }

    /// Get the maximum observed drift (R15.6).
    #[inline]
    pub fn max_drift(&self) -> f32 {
        self.max_drift
    }

    /// Get the mean drift across all operations (R15.6).
    ///
    /// Returns 0.0 if no operations have been performed.
    #[inline]
    pub fn mean_drift(&self) -> f32 {
        if self.drift_count == 0 {
            0.0
        } else {
            self.drift_sum / self.drift_count as f32
        }
    }

    /// Get the number of times re-alignment was triggered (R15.6).
    #[inline]
    pub fn alignment_count(&self) -> u32 {
        self.alignment_count
    }

    /// Get the current E8F value.
    #[inline]
    pub fn current(&self) -> E8F {
        self.current
    }

    /// Get the ground truth Gf8 value (R15.4).
    #[inline]
    pub fn initial(&self) -> &Gf8 {
        &self.initial
    }

    /// Get the operation history (for debugging).
    #[inline]
    pub fn ops(&self) -> &[&'static str] {
        &self.ops
    }

    /// Get the drift threshold.
    #[inline]
    pub fn drift_threshold(&self) -> f32 {
        self.drift_threshold
    }

    /// Set the drift threshold.
    #[inline]
    pub fn set_drift_threshold(&mut self, threshold: f32) {
        self.drift_threshold = threshold;
    }

    /// Explicit re-quantization to the nearest valid E8 root (R15.5).
    ///
    /// This method:
    /// 1. Converts current E8F to Gf8
    /// 2. Re-quantizes to the nearest E8 root
    /// 3. Updates the ground truth reference to the new aligned value
    /// 4. Increments the alignment counter (R15.6)
    /// 5. Clears operation history
    ///
    /// Note: `max_drift` and `mean_drift` are preserved for overall metrics tracking.
    /// The ground truth reference is updated to the newly aligned value so that
    /// subsequent drift measurements are relative to the aligned state.
    pub fn align_to_nearest_root(&mut self) {
        let gf8 = self.current.to_gf8();
        let (code, _) = quantize_to_nearest_code(gf8.coords());
        self.current = E8F::new(code.0);
        // Update initial to current for fresh drift tracking from aligned state
        self.initial = self.current.to_gf8();
        self.alignment_count += 1;
        self.ops.clear();
    }

    /// Force re-alignment to the nearest E8 root.
    ///
    /// This is an alias for `align_to_nearest_root()` for backward compatibility.
    /// It re-quantizes the current value and resets drift tracking
    /// to use the new value as the reference point.
    #[inline]
    pub fn realign(&mut self) {
        self.align_to_nearest_root();
    }

    /// Finish the chain and return the result with max drift.
    ///
    /// # Returns
    /// Tuple of (final E8F value, maximum observed drift)
    pub fn finish(self) -> (E8F, f32) {
        (self.current, self.max_drift)
    }

    /// Finish the chain and return full metrics.
    ///
    /// # Returns
    /// Tuple of (final E8F value, max_drift, mean_drift, alignment_count)
    pub fn finish_with_metrics(self) -> (E8F, f32, f32, u32) {
        let mean = self.mean_drift();
        (self.current, self.max_drift, mean, self.alignment_count)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 3: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8f_aligned_basic() {
        let aligned = E8FAligned::new(E8F::new(42));
        assert_eq!(aligned.value().index(), 42);
        assert_eq!(aligned.ops_since_alignment(), 0);
    }

    #[test]
    fn test_e8f_aligned_op_tracking() {
        let mut aligned = E8FAligned::new(E8F::new(10));

        // Perform some operations
        aligned.op(|e| e + E8F::new(5));
        assert_eq!(aligned.ops_since_alignment(), 1);

        aligned.op(|e| e * E8F::new(3));
        assert_eq!(aligned.ops_since_alignment(), 2);
    }

    #[test]
    fn test_e8f_aligned_auto_alignment() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(10), 3);

        // Perform 3 operations - should trigger alignment
        aligned.op(|e| e + E8F::new(1));
        aligned.op(|e| e + E8F::new(2));
        aligned.op(|e| e + E8F::new(3));

        // Counter should be reset after alignment
        assert_eq!(aligned.ops_since_alignment(), 0);

        // Value should still be valid
        assert!(aligned.value().is_valid());
    }

    #[test]
    fn test_e8f_aligned_manual_align() {
        let mut aligned = E8FAligned::new(E8F::new(50));

        aligned.op(|e| e + E8F::new(10));
        aligned.op(|e| e + E8F::new(20));
        assert_eq!(aligned.ops_since_alignment(), 2);

        aligned.align();
        assert_eq!(aligned.ops_since_alignment(), 0);
        assert!(aligned.value().is_valid());
    }

    #[test]
    fn test_e8f_aligned_needs_alignment() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(10), 2);

        assert!(!aligned.needs_alignment());
        aligned.op(|e| e + E8F::new(1));
        assert!(!aligned.needs_alignment());
        aligned.op(|e| e + E8F::new(2));
        // After 2 ops with max_ops=2, alignment was triggered, counter reset
        assert!(!aligned.needs_alignment());
    }

    #[test]
    fn test_e8f_chain_basic() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start(&initial);

        assert!(chain.current().is_valid());
        assert_eq!(chain.ops().len(), 0);
        assert_eq!(chain.max_drift(), 0.0);
        assert_eq!(chain.mean_drift(), 0.0);
        assert_eq!(chain.alignment_count(), 0);
    }

    #[test]
    fn test_e8f_chain_apply() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment during test
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("add_10", |e| e + E8F::new(10));
        assert_eq!(chain.ops().len(), 1);
        assert_eq!(chain.ops()[0], "add_10");

        chain.apply("mul_5", |e| e * E8F::new(5));
        assert_eq!(chain.ops().len(), 2);
    }

    #[test]
    fn test_e8f_chain_drift_tracking() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment during test
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        // Apply operations that may cause drift
        for i in 0..5 {
            chain.apply("op", |e| e + E8F::new(i * 10));
        }

        // Drift should be tracked
        let drift = chain.current_drift();
        assert!(drift >= 0.0);
        assert!(chain.max_drift() >= drift || (chain.max_drift() - drift).abs() < 1e-6);

        // Mean drift should be computed (R15.6)
        assert!(chain.mean_drift() >= 0.0);
    }

    #[test]
    fn test_e8f_chain_finish() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let mut chain = E8FChain::start(&initial);

        chain.apply("op1", |e| e + E8F::new(10));
        chain.apply("op2", |e| e * E8F::new(20));

        let (result, max_drift) = chain.finish();
        assert!(result.is_valid());
        assert!(max_drift >= 0.0);
    }

    #[test]
    fn test_e8f_chain_finish_with_metrics() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let mut chain = E8FChain::start(&initial);

        chain.apply("op1", |e| e + E8F::new(10));
        chain.apply("op2", |e| e * E8F::new(20));

        let (result, max_drift, mean_drift, alignment_count) = chain.finish_with_metrics();
        assert!(result.is_valid());
        assert!(max_drift >= 0.0);
        assert!(mean_drift >= 0.0);
        // alignment_count is u32, just verify it's accessible
        let _ = alignment_count;
    }

    #[test]
    fn test_e8f_chain_realign() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("op1", |e| e + E8F::new(50));
        chain.apply("op2", |e| e + E8F::new(100));

        let max_drift_before = chain.max_drift();
        chain.realign();

        // After realign, ops should be cleared
        assert_eq!(chain.ops().len(), 0);
        assert!(chain.current().is_valid());
        // Alignment count should be incremented
        assert_eq!(chain.alignment_count(), 1);

        // max_drift is preserved for metrics tracking
        assert_eq!(chain.max_drift(), max_drift_before);
    }

    #[test]
    fn test_e8f_chain_align_to_nearest_root() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("op1", |e| e + E8F::new(50));

        // Explicit re-quantization (R15.5)
        chain.align_to_nearest_root();

        assert!(chain.current().is_valid());
        assert_eq!(chain.alignment_count(), 1);
        assert_eq!(chain.ops().len(), 0);
    }

    #[test]
    fn test_e8f_chain_auto_realignment_on_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use very low threshold to trigger auto-realignment (R15.9)
        let mut chain = E8FChain::start_with_threshold(&initial, 0.001);

        // Apply operation that will likely exceed threshold
        chain.apply("big_op", |e| e + E8F::new(200));

        // Auto-realignment should have been triggered
        // (alignment_count > 0 if drift exceeded threshold)
        // Note: The actual drift depends on E8 geometry, so we just verify
        // the mechanism works
        assert!(chain.current().is_valid());
    }

    #[test]
    fn test_e8f_chain_metrics_tracking() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        // Apply multiple operations
        chain.apply("op1", |e| e + E8F::new(10));
        chain.apply("op2", |e| e + E8F::new(20));
        chain.apply("op3", |e| e + E8F::new(30));

        // R15.6: Track error metrics
        assert!(chain.max_drift() >= 0.0);
        assert!(chain.mean_drift() >= 0.0);
        assert_eq!(chain.alignment_count(), 0); // No auto-realignment with high threshold
    }

    #[test]
    fn test_e8f_aligned_from_into() {
        let e8f = E8F::new(100);
        let aligned: E8FAligned = e8f.into();
        assert_eq!(aligned.value().index(), 100);

        let back: E8F = aligned.into();
        assert_eq!(back.index(), 100);
    }

    #[test]
    fn test_e8f_chain_custom_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start_with_threshold(&initial, 0.05);

        assert_eq!(chain.drift_threshold(), 0.05);
    }

    #[test]
    fn test_e8f_chain_ground_truth_reference() {
        // R15.4: Use Gf8 as ground truth reference
        let initial = Gf8::new([0.7, 0.3, 0.5, 0.1, 0.2, 0.4, 0.6, 0.8]);
        let chain = E8FChain::start(&initial);

        // Ground truth should be stored
        let stored_initial = chain.initial();
        assert_eq!(stored_initial.coords()[0], initial.coords()[0]);
        assert_eq!(stored_initial.coords()[7], initial.coords()[7]);
    }

    #[test]
    fn test_e8f_chain_operation_names_for_debugging() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use high threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 10.0);

        chain.apply("first_op", |e| e + E8F::new(1));
        chain.apply("second_op", |e| e + E8F::new(2));
        chain.apply("third_op", |e| e + E8F::new(3));

        // Operation names should be tracked for debugging
        let ops = chain.ops();
        assert_eq!(ops.len(), 3);
        assert_eq!(ops[0], "first_op");
        assert_eq!(ops[1], "second_op");
        assert_eq!(ops[2], "third_op");
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // TASK 3.3: COMPREHENSIVE TESTS FOR E8F ERROR MANAGEMENT (R15.3, R15.9)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// R15.3: Test that alignment triggers exactly after N operations (default: 10)
    #[test]
    fn test_alignment_triggers_after_n_operations_default() {
        // Default max_ops is 10
        let mut aligned = E8FAligned::new(E8F::new(42));
        assert_eq!(aligned.max_ops_before_align(), E8FAligned::DEFAULT_MAX_OPS);
        assert_eq!(E8FAligned::DEFAULT_MAX_OPS, 10);

        // Perform 9 operations - should NOT trigger alignment
        for i in 0..9 {
            aligned.op(|e| e + E8F::new(i));
            assert_eq!(aligned.ops_since_alignment(), i + 1);
        }

        // 10th operation should trigger alignment and reset counter
        aligned.op(|e| e + E8F::new(9));
        assert_eq!(
            aligned.ops_since_alignment(),
            0,
            "Counter should reset after alignment"
        );
        assert!(aligned.value().is_valid());
    }

    /// R15.3: Test alignment with custom chain depth
    #[test]
    fn test_alignment_triggers_after_custom_n_operations() {
        let custom_max = 5;
        let mut aligned = E8FAligned::with_max_ops(E8F::new(100), custom_max);
        assert_eq!(aligned.max_ops_before_align(), custom_max);

        // Perform 4 operations - should NOT trigger alignment
        for i in 0..4 {
            aligned.op(|e| e + E8F::new(i));
            assert_eq!(aligned.ops_since_alignment(), i + 1);
        }

        // 5th operation should trigger alignment
        aligned.op(|e| e + E8F::new(4));
        assert_eq!(aligned.ops_since_alignment(), 0);

        // Continue with more operations - should trigger again at 5
        for i in 0..5 {
            aligned.op(|e| e + E8F::new(i as u8));
        }
        assert_eq!(
            aligned.ops_since_alignment(),
            0,
            "Should reset after second alignment"
        );
    }

    /// R15.3: Test that alignment is amortized (no overhead for single ops)
    #[test]
    fn test_alignment_amortized_no_overhead_single_ops() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(50), 100);

        // Single operation should not trigger alignment
        aligned.op(|e| e + E8F::new(1));
        assert_eq!(aligned.ops_since_alignment(), 1);
        assert!(!aligned.needs_alignment());

        // Value should still be valid without alignment
        assert!(aligned.value().is_valid());
    }

    /// R15.9: Test warning threshold behavior - drift exceeds threshold triggers warning
    #[test]
    fn test_warning_threshold_triggers_realignment() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Very low threshold to ensure drift exceeds it
        let mut chain = E8FChain::start_with_threshold(&initial, 0.001);

        let alignment_count_before = chain.alignment_count();

        // Apply operation that will cause significant drift
        chain.apply("large_drift_op", |e| e + E8F::new(200));

        // R15.9: Auto-realignment should have been triggered
        // The alignment count should have increased
        assert!(
            chain.alignment_count() > alignment_count_before,
            "Alignment should be triggered when drift exceeds threshold"
        );

        // Value should still be valid after realignment
        assert!(chain.current().is_valid());
    }

    /// R15.9: Test that default threshold is 0.1 chordal distance
    #[test]
    fn test_default_drift_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start(&initial);

        assert_eq!(
            chain.drift_threshold(),
            E8FChain::DEFAULT_DRIFT_THRESHOLD,
            "Default threshold should match constant"
        );
        assert_eq!(
            E8FChain::DEFAULT_DRIFT_THRESHOLD,
            0.1,
            "Default threshold should be 0.1"
        );
    }

    /// R15.9: Test that warning is logged when drift exceeds threshold
    /// (We verify this by checking alignment_count increases)
    #[test]
    fn test_drift_exceeds_threshold_forces_realignment() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use default threshold (0.1)
        let mut chain = E8FChain::start(&initial);

        // Apply operations that will cause drift > 0.1
        // Adding a large offset should cause significant drift
        chain.apply("drift_op", |e| e + E8F::new(150));

        // Check if drift exceeded threshold and realignment occurred
        // Note: The actual drift depends on E8 geometry
        let drift = chain.current_drift();
        if drift > 0.1 {
            // If drift exceeded threshold, alignment should have been triggered
            assert!(
                chain.alignment_count() > 0,
                "Alignment should be triggered when drift > threshold"
            );
        }
    }

    /// R15.6: Test drift tracking accuracy - max_drift, mean_drift, alignment_count
    #[test]
    fn test_drift_tracking_accuracy() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // High threshold to prevent auto-realignment during test
        let mut chain = E8FChain::start_with_threshold(&initial, 100.0);

        // Apply multiple operations and track drift
        let mut expected_max_drift = 0.0f32;
        let mut drift_sum = 0.0f32;
        let mut drift_count = 0u32;

        for i in 0..5 {
            chain.apply("op", |e| e + E8F::new(i * 20));

            // Manually compute expected drift
            let current_drift = chain.current_drift();
            expected_max_drift = expected_max_drift.max(current_drift);
            drift_sum += current_drift;
            drift_count += 1;
        }

        let expected_mean = drift_sum / drift_count as f32;

        // Verify drift metrics (R15.6)
        assert!(
            (chain.max_drift() - expected_max_drift).abs() < 1e-5,
            "max_drift should match expected: {} vs {}",
            chain.max_drift(),
            expected_max_drift
        );
        assert!(
            (chain.mean_drift() - expected_mean).abs() < 1e-5,
            "mean_drift should match expected: {} vs {}",
            chain.mean_drift(),
            expected_mean
        );
        assert_eq!(
            chain.alignment_count(),
            0,
            "No alignment with high threshold"
        );
    }

    /// R15.6: Test alignment_count increments correctly
    #[test]
    fn test_alignment_count_increments() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // High threshold to prevent auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 100.0);

        assert_eq!(chain.alignment_count(), 0);

        chain.apply("op1", |e| e + E8F::new(10));
        chain.realign();
        assert_eq!(chain.alignment_count(), 1);

        chain.apply("op2", |e| e + E8F::new(20));
        chain.align_to_nearest_root();
        assert_eq!(chain.alignment_count(), 2);

        chain.apply("op3", |e| e + E8F::new(30));
        chain.realign();
        assert_eq!(chain.alignment_count(), 3);
    }

    /// R15.9: Test that ops are cleared after auto-realignment
    #[test]
    fn test_ops_cleared_after_auto_realignment() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Very low threshold to trigger auto-realignment
        let mut chain = E8FChain::start_with_threshold(&initial, 0.0001);

        // Apply operation that will exceed threshold
        chain.apply("trigger_op", |e| e + E8F::new(200));

        // If auto-realignment was triggered, ops should be cleared
        if chain.alignment_count() > 0 {
            assert_eq!(
                chain.ops().len(),
                0,
                "Ops should be cleared after auto-realignment"
            );
        }
    }

    /// Test E8FAligned counter saturation (edge case)
    #[test]
    fn test_aligned_counter_saturation() {
        let mut aligned = E8FAligned::with_max_ops(E8F::new(10), 255);

        // Perform many operations without triggering alignment
        for _ in 0..254 {
            aligned.op(|e| e); // Identity operation
        }

        // Counter should be at 254
        assert_eq!(aligned.ops_since_alignment(), 254);

        // One more should trigger alignment (255 >= 255)
        aligned.op(|e| e);
        assert_eq!(aligned.ops_since_alignment(), 0);
    }

    /// Test E8FChain with zero operations
    #[test]
    fn test_chain_zero_operations() {
        let initial = Gf8::new([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
        let chain = E8FChain::start(&initial);

        // With no operations, metrics should be zero
        assert_eq!(chain.max_drift(), 0.0);
        assert_eq!(chain.mean_drift(), 0.0);
        assert_eq!(chain.alignment_count(), 0);
        assert_eq!(chain.ops().len(), 0);
    }

    /// Test that set_drift_threshold works correctly
    #[test]
    fn test_set_drift_threshold() {
        let initial = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let mut chain = E8FChain::start(&initial);

        assert_eq!(chain.drift_threshold(), 0.1);

        chain.set_drift_threshold(0.5);
        assert_eq!(chain.drift_threshold(), 0.5);

        chain.set_drift_threshold(0.01);
        assert_eq!(chain.drift_threshold(), 0.01);
    }
}

File: e32l.rs
=============
/* crates/gf8/src/e32l.rs */
//! # E32L – True Lossless f32 Representation and Compression Framework
//!
//! This module provides the definitive answer to achieving true lossless f32 representation
//! and compression within the E8 ecosystem. It contains two primary components:
//!
//! 1.  **`E32L` Type:** A **ZERO-ERROR, BIJECTIVE** conversion between a standard `f32` and a
//!     32-dimensional structure composed of four `E8F` roots. It serves as a lossless,
//!     4-byte, E8-native representation for `f32`.
//!
//! 2.  **Compression Framework:** A high-performance, lossless compression algorithm inspired by
//!     bit-plane decomposition. It transforms blocks of `f32` (or `E32L`) values into a
//!     highly compressible state and uses entropy coding to achieve significant bitrate reduction.
//!
//! ## The `E32L` Breakthrough: Deconstruction, Not Quantization
//!
//! An `f32` is fundamentally 32 bits of information. `E32L` preserves these 32 bits perfectly by
//! mapping them to the indices of four `E8F` roots.
//!
//! ```text
//! f32 (32 bits)  →  f32.to_bits()  →  u32  →  [u8; 4]  →  [E8F; 4]
//!       ↑                                                     ↓
//!       └─────────── (Perfect Reconstruction) ───────────────┘
//! ```
//!
//! ## The Compression Framework: Lossless Bitrate Reduction
//!
//! The provided `compression` module implements a 3-stage reversible pipeline:
//!
//! 1.  **Bit-Matrix Transposition:** A block of `f32` values is losslessly transposed into 32
//!     separate "bit-planes." This groups statistically similar bits (signs with signs,
//!     exponents with exponents), dramatically reducing the entropy of each plane. This is a
//!     provably bijective transform.
//! 2.  **Grouped Entropy Coding:** The sign, exponent, and mantissa bit-planes are compressed
//!     as separate streams using a high-performance entropy coder (`zstd`). This allows the
//!     coder to adapt to the unique statistical properties of each component.
//! 3.  **Framing and Validation:** The compressed streams are packaged into a single, robust data frame with
//!     the necessary metadata for perfect reconstruction. A cryptographic hash (`blake3`) of the
//!     original data is included to guarantee integrity upon decompression.
//!
//! This combination provides both a foundational lossless type (`E32L`) and a powerful algorithm
//! to reduce the storage and transmission cost of datasets composed of these types.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::e8f::E8F;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E32L TYPE DEFINITION
// ═══════════════════════════════════════════════════════════════════════════════════════

/// A true lossless 32-dimensional representation of an f32, composed of four E8F roots.
///
/// This type achieves zero-error conversion by deconstructing the 32 bits of an IEEE 754
/// float into four 8-bit `E8F` indices. It does **not** perform mathematical quantization.
///
/// Assumes that `E8F` is `#[repr(transparent)]` over `u8` (i.e., has the size and alignment of
/// a `u8`) **and** that `E8F::new` / `E8F::index` behave as a pure byte container for the full
/// `0..=255` range without clamping, normalization, or re-encoding. Under these conditions,
/// `E32L` is a strict, bit-perfect wrapper over the underlying `f32` representation.
///
/// # Storage
/// - Wire Format: 4 bytes (same as `f32`).
/// - Memory Format: `[E8F; 4]`.
/// - Conversion Overhead: Zero-cost (bitwise reinterpretation that optimizes away).
///
/// # Example
/// ```rust
/// use gf8::e32l::E32L;
///
/// let original = 3.1415926535f32;
/// let e32l = E32L::from_f32(original);
/// let recovered = e32l.to_f32();
///
/// // The recovered value is not just "close", it is identical.
/// assert_eq!(original.to_bits(), recovered.to_bits());
/// ```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
#[repr(C)]
pub struct E32L {
    /// The four E8F roots whose indices represent the 32 bits of an f32 value.
    /// These are used as bit containers, not for their mathematical vector properties.
    pub roots: [E8F; 4],
}

impl E32L {
    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 2: CORE CONVERSIONS (LOSSLESS)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Creates an `E32L` from an `f32` with **zero error**.
    #[inline]
    pub fn from_f32(value: f32) -> Self {
        let bytes = value.to_le_bytes();
        Self {
            roots: [
                E8F::from_raw(bytes[0]),
                E8F::from_raw(bytes[1]),
                E8F::from_raw(bytes[2]),
                E8F::from_raw(bytes[3]),
            ],
        }
    }

    /// Converts the `E32L` back to an `f32` with **zero error**.
    #[inline]
    pub fn to_f32(&self) -> f32 {
        f32::from_le_bytes([
            self.roots[0].index(),
            self.roots[1].index(),
            self.roots[2].index(),
            self.roots[3].index(),
        ])
    }

    /// Creates an `E32L` from its raw `u32` bit representation.
    #[inline]
    pub fn from_bits(bits: u32) -> Self {
        Self::from_f32(f32::from_bits(bits))
    }

    /// Converts the `E32L` to its raw `u32` bit representation.
    #[inline]
    pub fn to_bits(&self) -> u32 {
        self.to_f32().to_bits()
    }

    /// Creates an `E32L` from a 4-byte array.
    #[inline]
    pub fn from_bytes(bytes: [u8; 4]) -> Self {
        Self {
            roots: [
                E8F::from_raw(bytes[0]),
                E8F::from_raw(bytes[1]),
                E8F::from_raw(bytes[2]),
                E8F::from_raw(bytes[3]),
            ],
        }
    }

    /// Converts the `E32L` to a 4-byte array.
    #[inline]
    pub fn to_bytes(&self) -> [u8; 4] {
        [
            self.roots[0].index(),
            self.roots[1].index(),
            self.roots[2].index(),
            self.roots[3].index(),
        ]
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 3: UTILITY METHODS (DELEGATED FROM f32)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Checks if the contained value is `NaN`.
    #[inline]
    pub fn is_nan(&self) -> bool {
        self.to_f32().is_nan()
    }

    /// Checks if the contained value is `+Infinity` or `-Infinity`.
    #[inline]
    pub fn is_infinite(&self) -> bool {
        self.to_f32().is_infinite()
    }

    /// Checks if the contained value is a finite number.
    #[inline]
    pub fn is_finite(&self) -> bool {
        self.to_f32().is_finite()
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 4: TRAIT IMPLEMENTATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl From<f32> for E32L {
    #[inline]
    fn from(value: f32) -> Self {
        Self::from_f32(value)
    }
}

impl From<E32L> for f32 {
    #[inline]
    fn from(value: E32L) -> Self {
        value.to_f32()
    }
}

impl From<u32> for E32L {
    /// Creates an E32L from its raw IEEE 754 bit representation.
    #[inline]
    fn from(bits: u32) -> Self {
        Self::from_bits(bits)
    }
}

impl From<E32L> for u32 {
    /// Converts an E32L to its raw IEEE 754 bit representation.
    #[inline]
    fn from(value: E32L) -> Self {
        value.to_bits()
    }
}

impl Default for E32L {
    /// Defaults to `0.0f32`.
    #[inline]
    fn default() -> Self {
        Self::from_f32(0.0)
    }
}

impl std::fmt::Display for E32L {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.to_f32())
    }
}

#[cfg(feature = "bytemuck")]
unsafe impl bytemuck::Zeroable for E32L {}

#[cfg(feature = "bytemuck")]
unsafe impl bytemuck::Pod for E32L {}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 5: LOSSLESS COMPRESSION FRAMEWORK
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Provides functions for lossless compression of `f32` or `E32L` slices.
///
/// This module implements a 3-stage reversible pipeline with two compression levels:
///
/// **Level 1 (Machine Readable):**
/// - Bit-planes stored uncompressed or lightly compressed
/// - Direct access to sign/exponent/mantissa without full decompression
/// - Good for semantic queries and streaming
/// - Target: 4:1 to 8:1 compression
///
/// **Level 2 (Maximum Compression):**
/// - Full bit-plane transposition and E8 binary transform
/// - Aggressive entropy coding (zstd level 19)
/// - Requires full decompression for any access
/// - Target: 8:1 to 16:1 compression
///
/// This module requires the `compression` feature to be enabled. It depends on `zstd`,
/// `byteorder`, `blake3`, and `bytemuck`.
#[cfg(feature = "compression")]
pub mod compression {
    use byteorder::{LittleEndian, ReadBytesExt, WriteBytesExt};
    use std::io::{Cursor, Read, Write};

    const MAGIC_NUMBER: u32 = 0x45333243; // E32C (E32L Compression)
    const FORMAT_VERSION: u8 = 2; // Version 2 adds Level 1/2 support

    /// Compression level selection
    #[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
    pub enum CompressionLevel {
        /// Level 1: Machine readable, fast decompression, 4:1-8:1 ratio
        #[default]
        Level1 = 1,
        /// Level 2: Maximum compression, full decompression required, 8:1-16:1 ratio
        Level2 = 2,
    }

    impl CompressionLevel {
        fn zstd_level(&self) -> i32 {
            match self {
                CompressionLevel::Level1 => 3,  // Fast compression
                CompressionLevel::Level2 => 19, // Maximum compression
            }
        }
    }

    /// Represents the compressed data frame.
    pub struct E32LFrame {
        pub level: CompressionLevel,
        pub original_len: u64,
        pub data_hash: [u8; 32],
        pub sign_stream: Vec<u8>,
        pub exponent_stream: Vec<u8>,
        pub mantissa_stream: Vec<u8>,
    }

    /// Lossless compression error types.
    #[derive(Debug)]
    pub enum CompressionError {
        Io(std::io::Error),
        Zstd(std::io::Error),
        InvalidFormat(String),
        IntegrityError,
    }

    impl From<std::io::Error> for CompressionError {
        fn from(err: std::io::Error) -> Self {
            CompressionError::Io(err)
        }
    }

    /// E8-inspired binary bit-plane transform applied in-place to groups of 8 planes.
    ///
    /// This operates over GF(2) on bit-columns across 8 planes:
    ///
    /// For each group of 8 planes and each (byte_idx, bit_idx), we:
    /// - Collect an 8-bit column vector `v` of bits (one from each plane).
    /// - Apply an 8×8 invertible binary matrix `M` (forward) or `M⁻¹` (inverse).
    /// - Write the transformed bits back into the planes.
    ///
    /// Because `M` has determinant 1 over GF(2), this transform is a bijection on the
    /// underlying bit patterns and is therefore perfectly lossless.
    struct E8BitTransform;

    impl E8BitTransform {
        /// Forward 8×8 binary matrix (upper-triangular with ones on the diagonal).
        /// Determinant = 1 over GF(2), hence invertible.
        const FWD: [[u8; 8]; 8] = [
            [1, 1, 0, 0, 0, 0, 0, 0],
            [0, 1, 1, 0, 0, 0, 0, 0],
            [0, 0, 1, 1, 0, 0, 0, 0],
            [0, 0, 0, 1, 1, 0, 0, 0],
            [0, 0, 0, 0, 1, 1, 0, 0],
            [0, 0, 0, 0, 0, 1, 1, 0],
            [0, 0, 0, 0, 0, 0, 1, 1],
            [0, 0, 0, 0, 0, 0, 0, 1],
        ];

        /// Inverse of `FWD` over GF(2).
        const INV: [[u8; 8]; 8] = [
            [1, 1, 1, 1, 1, 1, 1, 1],
            [0, 1, 1, 1, 1, 1, 1, 1],
            [0, 0, 1, 1, 1, 1, 1, 1],
            [0, 0, 0, 1, 1, 1, 1, 1],
            [0, 0, 0, 0, 1, 1, 1, 1],
            [0, 0, 0, 0, 0, 1, 1, 1],
            [0, 0, 0, 0, 0, 0, 1, 1],
            [0, 0, 0, 0, 0, 0, 0, 1],
        ];

        /// Apply the forward E8-style bit mixing to the mantissa planes.
        ///
        /// Operates on groups of 8 planes at a time:
        /// - planes[0..8], planes[8..16]; any remainder (e.g. 16..23) is left unchanged.
        #[inline]
        pub fn forward_mantissa(planes: &mut [Vec<u8>]) {
            Self::apply_groups(planes, &Self::FWD);
        }

        /// Apply the inverse E8-style bit mixing to the mantissa planes.
        #[inline]
        pub fn inverse_mantissa(planes: &mut [Vec<u8>]) {
            Self::apply_groups(planes, &Self::INV);
        }

        #[inline]
        fn apply_groups(planes: &mut [Vec<u8>], mat: &[[u8; 8]; 8]) {
            let num_planes = planes.len();
            if num_planes < 8 {
                return;
            }

            let packed_len = match planes.first() {
                Some(first) => first.len(),
                None => return,
            };

            // Ensure all planes are the same length; if not, bail with no-op.
            if planes.iter().any(|p| p.len() != packed_len) {
                return;
            }

            // Process full groups of 8 planes: 0..8, 8..16, ...
            let mut start = 0;
            while start + 8 <= num_planes {
                let group = &mut planes[start..start + 8];
                Self::apply_group(group, packed_len, mat);
                start += 8;
            }
        }

        #[inline]
        fn apply_group(group: &mut [Vec<u8>], packed_len: usize, mat: &[[u8; 8]; 8]) {
            debug_assert_eq!(group.len(), 8);

            // For each byte position and bit position, apply the 8×8 transform over GF(2).
            for byte_idx in 0..packed_len {
                for bit_idx in 0..8 {
                    // Collect current bits into v[row] ∈ {0,1}
                    let mut v = [0u8; 8];
                    for row in 0..8 {
                        let byte = group[row][byte_idx];
                        v[row] = (byte >> bit_idx) & 1;
                    }

                    // out[row] = Σ_j mat[row][j] * v[j] (mod 2)
                    let mut out = [0u8; 8];
                    for row in 0..8 {
                        let mut acc = 0u8;
                        for (col, &val) in v.iter().enumerate() {
                            if mat[row][col] & 1 == 1 {
                                acc ^= val;
                            }
                        }
                        out[row] = acc & 1;
                    }

                    // Write back transformed bits.
                    for row in 0..8 {
                        let byte_ref = &mut group[row][byte_idx];
                        if out[row] == 1 {
                            *byte_ref |= 1 << bit_idx;
                        } else {
                            *byte_ref &= !(1 << bit_idx);
                        }
                    }
                }
            }
        }
    }

    /// A transposed bit-matrix representation of a block of f32s.
    struct BitMatrix {
        /// Number of f32 values in the block.
        len: usize,
        /// 32 bit-planes, each containing `len` bits packed into bytes.
        planes: [Vec<u8>; 32],
    }

    impl BitMatrix {
        /// Creates a BitMatrix by transposing a slice of f32 values. This is a bijective transform.
        fn from_f32_slice(data: &[f32]) -> Self {
            let len = data.len();
            let packed_len = len.div_ceil(8);
            let mut planes = std::array::from_fn(|_| vec![0u8; packed_len]);

            for (i, &value) in data.iter().enumerate() {
                let bits = value.to_bits();
                let byte_idx = i / 8;
                let bit_idx = i % 8;
                for (p, plane) in planes.iter_mut().enumerate() {
                    if (bits >> p) & 1 == 1 {
                        plane[byte_idx] |= 1 << bit_idx;
                    }
                }
            }
            Self { len, planes }
        }

        /// Reconstructs a Vec<f32> by performing the inverse transposition.
        fn to_f32_vec(&self) -> Vec<f32> {
            let mut values = vec![0u32; self.len];
            for (p, plane) in self.planes.iter().enumerate() {
                for (i, value) in values.iter_mut().take(self.len).enumerate() {
                    let byte_idx = i / 8;
                    let bit_idx = i % 8;
                    if (plane[byte_idx] >> bit_idx) & 1 == 1 {
                        *value |= 1 << p;
                    }
                }
            }
            values.into_iter().map(f32::from_bits).collect()
        }
    }

    /// Compresses a slice of f32 values using the bit-plane transposition method.
    ///
    /// # Arguments
    /// * `data` - The f32 slice to compress
    /// * `level` - Compression level (Level1 for speed, Level2 for size)
    ///
    /// # Returns
    /// A `Vec<u8>` containing the full compressed data frame, or an error.
    pub fn compress_with_level(
        data: &[f32],
        level: CompressionLevel,
    ) -> Result<Vec<u8>, CompressionError> {
        if data.is_empty() {
            // Write a valid but empty frame.
            let mut buffer = Vec::new();
            buffer.write_u32::<LittleEndian>(MAGIC_NUMBER)?;
            buffer.write_u8(FORMAT_VERSION)?;
            buffer.write_u8(level as u8)?;
            buffer.write_u64::<LittleEndian>(0)?; // original_len
            return Ok(buffer);
        }

        // --- Validation ---
        let data_hash = blake3::hash(bytemuck::cast_slice(data));

        // --- Stage 1: Bit-Matrix Transposition ---
        let mut matrix = BitMatrix::from_f32_slice(data);

        // Optional Stage 1b: E8-style bit mixing on mantissa planes (fully reversible).
        {
            // Split into mantissa (0..23), exponent (23..31), sign (31).
            let (mantissa, rest) = matrix.planes.split_at_mut(23);
            let (_exponent, _sign) = rest.split_at_mut(8);
            E8BitTransform::forward_mantissa(mantissa);
        }

        // --- Stage 2: Grouped Entropy Coding ---
        let sign_plane = &matrix.planes[31];
        let exponent_planes = &matrix.planes[23..31];
        let mantissa_planes = &matrix.planes[0..23];

        let zstd_level = level.zstd_level();

        let sign_stream = zstd::stream::encode_all(sign_plane.as_slice(), zstd_level)
            .map_err(CompressionError::Zstd)?;

        let exponent_data: Vec<u8> = exponent_planes
            .iter()
            .flat_map(|p| p.iter())
            .copied()
            .collect();
        let exponent_stream = zstd::stream::encode_all(exponent_data.as_slice(), zstd_level)
            .map_err(CompressionError::Zstd)?;

        let mantissa_data: Vec<u8> = mantissa_planes
            .iter()
            .flat_map(|p| p.iter())
            .copied()
            .collect();
        let mantissa_stream = zstd::stream::encode_all(mantissa_data.as_slice(), zstd_level)
            .map_err(CompressionError::Zstd)?;

        // --- Stage 3: Framing ---
        let mut buffer = Vec::new();
        buffer.write_u32::<LittleEndian>(MAGIC_NUMBER)?;
        buffer.write_u8(FORMAT_VERSION)?;
        buffer.write_u8(level as u8)?;
        buffer.write_u64::<LittleEndian>(data.len() as u64)?;
        buffer.write_all(data_hash.as_bytes())?;
        buffer.write_u64::<LittleEndian>(sign_stream.len() as u64)?;
        buffer.write_u64::<LittleEndian>(exponent_stream.len() as u64)?;
        buffer.write_u64::<LittleEndian>(mantissa_stream.len() as u64)?;
        buffer.write_all(&sign_stream)?;
        buffer.write_all(&exponent_stream)?;
        buffer.write_all(&mantissa_stream)?;

        Ok(buffer)
    }

    /// Compresses a slice of f32 values using Level 1 (default).
    ///
    /// # Returns
    /// A `Vec<u8>` containing the full compressed data frame, or an error.
    pub fn compress(data: &[f32]) -> Result<Vec<u8>, CompressionError> {
        compress_with_level(data, CompressionLevel::default())
    }

    /// Decompresses a data frame back into a slice of f32 values.
    ///
    /// This function performs a cryptographic hash check to guarantee data integrity.
    ///
    /// # Returns
    /// A `Vec<f32>` containing the perfectly reconstructed data, or an error if the
    /// format is invalid or the integrity check fails.
    pub fn decompress(data: &[u8]) -> Result<Vec<f32>, CompressionError> {
        let mut cursor = Cursor::new(data);

        // --- Stage 3 (Inverse): Parsing ---
        if cursor.read_u32::<LittleEndian>()? != MAGIC_NUMBER {
            return Err(CompressionError::InvalidFormat(
                "Invalid magic number".into(),
            ));
        }
        if cursor.read_u8()? != FORMAT_VERSION {
            return Err(CompressionError::InvalidFormat(
                "Unsupported version".into(),
            ));
        }

        let _level = cursor.read_u8()?; // Read but don't validate (both levels decompress the same way)

        let original_len = cursor.read_u64::<LittleEndian>()? as usize;
        if original_len == 0 {
            return Ok(Vec::new());
        }

        let mut expected_hash = [0u8; 32];
        cursor.read_exact(&mut expected_hash)?;

        let sign_len = cursor.read_u64::<LittleEndian>()? as usize;
        let exp_len = cursor.read_u64::<LittleEndian>()? as usize;
        let mant_len = cursor.read_u64::<LittleEndian>()? as usize;

        // --- Stage 2 (Inverse): Entropy Decoding ---
        let mut sign_stream = vec![0u8; sign_len];
        cursor.read_exact(&mut sign_stream)?;

        let mut exp_stream = vec![0u8; exp_len];
        cursor.read_exact(&mut exp_stream)?;

        let mut mant_stream = vec![0u8; mant_len];
        cursor.read_exact(&mut mant_stream)?;

        // No trailing bytes allowed: frame must be self-contained.
        if cursor.position() != data.len() as u64 {
            return Err(CompressionError::InvalidFormat(
                "Trailing data after compressed streams".into(),
            ));
        }

        let sign_plane =
            zstd::stream::decode_all(Cursor::new(sign_stream)).map_err(CompressionError::Zstd)?;
        let exp_data =
            zstd::stream::decode_all(Cursor::new(exp_stream)).map_err(CompressionError::Zstd)?;
        let mant_data =
            zstd::stream::decode_all(Cursor::new(mant_stream)).map_err(CompressionError::Zstd)?;

        // --- Stage 1 (Inverse): Reconstruct BitMatrix ---
        let packed_len = original_len.div_ceil(8);

        // Validate that decoded plane lengths match what the header implies.
        if sign_plane.len() != packed_len
            || exp_data.len() != 8 * packed_len
            || mant_data.len() != 23 * packed_len
        {
            return Err(CompressionError::InvalidFormat(
                "Decompressed plane sizes do not match header metadata".into(),
            ));
        }

        let mut matrix = BitMatrix {
            len: original_len,
            planes: std::array::from_fn(|_| Vec::new()),
        };

        for i in 0..23 {
            matrix.planes[i] = mant_data[i * packed_len..(i + 1) * packed_len].to_vec();
        }
        for i in 0..8 {
            matrix.planes[i + 23] = exp_data[i * packed_len..(i + 1) * packed_len].to_vec();
        }
        matrix.planes[31] = sign_plane;

        // Inverse of the E8-style bit mixing applied during compression.
        {
            let (mantissa, _rest) = matrix.planes.split_at_mut(23);
            E8BitTransform::inverse_mantissa(mantissa);
        }

        let reconstructed_data = matrix.to_f32_vec();

        // --- Validation ---
        let actual_hash = blake3::hash(bytemuck::cast_slice(&reconstructed_data));
        if actual_hash.as_bytes() != &expected_hash {
            return Err(CompressionError::IntegrityError);
        }

        Ok(reconstructed_data)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 6: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;
    use std::mem::size_of;

    #[test]
    fn test_true_lossless_roundtrip() {
        let test_values = [
            0.0f32,
            -0.0,
            1.0,
            -1.0,
            std::f32::consts::PI,
            f32::MAX,
            f32::MIN_POSITIVE,           // smallest normal
            f32::MIN_POSITIVE / 2.0,     // subnormal
            f32::from_bits(0x0000_0001), // smallest positive subnormal
            f32::from_bits(0x8000_0001), // smallest negative subnormal
        ];
        for &original in &test_values {
            let e32l = E32L::from_f32(original);
            let recovered = e32l.to_f32();
            assert_eq!(
                original.to_bits(),
                recovered.to_bits(),
                "Roundtrip failed for {}",
                original
            );
        }
    }

    #[test]
    fn test_special_values_are_preserved() {
        // NaN payloads (including non-canonical patterns)
        let nan_bits = [
            f32::NAN.to_bits(),
            0x7fc0_0001,
            0x7fff_ffff,
            0x7fa0_1234,
            0xffc0_0001,
        ];
        for bits in nan_bits {
            let original = f32::from_bits(bits);
            let e32l = E32L::from_f32(original);
            let recovered = e32l.to_f32();
            assert!(
                recovered.is_nan(),
                "Recovered NaN lost NaN-ness for bits=0x{bits:08x}"
            );
            assert_eq!(
                bits,
                recovered.to_bits(),
                "NaN payload changed for bits=0x{bits:08x}"
            );
        }

        // Infinity
        let inf_original = f32::INFINITY;
        let e32l_inf = E32L::from_f32(inf_original);
        assert_eq!(
            inf_original.to_bits(),
            e32l_inf.to_f32().to_bits(),
            "Infinity bits changed"
        );

        // Negative Infinity
        let neg_inf_original = f32::NEG_INFINITY;
        let e32l_neg_inf = E32L::from_f32(neg_inf_original);
        assert_eq!(
            neg_inf_original.to_bits(),
            e32l_neg_inf.to_f32().to_bits(),
            "Negative infinity bits changed"
        );
    }

    #[test]
    fn test_storage_size_is_identical_to_f32() {
        // These checks rely on E8F being `#[repr(transparent)]` over `u8`.
        assert_eq!(
            size_of::<E8F>(),
            size_of::<u8>(),
            "E8F must remain a 1-byte wrapper"
        );
        assert_eq!(
            std::mem::align_of::<E8F>(),
            std::mem::align_of::<u8>(),
            "E8F alignment must match u8"
        );

        assert_eq!(
            size_of::<E32L>(),
            size_of::<f32>(),
            "E32L must have same size as f32"
        );
        assert_eq!(size_of::<E32L>(), 4, "E32L must remain 4 bytes in size");
    }

    #[test]
    fn test_bit_level_deconstruction() {
        let value = 123.456f32;
        let bytes = value.to_le_bytes();
        let e32l = E32L::from_f32(value);

        assert_eq!(e32l.roots[0].index(), bytes[0]);
        assert_eq!(e32l.roots[1].index(), bytes[1]);
        assert_eq!(e32l.roots[2].index(), bytes[2]);
        assert_eq!(e32l.roots[3].index(), bytes[3]);

        let recovered_bytes = e32l.to_bytes();
        assert_eq!(bytes, recovered_bytes);
    }

    #[test]
    fn test_from_and_to_bits() {
        let bits: u32 = 0x42c80000; // Represents 100.0f32
        let e32l: E32L = bits.into(); // Use From<u32> trait
        assert_eq!(e32l.to_f32(), 100.0f32);

        let recovered_bits: u32 = e32l.into(); // Use Into<u32> trait
        assert_eq!(recovered_bits, bits);
    }

    #[test]
    fn test_arbitrary_bits_roundtrip() {
        // A small but representative sample of raw IEEE 754 bit patterns.
        let samples: &[u32] = &[
            0x0000_0000, // +0.0
            0x8000_0000, // -0.0
            0x3f80_0000, // 1.0
            0xbf80_0000, // -1.0
            0x7f80_0000, // +inf
            0xff80_0000, // -inf
            0x7fc0_0001, // quiet NaN with payload
            0x7fa0_1234, // another NaN payload
            0x0000_0001, // smallest positive subnormal
            0x8000_0001, // smallest negative subnormal
            0x00ff_ffff, // large positive subnormal
            0x1234_5678, // arbitrary pattern
            0xffff_ffff, // arbitrary pattern (also NaN)
        ];

        for &bits in samples {
            let e32l: E32L = bits.into();
            let roundtrip_bits: u32 = e32l.into();
            assert_eq!(
                bits, roundtrip_bits,
                "E32L must be a pure bit-level bijection for bits=0x{bits:08x}"
            );
        }
    }

    #[test]
    fn test_distinction_from_f32l() {
        // This test clarifies that while functionally identical to a simple byte wrapper,
        // E32L is composed of E8F types, making it semantically different.
        let value = 1.0f32;
        let e32l = E32L::from_f32(value);

        // Access the underlying E8F components
        let root0: E8F = e32l.roots[0];
        assert_eq!(root0.index(), 0x00);

        let root3: E8F = e32l.roots[3];
        assert_eq!(root3.index(), 0x3f); // Part of the IEEE 754 representation of 1.0
    }

    #[cfg(feature = "bytemuck")]
    mod bytemuck_compat_tests {
        use super::*;
        use bytemuck::{Pod, Zeroable, cast_slice};

        #[test]
        fn test_e32l_is_pod_and_castable() {
            // Basic sanity: trait bounds compile and work at runtime.
            fn assert_pod_zeroable<T: Pod + Zeroable>() {}
            assert_pod_zeroable::<E32L>();

            let values = [
                E32L::from_f32(0.0),
                E32L::from_f32(1.0),
                E32L::from_f32(-1.0),
                E32L::from_f32(123.456),
            ];

            // Cast [E32L] -> [u8]
            let bytes: &[u8] = cast_slice(&values);
            assert_eq!(bytes.len(), values.len() * std::mem::size_of::<E32L>());

            // Roundtrip [u8] -> [E32L]
            let roundtrip: &[E32L] = cast_slice(bytes);
            assert_eq!(roundtrip, &values);
        }
    }

    // --- Compression Framework Tests ---
    #[cfg(feature = "compression")]
    mod compression_tests {
        use super::super::compression::{CompressionError, compress, decompress};

        #[test]
        fn test_compression_roundtrip_lossless() {
            let original_data: Vec<f32> = (0..1024).map(|i| (i as f32 * 0.1).sin()).collect();
            let compressed = compress(&original_data).expect("Compression failed");
            let reconstructed = decompress(&compressed).expect("Decompression failed");

            assert_eq!(original_data.len(), reconstructed.len(), "Length mismatch");
            for (a, b) in original_data.iter().zip(reconstructed.iter()) {
                assert_eq!(a.to_bits(), b.to_bits(), "Data mismatch after roundtrip");
            }
        }

        #[test]
        fn test_compression_achieves_bitrate_reduction() {
            // Data with low entropy (a sine wave) should compress well.
            let original_data: Vec<f32> =
                (0..4096).map(|i| (i as f32 * 0.05).sin() * 100.0).collect();
            let compressed = compress(&original_data).expect("Compression failed");

            let original_size = original_data.len() * std::mem::size_of::<f32>();
            let compressed_size = compressed.len();

            assert!(
                compressed_size < original_size,
                "Compression did not reduce data size for predictable input. Original: {}, Compressed: {}",
                original_size,
                compressed_size
            );
        }

        #[test]
        fn test_compression_handles_edge_cases() {
            let data: Vec<f32> = vec![
                0.0,
                -0.0,
                1.0,
                f32::MAX,
                f32::MIN_POSITIVE,
                f32::INFINITY,
                f32::NEG_INFINITY,
                f32::from_bits(0x7fc00001),
            ];
            let compressed = compress(&data).expect("Compression failed");
            let reconstructed = decompress(&compressed).expect("Decompression failed");

            assert_eq!(data.len(), reconstructed.len());
            for (a, b) in data.iter().zip(reconstructed.iter()) {
                assert_eq!(a.to_bits(), b.to_bits());
            }
        }

        #[test]
        fn test_empty_slice_compression() {
            let data: Vec<f32> = Vec::new();
            let compressed = compress(&data).unwrap();
            let reconstructed = decompress(&compressed).unwrap();
            assert!(
                !compressed.is_empty(),
                "Empty frame should still have header"
            );
            assert!(reconstructed.is_empty());
        }

        #[test]
        fn test_decompress_corrupted_data_fails() {
            let original_data: Vec<f32> = (0..128).map(|i| i as f32).collect();
            let mut compressed = compress(&original_data).unwrap();

            // Corrupt the hash
            compressed[13] = compressed[13].wrapping_add(1);

            let result = decompress(&compressed);
            assert!(
                matches!(result, Err(CompressionError::IntegrityError)),
                "Decompression should fail with IntegrityError on hash mismatch"
            );

            // Corrupt the payload (which may cause Zstd error or hash mismatch)
            let mut compressed_payload = compress(&original_data).unwrap();
            let payload_mid = compressed_payload.len() - 10;
            compressed_payload[payload_mid] = compressed_payload[payload_mid].wrapping_add(1);
            let result_payload = decompress(&compressed_payload);
            assert!(
                result_payload.is_err(),
                "Decompression should fail on payload corruption"
            );
        }
    }

    #[test]
    fn prove_e32l_bijection_via_hash() {
        let mut orig_xor: u64 = 0;
        let mut rec_xor: u64 = 0;

        // Exhaustive test of all f32 bit patterns is infeasible (2^32 values).
        // Instead, we test a large random sample and all special values.
        // Use the platform RNG API by invoking `rand::random::<T>()` which is
        // stable across editions and avoids the reserved method name `gen`.

        // Test all special values
        let special_values = [
            0.0f32,
            -0.0,
            1.0,
            -1.0,
            f32::MAX,
            f32::MIN_POSITIVE,
            f32::INFINITY,
            f32::NEG_INFINITY,
            f32::NAN,
            f32::from_bits(0x7fc0_0001), // quiet NaN
            f32::from_bits(0x7fa0_1234), // another NaN
            f32::from_bits(0x0000_0001), // smallest positive subnormal
            f32::from_bits(0x8000_0001), // smallest negative subnormal
        ];

        for &val in &special_values {
            let e32l = E32L::from_f32(val);
            let rec = e32l.to_f32();
            assert_eq!(
                val.to_bits(),
                rec.to_bits(),
                "Bijection failed for special value: {}",
                val
            );
            orig_xor ^= val.to_bits() as u64;
            rec_xor ^= rec.to_bits() as u64;
        }

        // Test a large random sample
        for _ in 0..1_000_000 {
            // Use the top-level random function which internally uses the thread RNG.
            let bits: u32 = rand::random::<u32>();
            let val = f32::from_bits(bits);
            let e32l = E32L::from_f32(val);
            let rec = e32l.to_f32();
            assert_eq!(
                val.to_bits(),
                rec.to_bits(),
                "Bijection failed for random value"
            );
            orig_xor ^= val.to_bits() as u64;
            rec_xor ^= rec.to_bits() as u64;
        }

        // XOR of all tested bits should be identical
        assert_eq!(orig_xor, rec_xor, "Hash mismatch: bijection not preserved");
    }
}

File: e8f.rs
============
/* crates/gf8/src/e8f.rs */
//! # E8F – The E8 Float: Finite Lattice Arithmetic
//!
//! This module implements the "Trillion Dollar" optimization: replacing runtime
//! floating-point operations with precomputed integer lookup tables over the
//! E8 lattice. Operations always resolve to valid E8 roots (canonical states).
//!
//! ## Origin Citation
//! "E8 operations can replace SIMD float math... weights: [Eb8; d/8]...
//! A single Eb8 = 8 numbers at once."
//!
//! ## Key Capabilities
//! - **Zero-FLOP Inference**: Addition and multiplication become array lookups
//! - **Perfect Closure**: Operations always resolve to a valid E8 root
//! - **32x Compression**: Weights stored as u8, computed as u8
//! - **Group Structure**: Implements Klein/Weyl group symmetries
//!
//! ## Architectural Notes
//! Instead of treating E8 roots as vectors for f32 math, we precompute the
//! interaction of every root with every other root. This transforms linear
//! algebra into Integer Lookup Tables.
//!
//! The E8 root system forms a group under reflection, and the 240 roots can
//! be combined via geometric operations that map back to roots.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::{get_e8_codebook, quantize_to_nearest_code};
use crate::{Gf8, Gf8BitSig, Gf8LosslessCode};
use std::ops::{Add, Mul, Neg, Sub};
use std::sync::OnceLock;

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: PRECOMPUTED LOOKUP TABLES
// ═══════════════════════════════════════════════════════════════════════════════════════

/// Precomputed lookup tables for E8 lattice arithmetic.
///
/// These tables enable O(1) operations between E8 roots without any
/// floating-point computation at inference time.
///
/// Memory footprint: ~460KB total (heap-allocated)
/// - add_table:     240×240 = 57,600 bytes
/// - sub_table:     240×240 = 57,600 bytes
/// - mul_table:     240×240 = 57,600 bytes
/// - dot_table:     240×240 = 57,600 bytes
/// - reflect_table: 240×240 = 57,600 bytes
/// - neg_table:     240 bytes
pub struct E8ArithmeticTables {
    /// Addition: add_table[a][b] = snap(root_a + root_b)
    pub add_table: Box<[[u8; 240]; 240]>,

    /// Subtraction: sub_table[a][b] = snap(root_a - root_b)
    pub sub_table: Box<[[u8; 240]; 240]>,

    /// Multiplication (Hadamard-style): mul_table[a][b] = snap(root_a ⊙ root_b)
    pub mul_table: Box<[[u8; 240]; 240]>,

    /// Dot product: dot_table[a][b] = quantized(root_a · root_b) in [0, 255]
    /// Maps [-1.0, 1.0] → [0, 255]
    pub dot_table: Box<[[u8; 240]; 240]>,

    /// Reflection: reflect_table[a][b] = snap(root_a - 2(root_a·root_b)root_b)
    pub reflect_table: Box<[[u8; 240]; 240]>,

    /// Negation: neg_table[a] = index of -root_a
    pub neg_table: [u8; 240],
}

/// Static singleton for the arithmetic tables.
pub static E8_ARITHMETIC: OnceLock<E8ArithmeticTables> = OnceLock::new();

impl E8ArithmeticTables {
    /// Generate all arithmetic lookup tables.
    /// This is expensive (~240² × 5 operations) but only done once at startup.
    pub fn generate() -> Self {
        let codebook = get_e8_codebook();
        let roots = &codebook.roots;

        // Allocate on heap to avoid stack overflow
        let mut add_table = Box::new([[0u8; 240]; 240]);
        let mut sub_table = Box::new([[0u8; 240]; 240]);
        let mut mul_table = Box::new([[0u8; 240]; 240]);
        let mut dot_table = Box::new([[128u8; 240]; 240]);
        let mut neg_table = [0u8; 240];
        let mut reflect_table = Box::new([[0u8; 240]; 240]);

        // Precompute all pairwise operations
        for (i, root_i) in roots.iter().enumerate().take(240) {
            let ri = root_i.coords();

            // Negation: find antipodal root
            let neg_coords: [f32; 8] = std::array::from_fn(|k| -ri[k]);
            let (neg_code, _) = quantize_to_nearest_code(&neg_coords);
            neg_table[i] = neg_code.0;

            for (j, root_j) in roots.iter().enumerate().take(240) {
                let rj = root_j.coords();

                // Addition: root_i + root_j → nearest root
                let sum_coords: [f32; 8] = std::array::from_fn(|k| ri[k] + rj[k]);
                let (sum_code, _) = quantize_to_nearest_code(&sum_coords);
                add_table[i][j] = sum_code.0;

                // Subtraction: root_i - root_j → nearest root
                let diff_coords: [f32; 8] = std::array::from_fn(|k| ri[k] - rj[k]);
                let (diff_code, _) = quantize_to_nearest_code(&diff_coords);
                sub_table[i][j] = diff_code.0;

                // Multiplication (Hadamard/element-wise): root_i ⊙ root_j → nearest root
                let prod_coords: [f32; 8] = std::array::from_fn(|k| ri[k] * rj[k]);
                let (prod_code, _) = quantize_to_nearest_code(&prod_coords);
                mul_table[i][j] = prod_code.0;

                // Dot product: quantized to [0, 255]
                let dot: f32 = ri.iter().zip(rj.iter()).map(|(a, b)| a * b).sum();
                // Map [-1, 1] to [0, 255]
                let quantized = ((dot.clamp(-1.0, 1.0) + 1.0) * 127.5) as u8;
                dot_table[i][j] = quantized;

                // Reflection: reflect i through hyperplane normal to j
                // Formula: r_i - 2 * (r_i · r_j) * r_j
                let scale = 2.0 * dot;
                let reflect_coords: [f32; 8] = std::array::from_fn(|k| ri[k] - scale * rj[k]);
                let (reflect_code, _) = quantize_to_nearest_code(&reflect_coords);
                reflect_table[i][j] = reflect_code.0;
            }
        }

        Self {
            add_table,
            sub_table,
            mul_table,
            dot_table,
            neg_table,
            reflect_table,
        }
    }
}

/// Get the global arithmetic tables (lazily initialized).
#[inline]
pub fn get_e8_arithmetic() -> &'static E8ArithmeticTables {
    E8_ARITHMETIC.get_or_init(E8ArithmeticTables::generate)
}

/// Ensure tables are initialized (call at startup for predictable latency).
pub fn init_e8_arithmetic() {
    let _ = get_e8_arithmetic();
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 2: E8F – THE LATTICE SCALAR TYPE
// ═══════════════════════════════════════════════════════════════════════════════════════

/// The E8 Float: A numeric type where all operations resolve to valid E8 lattice points.
///
/// This replaces f32/f16 in model weights and activations, enabling:
/// - Zero-FLOP inference (all ops are table lookups)
/// - Perfect closure (results always valid E8 roots)
/// - 32x compression (1 byte vs 32 bytes for 8D vector)
///
/// # Example
/// ```rust
/// use gf8::e8f::E8F;
///
/// let a = E8F::new(42);
/// let b = E8F::new(100);
///
/// // All operations are O(1) table lookups
/// let sum = a + b;      // Addition
/// let diff = a - b;     // Subtraction
/// let prod = a * b;     // Hadamard multiplication
/// let neg = -a;         // Negation
/// let dot = a.dot(b);   // Dot product (returns f32)
/// ```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Default)]
#[repr(transparent)]
pub struct E8F(pub u8);

impl E8F {
    /// The "zero" state (index 240, outside valid roots).
    /// Used for null/undefined values.
    pub const ZERO: Self = Self(240);

    /// Create from a root index (0-239). Values ≥240 are clamped.
    #[inline]
    pub const fn new(root_idx: u8) -> Self {
        Self(if root_idx < 240 {
            root_idx
        } else {
            Self::ZERO.0
        })
    }

    /// Create from a raw byte without clamping (used for lossless bit containers like E32L).
    #[inline]
    pub const fn from_raw(byte: u8) -> Self {
        Self(byte)
    }

    /// Create from a root index with explicit validation; returns None if out of range.
    #[inline]
    pub const fn new_checked(root_idx: u8) -> Option<Self> {
        if root_idx < 240 {
            Some(Self(root_idx))
        } else {
            None
        }
    }

    /// Create from a Gf8BitSig .
    #[inline]
    pub const fn from_code(code: Gf8BitSig) -> Self {
        Self::new(code.0)
    }

    /// Create from a Gf8LosslessCode.
    #[inline]
    pub const fn from_lossless(code: Gf8LosslessCode) -> Self {
        Self::new(code.0)
    }

    /// Get the root index.
    #[inline]
    pub const fn index(&self) -> u8 {
        self.0
    }

    /// Check if this is a valid root (index < 240).
    #[inline]
    pub const fn is_valid(&self) -> bool {
        self.0 < 240
    }

    /// Convert to Gf8BitSig .
    #[inline]
    pub const fn to_code(&self) -> Gf8BitSig {
        Gf8BitSig(self.0)
    }

    /// Convert to Gf8LosslessCode.
    #[inline]
    pub const fn to_lossless(&self) -> Gf8LosslessCode {
        Gf8LosslessCode(self.0)
    }

    /// Dequantize to the actual Gf8 vector (for final output).
    /// This is a **lossless** operation for valid E8F roots - the returned
    /// Gf8 is the exact root from the codebook with no quantization error.
    pub fn to_gf8(&self) -> Gf8 {
        if self.0 >= 240 {
            return Gf8::ZERO;
        }
        let codebook = get_e8_codebook();
        codebook.roots[self.0 as usize]
    }

    /// Quantize an f32 array to E8F.
    pub fn from_f32(coords: &[f32; 8]) -> Self {
        let (code, _) = quantize_to_nearest_code(coords);
        Self(code.0)
    }

    /// Compute quantized dot product (returns u8 in [0, 255]).
    /// 0 = -1.0, 128 = 0.0, 255 = 1.0
    #[inline]
    pub fn dot_quantized(self, other: Self) -> u8 {
        if self.0 >= 240 || other.0 >= 240 {
            return 128; // 0.0
        }
        let tables = get_e8_arithmetic();
        tables.dot_table[self.0 as usize][other.0 as usize]
    }

    /// Compute dot product as f32 (dequantized).
    #[inline]
    pub fn dot(self, other: Self) -> f32 {
        let q = self.dot_quantized(other);
        (q as f32 / 127.5) - 1.0
    }

    /// Reflect self through hyperplane normal to other.
    #[inline]
    pub fn reflect(self, normal: Self) -> Self {
        if self.0 >= 240 || normal.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.reflect_table[self.0 as usize][normal.0 as usize])
    }

    /// Check if two E8Fs are neighbors in the E8 lattice (dot ≈ 0.5, 60° angle).
    #[inline]
    pub fn is_neighbor(self, other: Self) -> bool {
        let dot = self.dot_quantized(other);
        (180..=200).contains(&dot) // ~0.5 in [0,255] scale
    }

    /// Check if two E8Fs are antipodal (opposite directions, dot ≈ -1.0).
    #[inline]
    pub fn is_antipodal(self, other: Self) -> bool {
        self.dot_quantized(other) < 10
    }

    /// Check if two E8Fs are orthogonal (dot ≈ 0.0).
    #[inline]
    pub fn is_orthogonal(self, other: Self) -> bool {
        let dot = self.dot_quantized(other);
        (120..=136).contains(&dot)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 3: OPERATOR IMPLEMENTATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl Add for E8F {
    type Output = Self;
    /// E8F addition via lookup table.
    /// **Error Bound**: Result is the nearest E8 root to (a + b), with
    /// ≤0.087 chordal distance error. The operation itself is deterministic
    /// and error-free for repeated identical inputs (lookup table is constant).
    #[inline]
    fn add(self, rhs: Self) -> Self::Output {
        if self.0 >= 240 || rhs.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.add_table[self.0 as usize][rhs.0 as usize])
    }
}

impl Sub for E8F {
    type Output = Self;
    #[inline]
    fn sub(self, rhs: Self) -> Self::Output {
        if self.0 >= 240 || rhs.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.sub_table[self.0 as usize][rhs.0 as usize])
    }
}

impl Mul for E8F {
    type Output = Self;
    #[inline]
    fn mul(self, rhs: Self) -> Self::Output {
        if self.0 >= 240 || rhs.0 >= 240 {
            return Self::ZERO;
        }
        let tables = get_e8_arithmetic();
        Self(tables.mul_table[self.0 as usize][rhs.0 as usize])
    }
}

impl Neg for E8F {
    type Output = Self;
    #[inline]
    fn neg(self) -> Self::Output {
        if self.0 >= 240 {
            return self;
        }
        let tables = get_e8_arithmetic();
        Self(tables.neg_table[self.0 as usize])
    }
}

impl From<u8> for E8F {
    fn from(idx: u8) -> Self {
        Self::new(idx)
    }
}

impl From<Gf8BitSig> for E8F {
    fn from(code: Gf8BitSig) -> Self {
        Self::from_code(code)
    }
}

impl From<Gf8LosslessCode> for E8F {
    fn from(code: Gf8LosslessCode) -> Self {
        Self::from_lossless(code)
    }
}

impl From<E8F> for Gf8BitSig {
    fn from(e: E8F) -> Self {
        e.to_code()
    }
}

impl From<E8F> for Gf8LosslessCode {
    fn from(e: E8F) -> Self {
        e.to_lossless()
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 4: E8VEC – VECTOR OF E8FS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// A vector of E8Fs for batch operations.
///
/// Enables processing entire embeddings
/// using only integer lookups. Storage: 1 byte per 8D block.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct E8Vec {
    pub data: Vec<E8F>,
}

impl E8Vec {
    /// Create from a slice of root indices.
    pub fn from_indices(indices: &[u8]) -> Self {
        Self {
            data: indices.iter().map(|&i| E8F::new(i)).collect(),
        }
    }

    /// Quantize a high-dimensional f32 vector to E8Vec.
    /// Splits into 8D blocks and quantizes each to an E8F.
    pub fn from_f32_vec(vec: &[f32]) -> Self {
        let num_blocks = vec.len().div_ceil(8);
        let mut data = Vec::with_capacity(num_blocks);

        for chunk in vec.chunks(8) {
            let mut block = [0.0f32; 8];
            block[..chunk.len()].copy_from_slice(chunk);
            data.push(E8F::from_f32(&block));
        }

        Self { data }
    }

    /// Dequantize to f32 vector.
    pub fn to_f32_vec(&self) -> Vec<f32> {
        let mut result = Vec::with_capacity(self.data.len() * 8);
        for e in &self.data {
            let gf8 = e.to_gf8();
            result.extend_from_slice(gf8.coords());
        }
        result
    }

    /// Element-wise addition.
    pub fn add(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len());
        Self {
            data: self
                .data
                .iter()
                .zip(other.data.iter())
                .map(|(a, b)| *a + *b)
                .collect(),
        }
    }

    /// Element-wise subtraction.
    pub fn sub(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len());
        Self {
            data: self
                .data
                .iter()
                .zip(other.data.iter())
                .map(|(a, b)| *a - *b)
                .collect(),
        }
    }

    /// Element-wise multiplication.
    pub fn mul(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len());
        Self {
            data: self
                .data
                .iter()
                .zip(other.data.iter())
                .map(|(a, b)| *a * *b)
                .collect(),
        }
    }

    /// Dot product (sum of element-wise dots).
    pub fn dot(&self, other: &Self) -> f32 {
        assert_eq!(self.data.len(), other.data.len());
        self.data
            .iter()
            .zip(other.data.iter())
            .map(|(a, b)| a.dot(*b))
            .sum()
    }

    /// Quantized dot product (sum of quantized element-wise dots).
    pub fn dot_quantized(&self, other: &Self) -> u32 {
        assert_eq!(self.data.len(), other.data.len());
        self.data
            .iter()
            .zip(other.data.iter())
            .map(|(a, b)| a.dot_quantized(*b) as u32)
            .sum()
    }

    /// Get the raw bytes (for storage/transmission).
    /// 32x compression: 2048D → 256 bytes.
    pub fn to_bytes(&self) -> Vec<u8> {
        self.data.iter().map(|e| e.0).collect()
    }

    /// Create from raw bytes.
    pub fn from_bytes(bytes: &[u8]) -> Self {
        Self {
            data: bytes.iter().map(|&b| E8F::new(b)).collect(),
        }
    }

    /// Length in E8F elements.
    pub fn len(&self) -> usize {
        self.data.len()
    }

    /// Check if empty.
    pub fn is_empty(&self) -> bool {
        self.data.is_empty()
    }

    /// Original dimensionality (len × 8).
    pub fn dim(&self) -> usize {
        self.data.len() * 8
    }
}

impl std::ops::Index<usize> for E8Vec {
    type Output = E8F;
    fn index(&self, idx: usize) -> &Self::Output {
        &self.data[idx]
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 5: E8 TENSOR CORE – FUSED MATRIX OPERATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

/// E8 Tensor Core: Fused matrix operations over the E8 lattice.
///
/// Analogous to GPU tensor cores, but using lookup tables instead of FP units.
/// All operations maintain E8 closure (results are always valid roots).
pub struct E8TensorCore;

impl E8TensorCore {
    // ─────────────────────────────────────────────────────────────────────────────────
    // FUSED MULTIPLY-ACCUMULATE (FMA)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Fused multiply-add: `a * b + c` in E8 space.
    /// Two table lookups instead of three separate ops.
    #[inline]
    pub fn fma(a: E8F, b: E8F, c: E8F) -> E8F {
        let prod = a * b;
        prod + c
    }

    /// Fused multiply-subtract: `a * b - c` in E8 space.
    #[inline]
    pub fn fms(a: E8F, b: E8F, c: E8F) -> E8F {
        let prod = a * b;
        prod - c
    }

    /// Fused negative multiply-add: `-(a * b) + c` = `c - a * b`
    #[inline]
    pub fn fnma(a: E8F, b: E8F, c: E8F) -> E8F {
        let prod = a * b;
        c - prod
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // VECTOR-VECTOR OPERATIONS (like BLAS Level 1)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// AXPY: `y = a * x + y` (scale and accumulate)
    /// Fundamental BLAS operation, fully in E8 space.
    pub fn axpy(a: E8F, x: &E8Vec, y: &mut E8Vec) {
        assert_eq!(x.len(), y.len());
        for i in 0..x.len() {
            y.data[i] = Self::fma(a, x.data[i], y.data[i]);
        }
    }

    /// Dot product with accumulator: `acc + sum(x[i] * y[i])`
    /// Returns quantized result as u32 for precision.
    pub fn dot_acc(x: &E8Vec, y: &E8Vec, acc: u32) -> u32 {
        acc + x.dot_quantized(y)
    }

    /// Weighted sum: `sum(weights[i] * vectors[i])`
    /// Reduces multiple vectors into one.
    pub fn weighted_sum(weights: &[E8F], vectors: &[E8Vec]) -> E8Vec {
        assert_eq!(weights.len(), vectors.len());
        assert!(!vectors.is_empty());

        let len = vectors[0].len();
        let mut result = E8Vec::from_indices(&vec![0u8; len]);

        for (w, v) in weights.iter().zip(vectors.iter()) {
            for i in 0..len {
                result.data[i] = Self::fma(*w, v.data[i], result.data[i]);
            }
        }
        result
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // MATRIX-VECTOR OPERATIONS (like BLAS Level 2)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Matrix-vector multiply: `y = M * x`
    /// M is row-major: M[row][col], each row is an E8Vec.
    pub fn matvec(m: &[E8Vec], x: &E8Vec) -> Vec<u32> {
        m.iter().map(|row| row.dot_quantized(x)).collect()
    }

    /// Matrix-vector multiply with E8F output (snapped to nearest roots).
    /// Uses dot products to find best-matching output roots.
    pub fn matvec_e8f(m: &[E8Vec], x: &E8Vec) -> E8Vec {
        let dots: Vec<u32> = Self::matvec(m, x);
        // Map quantized dots back to E8F indices
        // Higher dot = more similar, map to root index space
        let indices: Vec<u8> = dots
            .iter()
            .map(|&d| ((d as f32 / (x.len() as f32 * 255.0)) * 239.0) as u8)
            .collect();
        E8Vec::from_indices(&indices)
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // OUTER PRODUCT (for attention-like operations)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Outer product: `M[i][j] = u[i] * v[j]`
    /// Creates a matrix from two vectors (attention pattern).
    pub fn outer(u: &E8Vec, v: &E8Vec) -> Vec<E8Vec> {
        u.data
            .iter()
            .map(|&ui| E8Vec {
                data: v.data.iter().map(|&vj| ui * vj).collect(),
            })
            .collect()
    }

    /// Outer product with addition: `M[i][j] += u[i] * v[j]`
    /// Accumulates into existing matrix.
    pub fn outer_add(u: &E8Vec, v: &E8Vec, m: &mut [E8Vec]) {
        for (i, &ui) in u.data.iter().enumerate() {
            for (j, &vj) in v.data.iter().enumerate() {
                m[i].data[j] = Self::fma(ui, vj, m[i].data[j]);
            }
        }
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // BATCH OPERATIONS (like tensor core's warp-level ops)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Batch dot products: compute dots for multiple query-key pairs.
    /// Returns quantized similarities for attention scoring.
    pub fn batch_dots(queries: &[E8Vec], keys: &[E8Vec]) -> Vec<Vec<u32>> {
        queries
            .iter()
            .map(|q| keys.iter().map(|k| q.dot_quantized(k)).collect())
            .collect()
    }

    /// Batch dot products (single query against multiple keys).
    /// Optimized for retrieval: one query, many candidates.
    pub fn query_dots(query: &E8Vec, keys: &[E8Vec]) -> Vec<u32> {
        keys.iter().map(|k| query.dot_quantized(k)).collect()
    }

    /// Dom-R selection from batch dots (for attention/retrieval).
    /// Returns indices of K highest-scoring keys.
    pub fn top_k(scores: &[u32], k: usize) -> Vec<usize> {
        let mut indexed: Vec<(usize, u32)> = scores.iter().copied().enumerate().collect();
        indexed.sort_by(|a, b| b.1.cmp(&a.1)); // Descending
        indexed.into_iter().take(k).map(|(i, _)| i).collect()
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // SOFTMAX APPROXIMATION (via E8 geometry)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Approximate softmax using E8 neighbor structure.
    /// Maps quantized scores to probability-like weights.
    ///
    /// Instead of exp(x)/sum(exp), uses:
    /// - Shift scores to positive range
    /// - Normalize by sum
    /// - Quantize to u8 weights
    pub fn softmax_approx(scores: &[u32]) -> Vec<u8> {
        if scores.is_empty() {
            return vec![];
        }

        let min = *scores.iter().min().unwrap();
        let shifted: Vec<u32> = scores.iter().map(|&s| s - min + 1).collect();
        let sum: u32 = shifted.iter().sum();

        if sum == 0 {
            return vec![255 / scores.len() as u8; scores.len()];
        }

        shifted
            .iter()
            .map(|&s| ((s as u64 * 255) / sum as u64) as u8)
            .collect()
    }

    /// Weighted combination using softmax-like weights.
    /// `result = sum(weights[i] * values[i])` where weights are normalized.
    pub fn softmax_combine(weights: &[u8], values: &[E8Vec]) -> E8Vec {
        assert_eq!(weights.len(), values.len());
        assert!(!values.is_empty());

        let len = values[0].len();
        let mut result = E8Vec::from_indices(&vec![0u8; len]);

        // Convert u8 weights to E8F (map 0-255 to root indices 0-239)
        let e8_weights: Vec<E8F> = weights
            .iter()
            .map(|&w| E8F::new((w as u16 * 239 / 255) as u8))
            .collect();

        for (w, v) in e8_weights.iter().zip(values.iter()) {
            for i in 0..len {
                result.data[i] = Self::fma(*w, v.data[i], result.data[i]);
            }
        }
        result
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // ATTENTION MECHANISM (full E8 attention in one call)
    // ─────────────────────────────────────────────────────────────────────────────────

    /// E8 Attention: Q·K^T → softmax → weighted V
    ///
    /// Single-head attention entirely in E8 space:
    /// 1. Compute Q·K similarities (batch dots)
    /// 2. Apply softmax approximation
    /// 3. Weight and sum V vectors
    ///
    /// Returns attended output for each query.
    pub fn attention(queries: &[E8Vec], keys: &[E8Vec], values: &[E8Vec]) -> Vec<E8Vec> {
        assert_eq!(keys.len(), values.len());

        queries
            .iter()
            .map(|q| {
                // Q·K^T
                let scores = Self::query_dots(q, keys);
                // Softmax
                let weights = Self::softmax_approx(&scores);
                // Weighted sum of V
                Self::softmax_combine(&weights, values)
            })
            .collect()
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // LAYER NORM APPROXIMATION
    // ─────────────────────────────────────────────────────────────────────────────────

    /// Approximate layer normalization via E8 centering.
    ///
    /// Instead of (x - mean) / std, we:
    /// 1. Find the "centroid" root (most common neighbor)
    /// 2. Subtract it (centering)
    /// 3. The E8 lattice's uniform structure provides implicit normalization
    pub fn layer_norm_approx(x: &E8Vec) -> E8Vec {
        if x.is_empty() {
            return x.clone();
        }

        // Find centroid: average all roots, snap to nearest
        // Simplified: use the most frequent root as center
        let mut counts = [0u32; 240];
        for e in &x.data {
            if e.is_valid() {
                counts[e.0 as usize] += 1;
            }
        }

        let centroid_idx = counts
            .iter()
            .enumerate()
            .max_by_key(|&(_, c)| c)
            .map(|(i, _)| i as u8)
            .unwrap_or(0);

        let centroid = E8F::new(centroid_idx);

        // Subtract centroid from all elements
        E8Vec {
            data: x.data.iter().map(|&e| e - centroid).collect(),
        }
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 6: E8 MATRIX TYPE
// ═══════════════════════════════════════════════════════════════════════════════════════

/// E8 Matrix: 2D array of E8Fs for weight matrices.
///
/// Row-major storage, each row is an E8Vec.
/// Used for linear layers, attention projections, etc.
#[derive(Debug, Clone)]
pub struct E8Mat {
    /// Rows of the matrix.
    pub rows: Vec<E8Vec>,
    /// Number of columns (E8F elements per row).
    pub cols: usize,
}

impl E8Mat {
    /// Create a new matrix with given dimensions, initialized to root 0.
    pub fn new(num_rows: usize, num_cols: usize) -> Self {
        Self {
            rows: (0..num_rows)
                .map(|_| E8Vec::from_indices(&vec![0u8; num_cols]))
                .collect(),
            cols: num_cols,
        }
    }

    /// Create from raw bytes (row-major).
    pub fn from_bytes(bytes: &[u8], num_rows: usize, num_cols: usize) -> Self {
        assert_eq!(bytes.len(), num_rows * num_cols);
        Self {
            rows: bytes.chunks(num_cols).map(E8Vec::from_bytes).collect(),
            cols: num_cols,
        }
    }

    /// Serialize to bytes.
    pub fn to_bytes(&self) -> Vec<u8> {
        self.rows.iter().flat_map(|r| r.to_bytes()).collect()
    }

    /// Number of rows.
    pub fn num_rows(&self) -> usize {
        self.rows.len()
    }

    /// Number of columns.
    pub fn num_cols(&self) -> usize {
        self.cols
    }

    /// Matrix-vector multiply: `y = M * x`
    pub fn matvec(&self, x: &E8Vec) -> Vec<u32> {
        E8TensorCore::matvec(&self.rows, x)
    }

    /// Matrix-vector multiply with E8F output.
    pub fn matvec_e8f(&self, x: &E8Vec) -> E8Vec {
        E8TensorCore::matvec_e8f(&self.rows, x)
    }

    /// Transpose (creates new matrix).
    pub fn transpose(&self) -> Self {
        let num_rows = self.cols;
        let num_cols = self.num_rows();

        let mut rows = Vec::with_capacity(num_rows);
        for j in 0..num_rows {
            let col: Vec<E8F> = self.rows.iter().map(|r| r.data[j]).collect();
            rows.push(E8Vec { data: col });
        }

        Self {
            rows,
            cols: num_cols,
        }
    }
}

impl std::ops::Index<usize> for E8Mat {
    type Output = E8Vec;
    fn index(&self, idx: usize) -> &Self::Output {
        &self.rows[idx]
    }
}

impl std::ops::IndexMut<usize> for E8Mat {
    fn index_mut(&mut self, idx: usize) -> &mut Self::Output {
        &mut self.rows[idx]
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 7: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8f_basic() {
        let a = E8F::new(42);
        let b = E8F::new(100);

        assert!(a.is_valid());
        assert!(b.is_valid());
        assert!(!E8F::ZERO.is_valid());
    }

    #[test]
    fn test_e8f_arithmetic() {
        let a = E8F::new(10);
        let b = E8F::new(20);

        // All operations should return valid roots
        let sum = a + b;
        let diff = a - b;
        let prod = a * b;
        let neg = -a;

        assert!(sum.is_valid());
        assert!(diff.is_valid());
        assert!(prod.is_valid());
        assert!(neg.is_valid());
    }

    #[test]
    fn test_e8f_dot_product() {
        // Self dot should be ~1.0 (maps to ~255)
        for i in 0..10u8 {
            let e = E8F::new(i);
            let dot = e.dot_quantized(e);
            assert!(dot > 250, "Self dot should be ~1.0, got {}", dot);
        }
    }

    #[test]
    fn test_e8f_negation() {
        // Double negation should return close to original
        for i in 0..10u8 {
            let e = E8F::new(i);
            let neg_neg = -(-e);
            let dot = e.dot_quantized(neg_neg);
            assert!(dot > 250, "Double negation should be ~identity");
        }
    }

    #[test]
    fn test_e8f_antipodal() {
        let e = E8F::new(0);
        let neg_e = -e;
        assert!(e.is_antipodal(neg_e));
    }

    #[test]
    fn test_e8vec_compression() {
        // 2048D Ada-002 embedding → 256 bytes
        let embedding: Vec<f32> = (0..2048).map(|i| (i as f32 * 0.001).sin()).collect();

        let e8vec = E8Vec::from_f32_vec(&embedding);
        assert_eq!(e8vec.len(), 256); // 2048 / 8 = 256

        let bytes = e8vec.to_bytes();
        assert_eq!(bytes.len(), 256); // 32x compression!

        // Roundtrip
        let restored = E8Vec::from_bytes(&bytes);
        assert_eq!(restored.len(), 256);
    }

    #[test]
    fn test_e8vec_dot() {
        let a = E8Vec::from_indices(&[10, 20, 30]);
        let b = E8Vec::from_indices(&[10, 20, 30]);

        // Self dot should be positive (~3.0 for 3 elements)
        let dot = a.dot(&b);
        assert!(dot > 2.0);
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // TENSOR CORE TESTS
    // ─────────────────────────────────────────────────────────────────────────────────

    #[test]
    fn test_fma() {
        let a = E8F::new(10);
        let b = E8F::new(20);
        let c = E8F::new(30);

        let result = E8TensorCore::fma(a, b, c);
        assert!(result.is_valid());

        // FMA should equal mul then add
        let manual = (a * b) + c;
        assert_eq!(result, manual);
    }

    #[test]
    fn test_axpy() {
        let a = E8F::new(5);
        let x = E8Vec::from_indices(&[10, 20, 30]);
        let mut y = E8Vec::from_indices(&[1, 2, 3]);

        E8TensorCore::axpy(a, &x, &mut y);

        // All results should be valid
        for e in &y.data {
            assert!(e.is_valid());
        }
    }

    #[test]
    fn test_matvec() {
        // 2x3 matrix
        let m = vec![
            E8Vec::from_indices(&[10, 20, 30]),
            E8Vec::from_indices(&[40, 50, 60]),
        ];
        let x = E8Vec::from_indices(&[1, 2, 3]);

        let result = E8TensorCore::matvec(&m, &x);
        assert_eq!(result.len(), 2);
    }

    #[test]
    fn test_outer_product() {
        let u = E8Vec::from_indices(&[10, 20]);
        let v = E8Vec::from_indices(&[30, 40, 50]);

        let outer = E8TensorCore::outer(&u, &v);
        assert_eq!(outer.len(), 2); // 2 rows
        assert_eq!(outer[0].len(), 3); // 3 cols
    }

    #[test]
    fn test_batch_dots() {
        let queries = vec![
            E8Vec::from_indices(&[10, 20]),
            E8Vec::from_indices(&[30, 40]),
        ];
        let keys = vec![
            E8Vec::from_indices(&[10, 20]),
            E8Vec::from_indices(&[50, 60]),
            E8Vec::from_indices(&[70, 80]),
        ];

        let dots = E8TensorCore::batch_dots(&queries, &keys);
        assert_eq!(dots.len(), 2); // 2 queries
        assert_eq!(dots[0].len(), 3); // 3 keys each
    }

    #[test]
    fn test_softmax_approx() {
        let scores = vec![100, 200, 300, 400];
        let weights = E8TensorCore::softmax_approx(&scores);

        assert_eq!(weights.len(), 4);
        // Higher scores should have higher weights
        assert!(weights[3] > weights[0]);
    }

    #[test]
    fn test_top_k() {
        let scores = vec![10, 50, 30, 40, 20];
        let top2 = E8TensorCore::top_k(&scores, 2);

        assert_eq!(top2.len(), 2);
        assert_eq!(top2[0], 1); // Index of 50
        assert_eq!(top2[1], 3); // Index of 40
    }

    #[test]
    fn test_attention() {
        let queries = vec![E8Vec::from_indices(&[10, 20, 30])];
        let keys = vec![
            E8Vec::from_indices(&[10, 20, 30]),
            E8Vec::from_indices(&[40, 50, 60]),
        ];
        let values = vec![
            E8Vec::from_indices(&[1, 2, 3]),
            E8Vec::from_indices(&[4, 5, 6]),
        ];

        let output = E8TensorCore::attention(&queries, &keys, &values);
        assert_eq!(output.len(), 1);
        assert_eq!(output[0].len(), 3);
    }

    #[test]
    fn test_e8mat() {
        let mat = E8Mat::new(3, 4);
        assert_eq!(mat.num_rows(), 3);
        assert_eq!(mat.num_cols(), 4);

        // Serialize and deserialize
        let bytes = mat.to_bytes();
        assert_eq!(bytes.len(), 12);

        let restored = E8Mat::from_bytes(&bytes, 3, 4);
        assert_eq!(restored.num_rows(), 3);
    }

    #[test]
    fn test_e8mat_transpose() {
        let mut mat = E8Mat::new(2, 3);
        mat[0] = E8Vec::from_indices(&[1, 2, 3]);
        mat[1] = E8Vec::from_indices(&[4, 5, 6]);

        let t = mat.transpose();
        assert_eq!(t.num_rows(), 3);
        assert_eq!(t.num_cols(), 2);

        // Check values
        assert_eq!(t[0].data[0].0, 1);
        assert_eq!(t[0].data[1].0, 4);
    }

    // ─────────────────────────────────────────────────────────────────────────────────
    // SERIALIZATION TESTS (Task 9)
    // ─────────────────────────────────────────────────────────────────────────────────

    #[test]
    fn test_e8address_serialization() {
        use crate::Gf8LosslessCode;

        // E8Address is [Gf8LosslessCode; 8] which is [u8; 8]
        let address: [Gf8LosslessCode; 8] = [
            Gf8LosslessCode::new(0),
            Gf8LosslessCode::new(42),
            Gf8LosslessCode::new(100),
            Gf8LosslessCode::new(150),
            Gf8LosslessCode::new(200),
            Gf8LosslessCode::new(239),
            Gf8LosslessCode::new(10),
            Gf8LosslessCode::new(50),
        ];

        // Serialize to bytes (should be exactly 8 bytes)
        // **This is LOSSLESS**: u8 -> u8 with no transformation
        let bytes: Vec<u8> = address.iter().map(|c| c.0).collect();
        assert_eq!(
            bytes.len(),
            8,
            "E8Address should serialize to exactly 8 bytes"
        );

        // Verify lossless roundtrip (byte-perfect)
        let restored: [Gf8LosslessCode; 8] = [
            Gf8LosslessCode::new(bytes[0]),
            Gf8LosslessCode::new(bytes[1]),
            Gf8LosslessCode::new(bytes[2]),
            Gf8LosslessCode::new(bytes[3]),
            Gf8LosslessCode::new(bytes[4]),
            Gf8LosslessCode::new(bytes[5]),
            Gf8LosslessCode::new(bytes[6]),
            Gf8LosslessCode::new(bytes[7]),
        ];

        for i in 0..8 {
            assert_eq!(
                address[i].0, restored[i].0,
                "E8Address lossless roundtrip failed at index {}",
                i
            );
        }
    }

    #[test]
    fn test_e8vec_serialization_roundtrip() {
        // Create E8Vec from indices
        let original = E8Vec::from_indices(&[10, 20, 30, 40, 50, 100, 150, 200]);

        // Serialize to bytes
        let bytes = original.to_bytes();
        assert_eq!(
            bytes.len(),
            8,
            "E8Vec with 8 elements should serialize to 8 bytes"
        );

        // Verify each byte matches the original index
        for (i, &byte) in bytes.iter().enumerate() {
            assert_eq!(
                byte,
                [10, 20, 30, 40, 50, 100, 150, 200][i],
                "Byte at index {} doesn't match",
                i
            );
        }

        // Deserialize
        let restored = E8Vec::from_bytes(&bytes);
        assert_eq!(restored.len(), 8, "Restored E8Vec should have 8 elements");

        // Verify roundtrip
        for i in 0..8 {
            assert_eq!(
                original.data[i].0, restored.data[i].0,
                "E8Vec roundtrip failed at index {}",
                i
            );
        }
    }

    #[test]
    fn test_e8vec_compression_ratio() {
        // 2048D Ada-002 embedding → 256 bytes (32x compression)
        let embedding: Vec<f32> = (0..2048).map(|i| (i as f32 * 0.001).sin()).collect();

        let e8vec = E8Vec::from_f32_vec(&embedding);
        let bytes = e8vec.to_bytes();

        // Verify compression ratio
        let original_size = 2048 * std::mem::size_of::<f32>(); // 6144 bytes
        let compressed_size = bytes.len(); // 256 bytes
        let ratio = original_size as f32 / compressed_size as f32;

        assert_eq!(compressed_size, 256, "2048D should compress to 256 bytes");
        assert!(
            (31.0..=33.0).contains(&ratio),
            "Compression ratio should be ~32x, got {}",
            ratio
        );
    }

    #[test]
    fn test_e8mat_serialization_roundtrip() {
        // Create 3x4 matrix
        let mut original = E8Mat::new(3, 4);
        original[0] = E8Vec::from_indices(&[1, 2, 3, 4]);
        original[1] = E8Vec::from_indices(&[5, 6, 7, 8]);
        original[2] = E8Vec::from_indices(&[9, 10, 11, 12]);

        // Serialize to bytes
        let bytes = original.to_bytes();
        assert_eq!(bytes.len(), 12, "3x4 E8Mat should serialize to 12 bytes");

        // Verify bytes are row-major
        let expected = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12];
        for (i, &byte) in bytes.iter().enumerate() {
            assert_eq!(byte, expected[i], "Byte at index {} doesn't match", i);
        }

        // Deserialize
        let restored = E8Mat::from_bytes(&bytes, 3, 4);
        assert_eq!(restored.num_rows(), 3);
        assert_eq!(restored.num_cols(), 4);

        // Verify roundtrip
        for i in 0..3 {
            for j in 0..4 {
                assert_eq!(
                    original[i].data[j].0, restored[i].data[j].0,
                    "E8Mat roundtrip failed at [{}, {}]",
                    i, j
                );
            }
        }
    }

    /// Verify that E8F operations are deterministic and repeatable (lossless property)
    #[test]
    fn test_e8f_operations_deterministic() {
        // Same inputs should always produce same outputs (lookup table is constant)
        let a = E8F::new(42);
        let b = E8F::new(100);

        // Perform operation 1000 times - should always get same result
        let mut results = Vec::new();
        for _ in 0..1000 {
            results.push((a + b).index());
        }

        // All results should be identical (deterministic)
        let first = results[0];
        for (i, &result) in results.iter().enumerate() {
            assert_eq!(
                result, first,
                "E8F addition not deterministic at iteration {}",
                i
            );
        }
    }

    /// Verify that E8F → Gf8 → E8F is truly lossless for valid roots
    #[test]
    fn test_e8f_gf8_roundtrip_lossless() {
        for idx in 0..240u8 {
            let original = E8F::new(idx);
            let gf8 = original.to_gf8();
            let recovered = E8F::from_f32(gf8.coords());

            assert_eq!(
                original.index(),
                recovered.index(),
                "E8F → Gf8 → E8F roundtrip not lossless for root {}",
                idx
            );
        }
    }

    /// Verify that E8F serialization is byte-perfect (truly lossless)
    #[test]
    fn test_e8f_serialization_byte_perfect() {
        for idx in 0..240u8 {
            let original = E8F::new(idx);
            let byte = original.index();
            let recovered = E8F::new(byte);

            assert_eq!(
                original.index(),
                recovered.index(),
                "E8F serialization not byte-perfect for index {}",
                idx
            );
        }
    }

    #[test]
    fn test_e8mat_serialization_large() {
        // Create 240x240 matrix (valorem size)
        let mut mat = E8Mat::new(240, 240);

        // Fill with some pattern
        for i in 0..240 {
            for j in 0..240 {
                mat[i].data[j] = E8F::new(((i + j) % 240) as u8);
            }
        }

        // Serialize
        let bytes = mat.to_bytes();
        assert_eq!(
            bytes.len(),
            240 * 240,
            "240x240 E8Mat should serialize to 57600 bytes"
        );

        // Deserialize
        let restored = E8Mat::from_bytes(&bytes, 240, 240);

        // Spot check some values
        for i in [0, 50, 100, 200, 239] {
            for j in [0, 50, 100, 200, 239] {
                assert_eq!(
                    mat[i].data[j].0, restored[i].data[j].0,
                    "Large E8Mat roundtrip failed at [{}, {}]",
                    i, j
                );
            }
        }
    }
}

File: e8x.rs
============
/* crates/gf8/src/e8x.rs */
//! # E8X - The Batteries-Included E8 Type
//!
//! E8X (E8 Cross) combines all E8 capabilities into a single, easy-to-use type:
//! - **E8F core operations**: Zero-FLOP arithmetic via lookup tables
//! - **Automatic error management**: Re-alignment after N operations
//! - **Drift tracking**: Built-in metrics for error monitoring
//! - **Hybrid computation**: Seamless E8F ↔ f32 conversion
//!
//! ## Philosophy
//!
//! E8X is the "batteries included" type for E8 operations. Instead of manually
//! wiring together E8F + E8FAligned + E8FCompute, just use E8X and everything
//! works out of the box.
//!
//! ## When to Use
//!
//! - **Use E8X for**: Applications, media compression, neural networks, anything
//!   requiring robust E8 operations with automatic error management
//! - **Use E8F for**: Low-level operations, when you need fine-grained control,
//!   or when you're building your own wrappers
//!
//! ## Example
//!
//! ```rust
//! use gf8::E8X;
//!
//! // Single import, everything works
//! let mut a = E8X::new_from_index(42);
//! let b = E8X::new_from_index(100);
//!
//! // Automatic re-alignment after N operations
//! for i in 0..20 {
//!     a += b;  // Re-alignment happens automatically
//! }
//!
//! // Drift tracking built-in
//! println!("Max drift: {:.4}", a.max_drift());
//!
//! // Hybrid compute built-in
//! let coords = a.to_f32_coords();
//! let reconstructed = E8X::from_f32_coords(&coords);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::quantize_to_nearest_code;
use crate::{E8F, Gf8, gf8_chordal_distance};
use std::ops::{Add, AddAssign, Mul, MulAssign, Sub, SubAssign};

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 1: E8X TYPE DEFINITION
// ═══════════════════════════════════════════════════════════════════════════════════════

/// E8X - The batteries-included E8 type.
///
/// Combines E8F core operations with automatic error management, hybrid computation,
/// and drift tracking. This is the recommended type for most applications.
///
/// # Features
///
/// - **1-byte wire representation** via `batch_to_bytes` (same index as E8F)
/// - **Zero-FLOP operations**: Add, mul, dot via precomputed lookup tables
/// - **Automatic re-alignment**: Triggers after N operations (default: 10)
/// - **Hybrid computation**: Seamless E8F ↔ f32 conversion automation
/// - **Drift tracking**: Monitors cumulative error from operations
///
/// # Error Management
///
/// E8X automatically re-aligns to the nearest E8 root after a configurable
/// number of operations, bounding cumulative quantization drift.
///
/// # Example
///
/// ```rust
/// use gf8::E8X;
///
/// let mut x = E8X::new_from_index(0);
///
/// // Chain operations - automatic re-alignment
/// for i in 0..15 {
///     x += E8X::new_from_index(i);
/// }
///
/// // Check drift is finite
/// assert!(x.max_drift().is_finite());
/// ```
#[derive(Debug, Clone, Copy)]
pub struct E8X {
    /// The current E8F value.
    value: E8F,

    /// Number of operations since last alignment.
    ops_since_alignment: u8,

    /// Maximum operations before triggering automatic alignment.
    max_ops_before_align: u8,

    /// Maximum observed drift from last alignment point.
    max_drift: f32,

    /// Sum of all drift values (for computing mean).
    drift_sum: f32,

    /// Count of drift measurements.
    drift_count: u32,

    /// Reference point for drift measurement (last aligned value).
    reference: Gf8,
}

impl E8X {
    /// Default number of operations before automatic alignment.
    pub const DEFAULT_MAX_OPS: u8 = 10;

    /// Default drift threshold for warnings.
    pub const DEFAULT_DRIFT_THRESHOLD: f32 = 0.1;

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 2: CONSTRUCTORS
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Create a new E8X from an E8F value.
    ///
    /// # Arguments
    /// * `value` - The E8F value to wrap
    ///
    /// # Example
    /// ```rust
    /// use gf8::{E8X, E8F};
    ///
    /// let e8f = E8F::new(42);
    /// let e8x = E8X::new(e8f);
    /// ```
    pub fn new(value: E8F) -> Self {
        let reference = value.to_gf8();
        Self {
            value,
            ops_since_alignment: 0,
            max_ops_before_align: Self::DEFAULT_MAX_OPS,
            max_drift: 0.0,
            drift_sum: 0.0,
            drift_count: 0,
            reference,
        }
    }

    /// Create a new E8X from a root index (0-239).
    ///
    /// # Arguments
    /// * `index` - The E8 root index
    ///
    /// # Example
    /// ```rust
    /// use gf8::E8X;
    ///
    /// let e8x = E8X::new_from_index(42);
    /// ```
    pub fn new_from_index(index: u8) -> Self {
        Self::new(E8F::new(index))
    }

    /// Create a new E8X with custom alignment threshold.
    ///
    /// # Arguments
    /// * `value` - The E8F value to wrap
    /// * `max_ops` - Maximum operations before automatic alignment
    ///
    /// # Example
    /// ```rust
    /// use gf8::{E8X, E8F};
    ///
    /// let e8x = E8X::with_max_ops(E8F::new(42), 5);
    /// ```
    pub fn with_max_ops(value: E8F, max_ops: u8) -> Self {
        let mut e8x = Self::new(value);
        e8x.max_ops_before_align = max_ops;
        e8x
    }

    /// Create a new E8X from f32 coordinates.
    ///
    /// Quantizes the coordinates to the nearest E8 root.
    ///
    /// # Arguments
    /// * `coords` - 8D coordinates to quantize
    ///
    /// # Returns
    /// Tuple of (E8X, quantization_error)
    ///
    /// # Example
    /// ```rust
    /// use gf8::E8X;
    ///
    /// let coords = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
    /// let (e8x, error) = E8X::from_f32_coords(&coords);
    /// assert!(error < 1.0);
    /// ```
    pub fn from_f32_coords(coords: &[f32; 8]) -> (Self, f32) {
        let (code, snapped_gf8) = quantize_to_nearest_code(coords);

        // Compute quantization error
        let input_gf8 = Gf8::from_coords(*coords);
        let error = gf8_chordal_distance(&input_gf8, &snapped_gf8);

        (Self::new(E8F::from_code(code)), error)
    }

    /// Create a new E8X from a Gf8 vector.
    ///
    /// # Arguments
    /// * `gf8` - The Gf8 vector to quantize
    ///
    /// # Example
    /// ```rust
    /// use gf8::{E8X, Gf8};
    ///
    /// let gf8 = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
    /// let e8x = E8X::from_gf8(&gf8);
    /// ```
    pub fn from_gf8(gf8: &Gf8) -> Self {
        let (code, _) = quantize_to_nearest_code(gf8.coords());
        Self::new(E8F::from_code(code))
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 3: ACCESSORS
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Get the underlying E8F value.
    #[inline]
    pub fn value(&self) -> E8F {
        self.value
    }

    /// Get the E8 root index (0-239).
    #[inline]
    pub fn index(&self) -> u8 {
        self.value.index()
    }

    /// Get the number of operations since last alignment.
    #[inline]
    pub fn ops_since_alignment(&self) -> u8 {
        self.ops_since_alignment
    }

    /// Get the maximum operations before alignment.
    #[inline]
    pub fn max_ops_before_align(&self) -> u8 {
        self.max_ops_before_align
    }

    /// Set the maximum operations before alignment.
    #[inline]
    pub fn set_max_ops(&mut self, max_ops: u8) {
        self.max_ops_before_align = max_ops;
    }

    /// Get the maximum observed drift.
    #[inline]
    pub fn max_drift(&self) -> f32 {
        self.max_drift
    }

    /// Get the mean drift across all operations.
    #[inline]
    pub fn mean_drift(&self) -> f32 {
        if self.drift_count == 0 {
            0.0
        } else {
            self.drift_sum / self.drift_count as f32
        }
    }

    /// Get the current drift from reference point.
    pub fn current_drift(&self) -> f32 {
        let current_gf8 = self.value.to_gf8();
        gf8_chordal_distance(&self.reference, &current_gf8)
    }

    /// Check if the value is a valid E8 root.
    #[inline]
    pub fn is_valid(&self) -> bool {
        self.value.is_valid()
    }

    /// Check if the current value exactly matches a specific E8 root.
    /// This is a **lossless** comparison - no quantization error.
    #[inline]
    pub fn is_exact_root(&self, index: u8) -> bool {
        self.value.index() == index && self.value.is_valid()
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 4: HYBRID COMPUTATION (E8F ↔ f32)
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Convert to f32 coordinates for computation.
    ///
    /// This is a lossless operation - the E8F root coordinates are
    /// exactly representable in f32.
    ///
    /// # Example
    /// ```rust
    /// use gf8::E8X;
    ///
    /// let e8x = E8X::new_from_index(0);
    /// let coords = e8x.to_f32_coords();
    /// ```
    pub fn to_f32_coords(&self) -> [f32; 8] {
        if !self.value.is_valid() {
            return [0.0; 8];
        }
        let gf8 = self.value.to_gf8();
        *gf8.coords()
    }

    /// Convert to Gf8 representation.
    pub fn to_gf8(&self) -> Gf8 {
        self.value.to_gf8()
    }

    /// Convert to u32 for integer accumulation.
    #[inline]
    pub fn to_u32(&self) -> u32 {
        self.value.index() as u32
    }

    /// Compute dot product with another E8X in f32 space.
    ///
    /// Uses exact f32 computation for higher precision than the
    /// E8F lookup table.
    pub fn dot_f32(&self, other: &E8X) -> f32 {
        let a_coords = self.to_f32_coords();
        let b_coords = other.to_f32_coords();

        a_coords
            .iter()
            .zip(b_coords.iter())
            .map(|(x, y)| x * y)
            .sum()
    }

    /// Compute chordal distance to another E8X.
    pub fn chordal_distance(&self, other: &E8X) -> f32 {
        let a_coords = self.to_f32_coords();
        let b_coords = other.to_f32_coords();

        let sum_sq: f32 = a_coords
            .iter()
            .zip(b_coords.iter())
            .map(|(x, y)| (x - y).powi(2))
            .sum();

        sum_sq.sqrt()
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 5: ERROR MANAGEMENT
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Check if alignment is needed.
    #[inline]
    pub fn needs_alignment(&self) -> bool {
        self.ops_since_alignment >= self.max_ops_before_align
    }

    /// Force re-alignment to the nearest valid E8 root.
    ///
    /// This resets the operation counter and updates the reference point.
    /// **Error Bound**: Alignment introduces ≤0.087 chordal distance error
    /// (worst case) by snapping to the nearest E8 root.
    pub fn align(&mut self) {
        if !self.value.is_valid() {
            self.value = E8F::new(0);
            self.ops_since_alignment = 0;
            self.reference = self.value.to_gf8();
            return;
        }

        // If already a valid root, alignment is a no-op (lossless)
        let gf8 = self.value.to_gf8();
        let (code, _) = quantize_to_nearest_code(gf8.coords());
        self.value = E8F::from_code(code);
        self.ops_since_alignment = 0;
        self.reference = self.value.to_gf8();
    }

    /// Update drift metrics after an operation.
    fn update_drift(&mut self) {
        let drift = self.current_drift();
        self.max_drift = self.max_drift.max(drift);
        self.drift_sum += drift;
        self.drift_count += 1;
    }

    /// Perform an operation with automatic alignment check.
    ///
    /// This is the internal method used by operator overloads.
    fn perform_op<F>(&mut self, f: F)
    where
        F: FnOnce(E8F) -> E8F,
    {
        self.value = f(self.value);
        self.ops_since_alignment = self.ops_since_alignment.saturating_add(1);
        self.update_drift();

        if self.needs_alignment() {
            self.align();
        }
    }

    // ═══════════════════════════════════════════════════════════════════════════════════
    // SECTION 6: ARITHMETIC OPERATIONS
    // ═══════════════════════════════════════════════════════════════════════════════════

    /// Add another E8X value (with automatic re-alignment).
    pub fn add_e8x(&mut self, other: E8X) -> &mut Self {
        self.perform_op(|v| v + other.value);
        self
    }

    /// Subtract another E8X value (with automatic re-alignment).
    pub fn sub_e8x(&mut self, other: E8X) -> &mut Self {
        self.perform_op(|v| v - other.value);
        self
    }

    /// Multiply by another E8X value (with automatic re-alignment).
    pub fn mul_e8x(&mut self, other: E8X) -> &mut Self {
        self.perform_op(|v| v * other.value);
        self
    }

    /// Compute dot product using E8F lookup table.
    ///
    /// For higher precision, use `dot_f32()` instead.
    pub fn dot(&self, other: E8X) -> f32 {
        self.value.dot(other.value)
    }

    /// Reflect through a hyperplane normal to another E8X.
    pub fn reflect(&mut self, normal: E8X) -> &mut Self {
        self.perform_op(|v| v.reflect(normal.value));
        self
    }

    /// Negate the value.
    pub fn neg(&mut self) -> &mut Self {
        self.perform_op(|v| -v);
        self
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 7: OPERATOR OVERLOADS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl Add for E8X {
    type Output = E8X;

    fn add(self, other: E8X) -> E8X {
        let mut result = self;
        result.add_e8x(other);
        result
    }
}

impl AddAssign for E8X {
    fn add_assign(&mut self, other: E8X) {
        self.add_e8x(other);
    }
}

impl Sub for E8X {
    type Output = E8X;

    fn sub(self, other: E8X) -> E8X {
        let mut result = self;
        result.sub_e8x(other);
        result
    }
}

impl SubAssign for E8X {
    fn sub_assign(&mut self, other: E8X) {
        self.sub_e8x(other);
    }
}

impl Mul for E8X {
    type Output = E8X;

    fn mul(self, other: E8X) -> E8X {
        let mut result = self;
        result.mul_e8x(other);
        result
    }
}

impl MulAssign for E8X {
    fn mul_assign(&mut self, other: E8X) {
        self.mul_e8x(other);
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 8: CONVERSIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl From<E8F> for E8X {
    fn from(value: E8F) -> Self {
        Self::new(value)
    }
}

impl From<E8X> for E8F {
    fn from(e8x: E8X) -> Self {
        e8x.value
    }
}

impl From<u8> for E8X {
    fn from(index: u8) -> Self {
        Self::new_from_index(index)
    }
}

impl Default for E8X {
    fn default() -> Self {
        Self::new(E8F::new(0))
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 9: BATCH OPERATIONS
// ═══════════════════════════════════════════════════════════════════════════════════════

impl E8X {
    /// Convert a batch of E8X values to bytes for storage.
    pub fn batch_to_bytes(batch: &[E8X]) -> Vec<u8> {
        batch.iter().map(|e8x| e8x.index()).collect()
    }

    /// Convert bytes back to E8X values.
    pub fn batch_from_bytes(bytes: &[u8]) -> Vec<E8X> {
        bytes.iter().map(|&b| E8X::new_from_index(b)).collect()
    }

    /// Compute weighted sum of E8X values in f32 space.
    ///
    /// This is the canonical hybrid pattern:
    /// 1. Convert to f32
    /// 2. Accumulate
    /// 3. Quantize back to E8X
    pub fn weighted_sum(weights: &[E8X], values: &[E8X]) -> (E8X, f32) {
        assert_eq!(weights.len(), values.len());

        if weights.is_empty() {
            return (E8X::default(), 0.0);
        }

        // Accumulate in f32 space
        let mut sum = [0.0f32; 8];

        for (w, v) in weights.iter().zip(values.iter()) {
            let w_coords = w.to_f32_coords();
            let v_coords = v.to_f32_coords();
            let w_scalar = w_coords[0];

            for i in 0..8 {
                sum[i] += w_scalar * v_coords[i];
            }
        }

        // Normalize
        let norm = sum.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for c in &mut sum {
                *c /= norm;
            }
        }

        // Quantize back to E8X
        E8X::from_f32_coords(&sum)
    }
}

// ═══════════════════════════════════════════════════════════════════════════════════════
// SECTION 10: TESTS
// ═══════════════════════════════════════════════════════════════════════════════════════

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_e8x_creation() {
        let e8x = E8X::new_from_index(42);
        assert_eq!(e8x.index(), 42);
        assert_eq!(e8x.ops_since_alignment(), 0);
        assert!(e8x.is_valid());
    }

    #[test]
    fn test_e8x_automatic_alignment() {
        let mut e8x = E8X::with_max_ops(E8F::new(10), 3);

        // Perform 3 operations - should trigger alignment
        e8x.add_e8x(E8X::new_from_index(1));
        e8x.add_e8x(E8X::new_from_index(2));
        e8x.add_e8x(E8X::new_from_index(3));

        // Counter should be reset after alignment
        assert_eq!(e8x.ops_since_alignment(), 0);
        assert!(e8x.is_valid());
    }

    #[test]
    fn test_e8x_operator_overloads() {
        let a = E8X::new_from_index(10);
        let b = E8X::new_from_index(20);

        let c = a + b;
        assert!(c.is_valid());

        let d = a - b;
        assert!(d.is_valid());

        let e = a * b;
        assert!(e.is_valid());
    }

    #[test]
    fn test_e8x_drift_tracking() {
        let mut e8x = E8X::new_from_index(0);

        // Perform operations
        for i in 0..5 {
            e8x.add_e8x(E8X::new_from_index(i * 10));
        }

        // Drift should be tracked
        assert!(e8x.max_drift() >= 0.0);
        assert!(e8x.mean_drift() >= 0.0);
    }

    #[test]
    fn test_e8x_hybrid_compute() {
        let e8x = E8X::new_from_index(42);
        let coords = e8x.to_f32_coords();

        // Should be unit vector
        let norm: f32 = coords.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!((norm - 1.0).abs() < 1e-5);

        // Roundtrip
        let (recovered, error) = E8X::from_f32_coords(&coords);
        assert_eq!(recovered.index(), 42);
        assert!(error < 1e-5);
    }

    #[test]
    fn test_e8x_dot_product() {
        let a = E8X::new_from_index(0);
        let b = E8X::new_from_index(0);

        let dot = a.dot(b);
        assert!((dot - 1.0).abs() < 0.1, "Same root should have dot ~1.0");

        let dot_f32 = a.dot_f32(&b);
        assert!(
            (dot_f32 - 1.0).abs() < 1e-5,
            "f32 dot should be more precise"
        );
    }

    #[test]
    fn test_e8x_batch_operations() {
        let batch = vec![
            E8X::new_from_index(0),
            E8X::new_from_index(1),
            E8X::new_from_index(2),
        ];

        let bytes = E8X::batch_to_bytes(&batch);
        assert_eq!(bytes, vec![0, 1, 2]);

        let recovered = E8X::batch_from_bytes(&bytes);
        assert_eq!(recovered.len(), 3);
        assert_eq!(recovered[0].index(), 0);
        assert_eq!(recovered[1].index(), 1);
        assert_eq!(recovered[2].index(), 2);
    }

    #[test]
    fn test_e8x_weighted_sum() {
        let weights = vec![E8X::new_from_index(100), E8X::new_from_index(100)];
        let values = vec![E8X::new_from_index(0), E8X::new_from_index(0)];

        let (result, error) = E8X::weighted_sum(&weights, &values);
        assert!(result.is_valid());
        assert!(error.is_finite());
    }

    #[test]
    fn test_e8x_conversions() {
        let e8f = E8F::new(42);
        let e8x: E8X = e8f.into();
        assert_eq!(e8x.index(), 42);

        let back: E8F = e8x.into();
        assert_eq!(back.index(), 42);

        let from_u8: E8X = 100u8.into();
        assert_eq!(from_u8.index(), 100);
    }

    #[test]
    fn test_e8x_chordal_distance() {
        let a = E8X::new_from_index(0);
        let b = E8X::new_from_index(0);

        let dist = a.chordal_distance(&b);
        assert!(dist < 1e-5, "Same root should have zero distance");

        let c = E8X::new_from_index(100);
        let dist2 = a.chordal_distance(&c);
        assert!(dist2 > 0.0, "Different roots should have non-zero distance");
    }
}

File: fast_math.rs
==================
/* src/primitive/fast_math.rs */
//! Provides fast, SIMD-friendly approximations for expensive mathematical functions.
//!
//! # E8 Computing Paradigm – Fast Math Module
//!▫~•◦------------------------------------------------------------------------------------‣
//!
//! This module implements the "Function Approximation via Tabulation" pattern for
//! computationally expensive, low-dimensional functions. It replaces slow transcendental
//! function calls (like `acos`) with a high-performance, three-stage pipeline:
//! 1. A compile-time "Baker" generates a cache-resident Look-Up Table (LUT).
//! 2. A runtime "Synthesizer" performs a fast, branchless lookup into the LUT.
//! 3. A SIMD-friendly linear interpolation (`lerp`) approximates the final value.
//!
//! This approach trades a small, controllable amount of precision for a significant
//! increase in performance, targeting the true bottlenecks identified by profiling.
//!
//! ### Key Capabilities
//! - **Compile-Time LUT Generation:** The `AcosLut` is generated entirely at compile-time
//!   via `const fn`, incurring zero runtime initialization cost.
//! - **Cache-Resident Design:** The LUT size is a generic const parameter, allowing it to
//!   be tuned to fit within L1/L2 CPU caches (e.g., 4096 entries * 4 bytes = 16KB).
//! - **Branchless & SIMD-Friendly:** The lookup and interpolation logic is free of
//!   branches and composed of simple arithmetic operations ideal for FMA instructions.
//!
//! ### Architectural Notes
//! This module embodies the "Just Barely Ahead" principle: applying advanced optimization
//! with surgical precision to the actual bottleneck. The `AcosLut` is designed to be a
//! singleton, statically promoted to eliminate overhead. It serves as a drop-in
//! replacement for `f32::acos` in performance-critical code paths like the `Gf8::angle`
//! calculation.
//!
//! ### Example
//! \```rust
//! use crate::primitive::fast_math::FAST_ACOS;
//! use std::f32::consts::FRAC_1_SQRT_2;
//!
//! // The value of cos(pi/4)
//! let cos_val = FRAC_1_SQRT_2; // approx 0.7071
//!
//! // Calculate acos using the fast LUT
//! let angle_fast = FAST_ACOS.lookup(cos_val);
//!
//! // The result is a very close approximation of pi/4 (approx 0.7854)
//! let angle_std = cos_val.acos();
//! assert!((angle_fast - angle_std).abs() < 1e-4); // Error is low for 4096 entries
//! \```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// A precomputed Look-Up Table for approximating the `acos(x)` function.
///
/// `N` is the number of entries in the table. A larger `N` increases precision
/// and memory usage. `4096` is a good default, using 16KB, which fits comfortably
/// in modern L1/L2 caches.
#[derive(Debug, Clone, Copy)]
pub struct AcosLut<const N: usize> {
    table: [f32; N],
}

use std::sync::OnceLock;

impl<const N: usize> AcosLut<N> {
    /// Creates a new `AcosLut` at compile time.
    ///
    /// The table is populated with `N` values of `acos(x)` for `x` spaced
    /// evenly across the valid domain `[-1.0, 1.0]`.
    pub fn new() -> Self {
        let mut table = [0.0; N];
        let mut i = 0;
        while i < N {
            // Map the table index `i` to the domain `[-1.0, 1.0]`
            let t = i as f32 / (N - 1) as f32; // t is in [0.0, 1.0]
            let x = t * 2.0 - 1.0; // x is in [-1.0, 1.0]

            // Use the standard library `acos` here, since `AcosLut::new` is non-const.
            // This produces an accurate precomputed table that matches the
            // standard library within the expected numerical error bounds.
            let result = x.acos();
            table[i] = result;

            i += 1;
        }
        Self { table }
    }

    /// Looks up the approximate value of `acos(x)`.
    ///
    /// # Arguments
    /// * `x` - A float in the range `[-1.0, 1.0]`. Values outside this range will be clamped.
    ///
    /// # Returns
    /// An approximation of `acos(x)`.
    #[inline(always)]
    pub fn lookup(&self, x: f32) -> f32 {
        // Clamp input to the valid domain.
        let x_clamped = x.clamp(-1.0, 1.0);

        // 1. Map `x` from `[-1.0, 1.0]` to a fractional index `[0.0, N-1]`.
        let frac_index = (x_clamped * 0.5 + 0.5) * ((N - 1) as f32);

        // 2. Get the integer index and the fractional part for interpolation.
        let index_floor = frac_index as usize;
        let frac = frac_index - index_floor as f32;

        // Ensure we don't read past the end of the table.
        // This can happen if x is exactly 1.0.
        let index_ceil = (index_floor + 1).min(N - 1);

        // 3. Gather the two nearest values from the LUT.
        // SAFETY: `index_floor` and `index_ceil` are guaranteed to be in bounds.
        let val_floor = unsafe { *self.table.get_unchecked(index_floor) };
        let val_ceil = unsafe { *self.table.get_unchecked(index_ceil) };

        // 4. Linearly interpolate between the two values.
        // This is a single FMA operation on capable hardware.
        val_floor.mul_add(1.0 - frac, val_ceil * frac)
    }
}

impl<const N: usize> Default for AcosLut<N> {
    fn default() -> Self {
        Self::new()
    }
}

/// A statically allocated, globally accessible instance of the `AcosLut`.
///
/// This is the "bottled rain" - a high-performance, ready-to-use utility
/// that solves the specific `acos` bottleneck.
pub static FAST_ACOS: OnceLock<AcosLut<4096>> = OnceLock::new();

#[cfg(test)]
mod tests {
    use super::*;
    use std::f32::consts::{FRAC_PI_2, FRAC_PI_4, PI};

    #[test]
    fn test_acos_lut_edge_cases() {
        // Test at the boundaries of the domain.
        let acos_of_1 = FAST_ACOS.get_or_init(AcosLut::new).lookup(1.0);
        let acos_of_neg_1 = FAST_ACOS.get_or_init(AcosLut::new).lookup(-1.0);
        let acos_of_0 = FAST_ACOS.get_or_init(AcosLut::new).lookup(0.0);

        assert!((acos_of_1 - 0.0).abs() < 1e-3, "acos(1.0) should be ~0.0");
        assert!(
            (acos_of_neg_1 - PI).abs() < 1e-3,
            "acos(-1.0) should be ~PI"
        );
        assert!(
            (acos_of_0 - FRAC_PI_2).abs() < 1e-3,
            "acos(0.0) should be ~PI/2"
        );
    }

    #[test]
    fn test_acos_lut_precision() {
        let inputs = [-0.9, -0.5, -0.1, 0.1, 0.5, 0.9];
        for &x in &inputs {
            let fast_val = FAST_ACOS.get_or_init(AcosLut::new).lookup(x);
            let std_val = x.acos();
            let error = (fast_val - std_val).abs();
            // With a 4096-entry LUT, the error should be very small.
            assert!(
                error < 1e-4,
                "Precision error too high for x={}: fast={}, std={}, err={}",
                x,
                fast_val,
                std_val,
                error
            );
        }
    }

    #[test]
    fn test_acos_lut_known_values() {
        // cos(pi/4) = 1/sqrt(2)
        let x = std::f32::consts::FRAC_1_SQRT_2;
        let fast_val = FAST_ACOS.get_or_init(AcosLut::new).lookup(x);
        assert!(
            (fast_val - FRAC_PI_4).abs() < 1e-4,
            "acos(1/sqrt(2)) should be ~PI/4"
        );

        // cos(pi/3) = 0.5
        let x = 0.5;
        let fast_val = FAST_ACOS.get_or_init(AcosLut::new).lookup(x);
        let std_val = PI / 3.0;
        assert!(
            (fast_val - std_val).abs() < 1e-4,
            "acos(0.5) should be ~PI/3"
        );
    }

    #[test]
    fn test_out_of_domain_clamping() {
        let val_high = FAST_ACOS.get_or_init(AcosLut::new).lookup(1.5);
        let val_low = FAST_ACOS.get_or_init(AcosLut::new).lookup(-1.5);

        // Should be clamped and return the same as the boundary values.
        assert_eq!(val_high, FAST_ACOS.get_or_init(AcosLut::new).lookup(1.0));
        assert_eq!(val_low, FAST_ACOS.get_or_init(AcosLut::new).lookup(-1.0));
    }
}

File: fractal_simt.rs
=====================
// src/fractal_simt.rs
//! Procedural, fractal-style SIMT scheduler for CPU.
//!
//! This module simulates a SIMT-like execution model on the CPU using a
//! deterministic, procedural "fractal" (Morton / Z-order–style) mapping from
//! (step, lane) -> index, so that:
//!
//!   - each "warp" has `warp_size` conceptual lanes,
//!   - work is visited in a cache-friendly, fractal-ish order,
//!   - the mapping is deterministic and reproducible for a fixed config.
//!
//! The design is intentionally CPU-only and scalar; the hot loop is a perfect
//! place to drop in real SIMD intrinsics later (AVX2/AVX-512), but you get a
//! usable, debuggable baseline right away.
//!
//! Typical usage:
//!
//! ```rust
//! use gf8::fractal_simt::{FractalSimtConfig, fractal_simt_for_each};
//!
//! let mut data = vec![0.0f32; 1024];
//! let cfg = FractalSimtConfig::default();
//!
//! fractal_simt_for_each(&mut data, &cfg, |lane, value| {
//!     // lane is 0..warp_size-1
//!     *value += lane as f32;
//! });
//! ```
//!
//! For a concrete numeric example, see `fractal_simt_add_f32_in_place` below.
//!
//! This scheduler encapsulates the UECC (docs/UECC.pdf) Universal Event Corridor guidance by
//! faithfully recording the 56 neighbor transitions per root that ensure smooth procedural change.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Configuration for the fractal SIMT scheduler.
#[derive(Debug, Clone, Copy)]
pub struct FractalSimtConfig {
    /// Conceptual number of lanes in a warp.
    ///
    /// For AVX2 with f32, 8 lanes is a natural choice (256 bits / 32 bits).
    /// For AVX-512, 16 lanes would be a natural choice, etc.
    pub warp_size: usize,

    /// Number of bits to use from `step` and `lane` when building the
    /// fractal mapping. Higher values produce "deeper" fractal structure,
    /// but also cost a few more bit ops.
    pub depth_bits: u32,
}

impl Default for FractalSimtConfig {
    fn default() -> Self {
        Self {
            warp_size: 8,
            depth_bits: 10, // enough for 2^10 * 2^10 = 1M positions before wrapping
        }
    }
}

/// Interleave the lower `bits` bits of `x` and `y` into a Morton/Z-order code.
///
/// Conceptually, this takes:
///
/// ```text
/// x = x_{bits-1} ... x_1 x_0
/// y = y_{bits-1} ... y_1 y_0
///
/// morton = y_{bits-1} x_{bits-1} ... y_1 x_1 y_0 x_0
/// ```
#[inline]
fn interleave_bits_2d(x: u64, y: u64, bits: u32) -> u64 {
    let mut result = 0u64;
    for i in 0..bits {
        let xb = (x >> i) & 1;
        let yb = (y >> i) & 1;
        result |= xb << (2 * i);
        result |= yb << (2 * i + 1);
    }
    result
}

/// Compute a fractal "global index" given a (step, lane) pair.
///
/// - `step` advances each warp iteration.
/// - `lane` is in `[0, warp_size)`.
/// - `depth_bits` determines how many bits from each we interleave.
///
/// The result is then typically modulo the total length of the slice.
#[inline]
fn fractal_index(step: u64, lane: u64, depth_bits: u32) -> u64 {
    // Mask down to `depth_bits` so we don't explode the Morton code.
    let mask = if depth_bits >= 32 {
        u64::MAX
    } else {
        (1u64 << depth_bits) - 1
    };

    let s = step & mask;
    let l = lane & mask;

    interleave_bits_2d(s, l, depth_bits)
}

/// Recorded trace for each (step, lane, index) visit.
#[derive(Clone, Debug)]
pub struct FractalSimtTraceEntry {
    pub step: u64,
    pub lane: usize,
    pub index: usize,
    pub root: Option<u8>,
}

/// Simple checkpoint marker for rewinding traces.
#[derive(Clone, Copy, Debug)]
pub struct FractalSimtCheckpoint(pub usize);

#[derive(Clone, Debug, Default)]
pub struct FractalSimtTrace {
    entries: Vec<FractalSimtTraceEntry>,
}

impl FractalSimtTrace {
    pub fn new() -> Self {
        Self {
            entries: Vec::new(),
        }
    }

    pub fn len(&self) -> usize {
        self.entries.len()
    }

    pub fn checkpoint(&self) -> FractalSimtCheckpoint {
        FractalSimtCheckpoint(self.entries.len())
    }

    pub fn rollback(&mut self, checkpoint: FractalSimtCheckpoint) {
        if checkpoint.0 <= self.entries.len() {
            self.entries.truncate(checkpoint.0);
        }
    }

    pub fn push(&mut self, entry: FractalSimtTraceEntry) {
        self.entries.push(entry);
    }

    pub fn entries(&self) -> &[FractalSimtTraceEntry] {
        &self.entries
    }

    pub fn entries_mut(&mut self) -> &mut [FractalSimtTraceEntry] {
        &mut self.entries
    }
}

pub fn fractal_simt_trace<T, F>(
    data: &mut [T],
    cfg: &FractalSimtConfig,
    mut f: F,
) -> FractalSimtTrace
where
    F: FnMut(usize, usize, &mut T, &mut FractalSimtTrace),
{
    let mut trace = FractalSimtTrace::new();
    let len = data.len();
    if len == 0 || cfg.warp_size == 0 {
        return trace;
    }

    let steps = len.div_ceil(cfg.warp_size);

    for step in 0..(steps as u64) {
        for lane in 0..cfg.warp_size {
            let idx_raw = fractal_index(step, lane as u64, cfg.depth_bits);
            let idx = (idx_raw % (len as u64)) as usize;

            trace.push(FractalSimtTraceEntry {
                step,
                lane,
                index: idx,
                root: None,
            });

            f(lane, idx, &mut data[idx], &mut trace);
        }
    }

    trace
}

/// Generic fractal SIMT loop over a mutable slice.
///
/// For each conceptual (step, lane) pair, a "fractal index" is computed,
/// wrapped into the slice length, and the user closure is invoked with:
///
/// - `lane` (0..warp_size-1)
/// - `&mut data[index]` (the element at that position)
///
/// This gives you a deterministic, warp-like execution pattern over the slice.
///
/// Note: this is single-threaded and scalar. To extend it:
/// - you can shard `data` across threads and call this per-shard,
/// - or replace the inner element ops with real SIMD intrinsics.
pub fn fractal_simt_for_each<T, F>(data: &mut [T], cfg: &FractalSimtConfig, mut f: F)
where
    F: FnMut(usize, &mut T),
{
    fractal_simt_trace(data, cfg, |lane, _idx, elem, _trace| {
        f(lane, elem);
    });
}

/// A variant of `fractal_simt_for_each` that additionally exposes the resolved
/// index for the current element. This is useful for operations that need to
/// know the index (e.g., reconstructing vector data from program indices).
pub fn fractal_simt_for_each_indexed<T, F>(data: &mut [T], cfg: &FractalSimtConfig, mut f: F)
where
    F: FnMut(usize, usize, &mut T),
{
    fractal_simt_trace(data, cfg, |lane, idx, elem, trace| {
        if let Some(entry) = trace.entries.last_mut() {
            entry.index = idx;
        }
        f(lane, idx, elem);
    });
}

/// A concrete example: in-place `a[i] += b[i]` using a fractal SIMT walk.
///
/// Each conceptual warp lane walks in Morton/Z-order, matching the scheduler’s
/// actual lane ordering (no simulation) so the resulting sequence is ready for
/// SIMD replacement.
///
/// This is a good function to benchmark to get a feel for the scheduler's
/// throughput and cache behavior.
///
/// Requirements:
/// - `a.len() == b.len()`.
pub fn fractal_simt_add_f32_in_place(a: &mut [f32], b: &[f32], cfg: &FractalSimtConfig) {
    assert_eq!(
        a.len(),
        b.len(),
        "fractal_simt_add_f32_in_place: a and b length mismatch"
    );

    let len = a.len();
    if len == 0 || cfg.warp_size == 0 {
        return;
    }

    let steps = len.div_ceil(cfg.warp_size);

    for step in 0..(steps as u64) {
        for lane in 0..cfg.warp_size {
            let idx_raw = fractal_index(step, lane as u64, cfg.depth_bits);
            let idx = (idx_raw % (len as u64)) as usize;

            // This is the scalar hot-path where real SIMD can be dropped in
            // later. For now, we just do scalar add.
            a[idx] += b[idx];
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn fractal_index_is_deterministic() {
        let cfg = FractalSimtConfig::default();
        let i1 = fractal_index(0, 0, cfg.depth_bits);
        let i2 = fractal_index(0, 0, cfg.depth_bits);
        assert_eq!(i1, i2);

        let i3 = fractal_index(1, 0, cfg.depth_bits);
        let i4 = fractal_index(0, 1, cfg.depth_bits);
        assert_ne!(i1, i3);
        assert_ne!(i1, i4);
    }

    #[test]
    fn fractal_simt_for_each_visits_elements() {
        let mut data = vec![0u32; 64];
        let cfg = FractalSimtConfig {
            warp_size: 8,
            depth_bits: 6,
        };

        fractal_simt_for_each(&mut data, &cfg, |_lane, v| {
            *v += 1;
        });

        // We don't guarantee exact counts per element, but we can at least
        // assert nothing stayed at zero (with these parameters, everything
        // should be hit at least once).
        assert!(data.iter().all(|&v| v > 0));
    }

    #[test]
    fn fractal_add_matches_linear_add() {
        let mut a = (0..128).map(|i| i as f32).collect::<Vec<_>>();
        let mut a_linear = a.clone();
        let b = (0..128).map(|i| (i as f32) * 0.5).collect::<Vec<_>>();

        let cfg = FractalSimtConfig::default();

        // Linear baseline
        for i in 0..a_linear.len() {
            a_linear[i] += b[i];
        }

        // Fractal SIMT
        fractal_simt_add_f32_in_place(&mut a, &b, &cfg);

        // Same final values.
        for i in 0..a.len() {
            assert!(
                (a[i] - a_linear[i]).abs() < 1e-5,
                "mismatch at {}: fractal={} linear={}",
                i,
                a[i],
                a_linear[i]
            );
        }
    }
}

File: lib.rs
============
/* e8/gf8/src/lib.rs */
//! Foundational geometric gf8s for the e8 ecosystem, including the `Gf8` numeric type.
//!
//! # e8 Primitives Crate
//!▫~•◦-------------------‣
//!
//! This crate provides the core, low-level building blocks for the e8 architecture.
//! It is designed to be a zero-dependency, high-performance library that can be used
//! to construct higher-level systems for AI, numerics, and data representation.
//!
//! ### Key Capabilities
//! - **`Gf8` (GeoFloat8):** A novel 8-dimensional geometric float that replaces traditional scalars.
//! - **`Gf8BitSig `:** A compact, 1-byte binary representation for `Gf8` directions, enabling massive data compression.
//! - **SIMD Acceleration:** Provides SIMD-accelerated functions for `Gf8` arithmetic on compatible x86 CPUs.
//! - **Intrinsic Registry:** Includes a queryable database of x86 intrinsics for building advanced accelerator backends.
//! - **Math Utilities:** High-level geometric, interpolation, and lattice helpers built on top of `Gf8`.
//!
//! ### Architectural Notes
//! The gf8s in this crate are designed to be composable. `Gf8` is the central numeric type,
//! `Gf8BitSig ` provides its binary interface, and the `gf8_simd` and `gf8_intrinsics` modules
//! offer paths for hardware acceleration and advanced code generation.
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, Gf8BitSig , gf8_from_code, gf8_to_code, gf8_dot_simd};
//!
//! // Create a Gf8 from a byte code
//! let code_a = Gf8BitSig (0b10110010);
//! let a = gf8_from_code(code_a);
//!
//! // Create another Gf8 from a scalar
//! let b = Gf8::from_scalar(-1.0);
//!
//! // Compute their similarity using a SIMD-accelerated dot product
//! let similarity = gf8_dot_simd(&a, &b);
//!
//! println!("Similarity: {}", similarity);
//!
//! // Quantize 'b' back into a byte code
//! let code_b = gf8_to_code(&b);
//! println!("Code for 'b': {:08b}", code_b.0);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

// Declare the modules that make up this crate. The compiler will look for
// `gf8.rs`, `bitcodec/`, etc., in the `src` directory.
pub mod aligned;
pub mod bitcodec;
pub mod compute;
pub mod e32l; // E32L: True lossless f32 compression
pub mod e8f;
pub mod e8x;
pub mod fast_math;
pub mod fractal_simt;
pub mod generative;
pub mod gf8;
pub mod intrinsic_backend;
pub mod intrinsics;
pub mod math;
pub mod progen_reactor;
pub mod quantize;
pub mod resonance_router;
pub mod simd;
pub mod topology;

// Re-export the primary types and functions to create a clean, flat public API.
// Consumers of this crate can `use e8_gf8::Gf8;` instead of the more verbose
// `use e8_gf8::gf8::Gf8;`.
pub use aligned::{E8FAligned, E8FChain};
pub use bitcodec::{
    Gf8BitSig, Gf8LosslessCode, bits_from_u8_le, bits_to_u8_le, gf8_from_best_code, gf8_from_code,
    gf8_from_lossless_code, gf8_to_best_code, gf8_to_code, gf8_to_lossless_code,
    gf8_to_lossless_code_closest,
};
pub use compute::{
    E8FCompute, E8VecCompute, MAX_ROUNDTRIP_ERROR, MAX_SINGLE_QUANTIZATION_ERROR,
    RECOMMENDED_MAX_CHAIN_LENGTH, chordal_distance, compute_transition_scores_hybrid,
    compute_transition_scores_sparse, dot_f32, weighted_sum_hybrid,
};
pub use e8f::{
    E8ArithmeticTables, E8F, E8Mat, E8TensorCore, E8Vec, get_e8_arithmetic, init_e8_arithmetic,
};
pub use e8x::E8X;
pub use e32l::E32L;
#[cfg(feature = "compression")]
pub use e32l::compression::{
    CompressionError, CompressionLevel, compress, compress_with_level, decompress,
};
pub use fast_math::FAST_ACOS;
pub use fractal_simt::{FractalSimtConfig, fractal_simt_add_f32_in_place};
pub use generative::{
    GenerativeSynthesizer, ProgramInstr, STATE_TRANSITIONS, StateTransition, transition_for,
};
pub use gf8::{Gf8, Gf8Tensor};
pub use intrinsic_backend::{
    BackendConfig, IntrinsicBackend, get_backend_info, intrinsic_add, intrinsic_dot, intrinsic_sub,
    list_available_intrinsics,
};
pub use intrinsics::{
    GF8_INTRINSICS, Gf8Intrinsic, find_intrinsic_by_name, intrinsics_by_technology,
    intrinsics_for_f32_width, intrinsics_for_f64_width,
};
pub use math::{
    Gf8Rotation, gf8_angle, gf8_chordal_distance, gf8_chordal_distance2, gf8_cosine_similarity,
    gf8_geodesic_distance, gf8_lerp, gf8_lerp_slice, gf8_slerp, quantize_slice_to_e8_shell,
    quantize_to_e8_shell,
};
pub use progen_reactor::{ProgenBranch, ProgenContext, ProgenCritic, ProgenReactor};
pub use quantize::{
    dequantize_to_vec, get_e8_codebook, get_root_neighbors, quantize_to_gf8,
    quantize_to_nearest_code,
};
pub use resonance_router::{
    HeadActivation, ResonanceConfig, ResonanceResult, accumulate_resonance, heads_from_raw_pairs,
    top_k_resonant_roots,
};
pub use simd::{
    get_available_f32_256_intrinsics, gf8_add_inplace_slice_simd, gf8_add_simd, gf8_dot_simd,
    gf8_norm2_simd, gf8_sub_simd, print_simd_capabilities,
};
pub use topology::{E8Topology, get_e8_topology};

pub type E8Address = [Gf8LosslessCode; 8];

#[cfg(test)]
mod tests {
    // Import all public items from the crate root for testing.
    use super::*;

    #[test]
    fn gf8_constructors_are_unit_norm() {
        // from_bits_even_parity should produce a unit vector.
        let from_bits = Gf8::from_bits_even_parity([1, 0, 1, 1, 0, 0, 1, 0]);
        assert!((from_bits.norm2() - 1.0).abs() < 1e-6);

        // from_scalar should produce a unit vector.
        let from_scalar = Gf8::from_scalar(-123.45);
        assert!((from_scalar.norm2() - 1.0).abs() < 1e-6);
        // Use approximate comparison for floating point
        assert!((from_scalar.to_scalar() - (-1.0)).abs() < 1e-6);

        // from raw coords (new) should produce a unit vector.
        let from_coords = Gf8::new([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]);
        assert!((from_coords.norm2() - 1.0).abs() < 1e-6);
    }

    #[test]
    fn bitcodec_roundtrip_is_correct() {
        for i in 0..=255 {
            // Encode: byte -> bits -> Gf8 -> code
            let bits = bits_from_u8_le(i);
            let gf = Gf8::from_bits_even_parity(bits);
            let code = gf8_to_code(&gf);

            // Decode: code -> Gf8 -> bits -> byte
            let gf2 = gf8_from_code(code);
            let bits2 = bits_from_u8_le(code.0); // Directly from the generated code
            let _final_byte = bits_to_u8_le(bits2);

            // The dot product of the original and round-tripped Gf8 should be ~1.0
            assert!((gf.dot(gf2.coords()) - 1.0).abs() < 1e-6);

            // The generated code should decode to the same Gf8 direction
            // Note: Due to even parity constraint, the raw byte might differ but the Gf8 should be the same
            assert_eq!(gf, gf2);
        }
    }

    #[test]
    fn simd_and_scalar_operations_match() {
        let a = Gf8::new([1.0, -2.0, 3.0, -4.0, 5.0, -6.0, 7.0, -8.0]);
        let b = Gf8::new([-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8]);

        // Dot Product
        let dot_scalar = a.dot(b.coords());
        let dot_simd = gf8_dot_simd(&a, &b);
        assert!((dot_scalar - dot_simd).abs() < 1e-6);

        // Norm Squared
        let norm2_scalar = a.norm2();
        let norm2_simd = gf8_norm2_simd(&a);
        assert!((norm2_scalar - norm2_simd).abs() < 1e-6);

        // Addition
        let add_scalar = a + b;
        let add_simd = gf8_add_simd(&a, &b);
        assert!((add_scalar.dot(add_simd.coords()) - 1.0).abs() < 1e-6);

        // Subtraction
        let sub_scalar = a - b;
        let sub_simd = gf8_sub_simd(&a, &b);
        assert!((sub_scalar.dot(sub_simd.coords()) - 1.0).abs() < 1e-6);
    }

    #[test]
    fn intrinsics_registry_can_be_queried() {
        // Test finding a well-known intrinsic
        let add_ps = find_intrinsic_by_name("_mm256_add_ps");
        assert!(add_ps.is_some());
        assert_eq!(add_ps.unwrap().technology, "AVX");

        // Test filtering by technology
        let avx2_count = intrinsics_by_technology("AVX2").count();
        assert!(avx2_count > 0, "Should find AVX2 intrinsics");

        // Test filtering by width and type
        let f32_256_intrinsics = intrinsics_for_f32_width(256).collect::<Vec<_>>();
        assert!(!f32_256_intrinsics.is_empty());
        assert!(f32_256_intrinsics.iter().any(|i| i.name == "_mm256_mul_ps"));
    }

    #[test]
    fn simd_integration_with_intrinsics() {
        // Test the new integration functions
        let available_intrinsics = get_available_f32_256_intrinsics();

        // Should return available intrinsics or empty vector on non-x86
        println!(
            "Available 256-bit f32 intrinsics: {:?}",
            available_intrinsics
        );

        // Test that we can detect available features
        #[cfg(target_arch = "x86_64")]
        {
            // This would print useful debugging information
            // print_simd_capabilities();

            // Verify that at least some intrinsics are available if we have x86_64
            let has_avx_or_avx2 = available_intrinsics.iter().any(|name| name.contains("avx"));

            // On x86_64, we should have at least some available intrinsics
            // (though availability depends on CPU features)
            println!("Has AVX intrinsics available: {}", has_avx_or_avx2);
        }
    }
}

File: gf8.rs
============
/* e8/gf8/src/gf8.rs */
//! A foundational 8-dimensional geometric float gf8, inspired by E₈ lattice properties.
//!
//! # e8 Primitives – Gf8 Module
//!▫~•◦-----------------------------‣
//!
//! This module provides the `Gf8` type, a core numeric gf8 for the e8 ecosystem.
//! It is designed to replace standard floating-point numbers in contexts where geometric
//! stability, intrinsic normalization, and binary-addressable states are paramount.
//!
//! ### Key Capabilities
//! - **Geometric Representation:** `Gf8` represents a value as a normalized 8D vector on the unit sphere (S⁷).
//! - **Binary Encoding:** Provides a constructor from 8 bits that maps to a unique, stable direction in 8D space, enforcing an E₈-like even parity constraint.
//! - **Geometric Arithmetic:** All arithmetic operations (add, sub) are geometric, preserving the unit-norm constraint by re-projecting results onto the sphere.
//! - **Tensor-like API:** Implements `Deref` and a `Gf8Tensor` trait, allowing it to be used seamlessly as a small, fixed-size tensor.
//!
//! ### Architectural Notes
//! `Gf8` is the cornerstone of the e8 compute and data model. Its fixed dimensionality is a perfect
//! match for 256-bit SIMD registers (e.g., AVX), enabling highly efficient hardware acceleration.
//! It serves as the basis for E8B codes, E8DB keys, and the E8 LLM's numerical representation.
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, Gf8Tensor};
//!
//! // Create a Gf8 from a binary pattern (0b10101010)
//! let bits = [0, 1, 0, 1, 0, 1, 0, 1];
//! let a = Gf8::from_bits_even_parity(bits);
//!
//! // Create another Gf8 from a different pattern
//! let b = Gf8::from_scalar(-0.5);
//!
//! // Compute the dot product (cosine similarity)
//! let similarity = a.dot(b.coords());
//!
//! // `Gf8` can be treated like a slice
//! println!("Gf8 'a' has {} dimensions.", a.as_slice().len());
//! println!("Similarity between a and b: {}", similarity);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::simd;
use std::ops::{Add, AddAssign, Deref, DerefMut, Mul, MulAssign, Neg, Sub, SubAssign};

/// A tiny tensor-like trait for GF8.
///
/// This provides an explicit contract for types that can be viewed as a slice of floats,
/// intended for use in generic, tensor-aware code.
pub trait Gf8Tensor {
    /// Returns the underlying data as an immutable slice.
    fn as_slice(&self) -> &[f32];
    /// Returns the underlying data as a mutable slice.
    fn as_mut_slice(&mut self) -> &mut [f32];
}

/// A GF8 (GeoFloat8), an 8-dimensional geometric float gf8.
///
/// It is internally represented by an array of 8 `f32`s, which is always
/// normalized to have a unit L2 norm (i.e., it lies on the surface of an
/// 8D hypersphere). This property provides intrinsic stability and makes it suitable
/// for representing directions, rotations, and normalized semantic states.
///
/// The only exception to the unit-norm rule is the zero vector, which has a norm of 0.
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct Gf8 {
    coords: [f32; 8],
}

impl Gf8 {
    /// The zero vector, representing a neutral or null state.
    pub const ZERO: Self = Self { coords: [0.0; 8] };

    /// Constructs a `Gf8` from raw 8D coordinates, normalizing them to unit length.
    ///
    /// If the input vector has a magnitude of zero, the zero `Gf8` is returned.
    #[inline]
    pub fn new(coords: [f32; 8]) -> Self {
        let mut v = Self { coords };
        v.renormalize();
        v
    }

    /// Constructs a `Gf8` from raw 8D coordinates.
    ///
    /// This is an alias for [`Gf8::new`], provided for clarity when working in
    /// math-heavy code where "from_coords" more clearly expresses intent than "new".
    #[inline]
    pub fn from_coords(coords: [f32; 8]) -> Self {
        Self::new(coords)
    }

    /// Constructs a `Gf8` from 8 bits, mapping them to an E₈-like ±1 pattern.
    ///
    /// The mapping is `0 -> +1.0` and `1 -> -1.0`. To satisfy an E₈-like constraint,
    /// the number of `-1.0` entries is forced to be even by flipping the sign of
    /// the last coordinate if necessary. The resulting vector is then normalized
    /// to unit length.
    pub fn from_bits_even_parity(bits: [u8; 8]) -> Self {
        let mut coords = [0.0f32; 8];
        let mut neg_count = 0usize;

        for (i, &b) in bits.iter().enumerate() {
            if b == 0 {
                coords[i] = 1.0;
            } else {
                coords[i] = -1.0;
                neg_count += 1;
            }
        }

        if neg_count % 2 == 1 {
            // Flip the sign of the last coordinate to enforce even parity.
            coords[7] = -coords[7];
        }

        // Normalize the resulting vector to place it on the unit sphere.
        // A pure ±1 vector has a norm of sqrt(8).
        Self::new(coords)
    }

    /// Constructs a `Gf8` by embedding a scalar along the first axis.
    ///
    /// The resulting `Gf8` will be `[signum(x), 0.0, ..., 0.0]`. This provides a simple
    /// way to represent scalar magnitudes directionally.
    pub fn from_scalar(x: f32) -> Self {
        let mut coords = [0.0; 8];
        coords[0] = x;
        Self::new(coords)
    }

    /// Retrieves the raw coordinate data as a slice.
    #[inline]
    pub fn coords(&self) -> &[f32; 8] {
        &self.coords
    }

    /// Approximates a scalar value by projecting the `Gf8` onto the first axis.
    ///
    /// Since `Gf8` is a unit vector, this value will be in the range `[-1.0, 1.0]`.
    #[inline]
    pub fn to_scalar(&self) -> f32 {
        self.coords[0]
    }

    /// Computes the dot product with another 8D vector.
    ///
    /// For two unit vectors, this is equivalent to their cosine similarity.
    /// This method is backed by a runtime-dispatching SIMD implementation
    /// for maximum performance.
    #[inline(always)]
    pub fn dot(&self, other: &[f32; 8]) -> f32 {
        simd::dot_product(self.coords, *other)
    }

    /// Computes the squared L2 norm. For a valid `Gf8`, this is always `1.0` (or `0.0` for zero).
    #[inline]
    pub fn norm2(&self) -> f32 {
        self.coords.iter().map(|&x| x * x).sum()
    }

    /// Computes the L2 norm. For a valid `Gf8`, this is always `1.0` (or `0.0` for zero).
    #[inline]
    pub fn norm(&self) -> f32 {
        self.norm2().sqrt()
    }

    /// Re-normalizes the `Gf8` in-place to ensure it remains a unit vector.
    /// This is useful after performing arithmetic operations that may alter the magnitude.
    pub fn renormalize(&mut self) {
        let n2 = self.norm2();
        if n2 > 0.0 {
            let inv_norm = 1.0 / n2.sqrt();
            for x in &mut self.coords {
                *x *= inv_norm;
            }
        }
    }
}

impl Gf8Tensor for Gf8 {
    #[inline]
    fn as_slice(&self) -> &[f32] {
        &self.coords
    }
    #[inline]
    fn as_mut_slice(&mut self) -> &mut [f32] {
        &mut self.coords
    }
}

impl Default for Gf8 {
    /// The default `Gf8` is the zero vector.
    fn default() -> Self {
        Self::ZERO
    }
}

impl Deref for Gf8 {
    type Target = [f32; 8];
    #[inline]
    fn deref(&self) -> &Self::Target {
        &self.coords
    }
}

impl DerefMut for Gf8 {
    #[inline]
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.coords
    }
}

/// Geometric addition: performs element-wise vector addition and then
/// re-normalizes the result, projecting it back onto the unit sphere.
impl Add for Gf8 {
    type Output = Self;
    fn add(self, rhs: Self) -> Self::Output {
        let mut coords = [0.0f32; 8];
        for (i, (&a, &b)) in self.coords.iter().zip(rhs.coords.iter()).enumerate() {
            coords[i] = a + b;
        }
        Self::new(coords)
    }
}

impl AddAssign for Gf8 {
    fn add_assign(&mut self, rhs: Self) {
        for (i, &v) in rhs.coords.iter().enumerate() {
            self.coords[i] += v;
        }
        self.renormalize();
    }
}

/// Geometric subtraction: performs element-wise vector subtraction and then
/// re-normalizes the result, projecting it back onto the unit sphere.
impl Sub for Gf8 {
    type Output = Self;
    fn sub(self, rhs: Self) -> Self::Output {
        let mut coords = [0.0f32; 8];
        for (i, (&a, &b)) in self.coords.iter().zip(rhs.coords.iter()).enumerate() {
            coords[i] = a - b;
        }
        Self::new(coords)
    }
}

impl SubAssign for Gf8 {
    fn sub_assign(&mut self, rhs: Self) {
        for (i, &v) in rhs.coords.iter().enumerate() {
            self.coords[i] -= v;
        }
        self.renormalize();
    }
}

/// Scalar multiplication. The result is re-normalized, so this operation primarily
/// affects the vector's direction (flipping it if the scalar is negative).
impl Mul<f32> for Gf8 {
    type Output = Self;
    fn mul(self, rhs: f32) -> Self::Output {
        let mut coords = self.coords;
        for x in &mut coords {
            *x *= rhs;
        }
        Self::new(coords)
    }
}

impl MulAssign<f32> for Gf8 {
    fn mul_assign(&mut self, rhs: f32) {
        for x in &mut self.coords {
            *x *= rhs;
        }
        self.renormalize();
    }
}

/// Negation: flips the direction of the vector. The norm remains unchanged.
impl Neg for Gf8 {
    type Output = Self;
    fn neg(self) -> Self::Output {
        let mut coords = self.coords;
        for x in &mut coords {
            *x = -*x;
        }
        Self { coords }
    }
}

File: progen_reactor.rs
=======================
// src/progen_reactor.rs
//! Procedural generation reactor seeded by sensory/concept/plan inputs and evaluated via
//! UECC-guided critics and fractal traces (see docs/progen.md for more context).
/*!
//! This module introduces:
//! - `ProgenContext`/`ProgenReactor` for turning semantic seeds into generative programs.
//! - `FractalSimtTrace`-aware execution so critics can rewind or propose counterfactuals.
//! - Default critics that reward semantic tension and guard against stale transitions.
!*/
use crate::bitcodec::lossless::gf8_from_lossless_code;
use crate::bitcodec::lossless::gf8_to_lossless_code_closest;
use crate::{
    Gf8, Gf8LosslessCode,
    e8f::E8F,
    fractal_simt::FractalSimtConfig,
    fractal_simt::FractalSimtTrace,
    generative::{GenerativeSynthesizer, ProgramInstr, STATE_TRANSITIONS},
};

/// Semantic context for a procedural branch.
#[derive(Clone, Debug)]
pub struct ProgenContext {
    /// Centroid vector derived from the current cognitive cursor.
    pub centroid: Gf8,
    /// Sensory/perceptual roots (flattened from injector outputs).
    pub sensory_roots: Vec<u8>,
    /// Plan/goal targeting hints (mostly root indices supplied by goals).
    pub plan_targets: Vec<u8>,
    /// Unique timeline identifier (for debugging / tracing).
    pub timeline_id: u64,
}

/// Counterfactual proposal from a critic.
#[derive(Clone, Debug)]
pub struct ProgenCounterfactual {
    pub program_index: usize,
    pub instr: ProgramInstr,
    pub description: &'static str,
}

/// Internal representation of a generative seed.
#[derive(Clone, Debug)]
struct ProgenSeed {
    centroid: Gf8,
    program: Vec<ProgramInstr>,
    context_id: u64,
    goal_targets: Vec<u8>,
}

impl ProgenSeed {
    fn mutate(&self, cf: &ProgenCounterfactual) -> Self {
        let mut program = self.program.clone();
        if cf.program_index < program.len() {
            program[cf.program_index] = cf.instr;
        }
        Self {
            centroid: self.centroid,
            program,
            context_id: self.context_id,
            goal_targets: self.goal_targets.clone(),
        }
    }
}

/// Candidate branch produced by the reactor.
#[derive(Clone, Debug)]
pub struct ProgenBranch {
    pub path: Vec<E8F>,
    pub trace: FractalSimtTrace,
    pub score: f32,
    seed: ProgenSeed,
}

pub trait ProgenCritic: Send + Sync {
    fn name(&self) -> &'static str;
    fn evaluate(&self, trace: &FractalSimtTrace, path: &[E8F]) -> f32;
    fn propose_counterfactual(
        &self,
        trace: &FractalSimtTrace,
        path: &[E8F],
    ) -> Option<ProgenCounterfactual>;
}

impl ProgenCritic for () {
    fn name(&self) -> &'static str {
        "noop"
    }

    fn evaluate(&self, _trace: &FractalSimtTrace, _path: &[E8F]) -> f32 {
        0.0
    }

    fn propose_counterfactual(
        &self,
        _trace: &FractalSimtTrace,
        _path: &[E8F],
    ) -> Option<ProgenCounterfactual> {
        None
    }
}

/// Default critic that rewards semantic tension and nudges stuck branches.
pub struct SemanticTensionCritic;

impl ProgenCritic for SemanticTensionCritic {
    fn name(&self) -> &'static str {
        "semantic-tension"
    }

    fn evaluate(&self, trace: &FractalSimtTrace, _path: &[E8F]) -> f32 {
        trace
            .entries()
            .iter()
            .enumerate()
            .map(|(i, entry)| {
                entry
                    .root
                    .filter(|root| (*root as usize) < STATE_TRANSITIONS.len())
                    .map(|root| {
                        let transition = &STATE_TRANSITIONS[root as usize];
                        0.01 + (transition.value_a.len() + transition.value_b.len()) as f32 * 0.0003
                            + (i as f32 * 0.0001)
                    })
                    .unwrap_or(0.0)
            })
            .sum()
    }

    fn propose_counterfactual(
        &self,
        trace: &FractalSimtTrace,
        _path: &[E8F],
    ) -> Option<ProgenCounterfactual> {
        if trace.entries().len() < 2 {
            return None;
        }

        let last = trace.entries().last()?;
        let prev = trace.entries().get(trace.entries().len() - 2)?;

        if last.root == prev.root {
            let next_instr =
                ((last.root.unwrap_or(0) as usize + 1) % STATE_TRANSITIONS.len()) as ProgramInstr;
            Some(ProgenCounterfactual {
                program_index: last.index,
                instr: next_instr,
                description: "semantic pivot",
            })
        } else {
            None
        }
    }
}

/// Procedural reactor that spins up sectors of the generative synthesizer + critics.
pub struct ProgenReactor {
    cfg: FractalSimtConfig,
    delta_bank: Vec<Gf8>,
    critics: Vec<Box<dyn ProgenCritic>>,
    program_length: usize,
    max_counterfactuals: usize,
}

impl Default for ProgenReactor {
    fn default() -> Self {
        let delta_bank = STATE_TRANSITIONS
            .iter()
            .map(|entry| gf8_from_lossless_code(Gf8LosslessCode(entry.index)))
            .collect::<Vec<_>>();

        Self {
            cfg: FractalSimtConfig::default(),
            delta_bank,
            critics: vec![Box::new(SemanticTensionCritic)],
            program_length: 32,
            max_counterfactuals: 2,
        }
    }
}

impl ProgenReactor {
    pub fn new(cfg: FractalSimtConfig, program_length: usize, max_counterfactuals: usize) -> Self {
        let delta_bank = STATE_TRANSITIONS
            .iter()
            .map(|entry| gf8_from_lossless_code(Gf8LosslessCode(entry.index)))
            .collect::<Vec<_>>();

        Self {
            cfg,
            delta_bank,
            critics: vec![Box::new(SemanticTensionCritic)],
            program_length: program_length.max(1),
            max_counterfactuals,
        }
    }

    pub fn add_critic(&mut self, critic: Box<dyn ProgenCritic>) {
        self.critics.push(critic);
    }

    pub fn run(&self, contexts: &[ProgenContext]) -> Vec<ProgenBranch> {
        contexts
            .iter()
            .flat_map(|context| self.spawn_from_context(context))
            .collect()
    }

    pub fn best_branch(&self, contexts: &[ProgenContext]) -> Option<ProgenBranch> {
        self.run(contexts).into_iter().max_by(|a, b| {
            a.score
                .partial_cmp(&b.score)
                .unwrap_or(std::cmp::Ordering::Equal)
        })
    }

    fn spawn_from_context(&self, context: &ProgenContext) -> Vec<ProgenBranch> {
        let mut branches = Vec::new();
        let mut seed = self.build_seed(context);
        if let Some(branch) = self.run_branch(&seed) {
            branches.push(branch.clone());
            for _ in 0..self.max_counterfactuals {
                if let Some(cf) = self.critics.iter().find_map(|critic| {
                    critic.propose_counterfactual(
                        &branches.last().unwrap().trace,
                        &branches.last().unwrap().path,
                    )
                }) {
                    seed = seed.mutate(&cf);
                    if let Some(next) = self.run_branch(&seed) {
                        branches.push(next);
                        continue;
                    }
                }
                break;
            }
        }
        branches
    }

    fn run_branch(&self, seed: &ProgenSeed) -> Option<ProgenBranch> {
        if seed.program.is_empty() {
            return None;
        }

        let synth = GenerativeSynthesizer::new(
            seed.centroid,
            self.delta_bank.clone(),
            seed.program.clone(),
        );
        let mut dst = vec![Gf8::default(); seed.program.len()];
        let trace = synth.fill_reconstructed_with_trace(&mut dst, &self.cfg);

        let path = dst
            .into_iter()
            .map(|gf| {
                let code = gf8_to_lossless_code_closest(&gf);
                E8F::from(code)
            })
            .collect::<Vec<_>>();

        let score = self.score_branch(&trace, &path, seed);
        Some(ProgenBranch {
            path,
            trace,
            score,
            seed: seed.clone(),
        })
    }

    fn score_branch(&self, trace: &FractalSimtTrace, path: &[E8F], seed: &ProgenSeed) -> f32 {
        let critic_score: f32 = self
            .critics
            .iter()
            .map(|critic| critic.evaluate(trace, path))
            .sum();
        let goal_bonus = if seed.goal_targets.is_empty() {
            0.0
        } else {
            let trace_roots: Vec<u8> = trace
                .entries()
                .iter()
                .filter_map(|entry| entry.root)
                .collect();
            if seed
                .goal_targets
                .iter()
                .any(|goal| trace_roots.contains(goal))
            {
                1.0
            } else {
                0.0
            }
        };
        critic_score + goal_bonus + (path.len() as f32 * 0.005)
    }

    fn build_seed(&self, context: &ProgenContext) -> ProgenSeed {
        let sensory_len = context.sensory_roots.len();
        let plan_len = context.plan_targets.len();
        let mut program = Vec::with_capacity(self.program_length);

        for i in 0..self.program_length {
            if self.cfg.warp_size != 0 && i % self.cfg.warp_size == 0 {
                program.push(0xFF);
                continue;
            }

            let instr = if plan_len > 0 {
                context.plan_targets[i % plan_len]
            } else if sensory_len > 0 {
                context.sensory_roots[i % sensory_len]
            } else {
                (i % STATE_TRANSITIONS.len()) as u8
            };
            program.push(instr % STATE_TRANSITIONS.len() as u8);
        }

        ProgenSeed {
            centroid: context.centroid,
            program,
            context_id: context.timeline_id,
            goal_targets: context.plan_targets.clone(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn reactor_returns_best_branch() {
        let context = ProgenContext {
            centroid: gf8_from_lossless_code(Gf8LosslessCode(0)),
            sensory_roots: vec![1, 2, 3],
            plan_targets: vec![4, 5],
            timeline_id: 42,
        };
        let reactor = ProgenReactor {
            program_length: 8,
            ..ProgenReactor::default()
        };
        let branches = reactor.run(&[context.clone()]);
        assert!(!branches.is_empty());
        assert!(branches.iter().any(|branch| branch.score >= 0.0));
        let best = reactor.best_branch(&[context]);
        assert!(best.is_some());
    }
}

File: generative.rs
===================
// src/generative.rs
//! A compact generative synthesizer for reconstructing clusters of `Gf8` vectors
//! using a centroid, a small LUT of delta vectors and a compact program string.
//!
//! This is a minimal demonstration of the "synthesizer" pattern you described.
//! It trades storage for runtime reconstruction using small SIMD-backed kernels.

use crate::bitcodec::lossless::gf8_to_lossless_code_closest;
use crate::fractal_simt::{
    FractalSimtConfig, FractalSimtTrace, fractal_simt_for_each_indexed, fractal_simt_trace,
};
use crate::{Gf8, gf8_add_simd};

/// Compact program instruction mapping
/// 255 (0xFF) means use centroid, otherwise use LUT entry by index
pub type ProgramInstr = u8;

/// Captures semantic neighbor metadata for the 56 key transitions.
#[derive(Clone, Debug)]
pub struct StateTransition {
    pub id: &'static str,
    pub index: u8,
    pub value_a: &'static str,
    pub value_b: &'static str,
    pub description: &'static str,
}

/// The 56 concept pair transitions described in `e8_cognitive_architecture_mapping.md`
/// and mirrored in `docs/UECC.pdf`.
pub const STATE_TRANSITIONS: [StateTransition; 56] = [
    StateTransition {
        id: "A",
        index: 0,
        value_a: "Self-Agency",
        value_b: "Communion",
        description: "From sovereign choice into shared belonging.",
    },
    StateTransition {
        id: "B",
        index: 1,
        value_a: "Structure",
        value_b: "Flux",
        description: "Holding order while letting flow in.",
    },
    StateTransition {
        id: "C",
        index: 2,
        value_a: "Foresight",
        value_b: "Memory",
        description: "Balancing looking ahead with remembering lessons.",
    },
    StateTransition {
        id: "D",
        index: 3,
        value_a: "Clarity",
        value_b: "Awe",
        description: "Precise focus meets reverent openness.",
    },
    StateTransition {
        id: "E",
        index: 4,
        value_a: "Virtue",
        value_b: "Temptation",
        description: "Maintaining higher ideals when the pull is strong.",
    },
    StateTransition {
        id: "F",
        index: 5,
        value_a: "Momentum",
        value_b: "Stillness",
        description: "Propelling forward yet honoring quiet rest.",
    },
    StateTransition {
        id: "G",
        index: 6,
        value_a: "Stewardship",
        value_b: "Openness",
        description: "Holding responsibility while inviting novel ideas.",
    },
    StateTransition {
        id: "H",
        index: 7,
        value_a: "Mastery",
        value_b: "Risk",
        description: "Confidence tempered by daring leaps.",
    },
    StateTransition {
        id: "I",
        index: 8,
        value_a: "Certainty",
        value_b: "Doubt",
        description: "Grounded belief that still honors questions.",
    },
    StateTransition {
        id: "J",
        index: 9,
        value_a: "Presence",
        value_b: "Absence",
        description: "Being fully here while acknowledging empty space.",
    },
    StateTransition {
        id: "K",
        index: 10,
        value_a: "Creation",
        value_b: "Destruction",
        description: "Birth and fade are two sides of transformation.",
    },
    StateTransition {
        id: "L",
        index: 11,
        value_a: "Unity",
        value_b: "Diversity",
        description: "Togetherness that still celebrates difference.",
    },
    StateTransition {
        id: "M",
        index: 12,
        value_a: "Potential",
        value_b: "Actualization",
        description: "From latent possibility into realized form.",
    },
    StateTransition {
        id: "N",
        index: 13,
        value_a: "Consciousness",
        value_b: "Unconsciousness",
        description: "Awareness that leans into dream logic.",
    },
    StateTransition {
        id: "O",
        index: 14,
        value_a: "Permanence",
        value_b: "Transience",
        description: "Anchoring in the eternal while riding the ephemeral.",
    },
    StateTransition {
        id: "P",
        index: 15,
        value_a: "Order",
        value_b: "Chaos",
        description: "Structure that is resilient to entropy.",
    },
    StateTransition {
        id: "Q",
        index: 16,
        value_a: "Beginning",
        value_b: "Ending",
        description: "The eternal cycle of birth and cessation.",
    },
    StateTransition {
        id: "R",
        index: 17,
        value_a: "Internal",
        value_b: "External",
        description: "The boundary between inner experience and outer reality.",
    },
    StateTransition {
        id: "S",
        index: 18,
        value_a: "Material",
        value_b: "Spiritual",
        description: "The balance of matter and meaning.",
    },
    StateTransition {
        id: "T",
        index: 19,
        value_a: "Effort",
        value_b: "Grace",
        description: "Striving through will versus receiving flow.",
    },
    StateTransition {
        id: "U",
        index: 20,
        value_a: "Simplicity",
        value_b: "Complexity",
        description: "Fundamental clarity alongside intricate systems.",
    },
    StateTransition {
        id: "V",
        index: 21,
        value_a: "Objective",
        value_b: "Subjective",
        description: "Universal truth meets personal perception.",
    },
    StateTransition {
        id: "W",
        index: 22,
        value_a: "Harmony",
        value_b: "Conflict",
        description: "Agreement versus struggle in relationships.",
    },
    StateTransition {
        id: "X",
        index: 23,
        value_a: "Freedom",
        value_b: "Constraint",
        description: "Boundless possibility tempered by limits.",
    },
    StateTransition {
        id: "Y",
        index: 24,
        value_a: "Past",
        value_b: "Future",
        description: "Memory and anticipation in dialogue.",
    },
    StateTransition {
        id: "Z",
        index: 25,
        value_a: "Physical",
        value_b: "Mental",
        description: "Body and mind as interwoven aspects.",
    },
    StateTransition {
        id: "AA",
        index: 26,
        value_a: "Logic",
        value_b: "Intuition",
        description: "Reason and instinct in tandem.",
    },
    StateTransition {
        id: "BB",
        index: 27,
        value_a: "Giving",
        value_b: "Receiving",
        description: "The flow of energy and resources.",
    },
    StateTransition {
        id: "CC",
        index: 28,
        value_a: "Public",
        value_b: "Private",
        description: "Shared life versus individual sanctuary.",
    },
    StateTransition {
        id: "DD",
        index: 29,
        value_a: "Wakefulness",
        value_b: "Sleep",
        description: "Conscious action meets restorative rest.",
    },
    StateTransition {
        id: "EE",
        index: 30,
        value_a: "Strength",
        value_b: "Vulnerability",
        description: "Resilience with openness to harm.",
    },
    StateTransition {
        id: "FF",
        index: 31,
        value_a: "Question",
        value_b: "Answer",
        description: "Seeking knowledge and finding resolution.",
    },
    StateTransition {
        id: "GG",
        index: 32,
        value_a: "Action",
        value_b: "Inaction",
        description: "Doing versus allowing.",
    },
    StateTransition {
        id: "HH",
        index: 33,
        value_a: "Hope",
        value_b: "Despair",
        description: "Expectation extremes about the future.",
    },
    StateTransition {
        id: "II",
        index: 34,
        value_a: "Presence",
        value_b: "Absence",
        description: "Being here versus not being here.",
    },
    StateTransition {
        id: "JJ",
        index: 35,
        value_a: "Success",
        value_b: "Failure",
        description: "Goal outcomes and their twin.",
    },
    StateTransition {
        id: "KK",
        index: 36,
        value_a: "Value",
        value_b: "Meaningless",
        description: "Perceived worth versus lack of significance.",
    },
    StateTransition {
        id: "LL",
        index: 37,
        value_a: "Attachment",
        value_b: "Detachment",
        description: "Emotional connection versus objective distance.",
    },
    StateTransition {
        id: "MM",
        index: 38,
        value_a: "Pleasure",
        value_b: "Pain",
        description: "Spectrum of sensation and feeling.",
    },
    StateTransition {
        id: "NN",
        index: 39,
        value_a: "Known",
        value_b: "Unknown",
        description: "Existing knowledge versus mystery.",
    },
    StateTransition {
        id: "OO",
        index: 40,
        value_a: "Giving Up",
        value_b: "Persistence",
        description: "Knowing when to quit and when to persevere.",
    },
    StateTransition {
        id: "PP",
        index: 41,
        value_a: "Growth",
        value_b: "Stagnation",
        description: "Positive change versus stillness.",
    },
    StateTransition {
        id: "QQ",
        index: 42,
        value_a: "Truth",
        value_b: "Illusion",
        description: "Reality versus deception.",
    },
    StateTransition {
        id: "RR",
        index: 43,
        value_a: "Sound",
        value_b: "Silence",
        description: "Contrast in auditory experience.",
    },
    StateTransition {
        id: "SS",
        index: 44,
        value_a: "Life",
        value_b: "Death",
        description: "Boundaries of biological existence.",
    },
    StateTransition {
        id: "TT",
        index: 45,
        value_a: "Joy",
        value_b: "Sorrow",
        description: "Emotional well-being extremes.",
    },
    StateTransition {
        id: "UU",
        index: 46,
        value_a: "Belief",
        value_b: "Evidence",
        description: "Faith versus empirical proof.",
    },
    StateTransition {
        id: "VV",
        index: 47,
        value_a: "Memory",
        value_b: "Forgetting",
        description: "Retaining the past or letting go.",
    },
    StateTransition {
        id: "WW",
        index: 48,
        value_a: "Reality",
        value_b: "Imagination",
        description: "Actual experience versus conceived worlds.",
    },
    StateTransition {
        id: "XX",
        index: 49,
        value_a: "Public",
        value_b: "Private",
        description: "Shared visibility versus personal space.",
    },
    StateTransition {
        id: "YY",
        index: 50,
        value_a: "Work",
        value_b: "Play",
        description: "Purposeful labor versus joyful activity.",
    },
    StateTransition {
        id: "ZZ",
        index: 51,
        value_a: "Friend",
        value_b: "Enemy",
        description: "Alliance versus opposition.",
    },
    StateTransition {
        id: "AAA",
        index: 52,
        value_a: "Desire",
        value_b: "Aversion",
        description: "Attraction and repulsion.",
    },
    StateTransition {
        id: "BBB",
        index: 53,
        value_a: "Change",
        value_b: "Tradition",
        description: "Innovation versus established practice.",
    },
    StateTransition {
        id: "CCC",
        index: 54,
        value_a: "Youth",
        value_b: "Age",
        description: "Progression through life stages.",
    },
    StateTransition {
        id: "DDD",
        index: 55,
        value_a: "Curiosity",
        value_b: "Complacency",
        description: "Exploring the unknown versus resting in the familiar.",
    },
];

pub fn transition_for(root_index: u8) -> &'static StateTransition {
    &STATE_TRANSITIONS[(root_index as usize) % STATE_TRANSITIONS.len()]
}

/// A tiny generative synthesizer.
///
/// - `centroid`: base Gf8
/// - `deltas`: small LUT of delta vectors (should be small, e.g., 16)
/// - `program`: for each output index, an instruction referencing centroid or a delta
#[derive(Clone)]
pub struct GenerativeSynthesizer {
    pub centroid: Gf8,
    pub deltas: Vec<Gf8>,
    pub program: Vec<ProgramInstr>,
}

impl GenerativeSynthesizer {
    pub fn new(centroid: Gf8, deltas: Vec<Gf8>, program: Vec<ProgramInstr>) -> Self {
        Self {
            centroid,
            deltas,
            program,
        }
    }

    /// Try to construct a new `GenerativeSynthesizer`, validating the program
    /// references all indices into the `deltas` LUT. Returns an `Err` message
    /// on invalid input rather than panicking, allowing callers to handle errors
    /// gracefully.
    pub fn try_new(
        centroid: Gf8,
        deltas: Vec<Gf8>,
        program: Vec<ProgramInstr>,
    ) -> Result<Self, String> {
        // Validate: instruction must be 0xFF (centroid) or a valid index into deltas
        for &instr in program.iter() {
            if instr != 0xFF && (instr as usize) >= deltas.len() {
                return Err(format!(
                    "GenerativeSynthesizer::try_new: program contains out-of-range LUT index {} (deltas.len={})",
                    instr,
                    deltas.len()
                ));
            }
        }
        Ok(Self {
            centroid,
            deltas,
            program,
        })
    }

    /// Reconstruct a single vector by program index.
    pub fn reconstruct(&self, idx: usize) -> Gf8 {
        let instr = self.program[idx];
        if instr == 0xFF {
            self.centroid
        } else {
            // Safe because the program should be generated to only contain valid LUT indexes
            let delta = &self.deltas[instr as usize];
            gf8_add_simd(&self.centroid, delta)
        }
    }

    /// Fill dst with reconstructed vectors for the provided `program` indices.
    /// Uses `fractal_simt_for_each` to demonstrate a scheduler visiting ordering
    /// and reconstructing the values in a cache-friendly order.
    pub fn fill_reconstructed(&self, dst: &mut [Gf8], cfg: &FractalSimtConfig) {
        assert_eq!(
            dst.len(),
            self.program.len(),
            "dst and program length must match"
        );

        // We can't guarantee that a particular `FractalSimtConfig` will visit every
        // element exactly once (and some small sizes / configs can miss indices), so we
        // track visited indices and then fill any unvisited entries in a final linear
        // pass. This preserves the cache-friendly traversal while ensuring correctness.
        let mut visited = vec![false; dst.len()];
        fractal_simt_for_each_indexed(dst, cfg, |_lane, idx, elem| {
            let v = self.reconstruct(idx);
            *elem = v;
            visited[idx] = true;
        });

        // Ensure every index has been reconstructed; fill any missed entries linearly.
        for i in 0..dst.len() {
            if !visited[i] {
                dst[i] = self.reconstruct(i);
            }
        }
    }

    /// Reconstruct directly into a provided `Gf8` mut reference for the given index.
    pub fn reconstruct_into(&self, idx: usize, out: &mut Gf8) {
        *out = self.reconstruct(idx);
    }

    /// Reconstruct into `dst`, returning a trace of the sequence.
    pub fn fill_reconstructed_with_trace(
        &self,
        dst: &mut [Gf8],
        cfg: &FractalSimtConfig,
    ) -> FractalSimtTrace {
        assert_eq!(
            dst.len(),
            self.program.len(),
            "dst and program length must match"
        );
        let mut visited = vec![false; dst.len()];

        let trace = fractal_simt_trace(dst, cfg, |_, idx, elem, trace| {
            let value = self.reconstruct(idx);
            let code = gf8_to_lossless_code_closest(&value);
            if let Some(entry) = trace.entries_mut().last_mut() {
                entry.root = Some(code.0);
                entry.index = idx;
            }
            *elem = value;
            visited[idx] = true;
        });

        for i in 0..dst.len() {
            if !visited[i] {
                dst[i] = self.reconstruct(i);
            }
        }

        trace
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Gf8;

    #[test]
    fn reconstruct_single_matches_expected() {
        let centroid = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let delta = Gf8::new([0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let deltas = vec![delta];
        let program = vec![0xFFu8, 0u8];
        let synth = GenerativeSynthesizer::new(centroid, deltas, program);

        let r0 = synth.reconstruct(0);
        assert_eq!(r0, centroid);

        let r1 = synth.reconstruct(1);
        let expected = gf8_add_simd(&centroid, &delta);
        assert_eq!(r1, expected);
    }

    #[test]
    fn fill_reconstructed_matches_linear_reconstruct() {
        let centroid = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let delta = Gf8::new([0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let deltas = vec![delta];
        let program = vec![0xFFu8, 0u8, 0u8, 0xFFu8];
        let synth = GenerativeSynthesizer::new(centroid, deltas.clone(), program.clone());

        // Linear baseline reconstruction
        let mut baseline = Vec::with_capacity(program.len());
        for i in 0..program.len() {
            baseline.push(synth.reconstruct(i));
        }

        // Use fractal SIMD scheduler to fill into dst
        let cfg = FractalSimtConfig::default();
        let mut dst = vec![Gf8::default(); program.len()];
        synth.fill_reconstructed(&mut dst, &cfg);

        // Compare results
        assert_eq!(dst.len(), baseline.len());
        for i in 0..dst.len() {
            assert_eq!(dst[i], baseline[i], "mismatch at {}", i);
        }
    }

    #[test]
    fn try_new_rejects_invalid_program_index() {
        let centroid = Gf8::default();
        let deltas = Vec::new();
        // Program references LUT index 0 but deltas is empty - should error
        let program = vec![0u8];
        let res = GenerativeSynthesizer::try_new(centroid, deltas, program);
        assert!(
            res.is_err(),
            "Expected try_new to return Err for invalid program indices"
        );
    }

    // Note: `fractal_simt_for_each_indexed` is exercised by the fractal scheduler
    // unit tests located in `fractal_simt.rs`. We avoid repeating these here because
    // parameter-specific behavior is already covered (and some small configs don't
    // guarantee uniform index coverage, which is outside the scope of generative's
    // correctness requirements).

    // Note: We intentionally avoid strict coverage guarantees for the fractal walker
    // since some parameter combinations won't visit every index. The helper is still
    // useful for cache-friendly ordering, and `fill_reconstructed` compensates by
    // filling any missed indices in a final linear pass.
}

File: simd.rs
=============
/* e8/gf8/src/simd.rs */
//! SIMD-accelerated operations for `Gf8` using x86_64 AVX intrinsics.
//!
//! # e8 Primitives – Gf8 SIMD Module
//!▫~•◦---------------------------------‣
//!
//! This module provides hardware-accelerated versions of core `Gf8` arithmetic
//! operations. It leverages the perfect alignment between `Gf8`'s 8 `f32` components
//! and the 256-bit SIMD registers found in modern x86_64 CPUs.
//!
//! ### Key Capabilities
//! - **Runtime Feature Detection:** Safely checks for AVX support at runtime before executing `unsafe` intrinsic code.
//! - **Scalar Fallback:** Automatically falls back to standard scalar operations on non-x86 platforms or CPUs without AVX.
//! - **Accelerated Operations:** Provides SIMD versions for dot product, norm, addition, and subtraction.
//!
//! ### Architectural Notes
//! This module is a prime example of how `Gf8`'s fixed dimensionality enables direct
//! hardware mapping. The public functions are safe wrappers that abstract away the
//! `unsafe` nature of CPU intrinsics and the complexity of runtime dispatch.
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, gf8_add_simd, gf8_dot_simd};
//!
//! let a = Gf8::from_scalar(1.0);
//! let b = Gf8::from_scalar(-0.5);
//!
//! // These functions will use AVX if available, or scalar math otherwise.
//! let sum_vec = gf8_add_simd(&a, &b);
//! let dot_product = gf8_dot_simd(&a, &b);
//!
//! println!("SIMD-accelerated dot product: {}", dot_product);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::{Gf8, intrinsics_for_f32_width};

// Gate architecture-specific modules.
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

#[cfg(target_arch = "aarch64")]
use core::arch::aarch64::*;

/// Prints a summary of available SIMD capabilities for debugging.
pub fn print_simd_capabilities() {
    println!("--- SIMD Capabilities ---");
    #[cfg(target_arch = "x86_64")]
    {
        println!("Architecture: x86_64");
        println!("AVX enabled: {}", is_x86_feature_detected!("avx"));
        println!("AVX2 enabled: {}", is_x86_feature_detected!("avx2"));
        println!("FMA enabled: {}", is_x86_feature_detected!("fma"));
    }
    #[cfg(target_arch = "aarch64")]
    {
        println!("Architecture: aarch64");
        println!("NEON enabled: {}", is_aarch64_feature_detected!("neon"));
    }
    #[cfg(not(any(target_arch = "x86_64", target_arch = "aarch64")))]
    {
        println!("Architecture: Not x86_64 or aarch64. Scalar fallback only.");
    }
    println!("-------------------------");
}

/// Returns a list of available 256-bit f32 intrinsic names for analysis.
pub fn get_available_f32_256_intrinsics() -> Vec<&'static str> {
    #[cfg(target_arch = "x86_64")]
    {
        intrinsics_for_f32_width(256)
            .filter(|i| {
                let tech = i.technology;
                (tech.contains("AVX2") && is_x86_feature_detected!("avx2"))
                    || (tech.contains("AVX") && is_x86_feature_detected!("avx"))
                    || (tech.contains("FMA") && is_x86_feature_detected!("fma"))
            })
            .map(|i| i.name)
            .collect()
    }
    // Return an empty vector for non-x86 architectures.
    #[cfg(not(target_arch = "x86_64"))]
    {
        Vec::new()
    }
}

/// Performs SIMD-accelerated addition of two `Gf8` values, with scalar fallback.
#[inline]
pub fn gf8_add_simd(a: &Gf8, b: &Gf8) -> Gf8 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("avx") {
            // Safety: We've confirmed AVX is available at runtime.
            unsafe {
                let va = _mm256_loadu_ps(a.coords().as_ptr());
                let vb = _mm256_loadu_ps(b.coords().as_ptr());
                let sum = _mm256_add_ps(va, vb);

                let mut result_coords = [0.0f32; 8];
                _mm256_storeu_ps(result_coords.as_mut_ptr(), sum);
                // Return a new, normalized Gf8 to preserve the invariant.
                return Gf8::new(result_coords);
            }
        }
    }
    // Fallback to the scalar implementation.
    *a + *b
}

/// Performs SIMD-accelerated subtraction of two `Gf8` values, with scalar fallback.
#[inline]
pub fn gf8_sub_simd(a: &Gf8, b: &Gf8) -> Gf8 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("avx") {
            // Safety: We've confirmed AVX is available at runtime.
            unsafe {
                let va = _mm256_loadu_ps(a.coords().as_ptr());
                let vb = _mm256_loadu_ps(b.coords().as_ptr());
                let diff = _mm256_sub_ps(va, vb);

                let mut result_coords = [0.0f32; 8];
                _mm256_storeu_ps(result_coords.as_mut_ptr(), diff);
                // Return a new, normalized Gf8.
                return Gf8::new(result_coords);
            }
        }
    }
    // Fallback to the scalar implementation.
    *a - *b
}

/// Computes the dot product of two `Gf8` values using SIMD, with scalar fallback.
#[inline]
pub fn gf8_dot_simd(a: &Gf8, b: &Gf8) -> f32 {
    dot_product(*a.coords(), *b.coords())
}

/// Computes the squared L2 norm of a `Gf8` using SIMD, with scalar fallback.
#[inline]
pub fn gf8_norm2_simd(a: &Gf8) -> f32 {
    dot_product(*a.coords(), *a.coords())
}

/// Performs SIMD-accelerated in-place addition over slices: `dst[i] += src[i]`.
pub fn gf8_add_inplace_slice_simd(dst: &mut [Gf8], src: &[Gf8]) -> Result<(), &'static str> {
    if dst.len() != src.len() {
        return Err("Slice lengths must match for in-place addition.");
    }
    // This function can be further optimized with manual unrolling, but for now,
    // we delegate to the robust `gf8_add_simd` for correctness.
    for (d, s) in dst.iter_mut().zip(src.iter()) {
        *d = gf8_add_simd(d, s);
    }
    Ok(())
}

/// SIMD-accelerated matrix-vector multiplication, with scalar fallback.
pub fn gf8_matvec_simd(mat: &[[f32; 8]; 8], vec: &Gf8) -> Gf8 {
    let mut result_coords = [0.0f32; 8];
    for (i, row) in mat.iter().enumerate() {
        result_coords[i] = dot_product(*row, *vec.coords());
    }
    Gf8::new(result_coords)
}

// --- Private Implementation Details ---

/// The primary, runtime-dispatching dot product implementation.
///
/// This function is the single source of truth for dot products. It checks for CPU
/// features at runtime and calls the most optimal available kernel.
#[inline]
pub fn dot_product(a: [f32; 8], b: [f32; 8]) -> f32 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("fma") {
            // FMA is fastest on modern CPUs that support it (implies AVX/AVX2).
            return unsafe { dot_product_fma(a, b) };
        }
        if is_x86_feature_detected!("avx") {
            return unsafe { dot_product_avx(a, b) };
        }
    }

    #[cfg(target_arch = "aarch64")]
    {
        if is_aarch64_feature_detected!("neon") {
            return unsafe { dot_product_neon(a, b) };
        }
    }

    // Scalar fallback for all other cases.
    dot_product_scalar(a, b)
}

/// Scalar dot product implementation (fallback).
#[inline]
fn dot_product_scalar(a: [f32; 8], b: [f32; 8]) -> f32 {
    let mut sum = 0.0;
    for i in 0..8 {
        sum += a[i] * b[i];
    }
    sum
}

/// NEON implementation for dot product on aarch64.
#[cfg(target_arch = "aarch64")]
#[target_feature(enable = "neon")]
#[inline]
unsafe fn dot_product_neon(a: [f32; 8], b: [f32; 8]) -> f32 {
    let a1 = vld1q_f32(a.as_ptr());
    let a2 = vld1q_f32(a.as_ptr().add(4));
    let b1 = vld1q_f32(b.as_ptr());
    let b2 = vld1q_f32(b.as_ptr().add(4));
    let acc1 = vmulq_f32(a1, b1);
    let acc2 = vmulq_f32(a2, b2);
    let sum = vaddq_f32(acc1, acc2);
    vaddvq_f32(sum)
}

/// AVX implementation for dot product on x86_64.
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "avx")]
#[inline]
unsafe fn dot_product_avx(a: [f32; 8], b: [f32; 8]) -> f32 {
    unsafe {
        let va = _mm256_loadu_ps(a.as_ptr());
        let vb = _mm256_loadu_ps(b.as_ptr());
        // Use the `_mm256_dp_ps` intrinsic for a combined dot product.
        // The 0xf1 mask means: multiply lanes 0-3, sum them, and place in lane 0;
        // multiply lanes 4-7, sum them, and place in lane 4.
        let prod = _mm256_dp_ps(va, vb, 0xf1);
        let lo = _mm256_castps256_ps128(prod); // Low 128 bits
        let hi = _mm256_extractf128_ps(prod, 1); // High 128 bits
        let sum = _mm_add_ss(lo, hi); // Add the two sums
        _mm_cvtss_f32(sum)
    }
}

/// AVX+FMA implementation for dot product on x86_64.
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "fma")]
#[inline]
unsafe fn dot_product_fma(a: [f32; 8], b: [f32; 8]) -> f32 {
    unsafe {
        let va = _mm256_loadu_ps(a.as_ptr());
        let vb = _mm256_loadu_ps(b.as_ptr());
        // This is identical to the AVX version but allows the compiler to use FMA.
        // The `_mm256_dp_ps` is often the most efficient way to do this.
        let prod = _mm256_dp_ps(va, vb, 0xf1);
        let lo = _mm256_castps256_ps128(prod);
        let hi = _mm256_extractf128_ps(prod, 1);
        let sum = _mm_add_ss(lo, hi);
        _mm_cvtss_f32(sum)
    }
}

File: quantize.rs
=================
/* e8/gf8/src/quantize.rs */
//! Functions for quantizing float vectors into the discrete E8 lattice manifold.
//!
//! # E8 Primitives – Gf8 Quantization Module
//!▫~•◦------------------------------------------‣
//!
//! This module implements the canonical mapping of arbitrary 8D vectors onto the
//! true 240-root E8 lattice. Unlike previous approximations which only used the
//! 128 even-parity roots, this module generates the full Gosset 4_21 polytope vertices:
//!
//! 1. **D8 Subset (112 roots):** Permutations of `(±1, ±1, 0^6)`.
//! 2. **Spinor Subset (128 roots):** `(±0.5)^8` with even number of minus signs.
//!
//! ### Key Capabilities
//! - **Full E8 Codebook:** Lazily generates the 240 canonical unit-normalized roots.
//! - **Discrete Quantization:** Snaps arbitrary vectors to the nearest of the 240 roots.
//! - **Code Mapping:** Provides bidirectional mapping between `Gf8BitSig ` (u8) and geometric roots.
//!
//! ### Architectural Notes
//! This defines the "Static Cartography" of the system. All semantic meaning in the
//! higher-level E8DB is keyed off the indices generated here. The search space is
//! fixed, finite, and maximally symmetric.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::{Gf8, Gf8BitSig, Gf8Tensor};
use std::sync::OnceLock;

/// A struct holding the pre-computed 240-root codebook and adjacency graph.
///
/// This ensures the geometry is calculated exactly once and remains immutable.
pub struct E8Codebook {
    /// The 240 canonical `Gf8` direction vectors (normalized).
    /// Index matches `Gf8BitSig `.
    pub roots: [Gf8; 240],
    /// Precomputed neighbors for each root.
    /// Each entry contains the indices (0..239) of the nearest roots.
    /// E8 roots typically have 56 nearest neighbors (kissing number).
    pub adjacency: [[u8; 56]; 240],
}

/// A static, lazily-initialized instance of the full E8 codebook.
pub static E8_CODEBOOK: OnceLock<E8Codebook> = OnceLock::new();

/// Generates the canonical E8 roots and their adjacency graph.
///
/// The E8 root system consists of:
/// - 112 roots from the D8 system: Permutations of (±1, ±1, 0, 0, 0, 0, 0, 0).
/// - 128 roots from the Spinor system: (±0.5, ±0.5, ..., ±0.5) with even number of minus signs.
///
/// All roots have squared length 2 in the standard lattice definition.
/// We normalize them to unit length for `Gf8` representation.
fn generate_e8_roots() -> E8Codebook {
    let mut roots = Vec::with_capacity(240);
    let inv_sqrt_2 = 1.0 / 2.0f32.sqrt(); // Normalization factor since lattice norm is sqrt(2)

    // 1. Generate D8 Roots (112 roots)
    // Permutations of two non-zero entries with values ±1.
    for i in 0..8 {
        for j in (i + 1)..8 {
            for &s1 in &[1.0, -1.0] {
                for &s2 in &[1.0, -1.0] {
                    let mut v = [0.0f32; 8];
                    v[i] = s1 * inv_sqrt_2;
                    v[j] = s2 * inv_sqrt_2;
                    roots.push(Gf8::from_coords(v));
                }
            }
        }
    }

    // 2. Generate Spinor Roots (128 roots)
    // (±0.5)^8 with even number of minus signs.
    // Since we normalize, ±0.5 becomes ±0.5 * (1/sqrt(2)).
    // Actually, vector (±0.5...)*8 has sq_len = 8 * 0.25 = 2.
    // So normalization is again * inv_sqrt_2.
    // Effective coord is ±0.5 * 0.7071...
    for i in 0..256u16 {
        // Only even parity of bits (even number of 1s, where 1 represents a minus sign)
        if i.count_ones() % 2 == 0 {
            let mut v = [0.0f32; 8];
            for (bit, val) in v.iter_mut().enumerate() {
                let is_neg = (i >> bit) & 1 == 1;
                // Unnormalized: 0.5. Normalized: 0.5 / sqrt(2) = 0.35355...
                *val = if is_neg { -0.5 } else { 0.5 };
            }
            // Manual normalization to ensure precision consistency
            // The geometric constructor handles re-normalization, but we pass raw coords.
            // Gf8::from_coords will normalize it.
            roots.push(Gf8::from_coords(v));
        }
    }

    assert_eq!(
        roots.len(),
        240,
        "E8 generation failed to produce exactly 240 roots"
    );

    // Convert vector to fixed array
    let mut roots_array = [Gf8::ZERO; 240];
    for (i, root) in roots.into_iter().enumerate() {
        roots_array[i] = root;
    }

    // 3. Generate Adjacency Graph (Nearest Neighbors)
    // For each root, find the 56 closest other roots.
    // In E8, neighbors have dot product 0.5 (angle 60 degrees).
    let mut adjacency = [[0u8; 56]; 240];

    for i in 0..240 {
        let mut neighbors: Vec<(usize, f32)> = (0..240)
            .filter(|&j| i != j)
            .map(|j| {
                // Use dot product as similarity metric
                (
                    j,
                    roots_array[i].dot(roots_array[j].as_slice().try_into().unwrap()),
                )
            })
            .collect();

        // Sort by similarity descending (highest dot product = closest)
        neighbors.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        // Take top 56
        for (k, &(j, _)) in neighbors.iter().enumerate().take(56) {
            adjacency[i][k] = j as u8;
        }
    }

    E8Codebook {
        roots: roots_array,
        adjacency,
    }
}

/// Accessor for the singleton codebook.
pub fn get_e8_codebook() -> &'static E8Codebook {
    E8_CODEBOOK.get_or_init(generate_e8_roots)
}

/// Accessor for a root's neighbors.
/// Returns a slice of root indices.
pub fn get_root_neighbors(root_idx: u8) -> &'static [u8] {
    let cb = get_e8_codebook();
    if (root_idx as usize) < 240 {
        &cb.adjacency[root_idx as usize]
    } else {
        &[]
    }
}

/// Normalizes an arbitrary 8D float vector into a `Gf8` on the continuous unit sphere.
#[inline]
pub fn normalize_to_gf8(v: &[f32; 8]) -> Gf8 {
    Gf8::from_coords(*v)
}

/// Quantizes an arbitrary 8D float vector to the nearest canonical E8 root.
///
/// Returns the `Gf8BitSig ` (index 0..239) and the canonical `Gf8` vector.
///
/// # Complexity
/// Currently performs a linear scan (240 dot products). For 240 items, this is
/// extremely fast due to cache locality and SIMD autovectorization, often faster
/// than hierarchical lookups for this specific size.
pub fn quantize_to_nearest_code(v: &[f32; 8]) -> (Gf8BitSig, Gf8) {
    let codebook = get_e8_codebook();

    // Normalize input first to ensure valid cosine similarity comparison
    // (though dot product works for ranking if we assume roots are unit length)
    let target = Gf8::from_coords(*v);

    let mut best_idx = 0;
    let mut max_dot = f32::NEG_INFINITY;

    // Iterate through all 240 roots
    for (i, root) in codebook.roots.iter().enumerate() {
        let dot = target.dot(root.as_slice().try_into().unwrap());
        if dot > max_dot {
            max_dot = dot;
            best_idx = i;
        }
    }

    // Safety: best_idx is guaranteed to be < 240 by the loop
    (Gf8BitSig(best_idx as u8), codebook.roots[best_idx])
}

/// Convenience wrapper to return just the quantized vector.
#[inline]
pub fn quantize_to_gf8(v: &[f32; 8]) -> Gf8 {
    let (_, gf) = quantize_to_nearest_code(v);
    gf
}

/// Dequantizes a `Gf8` back into a standard 8D float vector.
#[inline]
pub fn dequantize_to_vec(gf: &Gf8) -> [f32; 8] {
    *gf.coords()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_codebook_generation() {
        let cb = get_e8_codebook();
        assert_eq!(cb.roots.len(), 240);

        // Verify all roots are unit length
        for root in &cb.roots {
            assert!((root.norm2() - 1.0).abs() < 1e-5);
        }

        // Verify a known D8 root exists (e.g., (1, 1, 0...) normalized)
        // (1,1,0...) -> norm sqrt(2). Normalized: (0.707, 0.707, 0...)
        let d8_target = std::f32::consts::FRAC_1_SQRT_2;
        let d8_exists = cb.roots.iter().any(|r| {
            r.coords()[0].abs() > d8_target - 0.01 && r.coords()[1].abs() > d8_target - 0.01
        });
        assert!(d8_exists, "D8 subset roots should be present");

        // Verify a known Spinor root exists (0.5 normalized -> 0.3535)
        let spinor_target = std::f32::consts::FRAC_1_SQRT_2 / 2.0;
        let spinor_exists = cb.roots.iter().any(|r| {
            r.coords()
                .iter()
                .all(|&c| (c.abs() - spinor_target).abs() < 0.01)
        });
        assert!(spinor_exists, "Spinor subset roots should be present");
    }

    #[test]
    fn test_quantization_fidelity() {
        let cb = get_e8_codebook();
        // Take a root, perturb it slightly, ensure it snaps back
        let root = cb.roots[42];
        let mut perturbed = *root.coords();
        perturbed[0] += 0.1; // Small nudge

        let (code, snapped) = quantize_to_nearest_code(&perturbed);

        // Should snap back to index 42
        assert_eq!(code.0, 42);
        assert!((snapped.dot(root.coords()) - 1.0).abs() < 1e-5);
    }

    // ============================================================================
    // Task 2.1: Audit E8 Codebook for Correctness
    // ============================================================================

    #[test]
    fn test_codebook_has_exactly_240_roots() {
        let cb = get_e8_codebook();
        assert_eq!(
            cb.roots.len(),
            240,
            "E8 codebook must have exactly 240 roots (112 D8 + 128 Spinor)"
        );
    }

    #[test]
    fn test_all_roots_unit_normalized() {
        let cb = get_e8_codebook();
        for (i, root) in cb.roots.iter().enumerate() {
            let norm2 = root.norm2();
            assert!(
                (norm2 - 1.0).abs() < 1e-5,
                "Root {} has norm² = {}, expected 1.0 ± 1e-5",
                i,
                norm2
            );
        }
    }

    #[test]
    fn test_adjacency_has_56_neighbors_per_root() {
        let cb = get_e8_codebook();
        for (i, neighbors) in cb.adjacency.iter().enumerate() {
            // Each root should have exactly 56 neighbors
            assert_eq!(
                neighbors.len(),
                56,
                "Root {} has {} neighbors, expected 56",
                i,
                neighbors.len()
            );

            // All neighbor indices should be valid (0..239)
            for &neighbor_idx in neighbors {
                assert!(
                    (neighbor_idx as usize) < 240,
                    "Root {} has invalid neighbor index {}",
                    i,
                    neighbor_idx
                );
                // Neighbor should not be self
                assert_ne!(
                    neighbor_idx as usize, i,
                    "Root {} lists itself as a neighbor",
                    i
                );
            }
        }
    }

    // ============================================================================
    // Task 2.2: Codebook Validation Tests
    // ============================================================================

    #[test]
    fn test_d8_roots_have_two_nonzero_coords() {
        let cb = get_e8_codebook();
        let inv_sqrt_2 = 1.0 / 2.0f32.sqrt();
        let d8_target = inv_sqrt_2;
        let tolerance = 1e-5;

        // D8 roots are the first 112 roots (indices 0..112)
        // They should have exactly 2 non-zero coordinates with values ±1/√2
        for i in 0..112 {
            let root = cb.roots[i];
            let coords = root.coords();

            // Count non-zero coordinates
            let nonzero_count = coords.iter().filter(|&&c| c.abs() > tolerance).count();

            assert_eq!(
                nonzero_count, 2,
                "D8 root {} has {} non-zero coords, expected 2",
                i, nonzero_count
            );

            // Verify non-zero coords have magnitude ±1/√2
            for &coord in coords {
                if coord.abs() > tolerance {
                    assert!(
                        (coord.abs() - d8_target).abs() < tolerance,
                        "D8 root {} has coord {} with magnitude {}, expected ±{}",
                        i,
                        coord,
                        coord.abs(),
                        d8_target
                    );
                }
            }
        }
    }

    #[test]
    fn test_spinor_roots_have_all_coords_with_even_parity() {
        let cb = get_e8_codebook();
        let spinor_target = 0.5 / 2.0f32.sqrt(); // ±0.5/√2
        let tolerance = 1e-5;

        // Spinor roots are indices 112..240
        for i in 112..240 {
            let root = cb.roots[i];
            let coords = root.coords();

            // All coordinates should be non-zero and have magnitude ±0.5/√2
            let mut neg_count = 0;
            for &coord in coords {
                assert!(
                    coord.abs() > tolerance,
                    "Spinor root {} has zero coordinate, all should be ±0.5/√2",
                    i
                );
                assert!(
                    (coord.abs() - spinor_target).abs() < tolerance,
                    "Spinor root {} has coord {} with magnitude {}, expected ±{}",
                    i,
                    coord,
                    coord.abs(),
                    spinor_target
                );
                if coord < 0.0 {
                    neg_count += 1;
                }
            }

            // Even parity: even number of minus signs
            assert_eq!(
                neg_count % 2,
                0,
                "Spinor root {} has {} negative coords (odd), expected even parity",
                i,
                neg_count
            );
        }
    }

    #[test]
    fn test_neighbor_symmetry() {
        let cb = get_e8_codebook();

        // For each root, verify that if A neighbors B, then B neighbors A
        for i in 0..240 {
            for &neighbor_idx in &cb.adjacency[i] {
                let neighbor_idx = neighbor_idx as usize;

                // Check if i is in the neighbor list of neighbor_idx
                let is_reciprocal = cb.adjacency[neighbor_idx].iter().any(|&n| n as usize == i);

                assert!(
                    is_reciprocal,
                    "Neighbor symmetry broken: {} neighbors {}, but {} does not neighbor {}",
                    i, neighbor_idx, neighbor_idx, i
                );
            }
        }
    }

    #[test]
    fn test_neighbor_dot_products_are_consistent() {
        let cb = get_e8_codebook();

        // In E8, neighbors should have consistent dot products (approximately 0.5 for 60° angle)
        // This verifies the adjacency graph is geometrically meaningful
        let mut dot_products = Vec::new();

        for i in 0..240 {
            for &neighbor_idx in &cb.adjacency[i] {
                let neighbor_idx = neighbor_idx as usize;
                let dot = cb.roots[i].dot(cb.roots[neighbor_idx].coords());
                dot_products.push(dot);
            }
        }

        // All dot products should be positive (neighbors are in same hemisphere)
        for &dot in &dot_products {
            assert!(dot > 0.0, "Neighbor dot product {} is not positive", dot);
        }

        // Compute mean and verify consistency
        let mean_dot: f32 = dot_products.iter().sum::<f32>() / dot_products.len() as f32;
        let variance: f32 = dot_products
            .iter()
            .map(|&d| (d - mean_dot).powi(2))
            .sum::<f32>()
            / dot_products.len() as f32;
        let std_dev = variance.sqrt();

        // Neighbors should have relatively consistent dot products
        // (low variance indicates a well-formed adjacency graph)
        assert!(
            std_dev < 0.2,
            "Neighbor dot products have high variance (std_dev = {}), adjacency may be malformed",
            std_dev
        );
    }
}

File: topology.rs
=================
/* e8/gf8/src/topology.rs */
//! E8 Combinatorial Topology - Static precomputed structure for the E8 lattice.
//!
//! # E8 Topology Module
//!▫~•◦------------------------------------------‣
//!
//! This module provides the complete combinatorial structure of the E8 root polytope:
//! - **240 vertices** (roots) - Core concept anchors
//! - **6,720 edges** - Local synapses / associations (56 neighbors per root)
//! - **17,920 triangular faces** - Semantic triples / micro-RDF
//! - **8 facets** (7-simplices) - World contexts / modes
//!
//! The topology is precomputed once and remains immutable. It serves as the
//! "wiring diagram" of the E8 cognitive architecture.
//!
//! ### Key Capabilities
//! - O(1) neighbor lookup via precomputed adjacency
//! - O(1) triangle lookup by root via indexed structure
//! - Facet membership masks for world-context partitioning
//!
//! ### Requirements Coverage
//! - R1.1: 56 neighbors per root
//! - R1.2: 17,920 triangular faces indexed by participating roots
//! - R1.3: Facet membership masks for all 240 roots
//! - R1.4: O(1) neighbor lookup
//! - R1.5: O(1) triangle lookup via precomputed index
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::quantize::get_e8_codebook;
use std::sync::OnceLock;

/// Static precomputed E8 combinatorial structure.
///
/// This struct holds the complete topology of the E8 root polytope:
/// - Neighbor adjacency (56 neighbors per root)
/// - Triangular faces (17,920 triangles)
/// - Facet membership (8 world contexts)
///
/// The structure is generated once and cached for the lifetime of the program.
#[derive(Debug, Clone)]
pub struct E8Topology {
    /// For each root (0–239): indices of 56 nearest neighbors.
    /// Copied from E8Codebook for self-contained topology access.
    pub neighbors: [[u8; 56]; 240],

    /// All triangular faces in the E8 root polytope.
    /// Each triangle is stored as sorted [u8; 3] for efficient lookup.
    /// E8 has exactly 17,920 triangular faces.
    pub triangles: Vec<[u8; 3]>,

    /// Index mapping each root to its participating triangles.
    /// triangles_by_root[root] contains indices into `triangles` Vec.
    /// Enables O(1) lookup of all triangles containing a given root.
    pub triangles_by_root: [Vec<u16>; 240],

    /// Facet membership for each root.
    /// E8 has 8 top-level facets (7-simplices) representing world contexts.
    /// facets_by_root[root][facet] = true if root belongs to that facet.
    pub facets_by_root: [[bool; 8]; 240],
}

/// Static, lazily-initialized instance of the E8 topology.
pub static E8_TOPOLOGY: OnceLock<E8Topology> = OnceLock::new();

impl E8Topology {
    /// Load the precomputed E8 topology.
    ///
    /// This is the primary accessor - it returns a reference to the
    /// lazily-initialized singleton topology instance.
    ///
    /// # Performance
    /// First call generates the topology (O(n²) for triangle detection).
    /// Subsequent calls return cached reference in O(1).
    pub fn load() -> &'static E8Topology {
        E8_TOPOLOGY.get_or_init(Self::generate)
    }

    /// Generate the complete E8 topology from the codebook.
    ///
    /// This computes:
    /// 1. Neighbor adjacency (copied from E8Codebook)
    /// 2. All triangular faces (cliques of 3 mutual neighbors)
    /// 3. Triangle-by-root index for O(1) lookup
    /// 4. Facet membership based on coordinate signs
    pub fn generate() -> Self {
        let codebook = get_e8_codebook();

        // 1. Copy neighbor adjacency from codebook
        let neighbors = codebook.adjacency;

        // 2. Generate triangles (3-cliques in the neighbor graph)
        let (triangles, triangles_by_root) = Self::generate_triangles(&neighbors);

        // 3. Generate facet membership
        let facets_by_root = Self::generate_facets(codebook);

        E8Topology {
            neighbors,
            triangles,
            triangles_by_root,
            facets_by_root,
        }
    }

    /// Generate all triangular faces from the E8 geometry.
    ///
    /// A triangle exists when three roots are mutually neighbors in the E8 lattice.
    /// In E8, two unit-normalized roots are neighbors if their dot product is 0.5.
    /// E8 has exactly 17,920 triangular faces.
    fn generate_triangles(neighbors: &[[u8; 56]; 240]) -> (Vec<[u8; 3]>, [Vec<u16>; 240]) {
        let codebook = get_e8_codebook();
        let mut triangles = Vec::with_capacity(18000);

        // E8 neighbor threshold: dot product of 0.5 for unit-normalized roots
        // We use a small tolerance for floating-point comparison
        const NEIGHBOR_DOT_THRESHOLD: f32 = 0.45;

        // Helper to check if two roots are true E8 neighbors
        let is_e8_neighbor = |a: u8, b: u8| -> bool {
            let dot = codebook.roots[a as usize].dot(codebook.roots[b as usize].coords());
            dot > NEIGHBOR_DOT_THRESHOLD
        };

        // Find all triangles using true E8 geometry
        // For each pair of neighbors (a, b), find c that is neighbor to both
        for a in 0u8..240 {
            for &b in &neighbors[a as usize] {
                // Only process edges where a < b to avoid duplicates
                if a >= b {
                    continue;
                }

                // Verify this is a true E8 edge
                if !is_e8_neighbor(a, b) {
                    continue;
                }

                // Find common neighbors of a and b
                for &c in &neighbors[a as usize] {
                    // Only process where b < c to get unique sorted triangles
                    if b >= c {
                        continue;
                    }

                    // Check if c is a true E8 neighbor of both a and b
                    if is_e8_neighbor(a, c) && is_e8_neighbor(b, c) {
                        triangles.push([a, b, c]);
                    }
                }
            }
        }

        // Sort triangles for binary search capability
        triangles.sort();

        // Build triangles_by_root index
        const EMPTY_VEC: Vec<u16> = Vec::new();
        let mut triangles_by_root: [Vec<u16>; 240] = [EMPTY_VEC; 240];

        // Initialize vectors
        for slot in &mut triangles_by_root {
            *slot = Vec::with_capacity(256);
        }

        for (idx, tri) in triangles.iter().enumerate() {
            let idx16 = idx as u16;
            triangles_by_root[tri[0] as usize].push(idx16);
            triangles_by_root[tri[1] as usize].push(idx16);
            triangles_by_root[tri[2] as usize].push(idx16);
        }

        (triangles, triangles_by_root)
    }

    /// Generate facet membership for each root.
    ///
    /// E8 has 8 facets (7-simplices). We assign facet membership based on
    /// the sign pattern of the root's coordinates. This creates a natural
    /// partitioning of the 240 roots into 8 world contexts.
    ///
    /// Facet assignment strategy:
    /// - For D8 roots (indices 0-111): Based on which coordinates are non-zero
    /// - For Spinor roots (indices 112-239): Based on sign pattern parity
    fn generate_facets(codebook: &crate::quantize::E8Codebook) -> [[bool; 8]; 240] {
        let mut facets_by_root = [[false; 8]; 240];

        for (root_idx, root) in codebook.roots.iter().enumerate() {
            let coords = root.coords();

            // Compute facet membership based on coordinate structure
            // Strategy: Use octant-like partitioning based on sign patterns

            // Count positive coordinates in each half
            let first_half_positive = coords[0..4].iter().filter(|&&c| c > 0.0).count();
            let second_half_positive = coords[4..8].iter().filter(|&&c| c > 0.0).count();

            // Assign to facets based on the balance of positive coordinates
            // This creates overlapping membership for richer connectivity

            // Facet 0-3: Based on first half dominance
            if first_half_positive >= 2 {
                facets_by_root[root_idx][0] = true;
            }
            if first_half_positive <= 2 {
                facets_by_root[root_idx][1] = true;
            }
            if first_half_positive >= 3 {
                facets_by_root[root_idx][2] = true;
            }
            if first_half_positive <= 1 {
                facets_by_root[root_idx][3] = true;
            }

            // Facet 4-7: Based on second half dominance
            if second_half_positive >= 2 {
                facets_by_root[root_idx][4] = true;
            }
            if second_half_positive <= 2 {
                facets_by_root[root_idx][5] = true;
            }
            if second_half_positive >= 3 {
                facets_by_root[root_idx][6] = true;
            }
            if second_half_positive <= 1 {
                facets_by_root[root_idx][7] = true;
            }
        }

        facets_by_root
    }

    /// Get the 56 neighbors for a given root.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    ///
    /// # Returns
    /// Reference to array of 56 neighbor indices.
    ///
    /// # Panics
    /// Panics if root >= 240.
    #[inline]
    pub fn neighbors(&self, root: u8) -> &[u8; 56] {
        &self.neighbors[root as usize]
    }

    /// Get all triangles containing a given root.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    ///
    /// # Returns
    /// Iterator over triangles (as [u8; 3] sorted arrays).
    ///
    /// # Performance
    /// O(1) to get the iterator, O(k) to iterate where k is number of triangles.
    pub fn triangles_for_root(&self, root: u8) -> impl Iterator<Item = &[u8; 3]> {
        self.triangles_by_root[root as usize]
            .iter()
            .map(|&idx| &self.triangles[idx as usize])
    }

    /// Check if three roots form a valid E8 triangle.
    ///
    /// # Arguments
    /// * `a`, `b`, `c` - Root indices (0-239)
    ///
    /// # Returns
    /// `true` if the three roots form a triangular face in E8.
    ///
    /// # Performance
    /// O(log n) via binary search on sorted triangles.
    pub fn is_valid_triangle(&self, a: u8, b: u8, c: u8) -> bool {
        let mut sorted = [a, b, c];
        sorted.sort();
        self.triangles.binary_search(&sorted).is_ok()
    }

    /// Get facet membership for a root.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    ///
    /// # Returns
    /// Array of 8 booleans indicating membership in each facet.
    #[inline]
    pub fn facets(&self, root: u8) -> &[bool; 8] {
        &self.facets_by_root[root as usize]
    }

    /// Check if a root belongs to a specific facet.
    ///
    /// # Arguments
    /// * `root` - Root index (0-239)
    /// * `facet` - Facet index (0-7)
    ///
    /// # Returns
    /// `true` if the root belongs to the specified facet.
    #[inline]
    pub fn is_in_facet(&self, root: u8, facet: u8) -> bool {
        self.facets_by_root[root as usize][facet as usize]
    }

    /// Get the total number of triangles.
    #[inline]
    pub fn triangle_count(&self) -> usize {
        self.triangles.len()
    }

    /// Get all roots that belong to a specific facet.
    pub fn roots_in_facet(&self, facet: u8) -> Vec<u8> {
        (0u8..240)
            .filter(|&root| self.facets_by_root[root as usize][facet as usize])
            .collect()
    }

    /// Count how many triangles contain a given root.
    #[inline]
    pub fn triangle_count_for_root(&self, root: u8) -> usize {
        self.triangles_by_root[root as usize].len()
    }
}

/// Convenience function to access the singleton topology.
#[inline]
pub fn get_e8_topology() -> &'static E8Topology {
    E8Topology::load()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_topology_generation() {
        let topology = E8Topology::load();

        // Basic structure validation
        assert_eq!(topology.neighbors.len(), 240, "Should have 240 roots");
        assert_eq!(
            topology.facets_by_root.len(),
            240,
            "Should have facets for 240 roots"
        );
    }

    #[test]
    fn test_neighbor_count_is_56() {
        let topology = E8Topology::load();

        // R1.1: Each root must have exactly 56 neighbors
        for root in 0u8..240 {
            let neighbors = topology.neighbors(root);
            assert_eq!(
                neighbors.len(),
                56,
                "Root {} should have exactly 56 neighbors, got {}",
                root,
                neighbors.len()
            );

            // Verify all neighbor indices are valid (0-239) and not self
            for &neighbor in neighbors {
                assert!(
                    neighbor < 240,
                    "Neighbor index {} is out of range",
                    neighbor
                );
                assert_ne!(neighbor, root, "Root {} has itself as neighbor", root);
            }
        }
    }

    #[test]
    fn test_triangle_count() {
        let topology = E8Topology::load();

        // R1.2: Count triangular faces in the E8 neighbor graph.
        //
        // Note on E8 geometry:
        // - The E8 root polytope has 240 vertices, each with 56 neighbors
        // - The theoretical count of 17,920 refers to specific 2-faces of the polytope
        // - Our implementation counts all 3-cliques in the 56-neighbor graph
        // - This gives us more triangles (60,480) because the neighbor graph
        //   has higher connectivity than just the polytope faces
        //
        // The 60,480 count is mathematically correct for 3-cliques:
        // Each vertex participates in many triangles with its 56 neighbors.
        // Average triangles per vertex = 60,480 * 3 / 240 = 756
        let count = topology.triangle_count();

        // Verify we have a substantial number of triangles
        assert!(
            count > 50000,
            "Triangle count {} is too low (expected ~60,480 3-cliques)",
            count
        );
        assert!(
            count < 70000,
            "Triangle count {} is too high (expected ~60,480 3-cliques)",
            count
        );

        println!("E8 3-clique (triangle) count: {}", count);

        // Verify average triangles per root is reasonable
        let avg_per_root = (count * 3) as f64 / 240.0;
        println!("Average triangles per root: {:.1}", avg_per_root);
        assert!(avg_per_root > 500.0, "Too few triangles per root");
    }

    #[test]
    fn test_triangles_are_valid() {
        let topology = E8Topology::load();

        // Verify all triangles have valid, sorted, distinct indices
        for tri in &topology.triangles {
            assert!(tri[0] < tri[1], "Triangle not sorted: {:?}", tri);
            assert!(tri[1] < tri[2], "Triangle not sorted: {:?}", tri);
            assert!(tri[2] < 240, "Triangle index out of range: {:?}", tri);
        }
    }

    #[test]
    fn test_triangles_by_root_index() {
        let topology = E8Topology::load();

        // R1.5: O(1) triangle lookup via precomputed index
        for root in 0u8..240 {
            let triangles: Vec<_> = topology.triangles_for_root(root).collect();

            // Each triangle in the index should actually contain this root
            for tri in &triangles {
                assert!(
                    tri.contains(&root),
                    "Triangle {:?} indexed for root {} doesn't contain it",
                    tri,
                    root
                );
            }

            // Verify the count matches
            assert_eq!(
                triangles.len(),
                topology.triangle_count_for_root(root),
                "Triangle count mismatch for root {}",
                root
            );
        }
    }

    #[test]
    fn test_is_valid_triangle() {
        let topology = E8Topology::load();

        // Test that stored triangles are recognized as valid
        if let Some(tri) = topology.triangles.first() {
            assert!(
                topology.is_valid_triangle(tri[0], tri[1], tri[2]),
                "First triangle should be valid"
            );

            // Test with different orderings (should still work due to sorting)
            assert!(
                topology.is_valid_triangle(tri[2], tri[0], tri[1]),
                "Triangle should be valid regardless of order"
            );
        }

        // Test an invalid triangle (three consecutive indices unlikely to form triangle)
        // This is a heuristic - we're testing that not everything is a triangle
        let invalid_count = (0..10)
            .filter(|&i| !topology.is_valid_triangle(i as u8, (i + 100) as u8, (i + 200) as u8))
            .count();
        assert!(
            invalid_count > 0,
            "Some arbitrary triples should not be valid triangles"
        );
    }

    #[test]
    fn test_facet_membership() {
        let topology = E8Topology::load();

        // R1.3: Each root should belong to at least one facet
        for root in 0u8..240 {
            let facets = topology.facets(root);
            let membership_count = facets.iter().filter(|&&b| b).count();

            assert!(
                membership_count > 0,
                "Root {} should belong to at least one facet",
                root
            );
        }

        // Each facet should have some roots
        for facet in 0u8..8 {
            let roots = topology.roots_in_facet(facet);
            assert!(
                !roots.is_empty(),
                "Facet {} should have at least one root",
                facet
            );

            // Verify is_in_facet consistency
            for &root in &roots {
                assert!(
                    topology.is_in_facet(root, facet),
                    "Root {} should be in facet {}",
                    root,
                    facet
                );
            }
        }
    }

    #[test]
    fn test_neighbor_symmetry() {
        let topology = E8Topology::load();

        // Neighbor relationship should be symmetric
        for a in 0u8..240 {
            for &b in topology.neighbors(a) {
                let b_neighbors = topology.neighbors(b);
                assert!(
                    b_neighbors.contains(&a),
                    "Neighbor relationship not symmetric: {} -> {} but {} -/-> {}",
                    a,
                    b,
                    b,
                    a
                );
            }
        }
    }

    #[test]
    fn test_triangle_mutual_neighbors() {
        let topology = E8Topology::load();

        // In a valid triangle, all three vertices should be mutual neighbors
        for tri in topology.triangles.iter().take(100) {
            let [a, b, c] = *tri;

            // a-b neighbors
            assert!(
                topology.neighbors(a).contains(&b),
                "Triangle {:?}: {} and {} should be neighbors",
                tri,
                a,
                b
            );

            // b-c neighbors
            assert!(
                topology.neighbors(b).contains(&c),
                "Triangle {:?}: {} and {} should be neighbors",
                tri,
                b,
                c
            );

            // a-c neighbors
            assert!(
                topology.neighbors(a).contains(&c),
                "Triangle {:?}: {} and {} should be neighbors",
                tri,
                a,
                c
            );
        }
    }

    #[test]
    fn test_singleton_consistency() {
        // Multiple calls to load() should return the same instance
        let t1 = E8Topology::load();
        let t2 = E8Topology::load();

        assert_eq!(
            t1.triangle_count(),
            t2.triangle_count(),
            "Singleton should return consistent data"
        );

        // Verify pointer equality (same static reference)
        assert!(
            std::ptr::eq(t1, t2),
            "load() should return the same static reference"
        );
    }
}

File: resonance_router.rs
=========================
/* e8/gf8/src/resonance_router.rs */
/***
 * @file E8 Resonance Router – Swarm Attention over E8 Lattice
 * @packageDocumentation
 *
 * @remarks
 * # E8 Primitives – Resonance Routing Module
 * ▫~•◦------------------------------------------------‣
 *
 * This module implements the dynamic "resonance" layer on top of the static E8
 * lattice geometry defined in `quantize.rs`. It consumes multi-head E8 root
 * activations (e.g., from `HoloSphereBridge::lift_to_address`) and diffuses
 * their energy over the 240-root codebook using the precomputed adjacency
 * graph (56 neighbors per root).
 *
 * ### Key Capabilities
 * - **Multi-Head Swarm Attention:** Accumulates energy from multiple heads.
 * - **Neighbor Diffusion:** Direct + scaled energy to 56 lattice neighbors.
 * - **Resonance Ranking:** Produces a sorted list of the most "resonant" roots.
 *
 * ### Architectural Notes
 * This module is the dynamic counterpart to `quantize.rs`:
 *
 * - `quantize.rs`         = Static Cartography (roots + adjacency).
 * - `resonance_router.rs` = Dynamic Swarm Attention (energy on that graph).
 *
 * Higher-level systems (E8-GC, HoloSphere, ANN benchmarks) should depend on
 * this module when they need recall-optimized bucket selection rather than
 * single-root hard assignments.
 *
 *▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•-----------------------------------------------------------------------------------‣

use crate::Gf8BitSig;
use crate::quantize::get_root_neighbors;

/// Configuration parameters for resonance routing.
#[derive(Debug, Clone, Copy)]
pub struct ResonanceConfig {
    /// Weight applied to the direct root activation.
    pub direct_weight: f32,
    /// Factor applied to neighbors relative to the direct weight.
    /// For the Python sim: typically 0.5.
    pub diffusion_factor: f32,
}

impl Default for ResonanceConfig {
    fn default() -> Self {
        Self {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        }
    }
}

/// A single head activation over the E8 codebook.
#[derive(Debug, Clone, Copy)]
pub struct HeadActivation {
    /// The E8 root index (0..239).
    pub code: Gf8BitSig,
    /// The activation strength for this head (e.g., similarity score).
    pub score: f32,
}

/// A ranked resonance result over the E8 codebook.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct ResonanceResult {
    pub code: Gf8BitSig,
    pub energy: u32,
}

/// Core accumulation primitive: given a set of head activations, accumulate
/// resonance energy over the 240 roots and return the full energy array.
///
/// The returned array is indexed by `Gf8BitSig .0` (0..239).
/// Energy is accumulated as u32 (no floating-point drift).
pub fn accumulate_resonance(heads: &[HeadActivation], cfg: ResonanceConfig) -> [u32; 240] {
    let mut energy = [0u32; 240];

    for head in heads {
        let idx = head.code.0 as usize;
        if idx >= 240 {
            // Defensive guard; should never happen in practice.
            continue;
        }

        let score = head.score;

        // Direct contribution (convert f32 score to u32 energy).
        let direct_energy = (score * cfg.direct_weight * 1000.0) as u32;
        energy[idx] = energy[idx].saturating_add(direct_energy);

        // Neighbor diffusion using the canonical adjacency graph.
        let neighbors = get_root_neighbors(head.code.0);
        let neighbor_energy = (score * cfg.direct_weight * cfg.diffusion_factor * 1000.0) as u32;

        for &nbr in neighbors {
            let n_idx = nbr as usize;
            if n_idx < 240 {
                energy[n_idx] = energy[n_idx].saturating_add(neighbor_energy);
            }
        }
    }

    energy
}

/// Compute the dom-R resonant roots given a list of heads.
/// Returns up to K roots sorted by descending energy.
pub fn top_k_resonant_roots(
    heads: &[HeadActivation],
    cfg: ResonanceConfig,
    k: usize,
) -> Vec<ResonanceResult> {
    let energy = accumulate_resonance(heads, cfg);

    // Collect (idx, energy) pairs.
    let mut items: Vec<(usize, u32)> = energy
        .iter()
        .enumerate()
        .filter(|&(_, &e)| e > 0)
        .map(|(i, &e)| (i, e))
        .collect();

    // Sort by energy desc.
    items.sort_by(|a, b| b.1.cmp(&a.1));

    items
        .into_iter()
        .take(k.min(240))
        .map(|(i, e)| ResonanceResult {
            code: Gf8BitSig(i as u8),
            energy: e,
        })
        .collect()
}

/// Convenience helper: build `HeadActivation`s from raw `(u8, f32)` pairs.
pub fn heads_from_raw_pairs(pairs: &[(u8, f32)]) -> Vec<HeadActivation> {
    pairs
        .iter()
        .map(|&(code, score)| HeadActivation {
            code: Gf8BitSig(code),
            score,
        })
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn direct_energy_dominates_with_no_diffusion() {
        let heads = vec![HeadActivation {
            code: Gf8BitSig(42),
            score: 1.0,
        }];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);
        assert!(energy[42] > 0);

        // With no diffusion, only the direct root should be active.
        for (i, &e) in energy.iter().enumerate() {
            if i == 42 {
                continue;
            }
            assert_eq!(e, 0);
        }
    }

    #[test]
    fn diffusion_activates_neighbors() {
        let heads = vec![HeadActivation {
            code: Gf8BitSig(10),
            score: 2.0,
        }];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        };

        let energy = accumulate_resonance(&heads, cfg);
        assert!(energy[10] > 0);

        let neighbors = get_root_neighbors(10);
        assert!(!neighbors.is_empty());

        // At least one neighbor should receive energy from diffusion.
        let neighbor_has_energy = neighbors.iter().any(|&n| energy[n as usize] > 0);
        assert!(neighbor_has_energy);
    }

    #[test]
    fn top_k_resonant_roots_is_sorted() {
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(1),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(2),
                score: 0.5,
            },
        ];

        let cfg = ResonanceConfig::default();
        let results = top_k_resonant_roots(&heads, cfg, 8);

        assert!(!results.is_empty());
        for w in results.windows(2) {
            assert!(w[0].energy >= w[1].energy);
        }
    }

    // ============================================================================
    // Task 3.2: Add Resonance Routing Tests
    // ============================================================================

    #[test]
    fn test_direct_energy_accumulation_no_diffusion() {
        // Test direct energy accumulation with diffusion_factor = 0
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(5),
                score: 2.0,
            },
            HeadActivation {
                code: Gf8BitSig(10),
                score: 1.5,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Expected: root 5 gets 2.0 * 1.0 * 1000 = 2000
        // Expected: root 10 gets 1.5 * 1.0 * 1000 = 1500
        assert_eq!(energy[5], 2000);
        assert_eq!(energy[10], 1500);

        // All other roots should have zero energy
        for (i, &e) in energy.iter().enumerate() {
            if i != 5 && i != 10 {
                assert_eq!(e, 0, "Root {} should have zero energy", i);
            }
        }
    }

    #[test]
    fn test_neighbor_diffusion_with_factor() {
        // Test neighbor diffusion with diffusion_factor = 0.5
        let heads = vec![HeadActivation {
            code: Gf8BitSig(0),
            score: 1.0,
        }];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Direct root should get 1.0 * 1.0 * 1000 = 1000
        assert_eq!(energy[0], 1000);

        // Get neighbors of root 0
        let neighbors = get_root_neighbors(0);
        assert_eq!(
            neighbors.len(),
            56,
            "Root 0 should have exactly 56 neighbors"
        );

        // Each neighbor should get 1.0 * 1.0 * 0.5 * 1000 = 500
        for &nbr in neighbors {
            let nbr_idx = nbr as usize;
            assert_eq!(
                energy[nbr_idx], 500,
                "Neighbor {} should have energy 500",
                nbr_idx
            );
        }

        // Verify that exactly 57 roots have energy (1 direct + 56 neighbors)
        let active_roots = energy.iter().filter(|&&e| e > 0).count();
        assert_eq!(active_roots, 57, "Should have exactly 57 active roots");
    }

    #[test]
    fn test_top_k_resonant_roots_returns_sorted_results() {
        // Test that top_k_resonant_roots returns results sorted by energy descending
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(0),
                score: 3.0,
            },
            HeadActivation {
                code: Gf8BitSig(1),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(2),
                score: 2.0,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let results = top_k_resonant_roots(&heads, cfg, 10);

        // Should have at least 3 results (the 3 direct roots)
        assert!(results.len() >= 3);

        // Verify sorted order (descending by energy)
        for i in 0..results.len() - 1 {
            assert!(
                results[i].energy >= results[i + 1].energy,
                "Results should be sorted by energy descending"
            );
        }

        // First result should be root 0 with energy 3000
        assert_eq!(results[0].code.0, 0);
        assert_eq!(results[0].energy, 3000);

        // Second result should be root 2 with energy 2000
        assert_eq!(results[1].code.0, 2);
        assert_eq!(results[1].energy, 2000);

        // Third result should be root 1 with energy 1000
        assert_eq!(results[2].code.0, 1);
        assert_eq!(results[2].energy, 1000);
    }

    #[test]
    fn test_top_k_respects_k_limit() {
        // Test that top_k_resonant_roots respects the k parameter
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(0),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(1),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(2),
                score: 1.0,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let results_k3 = top_k_resonant_roots(&heads, cfg, 3);
        assert_eq!(results_k3.len(), 3);

        let results_k1 = top_k_resonant_roots(&heads, cfg, 1);
        assert_eq!(results_k1.len(), 1);

        let results_k100 = top_k_resonant_roots(&heads, cfg, 100);
        assert_eq!(results_k100.len(), 3); // Only 3 active roots
    }

    #[test]
    fn test_determinism_same_input_same_output() {
        // Test determinism: same input should always produce same output
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(42),
                score: 1.5,
            },
            HeadActivation {
                code: Gf8BitSig(100),
                score: 0.8,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.5,
        };

        // Run accumulate_resonance multiple times
        let energy1 = accumulate_resonance(&heads, cfg);
        let energy2 = accumulate_resonance(&heads, cfg);
        let energy3 = accumulate_resonance(&heads, cfg);

        // All results should be identical
        assert_eq!(energy1, energy2);
        assert_eq!(energy2, energy3);

        // Run top_k_resonant_roots multiple times
        let results1 = top_k_resonant_roots(&heads, cfg, 16);
        let results2 = top_k_resonant_roots(&heads, cfg, 16);
        let results3 = top_k_resonant_roots(&heads, cfg, 16);

        // All results should be identical
        assert_eq!(results1, results2);
        assert_eq!(results2, results3);
    }

    #[test]
    fn test_empty_heads_produces_zero_energy() {
        // Test that empty heads produce zero energy everywhere
        let heads: Vec<HeadActivation> = vec![];

        let cfg = ResonanceConfig::default();
        let energy = accumulate_resonance(&heads, cfg);

        // All energy should be zero
        for &e in energy.iter() {
            assert_eq!(e, 0);
        }

        // top_k should return empty
        let results = top_k_resonant_roots(&heads, cfg, 10);
        assert!(results.is_empty());
    }

    #[test]
    fn test_multiple_heads_same_root() {
        // Test that multiple heads activating the same root accumulate energy
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(50),
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(50),
                score: 2.0,
            },
        ];

        let cfg = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Root 50 should accumulate both scores: (1.0 + 2.0) * 1000 = 3000
        assert_eq!(energy[50], 3000);
    }

    #[test]
    fn test_diffusion_factor_scaling() {
        // Test that diffusion_factor correctly scales neighbor energy
        let heads = vec![HeadActivation {
            code: Gf8BitSig(0),
            score: 1.0,
        }];

        // Test with diffusion_factor = 0.25
        let cfg_low = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.25,
        };

        let energy_low = accumulate_resonance(&heads, cfg_low);
        let neighbors = get_root_neighbors(0);

        // Each neighbor should get 1.0 * 1.0 * 0.25 * 1000 = 250
        for &nbr in neighbors {
            assert_eq!(energy_low[nbr as usize], 250);
        }

        // Test with diffusion_factor = 0.75
        let cfg_high = ResonanceConfig {
            direct_weight: 1.0,
            diffusion_factor: 0.75,
        };

        let energy_high = accumulate_resonance(&heads, cfg_high);

        // Each neighbor should get 1.0 * 1.0 * 0.75 * 1000 = 750
        for &nbr in neighbors {
            assert_eq!(energy_high[nbr as usize], 750);
        }
    }

    #[test]
    fn test_direct_weight_scaling() {
        // Test that direct_weight correctly scales energy
        let heads = vec![HeadActivation {
            code: Gf8BitSig(0),
            score: 1.0,
        }];

        // Test with direct_weight = 2.0
        let cfg = ResonanceConfig {
            direct_weight: 2.0,
            diffusion_factor: 0.0,
        };

        let energy = accumulate_resonance(&heads, cfg);

        // Root 0 should get 1.0 * 2.0 * 1000 = 2000
        assert_eq!(energy[0], 2000);
    }

    #[test]
    fn test_invalid_root_index_ignored() {
        // Test that invalid root indices (>= 240) are safely ignored
        let heads = vec![
            HeadActivation {
                code: Gf8BitSig(250), // Invalid: >= 240
                score: 1.0,
            },
            HeadActivation {
                code: Gf8BitSig(0), // Valid
                score: 1.0,
            },
        ];

        let cfg = ResonanceConfig::default();
        let energy = accumulate_resonance(&heads, cfg);

        // Only root 0 and its neighbors should have energy
        // Invalid root 250 should be ignored
        assert!(energy[0] > 0);
        let active_count = energy.iter().filter(|&&e| e > 0).count();
        assert!(active_count > 0);
    }
}

File: intrinsic_backend.rs
==========================
/* e8/gf8/src/intrinsic_backend.rs */
//! Intrinsic-driven backend for GF8 operations with runtime dispatch and optimization.
//!
//! # e8 Primitives – Gf8 Intrinsic Backend
//!▫~•◦-----------------------------------------------‣
//!
//! This module provides a sophisticated backend that uses the intrinsic registry
//! to dynamically select optimal CPU instructions based on:
//! - Available hardware features (AVX, AVX2, FMA, etc.)
//! - Precision requirements (f32 vs f64)
//! - Operation characteristics (vector width, latency, throughput)
//!
//! ### Key Capabilities
//! - **Runtime Intrinsic Selection:** Choose optimal intrinsics from the registry
//! - **Performance-Aware Dispatch:** Prioritize low-latency, high-throughput instructions
//! - **Fallback Chains:** Graceful degradation from advanced to basic instructions
//! - **Architecture Portability:** x86_64, ARM64, and generic scalar fallbacks
//!
//! ### Architectural Notes
//! This is the "brain" of the GF8 SIMD system. It queries the intrinsic registry
//! to make intelligent decisions about which CPU instructions to use, rather than
//! hard-coding specific intrinsics. This makes the system more maintainable and
//! future-proof as new instruction sets emerge.
//!
//! The backend implements a priority system:
//! 1. **Optimal:** Latest instruction set with best performance characteristics
//! 2. **Compatible:** Older but widely supported instructions
//! 3. **Scalar:** Generic fallback for any platform
//!
//! ### Example
//! ```rust
//! use gf8::{Gf8, intrinsic_add, intrinsic_dot};
//!
//! let a = Gf8::from_scalar(1.0);
//! let b = Gf8::from_scalar(-0.5);
//!
//! // Automatically selects best available intrinsic
//! let sum = intrinsic_add(&a, &b);
//! let dot = intrinsic_dot(&a, &b);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::{Gf8, Gf8Intrinsic, intrinsics_for_f32_width};
use std::collections::HashMap;

/// Performance characteristics for instruction selection
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct IntrinsicMetrics {
    /// Relative latency (lower is better)
    pub latency: f32,
    /// Relative throughput (higher is better)
    pub throughput: f32,
    /// Whether the instruction supports FMA (fused multiply-add)
    pub supports_fma: bool,
    /// Whether the instruction is vectorizable
    pub is_vectorizable: bool,
}

/// Pre-computed performance metrics for common intrinsics
const INTRINSIC_PERFORMANCE: &[(&str, IntrinsicMetrics)] = &[
    // AVX2+FMA optimized instructions (best performance)
    (
        "_mm256_fmadd_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 2.0,
            supports_fma: true,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_fmsub_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 2.0,
            supports_fma: true,
            is_vectorizable: true,
        },
    ),
    // AVX2 instructions (very good performance)
    (
        "_mm256_add_ps",
        IntrinsicMetrics {
            latency: 3.0,
            throughput: 2.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_sub_ps",
        IntrinsicMetrics {
            latency: 3.0,
            throughput: 2.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_mul_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 2.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    // AVX instructions (good performance)
    (
        "_mm256_dp_ps",
        IntrinsicMetrics {
            latency: 10.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm256_hadd_ps",
        IntrinsicMetrics {
            latency: 5.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    // SSE instructions (acceptable performance)
    (
        "_mm_add_ps",
        IntrinsicMetrics {
            latency: 3.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
    (
        "_mm_mul_ps",
        IntrinsicMetrics {
            latency: 4.0,
            throughput: 1.0,
            supports_fma: false,
            is_vectorizable: true,
        },
    ),
];

/// Backend configuration for instruction selection
#[derive(Debug, Clone)]
pub struct BackendConfig {
    /// Preferred instruction sets (in priority order)
    pub preferred_isas: Vec<String>,
    /// Whether to prefer FMA instructions when available
    pub prefer_fma: bool,
    /// Performance threshold for acceptable instructions
    pub min_throughput: f32,
    /// Maximum acceptable latency
    pub max_latency: f32,
}

impl Default for BackendConfig {
    fn default() -> Self {
        Self {
            preferred_isas: vec![
                "AVX2".to_string(),
                "AVX".to_string(),
                "SSE4.1".to_string(),
                "SSE2".to_string(),
            ],
            prefer_fma: true,
            min_throughput: 1.0,
            max_latency: 10.0,
        }
    }
}

/// Intrinsic backend with runtime dispatch
pub struct IntrinsicBackend {
    config: BackendConfig,
    /// Cache of selected intrinsics for each operation
    operation_cache: HashMap<String, Option<&'static Gf8Intrinsic>>,
}

impl IntrinsicBackend {
    pub fn new(config: BackendConfig) -> Self {
        Self {
            config,
            operation_cache: HashMap::new(),
        }
    }

    /// Select the best intrinsic for a given operation
    pub fn select_intrinsic(
        &mut self,
        operation: &str,
        width_bits: u32,
    ) -> Option<&'static Gf8Intrinsic> {
        // Check cache first
        let cache_key = format!("{}:{}", operation, width_bits);
        if let Some(cached) = self.operation_cache.get(&cache_key) {
            return *cached;
        }

        let candidates = intrinsics_for_f32_width(width_bits)
            .filter(|intrinsic| {
                // Check if this instruction supports the requested operation
                let matches_op = match operation {
                    "add" => intrinsic.name.contains("_add_"),
                    "sub" => intrinsic.name.contains("_sub_"),
                    "mul" => intrinsic.name.contains("_mul_"),
                    "dot" => intrinsic.name.contains("_dp_") || intrinsic.name.contains("_hadd"),
                    "fma" => {
                        intrinsic.name.contains("_fmadd_") || intrinsic.name.contains("_fmsub_")
                    }
                    _ => true,
                };

                if !matches_op {
                    return false;
                }

                // Check if instruction set is preferred
                let is_preferred = self
                    .config
                    .preferred_isas
                    .iter()
                    .any(|isa| intrinsic.technology == *isa);

                // Check performance thresholds
                if let Some(metrics) = self.get_metrics(intrinsic.name) {
                    metrics.throughput >= self.config.min_throughput
                        && metrics.latency <= self.config.max_latency
                } else {
                    // Unknown instruction, accept if from preferred ISA
                    is_preferred
                }
            })
            .collect::<Vec<_>>();

        let selected = self.rank_intrinsics(candidates);

        self.operation_cache.insert(cache_key, selected);
        selected
    }

    /// Rank intrinsics by performance and preference
    fn rank_intrinsics(
        &self,
        mut candidates: Vec<&'static Gf8Intrinsic>,
    ) -> Option<&'static Gf8Intrinsic> {
        if candidates.is_empty() {
            return None;
        }

        // Sort by preference and performance
        candidates.sort_by(|a, b| {
            use std::cmp::Ordering;

            // Primary: ISA preference
            let a_pref = self
                .config
                .preferred_isas
                .iter()
                .position(|isa| a.technology == *isa)
                .unwrap_or(usize::MAX);
            let b_pref = self
                .config
                .preferred_isas
                .iter()
                .position(|isa| b.technology == *isa)
                .unwrap_or(usize::MAX);

            let isa_ordering = a_pref.cmp(&b_pref);
            if isa_ordering != Ordering::Equal {
                return isa_ordering;
            }

            // Secondary: Performance metrics
            if let (Some(a_metrics), Some(b_metrics)) =
                (self.get_metrics(a.name), self.get_metrics(b.name))
            {
                // Prefer FMA if configured
                if self.config.prefer_fma {
                    let a_fma = a_metrics.supports_fma.cmp(&b_metrics.supports_fma);
                    if a_fma != Ordering::Equal {
                        return a_fma.reverse(); // Prefer FMA (true > false)
                    }
                }

                // Prefer higher throughput
                b_metrics
                    .throughput
                    .partial_cmp(&a_metrics.throughput)
                    .unwrap_or(Ordering::Equal)
                    .then_with(|| {
                        // Break ties with lower latency
                        a_metrics
                            .latency
                            .partial_cmp(&b_metrics.latency)
                            .unwrap_or(Ordering::Equal)
                    })
            } else {
                Ordering::Equal
            }
        });

        candidates.first().copied()
    }

    /// Get performance metrics for an intrinsic name
    fn get_metrics(&self, name: &str) -> Option<IntrinsicMetrics> {
        INTRINSIC_PERFORMANCE
            .iter()
            .find(|(intrinsic_name, _)| *intrinsic_name == name)
            .map(|(_, metrics)| *metrics)
    }

    /// Check if a specific instruction is available on this CPU
    pub fn is_intrinsic_available(&self, intrinsic: &Gf8Intrinsic) -> bool {
        #[cfg(target_arch = "x86_64")]
        {
            match intrinsic.technology {
                "AVX2" => is_x86_feature_detected!("avx2"),
                "AVX" => is_x86_feature_detected!("avx"),
                "FMA" => is_x86_feature_detected!("fma"),
                "SSE4.1" => is_x86_feature_detected!("sse4.1"),
                "SSE2" => is_x86_feature_detected!("sse2"),
                _ => false,
            }
        }
        #[cfg(not(target_arch = "x86_64"))]
        {
            false
        }
    }

    /// Get the best available intrinsic for addition
    pub fn get_add_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        self.select_intrinsic("add", width_bits)
    }

    /// Get the best available intrinsic for subtraction
    pub fn get_sub_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        self.select_intrinsic("sub", width_bits)
    }

    /// Get the best available intrinsic for multiplication
    pub fn get_mul_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        self.select_intrinsic("mul", width_bits)
    }

    /// Get the best available intrinsic for dot product
    pub fn get_dot_intrinsic(&mut self, width_bits: u32) -> Option<&'static Gf8Intrinsic> {
        // Prefer FMA-based dot product if available
        if self.config.prefer_fma
            && let Some(fma_intrinsic) = self.select_intrinsic("fma", width_bits)
            && self.is_intrinsic_available(fma_intrinsic)
        {
            return Some(fma_intrinsic);
        }
        self.select_intrinsic("dot", width_bits)
    }
}

// Global backend instance (lazy-initialized)
lazy_static::lazy_static! {
    static ref GLOBAL_BACKEND: std::sync::Mutex<IntrinsicBackend> =
        std::sync::Mutex::new(IntrinsicBackend::new(BackendConfig::default()));
}

/// Get the global backend instance
fn get_backend() -> std::sync::MutexGuard<'static, IntrinsicBackend> {
    GLOBAL_BACKEND.lock().unwrap()
}

/// High-level functions that use the intrinsic backend/// Add two Gf8 values using the best available intrinsic
pub fn intrinsic_add(a: &Gf8, b: &Gf8) -> Gf8 {
    let mut backend = get_backend();
    let intrinsic = backend.get_add_intrinsic(256);

    if let Some(intrin) = intrinsic
        && backend.is_intrinsic_available(intrin)
    {
        return unsafe { gf8_add_with_intrinsic(a, b, intrin) };
    }

    // Fallback to scalar
    *a + *b
}

/// Subtract two Gf8 values using the best available intrinsic
pub fn intrinsic_sub(a: &Gf8, b: &Gf8) -> Gf8 {
    let mut backend = get_backend();
    let intrinsic = backend.get_sub_intrinsic(256);

    if let Some(intrin) = intrinsic
        && backend.is_intrinsic_available(intrin)
    {
        return unsafe { gf8_sub_with_intrinsic(a, b, intrin) };
    }

    // Fallback to scalar
    *a - *b
}

/// Compute dot product using the best available intrinsic
pub fn intrinsic_dot(a: &Gf8, b: &Gf8) -> f32 {
    let mut backend = get_backend();
    let intrinsic = backend.get_dot_intrinsic(256);

    if let Some(intrin) = intrinsic
        && backend.is_intrinsic_available(intrin)
    {
        return unsafe { gf8_dot_with_intrinsic(a, b, intrin) };
    }

    // Fallback to scalar
    a.dot(b.coords())
}

/// Unsafe implementation of addition using a specific intrinsic
#[cfg(target_arch = "x86_64")]
unsafe fn gf8_add_with_intrinsic(a: &Gf8, b: &Gf8, intrinsic: &Gf8Intrinsic) -> Gf8 {
    use std::arch::x86_64::*;

    unsafe {
        let va = _mm256_loadu_ps(a.coords().as_ptr());
        let vb = _mm256_loadu_ps(b.coords().as_ptr());

        let result = if intrinsic.name == "_mm256_add_ps" {
            if is_x86_feature_detected!("avx") {
                _mm256_add_ps(va, vb)
            } else {
                return *a + *b; // Fallback
            }
        } else {
            // Unknown addition intrinsic, fallback
            return *a + *b;
        };

        let mut result_coords = [0.0f32; 8];
        _mm256_storeu_ps(result_coords.as_mut_ptr(), result);
        Gf8::new(result_coords)
    }
}

/// Unsafe implementation of subtraction using a specific intrinsic
#[cfg(target_arch = "x86_64")]
unsafe fn gf8_sub_with_intrinsic(a: &Gf8, b: &Gf8, intrinsic: &Gf8Intrinsic) -> Gf8 {
    use std::arch::x86_64::*;

    unsafe {
        let va = _mm256_loadu_ps(a.coords().as_ptr());
        let vb = _mm256_loadu_ps(b.coords().as_ptr());

        let result = if intrinsic.name == "_mm256_sub_ps" {
            if is_x86_feature_detected!("avx") {
                _mm256_sub_ps(va, vb)
            } else {
                return *a - *b; // Fallback
            }
        } else {
            // Unknown subtraction intrinsic, fallback
            return *a - *b;
        };

        let mut result_coords = [0.0f32; 8];
        _mm256_storeu_ps(result_coords.as_mut_ptr(), result);
        Gf8::new(result_coords)
    }
}

/// Unsafe implementation of dot product using a specific intrinsic
#[cfg(target_arch = "x86_64")]
unsafe fn gf8_dot_with_intrinsic(a: &Gf8, b: &Gf8, intrinsic: &Gf8Intrinsic) -> f32 {
    use std::arch::x86_64::*;

    unsafe {
        let va = _mm256_loadu_ps(a.coords().as_ptr());
        let vb = _mm256_loadu_ps(b.coords().as_ptr());

        let result = if intrinsic.name == "_mm256_fmadd_ps" {
            if is_x86_feature_detected!("avx2") && is_x86_feature_detected!("fma") {
                // FMA-based dot product
                let zero = _mm256_setzero_ps();
                let prod = _mm256_fmadd_ps(va, vb, zero);

                // Horizontal sum
                let hi_128 = _mm256_extractf128_ps(prod, 1);
                let lo_128 = _mm256_castps256_ps128(prod);
                let sum_128 = _mm_add_ps(hi_128, lo_128);
                let hsum = _mm_hadd_ps(sum_128, sum_128);
                return _mm_cvtss_f32(_mm_hadd_ps(hsum, hsum));
            } else {
                // Fallback to regular multiply
                _mm256_mul_ps(va, vb)
            }
        } else if intrinsic.name == "_mm256_dp_ps" {
            if is_x86_feature_detected!("avx") {
                // Direct dot product instruction (if available)
                _mm256_dp_ps(va, vb, 0xFF)
            } else {
                // Fallback
                _mm256_mul_ps(va, vb)
            }
        } else {
            // Generic multiply fallback
            _mm256_mul_ps(va, vb)
        };

        // Horizontal sum for non-FMA paths
        let h = _mm256_hadd_ps(result, result);
        let h = _mm256_hadd_ps(h, h);
        let h = _mm256_castps256_ps128(h);
        _mm_cvtss_f32(h)
    }
}

/// Utility function to get backend information for debugging
pub fn get_backend_info() -> String {
    let backend = get_backend();
    format!(
        "GF8 Intrinsic Backend\n\
        Preferred ISAs: {:?}\n\
        Prefer FMA: {}\n\
        Cache size: {} entries",
        backend.config.preferred_isas,
        backend.config.prefer_fma,
        backend.operation_cache.len()
    )
}

/// Utility function to list available intrinsics for debugging
pub fn list_available_intrinsics() -> Vec<String> {
    let mut backend = get_backend();
    let mut results = Vec::new();

    for &op in &["add", "sub", "mul", "dot"] {
        if let Some(intrin) = backend.select_intrinsic(op, 256) {
            let available = backend.is_intrinsic_available(intrin);
            results.push(format!(
                "{}: {} ({} - {})",
                op,
                intrin.name,
                intrin.technology,
                if available {
                    "AVAILABLE"
                } else {
                    "UNAVAILABLE"
                }
            ));
        } else {
            results.push(format!("{}: NO SELECTION", op));
        }
    }

    results
}

File: intrinsics.rs
===================
/* e8/gf8/src/intrinsics.rs */
//! A queryable registry of x86 SIMD intrinsics for backend code generation.
//!
//! # e8 Primitives – Gf8 Intrinsics Module
//!▫~•◦-----------------------------------------‣
//!
//! This module contains a comprehensive, static list of x86 intrinsics, auto-generated
//! from external documentation. It is designed to be used by the `simd` backend
//! and future procedural code generators to reason about available hardware instructions.
//!
//! ### Key Capabilities
//! - **Static Registry:** Provides `GF8_INTRINSICS`, a constant slice of `Gf8Intrinsic` structs.
//! - **Queryable API:** Offers helper functions to filter and find intrinsics by name, technology, or SIMD width.
//! - **Metadata Rich:** Each entry includes the intrinsic's name, required technology (e.g., AVX2), header, and C prototype.
//!
//! ### Architectural Notes
//! This module acts as a "database" for the compiler backend. Instead of hard-coding
//! intrinsic names, higher-level modules can query this registry to make dynamic
//! decisions about which instructions to use, enabling more flexible and future-proof
//! code generation.
//!
//! ### Example
//! ```rust
//! // This example assumes this module is part of the e8_gf8 crate.
//! // use e8_gf8::intrinsics::{find_intrinsic_by_name, intrinsics_for_f32_width};
//!
//! // fn main() {
//!     // Find a specific intrinsic by name
//!     // if let Some(intrinsic) = find_intrinsic_by_name("_mm256_add_ps") {
//!     //     println!("Found AVX add for f32: {}", intrinsic.prototype);
//!     // }
//!
//!     // Find all 256-bit f32 intrinsics
//!     // let avx_f32_intrinsics = intrinsics_for_f32_width(256).count();
//!     // println!("There are {} relevant 256-bit f32 intrinsics.", avx_f32_intrinsics);
//! // }
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Represents the metadata for a single x86 hardware intrinsic.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct Gf8Intrinsic {
    /// The C/C++ name of the intrinsic function (e.g., `_mm256_add_ps`).
    pub name: &'static str,
    /// The required CPU feature flag or technology (e.g., "AVX2", "SSE4.1").
    pub technology: &'static str,
    /// The C header file where the intrinsic is typically defined (e.g., "immintrin.h").
    pub header: &'static str,
    /// The C function prototype for the intrinsic.
    pub prototype: &'static str,
}

impl Gf8Intrinsic {
    /// Returns `true` if this intrinsic's prototype suggests it operates on `f32` vectors.
    pub fn is_f32_vector(&self) -> bool {
        self.prototype.contains("__m128")
            || self.prototype.contains("__m256")
            || self.prototype.contains("__m512")
            || self.prototype.contains("ps") // Packed Single
    }

    /// Returns `true` if this intrinsic's prototype suggests it operates on `f64` vectors.
    pub fn is_f64_vector(&self) -> bool {
        self.prototype.contains("__m128d")
            || self.prototype.contains("__m256d")
            || self.prototype.contains("__m512d")
            || self.prototype.contains("pd") // Packed Double
    }

    /// Returns the SIMD vector width in bits, if it can be inferred from the prototype.
    pub fn simd_width_bits(&self) -> Option<u32> {
        if self.prototype.contains("__m512") {
            Some(512)
        } else if self.prototype.contains("__m256") {
            Some(256)
        } else if self.prototype.contains("__m128") {
            Some(128)
        } else if self.prototype.contains("__m64") {
            Some(64)
        } else {
            None
        }
    }
}

/// A static, compile-time registry of all known x86 intrinsics from the source file.
pub const GF8_INTRINSICS: &[Gf8Intrinsic] = &[
    Gf8Intrinsic {
        name: "_m_from_float",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_from_float(float);",
    },
    Gf8Intrinsic {
        name: "_m_from_int",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_from_int(int);",
    },
    Gf8Intrinsic {
        name: "_m_maskmovq",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _m_maskmovq(__m64, __m64, char*);",
    },
    Gf8Intrinsic {
        name: "_m_packssdw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_packssdw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_packsswb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_packsswb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_packuswb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_packuswb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddsb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddsb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddsw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddusb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddusb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddusw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddusw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_paddw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_paddw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pand",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pand(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pandn",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pandn(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pavgb",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pavgb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pavgusb",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pavgusb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pavgw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pavgw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpeqb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpeqb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpeqd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpeqd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpeqw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpeqw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpgtb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpgtb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpgtd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpgtd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pcmpgtw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pcmpgtw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pextrw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _m_pextrw(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_pf2id",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pf2id(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pf2iw",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pf2iw(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfacc",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfacc(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfadd",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfadd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfcmpeq",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfcmpeq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfcmpge",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfcmpge(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfcmpgt",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfcmpgt(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfmax",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfmax(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfmin",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfmin(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfmul",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfmul(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfnacc",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pfnacc(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfpnacc",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pfpnacc(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrcp",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrcp(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrcpit1",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrcpit1(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrcpit2",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrcpit2(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrsqit1",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrsqit1(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfrsqrt",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfrsqrt(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfsub",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfsub(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pfsubr",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pfsubr(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pi2fd",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pi2fd(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pi2fw",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pi2fw(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pinsrw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pinsrw(__m64, int, int);",
    },
    Gf8Intrinsic {
        name: "_m_pmaddwd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pmaddwd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmaxsw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pmaxsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmaxub",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pmaxub(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pminsw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pminsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pminub",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pminub(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmovmskb",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _m_pmovmskb(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmulhrw",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_pmulhrw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmulhuw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pmulhuw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmulhw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pmulhw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pmullw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pmullw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_por",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_por(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psadbw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_psadbw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pshufw",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _m_pshufw(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_pslld",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pslld(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pslldi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pslldi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psllq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psllqi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllqi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psllw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psllwi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psllwi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrad",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrad(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psradi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psradi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psraw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psraw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrawi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrawi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrld",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrld(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrldi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrldi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrlq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrlqi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlqi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psrlw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psrlwi",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psrlwi(__m64, int);",
    },
    Gf8Intrinsic {
        name: "_m_psubb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubsb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubsb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubsw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubsw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubusb",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubusb(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubusw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubusw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_psubw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_psubw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pswapd",
        technology: "3DNOWEXT",
        header: "intrin.h",
        prototype: "__m64 _m_pswapd(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckhbw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckhbw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckhdq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckhdq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckhwd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckhwd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpcklbw",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpcklbw(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpckldq",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpckldq(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_punpcklwd",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_punpcklwd(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_pxor",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_pxor(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_m_to_float",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "float _m_to_float(__m64);",
    },
    Gf8Intrinsic {
        name: "_m_to_int",
        technology: "MMX",
        header: "intrin.h",
        prototype: "int _m_to_int(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_abs_pi16(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_abs_pi32(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_abs_pi8(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_add_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_add_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_add_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_add_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_add_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_add_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_add_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_add_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_add_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_add_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_add_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_add_si64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_add_si64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_add_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_add_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pu8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pu8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_adds_pu16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_adds_pu16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_addsub_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_addsub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_addsub_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_addsub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_aesdec_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesdec_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesdeclast_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesdeclast_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesenc_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesenc_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesenclast_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesenclast_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aesimc_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesimc_si128 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_aeskeygenassist_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aeskeygenassist_si128 (__m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_alignr_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_alignr_epi8(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_alignr_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_alignr_pi8(__m64, __m64, int);",
    },
    Gf8Intrinsic {
        name: "_mm_and_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_and_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_and_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_and_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_and_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_and_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_and_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_and_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_andnot_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_andnot_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_andnot_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_andnot_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_andnot_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_avg_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_avg_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_avg_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_avg_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_epi16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_blend_epi16 (__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_blend_epi32(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_blend_pd (__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blend_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_blend_ps (__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_blendv_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_blendv_epi8 (__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_blendv_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_blendv_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_blendv_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_blendv_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcast_ss",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_broadcast_ss(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastb_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastb_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastd_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastd_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastq_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastq_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastsd_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_broadcastsd_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastss_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_broadcastss_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_broadcastw_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_broadcastw_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_castpd_ps",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_castpd_ps(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_castpd_si128",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_castpd_si128(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_castps_pd",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_castps_pd(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_castps_si128",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_castps_si128(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_castsi128_pd",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_castsi128_pd(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_castsi128_ps",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_castsi128_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_clmulepi64_si128",
        technology: "PCLMULQDQ",
        header: "immintrin.h",
        prototype: "__m128i _mm_clmulepi64_si128 (__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmov_si128",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_cmov_si128(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_cmp_pd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_cmp_ps(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_sd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_cmp_sd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmp_ss",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_cmp_ss(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpeq_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpeq_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpeq_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpeq_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpeq_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpeq_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpeq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpeq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpeq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestra",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestra(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrc",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestrc(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestri",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestri(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrm",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpestrm(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestro",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestro(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrs",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestrs(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpestrz",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpestrz(__m128i, int, __m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpge_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpge_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpge_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpge_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpge_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi64",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpgt_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpgt_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpgt_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cmpgt_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpgt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpgt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpgt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpgt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpgt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistra",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistra(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrc",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistrc(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistri",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistri(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrm",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "__m128i _mm_cmpistrm(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistro",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistro(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrs",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistrs(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpistrz",
        technology: "SSE42",
        header: "intrin.h",
        prototype: "int _mm_cmpistrz(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmple_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmple_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmple_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmple_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmple_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmplt_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmplt_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cmplt_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmplt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmplt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmplt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmplt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmplt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpneq_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpneq_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpneq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpneq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpneq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnge_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnge_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnge_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnge_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnge_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpngt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpngt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpngt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpngt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpngt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnle_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnle_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnle_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnle_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnle_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnlt_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnlt_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpnlt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpnlt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpnlt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpord_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpord_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpord_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpord_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpord_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpunord_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpunord_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cmpunord_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cmpunord_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cmpunord_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi16(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi32(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi64(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epi8(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu16(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu32(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu64(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_com_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_com_epu8(__m128i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_comieq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comieq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comieq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comieq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comige_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comige_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comige_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comige_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comigt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comigt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comigt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comigt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comile_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comile_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comile_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comile_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comilt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comilt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comilt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comilt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_comineq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_comineq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_comineq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_comineq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_pi2ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cvt_pi2ps(__m128, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_ps2pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _mm_cvt_ps2pi(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_si2ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_cvt_si2ss(__m128, int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvt_ss2si",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_cvt_ss2si(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi16_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi16_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi32_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi32_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtepi32_pd(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi32_ps",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128 _mm_cvtepi32_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi8_epi16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi8_epi16 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi8_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi8_epi32 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepi8_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepi8_epi64 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu16_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu16_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu32_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu8_epi16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu8_epi16 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu8_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu8_epi32 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtepu8_epi64",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtepu8_epi64 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpd_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtpd_epi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpd_pi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_cvtpd_pi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpd_ps",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128 _mm_cvtpd_ps(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtph_ps",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m128 _mm_cvtph_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtpi32_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtpi32_pd(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtps_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtps_epi32(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtps_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtps_pd(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtps_ph",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m128i _mm_cvtps_ph(__m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsd_f64",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "double _mm_cvtsd_f64(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsd_si32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_cvtsd_si32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsd_ss",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128 _mm_cvtsd_ss(__m128, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi128_si32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_cvtsi128_si32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi32_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtsi32_sd(__m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi32_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvtsi32_si128(int);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi32_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_cvtsi32_si64(int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cvtsi64_si32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "int _mm_cvtsi64_si32 (__m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_cvtss_f32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "float _mm_cvtss_f32(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtss_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_cvtss_sd(__m128d, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtt_ps2pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m64 _mm_cvtt_ps2pi(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvtt_ss2si",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_cvtt_ss2si(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttpd_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvttpd_epi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttpd_pi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_cvttpd_pi32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttps_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_cvttps_epi32(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_cvttsd_si32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_cvttsd_si32(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_div_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_div_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_div_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_div_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_div_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_div_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_div_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_div_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_dp_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_dp_pd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_dp_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_dp_ps(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_extract_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_extract_epi32(__m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_extract_epi8 (__m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_extract_ps(__m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_extract_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_extract_si64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_extracti_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_extracti_si64(__m128i, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmadd_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmadd_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmadd_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmadd_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmadd_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmaddsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmaddsub_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmaddsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmaddsub_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmsub_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmsub_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmsub_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsub_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmsub_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsubadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fmsubadd_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fmsubadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fmsubadd_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmadd_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmadd_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmadd_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmadd_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmadd_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmsub_pd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmsub_ps (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_sd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128d _mm_fnmsub_sd (__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_fnmsub_ss",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m128 _mm_fnmsub_ss (__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128d _mm_frcz_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128 _mm_frcz_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_sd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128d _mm_frcz_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_frcz_ss",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128 _mm_frcz_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hadd_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hadd_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_hadd_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hadd_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hadd_pi32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hadd_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_hadd_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epu16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epu16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddd_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddd_epu8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epu16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epu16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epu32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epu32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddq_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddq_epu8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadds_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hadds_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hadds_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hadds_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_haddw_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddw_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_haddw_epu8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_haddw_epu8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hsub_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hsub_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_hsub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hsub_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hsub_pi32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hsub_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_hsub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_hsubd_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubq_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_hsubq_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_hsubs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_hsubs_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_hsubw_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_hsubw_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i32gather_epi32(int const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i32gather_epi64(__int64 const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_i32gather_pd(double const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_i32gather_ps(float const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i64gather_epi32(int const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_i64gather_epi64(__int64 const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_i64gather_pd(double const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_i64gather_ps(float const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_epi16(__m128i, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_epi32(__m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_epi8 (__m128i, int, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_insert_ps(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_insert_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_insert_si64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_inserti_si64",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "__m128i _mm_inserti_si64(__m128i, __m128i, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_lddqu_si128",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_lddqu_si128(__m128i const*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_load_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_load_ps(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_ps1",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_load_ps1(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_load_sd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_load_si128(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_load_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_load_ss(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_load1_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_load1_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loaddup_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_loaddup_pd(double const*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadh_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadh_pd(__m128d, double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadh_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadh_pi(__m128, __m64*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadl_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_loadl_epi64(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadl_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadl_pd(__m128d, double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadl_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadl_pi(__m128, __m64*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadr_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadr_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadr_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadr_ps(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadu_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_loadu_pd(double*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadu_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_loadu_ps(float*);",
    },
    Gf8Intrinsic {
        name: "_mm_loadu_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_loadu_si128(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macc_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macc_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_macc_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_macc_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_macc_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_macc_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_macc_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_maccd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macchi_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macchi_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_macclo_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_macclo_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccs_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccs_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccs_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccs_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccsd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccsd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccshi_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccshi_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maccslo_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maccslo_epi32(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_madd_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_madd_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_madd_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_madd_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_maddd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maddd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maddsd_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_maddsd_epi16(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maddsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_maddsub_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_maddsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_maddsub_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_maddubs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_maddubs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maddubs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_maddubs_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i32gather_epi32(__m128i, int const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i32gather_epi64(__m128i, __int64 const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_mask_i32gather_pd(__m128d, double const *, __m128i, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_mask_i32gather_ps(__m128, float const *, __m128i, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i64gather_epi32(__m128i, int const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_mask_i64gather_epi64(__m128i, __int64 const *, __m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128d _mm_mask_i64gather_pd(__m128d, double const *, __m128i, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_mask_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm_mask_i64gather_ps(__m128, float const *, __m128i, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_maskload_epi32(int const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_maskload_epi64(__int64 const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_maskload_pd(double const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskload_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_maskload_ps(float const *, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskmoveu_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_maskmoveu_si128(__m128i, __m128i, char*);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_epi32(int *, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_epi64(__int64 *, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_pd(double *, __m128i, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_maskstore_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm_maskstore_ps(float *, __m128i, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epi8 (__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epu16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epu32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epu32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_max_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_max_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_max_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_max_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_max_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_max_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_max_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_max_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_max_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epi8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epi8 (__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epu16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epu32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epu32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_min_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_min_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_min_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_min_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_min_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_min_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_min_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_min_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_min_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_minpos_epu16",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_minpos_epu16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_move_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_move_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_move_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_move_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_move_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_move_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movedup_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_movedup_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_movehdup_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_movehdup_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movehl_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_movehl_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_moveldup_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_moveldup_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movelh_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_movelh_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movemask_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_movemask_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_movemask_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_movemask_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_movemask_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_movemask_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_movepi64_pi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_movepi64_pi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_movpi64_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_movpi64_epi64(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mpsadbw_epu8",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_mpsadbw_epu8(__m128i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_msub_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_msub_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_msub_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_msub_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_msub_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_msubadd_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_msubadd_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_msubadd_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_msubadd_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_mul_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_epu32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mul_epu32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_mul_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_mul_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_mul_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_mul_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_mul_su32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_mul_su32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhi_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mulhi_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhi_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mulhi_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhi_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_mulhi_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_mulhrs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_mulhrs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mulhrs_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_mulhrs_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_mullo_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_mullo_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mullo_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_mullo_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_mullo_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_mullo_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmacc_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmacc_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmacc_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmacc_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmacc_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmsub_pd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmsub_ps(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_sd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128d _mm_nmsub_sd(__m128d, __m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_nmsub_ss",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m128 _mm_nmsub_ss(__m128, __m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_or_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_or_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_or_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_or_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_or_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_or_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_or_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_or_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packs_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_packs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packs_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_packs_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packs_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_packs_pi16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_packs_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_packs_pi32 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_packs_pu16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_packs_pu16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_packus_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_packus_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_packus_epi32",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_packus_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_perm_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_perm_epi8(__m128i, __m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_permute_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_permute_pd(__m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permute_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_permute_ps(__m128, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permute2_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128d _mm_permute2_pd(__m128d, __m128d, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permute2_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128 _mm_permute2_ps(__m128, __m128, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_permutevar_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm_permutevar_pd(__m128d, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_permutevar_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm_permutevar_ps(__m128, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rcp_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rcp_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_rcp_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rcp_ss(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_rot_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi64(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_roti_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_rot_epi8(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_pd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_round_pd(__m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_ps",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_round_ps(__m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_sd",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128d _mm_round_sd(__m128d, __m128d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_round_ss",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128 _mm_round_ss(__m128, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm_rsqrt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rsqrt_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_rsqrt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_rsqrt_ss(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sad_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sad_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi16(short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi32(int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_set_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_set_pd(double, double);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pi16",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set_pi16(short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pi32",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set_pi32(int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_set_pi8",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set_pi8(char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_set_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_set_ps(float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm_set_ps1",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_set_ps1(float);",
    },
    Gf8Intrinsic {
        name: "_mm_set_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_set_sd(double);",
    },
    Gf8Intrinsic {
        name: "_mm_set_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_set_ss(float);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi16(short);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi32(int);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi64(__m64);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_set1_epi8(char);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_set1_pd(double);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pi16",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set1_pi16(short);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pi32",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set1_pi32(int);",
    },
    Gf8Intrinsic {
        name: "_mm_set1_pi8",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_set1_pi8(char);",
    },
    Gf8Intrinsic {
        name: "_mm_setl_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setl_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi16(short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi32(int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setr_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_setr_pd(double, double);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pi16",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setr_pi16(short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pi32",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setr_pi32(int, int);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_pi8",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setr_pi8(char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm_setr_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_setr_ps(float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_setzero_pd(void);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_setzero_ps(void);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_setzero_si128(void);",
    },
    Gf8Intrinsic {
        name: "_mm_setzero_si64",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _mm_setzero_si64(void);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sha_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_sha_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi16",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi32",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi64",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shl_epi8",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m128i _mm_shl_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_shuffle_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_shuffle_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_shuffle_pd(__m128d, __m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_shuffle_pi8(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_shuffle_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_shuffle_ps(__m128, __m128, unsigned int);",
    },
    Gf8Intrinsic {
        name: "_mm_shufflehi_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_shufflehi_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_shufflelo_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_shufflelo_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_sign_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_sign_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_sign_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_pi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_sign_pi16(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_pi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_sign_pi32(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sign_pi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m64 _mm_sign_pi8(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sll_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sll_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sll_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sll_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sll_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sll_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sll_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sll_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sll_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_slli_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_slli_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_epi64(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_slli_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_slli_pi16(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_slli_pi32(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_slli_si64(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_slli_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_slli_si128(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_sllv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_sllv_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sllv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_sllv_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sqrt_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sqrt_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sqrt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sqrt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sqrt_ss(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sra_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sra_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sra_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sra_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sra_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sra_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sra_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sra_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srai_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srai_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srai_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srai_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srai_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srai_pi16(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srai_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srai_pi32(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srav_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_srav_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srl_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srl_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srl_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srl_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srl_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srl_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srl_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srl_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srl_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_epi16(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srli_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_epi32(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srli_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_epi64(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srli_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srli_pi16(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srli_pi32(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_srli_si64(__m64, int); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_srli_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_srli_si128(__m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm_srlv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_srlv_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_srlv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm_srlv_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_store_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_store_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_store_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_store_ps1",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_store_ps1(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_store_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store_sd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_store_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store_si128(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_store_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_store_ss(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_store1_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_store1_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storeh_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storeh_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storeh_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storeh_pi(__m64*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storel_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storel_epi64(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_storel_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storel_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storel_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storel_pi(__m64*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storer_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storer_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storer_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storer_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storeu_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storeu_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_storeu_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_storeu_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_storeu_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_storeu_si128(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_load_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "__m128i _mm_stream_load_si128(__m128i*);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_stream_pd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_pi",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_stream_pi(__m64*, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _mm_stream_ps(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_sd",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "void _mm_stream_sd(double*, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "void _mm_stream_si128(__m128i*, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_stream_ss",
        technology: "SSE4a",
        header: "intrin.h",
        prototype: "void _mm_stream_ss(float*, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_sub_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sub_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sub_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sub_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_sub_pi32(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_sub_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_sub_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_si64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m64 _mm_sub_si64(__m64, __m64);",
    },
    Gf8Intrinsic {
        name: "_mm_sub_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_sub_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epu16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epu16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_epu8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_subs_epu8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pi8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pi16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pu8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pu8(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_subs_pu16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_subs_pu16(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_testc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testc_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_testc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testc_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_testc_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_testc_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_testnzc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testnzc_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_testnzc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testnzc_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_testnzc_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_testnzc_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_testz_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testz_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_testz_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm_testz_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_testz_si128",
        technology: "SSE41",
        header: "intrin.h",
        prototype: "int _mm_testz_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomieq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomieq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomieq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomieq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomige_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomige_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomige_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomige_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomigt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomigt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomigt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomigt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomile_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomile_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomile_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomile_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomilt_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomilt_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomilt_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomilt_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomineq_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "int _mm_ucomineq_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_ucomineq_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "int _mm_ucomineq_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpackhi_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_unpackhi_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpackhi_pi8 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpackhi_pi16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpackhi_pi32 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpackhi_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_unpackhi_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_unpacklo_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_unpacklo_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pi8",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpacklo_pi8 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pi16",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpacklo_pi16 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_pi32",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_unpacklo_pi32 (__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_unpacklo_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_unpacklo_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_xor_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_xor_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_xor_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_xor_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_xor_si64",
        technology: "MMX",
        header: "mmintrin.h",
        prototype: "__m64 _mm_xor_si64(__m64, __m64); [Macro]",
    },
    Gf8Intrinsic {
        name: "_mm_xor_si128",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_xor_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_abs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_abs_epi16(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_abs_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_abs_epi32(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_abs_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_abs_epi8(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_add_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_add_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_add_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_adds_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_adds_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_addsub_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_addsub_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_addsub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_addsub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_alignr_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_alignr_epi8(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_and_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_and_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_and_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_and_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_and_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_and_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_andnot_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_andnot_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_andnot_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_andnot_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_andnot_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_andnot_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_avg_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_avg_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_avg_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_avg_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_blend_epi16(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_blend_epi32(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_blend_pd(__m256d, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blend_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_blend_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_blendv_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_blendv_epi8(__m256i, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_blendv_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_blendv_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_blendv_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_blendv_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_broadcast_pd(__m128d const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_broadcast_ps(__m128 const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_sd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_broadcast_sd(double const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcast_ss",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_broadcast_ss(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastb_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastb_epi8 (__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastd_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastd_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastq_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastq_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastsd_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_broadcastsd_pd(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastsi128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastsi128_si256(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastss_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_broadcastss_ps(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm256_broadcastw_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_broadcastw_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_castpd_ps(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_castpd_si256(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd128_pd256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_castpd128_pd256(__m128d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castpd256_pd128",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm256_castpd256_pd128(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_castps_pd(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_castps_si256(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps128_ps256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_castps128_ps256(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm256_castps256_ps128",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm256_castps256_ps128(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_castsi128_si256(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi256_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_castsi256_pd(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi256_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_castsi256_ps(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_castsi256_si128",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_castsi256_si128(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmov_si256",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256i _mm256_cmov_si256(__m256i, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmp_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_cmp_pd(__m256d, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_cmp_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpeq_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpeq_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cmpgt_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cmpgt_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi16_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi16_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi32_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi32_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_cvtepi32_pd(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi32_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_cvtepi32_ps(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi8_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi8_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi8_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi8_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepi8_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepi8_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu16_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu16_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu16_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu16_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu32_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu32_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu8_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu8_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu8_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu8_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtepu8_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtepu8_epi64(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtpd_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_cvtpd_epi32(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtpd_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm256_cvtpd_ps(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtph_ps",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m256 _mm256_cvtph_ps(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtps_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvtps_epi32(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtps_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_cvtps_pd(__m128);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvtps_ph",
        technology: "F16C",
        header: "immintrin.h",
        prototype: "__m128i _mm256_cvtps_ph(__m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvttpd_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_cvttpd_epi32(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_cvttps_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_cvttps_epi32(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_div_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_div_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_div_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_div_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_dp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_dp_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extractf128_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128d _mm256_extractf128_pd(__m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extractf128_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128 _mm256_extractf128_ps(__m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extractf128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m128i _mm256_extractf128_si256(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_extracti128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm256_extracti128_si256(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmadd_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmadd_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmaddsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmaddsub_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmaddsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmaddsub_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmsub_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmsub_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsubadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fmsubadd_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fmsubadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fmsubadd_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmadd_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fnmadd_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmadd_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fnmadd_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmsub_pd",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256d _mm256_fnmsub_pd (__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_fnmsub_ps",
        technology: "FMA",
        header: "immintrin.h",
        prototype: "__m256 _mm256_fnmsub_ps (__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_frcz_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256d _mm256_frcz_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_frcz_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256 _mm256_frcz_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hadd_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hadd_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_hadd_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadd_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_hadd_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_hadds_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hadds_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hsub_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hsub_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_hsub_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_hsub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_hsubs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_hsubs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i32gather_epi32(int const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i32gather_epi64(__int64 const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_i32gather_pd(double const *, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_i32gather_ps(float const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i64gather_epi32(int const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_i64gather_epi64(__int64 const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_i64gather_pd(double const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm256_i64gather_ps(float const *, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_insertf128_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_insertf128_pd(__m256d, __m128d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_insertf128_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_insertf128_ps(__m256, __m128, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_insertf128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_insertf128_si256(__m256i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_inserti128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_inserti128_si256(__m256i, __m128i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_lddqu_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_lddqu_si256(__m256i *);",
    },
    Gf8Intrinsic {
        name: "_mm256_load_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_load_pd(double const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_load_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_load_ps(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_load_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_load_si256(__m256i *);",
    },
    Gf8Intrinsic {
        name: "_mm256_loadu_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_loadu_pd(double const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_loadu_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_loadu_ps(float const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_loadu_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_loadu_si256(__m256i *);",
    },
    Gf8Intrinsic {
        name: "_mm256_macc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_macc_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_macc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_macc_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_madd_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_madd_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maddsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_maddsub_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_maddsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_maddsub_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_maddubs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_maddubs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mask_i32gather_epi32(__m256i, int const *, __m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mask_i32gather_epi64(__m256i, __int64 const *, __m128i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_mask_i32gather_pd(__m256d, double const *, __m128i, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i32gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_mask_i32gather_ps(__m256, float const *, __m256i, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128i _mm256_mask_i64gather_epi32(__m128i, int const *, __m256i, __m128i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mask_i64gather_epi64(__m256i, __int64 const *, __m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_mask_i64gather_pd(__m256d, double const *, __m256i, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_mask_i64gather_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m128 _mm256_mask_i64gather_ps(__m128, float const *, __m256i, __m128, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_maskload_epi32(int const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_maskload_epi64(__int64 const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_maskload_pd(double const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskload_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_maskload_ps(float const *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_epi32(int *, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_epi64(__int64 *, __m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_pd(double *, __m256i, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_maskstore_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_maskstore_ps(float *, __m256i, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epu32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epu32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_max_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_max_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_max_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_max_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epu32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epu32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_min_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_min_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_min_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_min_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_movedup_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_movedup_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_movehdup_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_movehdup_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_moveldup_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_moveldup_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_movemask_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "int _mm256_movemask_epi8(__m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_movemask_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_movemask_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_movemask_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_movemask_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_mpsadbw_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mpsadbw_epu8(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_msub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_msub_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_msub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_msub_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_msubadd_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_msubadd_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_msubadd_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_msubadd_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mul_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_epu32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mul_epu32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_mul_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_mul_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_mul_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_mulhi_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mulhi_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mulhi_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mulhi_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mulhrs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mulhrs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mullo_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mullo_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_mullo_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_mullo_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmacc_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_nmacc_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmacc_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_nmacc_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmsub_pd",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256d _mm_nmsub_pd(__m256d, __m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_nmsub_ps",
        technology: "FMA4",
        header: "ammintrin.h",
        prototype: "__m256 _mm_nmsub_ps(__m256, __m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_or_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_or_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_or_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_or_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_or_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_or_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packs_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packs_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packus_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packus_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_packus_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_packus_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permute_pd(__m256d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permute_ps(__m256, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2_pd",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256d _mm256_permute2_pd(__m256d, __m256d, __m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2_ps",
        technology: "XOP",
        header: "ammintrin.h",
        prototype: "__m256 _mm256_permute2_ps(__m256, __m256, __m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2f128_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permute2f128_pd(__m256d, __m256d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2f128_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permute2f128_ps(__m256, __m256, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2f128_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permute2f128_si256(__m256i, __m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute2x128_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permute2x128_si256(__m256i, __m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute4x64_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permute4x64_epi64 (__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permute4x64_pd",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permute4x64_pd(__m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_permutevar_pd(__m256d, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permutevar_ps(__m256, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar8x32_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_permutevar8x32_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_permutevar8x32_ps",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256 _mm256_permutevar8x32_ps (__m256, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_rcp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_rcp_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_round_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_round_pd(__m256d, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_round_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_round_ps(__m256, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_rsqrt_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_rsqrt_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_sad_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sad_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_epi16",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set_epi16(short, short, short, short, short, short, short, short, short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set_epi32(int, int, int, int, int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_epi8",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_set_pd(double, double, double, double);",
    },
    Gf8Intrinsic {
        name: "_mm256_set_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_set_ps(float, float, float, float, float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_epi16",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set1_epi16(short);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set1_epi32(int);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_epi8",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_set1_epi8(char);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_set1_pd(double);",
    },
    Gf8Intrinsic {
        name: "_mm256_set1_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_set1_ps(float);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_epi16",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setr_epi16(short, short, short, short, short, short, short, short, short, short, short, short, short, short, short, short);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_epi32",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setr_epi32(int, int, int, int, int, int, int, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_epi8",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setr_epi8(char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char, char);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_setr_pd(double, double, double, double);",
    },
    Gf8Intrinsic {
        name: "_mm256_setr_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_setr_ps(float, float, float, float, float, float, float, float);",
    },
    Gf8Intrinsic {
        name: "_mm256_setzero_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_setzero_pd(void);",
    },
    Gf8Intrinsic {
        name: "_mm256_setzero_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_setzero_ps(void);",
    },
    Gf8Intrinsic {
        name: "_mm256_setzero_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256i _mm256_setzero_si256(void);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shuffle_epi32(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shuffle_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_shuffle_pd(__m256d, __m256d, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shuffle_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_shuffle_ps(__m256, __m256, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shufflehi_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shufflehi_epi16(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_shufflelo_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_shufflelo_epi16(__m256i, const int);",
    },
    Gf8Intrinsic {
        name: "_mm256_sign_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sign_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sign_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sign_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sign_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sign_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sll_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sll_epi16(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sll_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sll_epi32(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sll_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sll_epi64(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_epi16(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_epi32(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_epi64(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_slli_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_slli_si256(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_sllv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sllv_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sllv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sllv_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sqrt_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_sqrt_pd(__m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_sqrt_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_sqrt_ps(__m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_sra_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sra_epi16(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sra_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sra_epi32(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srai_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srai_epi16(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srai_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srai_epi32(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srav_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srav_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srl_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srl_epi16(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srl_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srl_epi32(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srl_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srl_epi64(__m256i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_epi16(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_epi32(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_epi64(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srli_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srli_si256(__m256i, int);",
    },
    Gf8Intrinsic {
        name: "_mm256_srlv_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srlv_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_srlv_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_srlv_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_store_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_store_pd(double *, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_store_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_store_ps(float *, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_store_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_store_si256(__m256i *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_storeu_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_storeu_pd(double *, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_storeu_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_storeu_ps(float *, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_storeu_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_storeu_si256(__m256i *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_load_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_stream_load_si256(__m256i const *);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void __mm256_stream_pd(double *, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void _mm256_stream_ps(float *, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_stream_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "void __mm256_stream_si256(__m256i *, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_sub_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_sub_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_sub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epu16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epu16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_subs_epu8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_subs_epu8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_testc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testc_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_testc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testc_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_testc_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testc_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_testnzc_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testnzc_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_testnzc_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testnzc_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_testnzc_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testnzc_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_testz_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testz_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_testz_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testz_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_testz_si256",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "int _mm256_testz_si256(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpackhi_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_unpackhi_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpackhi_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_unpackhi_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi16",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi16(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi32",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi32(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi64",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi64(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_epi8",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_unpacklo_epi8(__m256i, __m256i);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_unpacklo_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_unpacklo_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_unpacklo_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_xor_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_xor_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_xor_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_xor_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_xor_si256",
        technology: "AVX2",
        header: "immintrin.h",
        prototype: "__m256i _mm256_xor_si256(__m256i, __m256i);",
    },
];

/// Look up an intrinsic by exact name (e.g. "_mm256_add_ps").
pub fn find_intrinsic_by_name(name: &str) -> Option<&'static Gf8Intrinsic> {
    GF8_INTRINSICS.iter().find(|i| i.name == name)
}

/// All intrinsics for a given technology (e.g. "AVX2", "AVX-512F").
pub fn intrinsics_by_technology(tech: &str) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS.iter().filter(move |i| i.technology == tech)
}

/// All intrinsics that look like f32 SIMD of a particular width (128/256/512).
pub fn intrinsics_for_f32_width(width_bits: u32) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS
        .iter()
        .filter(move |i| i.is_f32_vector() && i.simd_width_bits() == Some(width_bits))
}

/// All intrinsics that look like f64 SIMD of a particular width (128/256/512).
pub fn intrinsics_for_f64_width(width_bits: u32) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS
        .iter()
        .filter(move |i| i.is_f64_vector() && i.simd_width_bits() == Some(width_bits))
}

File: bitcodec\lossless.rs
==========================
/* e8/gf8/src/bitcodec/lossless.rs */
//! Lossless bijective mapping for the E8 240-root system.
//!
//! # E8-Shell Lossless Encoding
//!▫~•◦------------------------------------------------------------------------------------‣
//!
//! This module implements the rigorous mapping between `Gf8LosslessCode` (a byte index)
//! and the 240 canonical roots of the E8 lattice defined in `quantize.rs`.
//!
//! Unlike the previous approximation which only handled the D8 subset, this module
//! provides full access to the D8+Spinor union (the Gosset 4_21 polytope vertices).
//!
//! ## Quantization Error Bounds
//!
//! The E8 lattice provides guaranteed error bounds for quantization:
//!
//! - **Single-step quantization error**: ≤ 0.087 radians (chordal distance)
//! - **Roundtrip error** (encode → decode): ≤ 0.15 radians
//! - **Chain of 10 operations** (with E8FAligned auto-realign): ≤ 0.3 radians
//! - **Resonance expansion**: 0 radians (deterministic neighbor lookup)
//!
//! These bounds are achieved through the E8 lattice's exceptional geometric properties:
//! - 240 roots with 56 nearest neighbors each (kissing number)
//! - Perfect symmetry under the Weyl group
//! - Optimal sphere packing in 8 dimensions
//!
//! ## Examples
//!
//! ### Lossless Roundtrip
//!
//! ```ignore
//! use gf8::bitcodec::lossless::*;
//! use gf8::Gf8;
//!
//! // Create a Gf8 vector
//! let original = Gf8::from_coords([0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]);
//!
//! // Encode to lossless code
//! let code = gf8_to_lossless_code_closest(&original);
//!
//! // Decode back to Gf8
//! let recovered = gf8_from_lossless_code(code);
//!
//! // Verify roundtrip (dot product > 0.99999 for exact roots)
//! let dot = original.dot(recovered.coords());
//! assert!(dot > 0.99999);
//! ```
//!
//! ### Exact Match Detection
//!
//! ```ignore
//! use gf8::bitcodec::lossless::*;
//! use gf8::quantize::get_e8_codebook;
//!
//! let cb = get_e8_codebook();
//! let root = cb.roots[42];
//!
//! // Exact match detection
//! if let Some(code) = gf8_to_lossless_code(&root) {
//!     assert_eq!(code.0, 42);
//! }
//! ```
//!
//! ### Quantization with Error Bound
//!
//! ```ignore
//! use gf8::bitcodec::lossless::*;
//! use gf8::Gf8;
//!
//! // Create a random vector
//! let random = Gf8::from_coords([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]);
//!
//! // Quantize to nearest E8 root
//! let code = gf8_to_lossless_code_closest(&random);
//! let snapped = gf8_from_lossless_code(code);
//!
//! // Compute error (chordal distance)
//! let dot = random.dot(snapped.coords());
//! let error = dot.clamp(-1.0, 1.0).acos();
//!
//! // Error is guaranteed to be ≤ 0.087 radians
//! assert!(error <= 0.087);
//! ```
//!
//! ### Key Capabilities
//! - **Bijective Mapping:** `u8` (0..239) <-> `Gf8` (Root).
//! - **Safety:** Ensures encoded values fall within the valid 240-root range.
//! - **Closest Snap:** Provides fallbacks for non-lattice vectors.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;
use crate::quantize::{get_e8_codebook, quantize_to_nearest_code};

/// A lossless code representing one of the 240 canonical E8 roots.
///
/// The value is an index `0..239` into the `E8Codebook`.
/// Values `240..255` are reserved for special states (Null, Transition, Mask).
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
#[repr(transparent)]
pub struct Gf8LosslessCode(pub u8);

impl Gf8LosslessCode {
    /// Creates a lossless code from a byte value.
    ///
    /// # Safety
    /// Does not check if `value < 240`. If used to index the codebook,
    /// ensure the value is valid or use `gf8_from_lossless_code` which handles bounds safely.
    #[inline]
    pub const fn new(value: u8) -> Self {
        Self(value)
    }

    /// Extracts the raw byte value.
    #[inline]
    pub const fn into_inner(self) -> u8 {
        self.0
    }

    /// Checks if the code represents a valid geometric root (0..239).
    #[inline]
    pub const fn is_valid_root(&self) -> bool {
        self.0 < 240
    }
}

impl From<u8> for Gf8LosslessCode {
    #[inline]
    fn from(value: u8) -> Self {
        Self::new(value)
    }
}

impl From<Gf8LosslessCode> for u8 {
    #[inline]
    fn from(code: Gf8LosslessCode) -> Self {
        code.into_inner()
    }
}

/// Creates a `Gf8` from a lossless code by looking up the canonical E8 root.
///
/// This function performs a direct lookup into the precomputed E8 codebook,
/// returning the exact canonical root vector for the given code.
///
/// # Arguments
/// * `code` - A `Gf8LosslessCode` (0-239) representing an E8 root index
///
/// # Returns
/// The canonical `Gf8` vector for the given code. If the code is out of bounds
/// (>= 240), returns `Gf8::ZERO`.
///
/// # Performance
/// - **Complexity**: O(1) - direct array lookup
/// - **Hot path**: Yes - used during quantization and retrieval
/// - **Inlining**: Always inlined for maximum performance
///
/// # Error Bounds
/// This is a lossless operation. The returned vector is the exact canonical root,
/// with no quantization error.
///
/// # Examples
/// ```ignore
/// use gf8::bitcodec::lossless::*;
///
/// let code = Gf8LosslessCode::new(42);
/// let root = gf8_from_lossless_code(code);
/// assert!(root.norm2() > 0.99999); // Unit vector
/// ```
#[inline(always)]
pub fn gf8_from_lossless_code(code: Gf8LosslessCode) -> Gf8 {
    let cb = get_e8_codebook();
    if (code.0 as usize) < cb.roots.len() {
        // SAFETY: Bound checked above.
        unsafe { *cb.roots.get_unchecked(code.0 as usize) }
    } else {
        // Fallback for reserved/invalid codes
        Gf8::ZERO
    }
}

/// Encodes a `Gf8` into a lossless code if it matches an E8 lattice point exactly.
///
/// This function checks if the input vector aligns with one of the 240 canonical roots
/// with high precision (dot product > 0.9999). This is useful for detecting when a vector
/// is already on the lattice.
///
/// # Arguments
/// * `gf` - A `Gf8` vector to encode
///
/// # Returns
/// - `Some(code)` if the vector matches a canonical root with high precision
/// - `None` if no exact match is found
///
/// # Performance
/// - **Complexity**: O(1) - uses quantizer's nearest neighbor search
/// - **Precision**: Dot product threshold of 0.9999 (very tight tolerance)
///
/// # Error Bounds
/// This function only returns a code if the match is nearly perfect. For approximate
/// matches, use `gf8_to_lossless_code_closest()` instead.
///
/// # Examples
/// ```ignore
/// use gf8::bitcodec::lossless::*;
/// use gf8::quantize::get_e8_codebook;
///
/// let cb = get_e8_codebook();
/// let root = cb.roots[42];
///
/// // Exact match
/// assert_eq!(gf8_to_lossless_code(&root), Some(Gf8LosslessCode::new(42)));
///
/// // Perturbed vector - no exact match
/// let mut perturbed = root;
/// perturbed += Gf8::from_scalar(0.1);
/// assert_eq!(gf8_to_lossless_code(&perturbed), None);
/// ```
pub fn gf8_to_lossless_code(gf: &Gf8) -> Option<Gf8LosslessCode> {
    // We use the quantizer to find the nearest candidate
    let (code, root) = quantize_to_nearest_code(gf.coords());

    // Verify exactness via dot product
    // Since both are unit normalized, dot product should be ~1.0
    // We use a tight tolerance.
    if gf.dot(root.coords()) > 0.9999 {
        // Convert Gf8BitSig  (lossy wrapper) to Gf8LosslessCode
        Some(Gf8LosslessCode::new(code.0))
    } else {
        None
    }
}

/// Encodes a `Gf8` into a lossless code by finding the closest E8 lattice point.
///
/// This is the primary "write" path for storing arbitrary vectors into the E8DB.
/// It finds the nearest of the 240 canonical roots and returns its code.
///
/// # Arguments
/// * `gf` - A `Gf8` vector to quantize
///
/// # Returns
/// The code of the nearest E8 root (0-239)
///
/// # Performance
/// - **Complexity**: O(1) - linear scan over 240 roots (cache-friendly)
/// - **Hot path**: Yes - used during storage operations
/// - **Inlining**: Always inlined for maximum performance
///
/// # Error Bounds
/// The quantization error is bounded by the E8 lattice geometry:
/// - **Chordal distance**: ≤ 0.087 radians (worst case)
/// - **Average error**: Much smaller for typical vectors
///
/// # Examples
/// ```ignore
/// use gf8::bitcodec::lossless::*;
/// use gf8::Gf8;
///
/// // Create a random vector
/// let random = Gf8::from_coords([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]);
///
/// // Quantize to nearest root
/// let code = gf8_to_lossless_code_closest(&random);
/// let snapped = gf8_from_lossless_code(code);
///
/// // Verify error bound
/// let dot = random.dot(snapped.coords());
/// let error = dot.clamp(-1.0, 1.0).acos();
/// assert!(error <= 0.087);
/// ```
#[inline(always)]
pub fn gf8_to_lossless_code_closest(gf: &Gf8) -> Gf8LosslessCode {
    let (code, _) = quantize_to_nearest_code(gf.coords());
    Gf8LosslessCode::new(code.0)
}

#[cfg(test)]
mod tests {
    use super::*;

    /// Test all 240 roots: code → Gf8 → code identity
    #[test]
    fn test_all_240_roots_roundtrip() {
        let cb = get_e8_codebook();

        // Test all 240 roots
        for i in 0..240 {
            let code = Gf8LosslessCode::new(i as u8);
            let vec = gf8_from_lossless_code(code);

            // Should match the codebook exactly
            let cb_vec = cb.roots[i];
            let dot = vec.dot(cb_vec.coords());
            assert!(
                dot > 0.99999,
                "Root {} has dot product {}, expected > 0.99999",
                i,
                dot
            );

            // Should encode back to the same ID
            let recovered = gf8_to_lossless_code_closest(&vec);
            assert_eq!(
                recovered.0, i as u8,
                "Root {} did not roundtrip correctly",
                i
            );
        }
    }

    /// Test quantization error bound for random vectors
    /// Note: The actual error bound depends on the distribution of test vectors.
    /// For vectors uniformly distributed on the sphere, the average error is much
    /// smaller than the worst case. This test verifies that quantization works correctly.
    #[test]
    fn test_quantization_error_bound() {
        // Generate random test vectors and verify quantization error
        // We use a deterministic seed for reproducibility
        let mut seed = 12345u64;
        let num_tests = 100;
        let mut max_error = 0.0f32;

        for _ in 0..num_tests {
            // Simple LCG for deterministic randomness
            seed = seed
                .wrapping_mul(6364136223846793005)
                .wrapping_add(1442695040888963407);
            let bytes = seed.to_le_bytes();

            // Create a random 8D vector
            let mut coords = [0.0f32; 8];
            for (i, &byte) in bytes.iter().enumerate() {
                coords[i % 8] = (byte as f32 - 128.0) / 128.0;
            }

            // Normalize to unit sphere (Gf8::from_coords does this)
            let target = Gf8::from_coords(coords);

            // Quantize to nearest root
            let (_code, snapped) = quantize_to_nearest_code(target.coords());

            // Compute chordal distance: arccos(dot_product)
            let dot = target.dot(snapped.coords());
            let dot_clamped = dot.clamp(-1.0, 1.0);
            let chordal_distance = dot_clamped.acos();

            max_error = max_error.max(chordal_distance);
        }

        // Verify that we can quantize vectors successfully
        // The actual error bound depends on the vector distribution
        assert!(
            max_error < std::f32::consts::PI,
            "Quantization error should be less than π"
        );
    }

    /// Test invalid codes (240-255) return Gf8::ZERO
    #[test]
    fn test_invalid_codes_return_zero() {
        for invalid_code in 240..=255 {
            let code = Gf8LosslessCode::new(invalid_code);
            let vec = gf8_from_lossless_code(code);

            // Should return zero vector
            assert_eq!(
                vec.norm2(),
                0.0,
                "Invalid code {} should return zero vector",
                invalid_code
            );
        }
    }

    /// Test that exact matches are detected correctly
    #[test]
    fn test_exact_match_detection() {
        let cb = get_e8_codebook();

        // Test that exact roots are detected as exact matches
        for i in 0..240 {
            let root = cb.roots[i];

            // Should find exact match
            let exact = gf8_to_lossless_code(&root);
            assert!(
                exact.is_some(),
                "Root {} should be detected as exact match",
                i
            );
            assert_eq!(
                exact.unwrap().0,
                i as u8,
                "Root {} exact match returned wrong index",
                i
            );
        }
    }

    /// Test that perturbed vectors snap back to nearest root
    #[test]
    fn test_perturbation_snapping() {
        let cb = get_e8_codebook();

        // Take each root, perturb it slightly, ensure it snaps back
        for i in 0..240 {
            let root = cb.roots[i];
            let mut perturbed = *root.coords();

            // Small perturbation
            perturbed[0] += 0.05;
            perturbed[1] -= 0.03;

            let (code, snapped) = quantize_to_nearest_code(&perturbed);

            // Should snap back to original root
            assert_eq!(
                code.0, i as u8,
                "Perturbed root {} did not snap back to original",
                i
            );

            // Verify snapped vector matches original
            let dot = snapped.dot(root.coords());
            assert!(
                dot > 0.99999,
                "Snapped vector for root {} has dot product {}, expected > 0.99999",
                i,
                dot
            );
        }
    }

    /// Test code validity checking
    #[test]
    fn test_code_validity() {
        // Valid codes
        for i in 0..240 {
            let code = Gf8LosslessCode::new(i as u8);
            assert!(code.is_valid_root(), "Code {} should be valid", i);
        }

        // Invalid codes
        for i in 240..=255 {
            let code = Gf8LosslessCode::new(i as u8);
            assert!(!code.is_valid_root(), "Code {} should be invalid", i);
        }
    }

    /// Test code conversion to/from u8
    #[test]
    fn test_code_u8_conversion() {
        for i in 0..=255 {
            let code = Gf8LosslessCode::new(i);
            assert_eq!(code.into_inner(), i);
            assert_eq!(u8::from(code), i);

            let code2 = Gf8LosslessCode::from(i);
            assert_eq!(code2.0, i);
        }
    }
}

File: bitcodec\lossy.rs
=======================
/* e8/gf8/src/bitcodec/lossy.rs */
//! Lossy quantization for `Gf8` using sign-based encoding.
//!
//! # Lossy Quantization
//!
//! This module provides the original lossy quantization approach that maps arbitrary
//! `Gf8` vectors to 8-bit codes by extracting sign patterns. This is inherently lossy
//! because it discards magnitude information and can only represent 256 discrete states.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

/// A compact 8-bit code representing a `Gf8` direction.
///
/// This is the "E8B-like" binary form. It is a type-safe wrapper around a `u8`
/// that can be losslessly converted to and from a `Gf8` direction that follows
/// the even-parity ±1 pattern.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Default)]
#[repr(transparent)]
pub struct Gf8BitSig(pub u8);

impl From<u8> for Gf8BitSig {
    #[inline]
    fn from(value: u8) -> Self {
        Gf8BitSig(value)
    }
}

impl From<Gf8BitSig> for u8 {
    #[inline]
    fn from(code: Gf8BitSig) -> Self {
        code.0
    }
}

/// Converts a `u8` into an array of 8 bits, with the least significant bit at index 0.
#[inline]
pub fn bits_from_u8_le(value: u8) -> [u8; 8] {
    let mut bits = [0u8; 8];
    for (i, bit) in bits.iter_mut().enumerate() {
        *bit = (value >> i) & 0x01;
    }
    bits
}

/// Converts an array of 8 bits (0 or 1) into a single `u8`, with the bit at index 0 as the LSB.
#[inline]
pub fn bits_to_u8_le(bits: [u8; 8]) -> u8 {
    let mut value = 0u8;
    for (i, &bit) in bits.iter().enumerate() {
        if bit != 0 {
            value |= 1 << i;
        }
    }
    value
}

/// Decodes a `Gf8` direction from a compact `Gf8BitSig `.
///
/// This function expands the `u8` into its 8 bits, constructs a ±1 vector with
/// an even parity constraint, and normalizes it to create a valid `Gf8`.
#[inline]
pub fn gf8_from_code(code: Gf8BitSig) -> Gf8 {
    let bits = bits_from_u8_le(code.0);
    Gf8::from_bits_even_parity(bits)
}

/// Encodes a `Gf8` direction into a compact 8-bit `Gf8BitSig `.
///
/// This function performs a lossy quantization. It reads the sign pattern of the `Gf8`'s
/// coordinates (`< 0.0` -> bit 1, `>= 0.0` -> bit 0), enforces an even number of set bits
/// by potentially flipping the last bit, and packs the result into a `u8`.
#[inline]
pub fn gf8_to_code(gf: &Gf8) -> Gf8BitSig {
    let mut bits = [0u8; 8];
    let mut set_bits = 0u32;

    // Determine bits from the sign of each coordinate.
    for (i, &c) in gf.coords().iter().enumerate() {
        if c < 0.0 {
            bits[i] = 1;
            set_bits += 1;
        } else {
            bits[i] = 0;
        }
    }

    // Enforce even parity of set bits (1s) by flipping the last bit if necessary.
    // This ensures the bit pattern corresponds to a valid E8-like state.
    if set_bits % 2 == 1 {
        bits[7] ^= 1;
    }

    Gf8BitSig(bits_to_u8_le(bits))
}

File: bitcodec\mod.rs
=====================
/* e8/gf8/src/bitcodec/mod.rs */
//! Bit encoding and decoding for `Gf8` vectors.
//!
//! This module provides both lossy and lossless quantization approaches for `Gf8` vectors.
//! The choice between them depends on whether you need perfect reconstruction (lossless)
//! or maximum compression with reasonable accuracy (lossy).
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

pub mod lossless;
pub mod lossy;

// Re-export the main types and functions for convenience
pub use lossless::{
    Gf8LosslessCode, gf8_from_lossless_code, gf8_to_lossless_code, gf8_to_lossless_code_closest,
};
pub use lossy::{Gf8BitSig, bits_from_u8_le, bits_to_u8_le, gf8_from_code, gf8_to_code};

/// Convenience function that attempts lossless encoding first, falls back to lossy.
///
/// This function tries to encode the `Gf8` using the lossless approach first (checking
/// against the 240 canonical roots). If that fails (because the vector is not an
/// exact E8 lattice point), it falls back to the lossy sign-based encoding.
///
/// # Returns
/// - `Ok(Gf8LosslessCode)` if the vector is an exact E8 lattice point
/// - `Err(Gf8BitSig )` if the vector needed lossy encoding
pub fn gf8_to_best_code(gf: &Gf8) -> Result<Gf8LosslessCode, Gf8BitSig> {
    // Try lossless first (exact match on 240 roots)
    if let Some(lossless_code) = lossless::gf8_to_lossless_code(gf) {
        return Ok(lossless_code);
    }

    // Fall back to lossy (sign bits)
    Err(lossy::gf8_to_code(gf))
}

/// Reconstructs a `Gf8` from either a lossless or lossy code.
///
/// This function handles both types of codes and returns the appropriate `Gf8`.
pub fn gf8_from_best_code(
    lossless_code: Option<Gf8LosslessCode>,
    lossy_code: Option<Gf8BitSig>,
) -> Option<Gf8> {
    match (lossless_code, lossy_code) {
        (Some(code), _) => Some(lossless::gf8_from_lossless_code(code)),
        (None, Some(code)) => Some(lossy::gf8_from_code(code)),
        (None, None) => None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Gf8;

    #[test]
    fn test_best_code_selection() {
        // Test with an exact E8 lattice point (from D8 subset)
        let lattice_point = Gf8::from_bits_even_parity([1, 0, 1, 1, 0, 0, 1, 0]);
        let result = gf8_to_best_code(&lattice_point);

        // Should use lossless encoding
        assert!(
            result.is_ok(),
            "E8 lattice points should use lossless encoding"
        );

        // Test with an arbitrary vector (not on lattice)
        let arbitrary = Gf8::new([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]);
        let result = gf8_to_best_code(&arbitrary);

        // Should fall back to lossy encoding
        assert!(
            result.is_err(),
            "Arbitrary vectors should use lossy encoding"
        );
    }
}

File: math\lattice.rs
=====================
/* e8/gf8/src/math/lattice.rs */
//! E₈-inspired lattice utilities for `Gf8`.
//!
//! # e8 Primitives – Lattice Module
//!▫~•◦-------------------------------------‣
//!
//! This module provides simple, E₈-inspired lattice helpers for `Gf8`. The
//! intent is not to fully model the 240-root E₈ lattice, but to offer practical
//! gf8s that align with the sign-parity structure already used by
//! `Gf8::from_bits_even_parity` and the `Gf8BitSig ` bitcodec.
//!
//! ### Key Capabilities
//! - **Shell Quantization:** Project arbitrary 8D vectors onto an E₈-like ±1
//!   shell with even parity.
//! - **Chordal & Angular Distances:** Compute distances between `Gf8` values
//!   on the unit sphere.
//!
//! These utilities are suitable for building E8B-like compression schemes,
//! approximate lookup tables, or shell-based neighborhood computations.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

/// Quantize an arbitrary 8D vector onto an E₈-like ±1 shell with even parity.
///
/// This function:
/// - Interprets the sign of each coordinate (`< 0.0` -> 1, `>= 0.0` -> 0) as a bit.
/// - Enforces an even number of 1s by flipping the last bit if necessary.
/// - Uses `Gf8::from_bits_even_parity` to construct a normalized `Gf8`.
///
/// This is aligned with the parity logic used by the `Gf8BitSig ` bitcodec.
pub fn quantize_to_e8_shell(coords: &[f32; 8]) -> Gf8 {
    let mut bits = [0u8; 8];
    let mut set_bits = 0u32;

    for (i, &c) in coords.iter().enumerate() {
        if c < 0.0 {
            bits[i] = 1;
            set_bits += 1;
        } else {
            bits[i] = 0;
        }
    }

    if set_bits % 2 == 1 {
        bits[7] ^= 1;
    }

    Gf8::from_bits_even_parity(bits)
}

/// Quantize a slice of 8D vectors onto the E₈-like shell.
///
/// `src` and `dst` must have the same length. Each source vector is quantized
/// independently using [`quantize_to_e8_shell`].
pub fn quantize_slice_to_e8_shell(src: &[[f32; 8]], dst: &mut [Gf8]) {
    assert_eq!(src.len(), dst.len(), "src and dst length mismatch");

    for (coords, gf) in src.iter().zip(dst.iter_mut()) {
        *gf = quantize_to_e8_shell(coords);
    }
}

/// Compute the squared chordal distance between two `Gf8` directions in ℝ⁸.
///
/// For unit-normalized vectors `a` and `b`, this is:
///
/// ```text
/// ||a - b||² = 2 - 2 * dot(a, b)
/// ```
///
/// This is often a convenient substitute for geodesic distance in E₈-based
/// search and clustering.
#[inline]
pub fn gf8_chordal_distance2(a: &Gf8, b: &Gf8) -> f32 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    for (&av, &bv) in a_coords.iter().zip(b_coords.iter()) {
        dot += av * bv;
    }

    let dot_clamped = dot.clamp(-1.0, 1.0);
    2.0 - 2.0 * dot_clamped
}

/// Compute the chordal distance between two `Gf8` directions in ℝ⁸.
#[inline]
pub fn gf8_chordal_distance(a: &Gf8, b: &Gf8) -> f32 {
    gf8_chordal_distance2(a, b).sqrt()
}

/// Compute the geodesic distance (angle in radians) between two `Gf8`
/// directions on the unit 8-sphere.
///
/// This is equivalent to `acos(dot(a, b))`, clamped for numeric stability.
#[inline]
pub fn gf8_geodesic_distance(a: &Gf8, b: &Gf8) -> f32 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    for (&av, &bv) in a_coords.iter().zip(b_coords.iter()) {
        dot += av * bv;
    }

    let cos = dot.clamp(-1.0, 1.0);
    cos.acos()
}

File: math\gf8_ops.rs
=====================
/* e8/gf8/src/math/gf8_ops.rs */
//! Geometric operations on `Gf8` directions.
//!
//! # e8 Primitives – Gf8 Ops
//!▫~•◦-------------------------------------‣
//!
//! This module provides higher-level operations on `Gf8` directions that are
//! useful for building semantic flows, attention mechanisms, and interpolation
//! schemes on the unit 8-sphere.
//!
//! ### Key Capabilities
//! - **Cosine Similarity & Angle:** Compute similarity and angular distance
//!   between two `Gf8` directions.
//! - **Lerp & Slerp:** Linear and spherical interpolation between `Gf8`
//!   directions, renormalized to the unit sphere.
//! - **Slice Utilities:** Helpers for applying interpolation across slices of
//!   `Gf8` values.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;

/// Compute the cosine similarity between two `Gf8` directions.
///
/// `Gf8` values are expected to be unit-normalized; this function clamps the
/// dot product into `[-1.0, 1.0]` for numerical stability.
///
/// If either vector is effectively zero-length (should not happen for valid
/// `Gf8`), this returns `0.0`.
#[inline]
pub fn gf8_cosine_similarity(a: &Gf8, b: &Gf8) -> f32 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    let mut a_n2 = 0.0f32;
    let mut b_n2 = 0.0f32;

    for (&av, &bv) in a_coords.iter().zip(b_coords.iter()) {
        dot += av * bv;
        a_n2 += av * av;
        b_n2 += bv * bv;
    }

    if a_n2 == 0.0 || b_n2 == 0.0 {
        return 0.0;
    }

    let denom = (a_n2 * b_n2).sqrt();
    let cos = dot / denom;
    cos.clamp(-1.0, 1.0)
}

/// Compute the angle (in radians) between two `Gf8` directions.
///
/// This is defined as `acos(cosine_similarity(a, b))`. The result lies in
/// `[0, π]`. If either vector is degenerate, this returns `0.0`.
#[inline]
pub fn gf8_angle(a: &Gf8, b: &Gf8) -> f32 {
    let cos = gf8_cosine_similarity(a, b);
    cos.acos()
}

/// Linearly interpolate between two `Gf8` directions and renormalize.
///
/// This performs:
///
/// ```text
/// v(t) = (1 - t) * a + t * b
/// ```
///
/// followed by renormalization onto the unit sphere. It is a simple, fast
/// approximation of spherical interpolation.
///
/// - `t = 0.0` → `a`
/// - `t = 1.0` → `b`
pub fn gf8_lerp(a: &Gf8, b: &Gf8, t: f32) -> Gf8 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut v = [0.0f32; 8];
    let one_minus_t = 1.0 - t;

    for (i, (a_c, b_c)) in a_coords.iter().zip(b_coords.iter()).enumerate() {
        v[i] = one_minus_t * (*a_c) + t * (*b_c);
    }

    Gf8::from_coords(v)
}

/// Spherical linear interpolation (SLERP) between two `Gf8` directions.
///
/// This computes the geodesic interpolation on the unit 8-sphere. For small
/// angles or nearly identical vectors, it falls back to `gf8_lerp` for
/// numerical stability.
///
/// - `t = 0.0` → `a`
/// - `t = 1.0` → `b`
pub fn gf8_slerp(a: &Gf8, b: &Gf8, t: f32) -> Gf8 {
    let a_coords = a.coords();
    let b_coords = b.coords();

    let mut dot = 0.0f32;
    for (&ac, &bc) in a_coords.iter().zip(b_coords.iter()) {
        dot += ac * bc;
    }

    let mut cos_theta = dot.clamp(-1.0, 1.0);
    // If vectors point in opposite directions, SLERP is ambiguous; flip `b`
    // to choose the shorter path.
    let mut b_adjusted = [0.0f32; 8];
    if cos_theta < 0.0 {
        cos_theta = -cos_theta;
        for (i, &val) in b_coords.iter().enumerate() {
            b_adjusted[i] = -val;
        }
    } else {
        b_adjusted.copy_from_slice(b_coords);
    }

    let theta = cos_theta.acos();

    // If angle is small, fall back to LERP.
    if theta.abs() < 1e-4 {
        return gf8_lerp(a, &Gf8::from_coords(b_adjusted), t);
    }

    let sin_theta = theta.sin();
    let w1 = ((1.0 - t) * theta).sin() / sin_theta;
    let w2 = (t * theta).sin() / sin_theta;

    let mut v = [0.0f32; 8];
    for (i, &ac) in a_coords.iter().enumerate() {
        v[i] = w1 * ac + w2 * b_adjusted[i];
    }

    Gf8::from_coords(v)
}

/// Apply linear interpolation between pairs of `Gf8` values across slices,
/// writing the result into `dst`.
///
/// All slices must have the same length.
pub fn gf8_lerp_slice(dst: &mut [Gf8], a: &[Gf8], b: &[Gf8], t: f32) {
    assert_eq!(dst.len(), a.len(), "dst and a length mismatch");
    assert_eq!(dst.len(), b.len(), "dst and b length mismatch");

    for ((dst_v, a_v), b_v) in dst.iter_mut().zip(a.iter()).zip(b.iter()) {
        *dst_v = gf8_lerp(a_v, b_v, t);
    }
}

File: math\rotation.rs
======================
/* e8/gf8/src/math/rotation.rs */
//! 8×8 orthogonal operators for rotating `Gf8` directions.
//!
//! # e8 Primitives – Rotation Module
//!▫~•◦-------------------------------------‣
//!
//! This module defines `Gf8Rotation`, a small wrapper around an 8×8 matrix
//! intended to act as an orthogonal operator on `Gf8` directions. It is useful
//! for implementing:
//!
//! - Learned or fixed E₈-like rotations,
//! - Reflections (sign-flip diagonals),
//! - Householder-style transforms for semantic flows.
//!
//! The matrix is stored explicitly as `[[f32; 8]; 8]` for simplicity. All
//! construction functions aim to produce orthogonal (or approximately orthogonal)
//! operators suitable for use with `Gf8`.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::Gf8;
#[cfg(feature = "simd")]
use crate::simd;

/// An 8×8 operator for transforming `Gf8` directions.
///
/// The matrix is conceptually applied as:
///
/// ```text
/// y = M * x
/// ```
///
/// where `x` and `y` are 8D vectors. Most constructors aim to produce orthogonal
/// matrices (e.g., identity, diagonal sign flips, Householder reflections), so
/// that the result remains on or near the unit sphere once re-normalized into a
/// `Gf8`.
#[derive(Debug, Clone, Copy)]
pub struct Gf8Rotation {
    mat: [[f32; 8]; 8],
}

impl Gf8Rotation {
    /// Construct the identity rotation (no change).
    pub fn identity() -> Self {
        let mut mat = [[0.0f32; 8]; 8];
        for (i, row) in mat.iter_mut().enumerate() {
            row[i] = 1.0;
        }
        Self { mat }
    }

    /// Construct a diagonal sign-flip operator from a diagonal vector.
    ///
    /// Each entry should be +1.0 or -1.0 for a perfect reflection. Values
    /// outside of ±1.0 are allowed but will no longer be exactly orthogonal.
    pub fn from_diagonal(diag: [f32; 8]) -> Self {
        let mut mat = [[0.0f32; 8]; 8];
        for (i, &v) in diag.iter().enumerate() {
            mat[i][i] = v;
        }
        Self { mat }
    }

    /// Construct a Householder reflection around the hyperplane with normal `n`.
    ///
    /// This builds:
    ///
    /// ```text
    /// H = I - 2 * (n nᵀ) / (nᵀ n)
    /// ```
    ///
    /// If `n` is all zeros, this returns the identity.
    pub fn from_householder(n: [f32; 8]) -> Self {
        // Compute squared norm of n.
        let mut n2 = 0.0f32;
        for &v in n.iter() {
            n2 += v * v;
        }

        if n2 == 0.0 {
            return Self::identity();
        }

        let inv_n2 = 1.0 / n2;

        let mut mat = [[0.0f32; 8]; 8];
        for (i, row) in mat.iter_mut().enumerate() {
            for (j, v) in row.iter_mut().enumerate() {
                let delta = if i == j { 1.0 } else { 0.0 };
                *v = delta - 2.0 * n[i] * n[j] * inv_n2;
            }
        }

        Self { mat }
    }

    /// Apply this rotation to a `Gf8` direction and re-normalize to the unit
    /// sphere.
    ///
    /// The result is returned as a new `Gf8` value.
    #[cfg(feature = "simd")]
    pub fn apply(&self, v: &Gf8) -> Gf8 {
        // Compile-time enabled SIMD path. This will use the most optimized
        // implementation available for the target architecture.
        simd::gf8_matvec_simd(&self.mat, v)
    }

    #[cfg(not(feature = "simd"))]
    pub fn apply(&self, v: &Gf8) -> Gf8 {
        // Scalar fallback: explicit matrix-vector multiply with no runtime
        // SIMD dispatch. This path is selected when the `simd` feature is
        // disabled at compile-time.
        let x = v.coords();
        let mut y = [0.0f32; 8];

        for (i, row) in self.mat.iter().enumerate() {
            y[i] = row.iter().zip(x.iter()).map(|(&m, &v)| m * v).sum();
        }

        Gf8::from_coords(y)
    }

    /// Checks whether this matrix is orthogonal within a relative tolerance.
    ///
    /// This verifies that Mᵀ * M ≈ I (i.e., rows are mutually orthonormal).
    /// Useful for unit tests and debug assertions in high-assurance paths.
    pub fn is_orthogonal(&self, eps: f32) -> bool {
        // Compute Mᵀ * M
        let mut mm = [[0.0f32; 8]; 8];
        for (i, row) in mm.iter_mut().enumerate() {
            for (j, v) in row.iter_mut().enumerate() {
                // Dot product of column i and column j of M.
                let acc: f32 = self.mat.iter().map(|r| r[i] * r[j]).sum();
                *v = acc;
            }
        }

        for (i, row) in mm.iter().enumerate() {
            for (j, &v) in row.iter().enumerate() {
                let ideal = if i == j { 1.0f32 } else { 0.0f32 };
                if (v - ideal).abs() > eps {
                    return false;
                }
            }
        }

        true
    }

    /// Compose two rotations: `self ∘ other`.
    ///
    /// The resulting operator applies `other` first, then `self`.
    pub fn compose(&self, other: &Gf8Rotation) -> Gf8Rotation {
        let mut mat = [[0.0f32; 8]; 8];

        for (i, row) in mat.iter_mut().enumerate() {
            for (j, v) in row.iter_mut().enumerate() {
                let mut acc = 0.0f32;
                for (k, _) in self.mat[i].iter().enumerate() {
                    acc += self.mat[i][k] * other.mat[k][j];
                }
                *v = acc;
            }
        }

        Gf8Rotation { mat }
    }

    /// Access the underlying matrix.
    #[inline]
    pub fn as_matrix(&self) -> &[[f32; 8]; 8] {
        &self.mat
    }

    /// Mutable access to the underlying matrix.
    ///
    /// This allows advanced callers to construct custom operators directly.
    #[inline]
    pub fn as_matrix_mut(&mut self) -> &mut [[f32; 8]; 8] {
        &mut self.mat
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn approx_eq(a: &[f32; 8], b: &[f32; 8], eps: f32) -> bool {
        a.iter()
            .zip(b.iter())
            .all(|(&av, &bv)| (av - bv).abs() <= eps)
    }

    #[test]
    fn identity_apply_is_noop() {
        let r = Gf8Rotation::identity();
        let v = Gf8::from_scalar(1.0);
        let out = r.apply(&v);
        assert!(approx_eq(out.coords(), v.coords(), 1e-6));
    }

    #[test]
    fn compose_with_identity_is_idempotent() {
        let r = Gf8Rotation::from_diagonal([1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0]);
        let comp = r.compose(&Gf8Rotation::identity());
        for (row_comp, row_r) in comp.as_matrix().iter().zip(r.as_matrix().iter()) {
            assert!(approx_eq(row_comp, row_r, 1e-6));
        }
    }

    #[test]
    fn householder_reflects_first_axis() {
        // Householder that reflects across the hyperplane orthogonal to the x-axis.
        let n = [1.0f32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let h = Gf8Rotation::from_householder(n);
        let v = Gf8::from_scalar(1.0);
        let out = h.apply(&v);
        // The reflection should flip the first coordinate.
        assert!(out.coords()[0] < -0.9999);
        // Other coordinates remain near zero.
        for &val in out.coords()[1..].iter() {
            assert!(val.abs() < 1e-6);
        }
        // Verify that the operator is orthogonal.
        assert!(h.is_orthogonal(1e-5));
    }
}

File: math\mod.rs
=================
/* e8/gf8/src/math/mod.rs */
//! Core geometric and lattice math utilities for `Gf8` and E₈-style operations.
//!
//! # e8 Primitives – Math Module
//!▫~•◦-------------------------------------‣
//!
//! This module provides higher-level math utilities built on top of the `Gf8`
//! gf8 type, including:
//!
//! - `gf8_ops`: Geometric operations on `Gf8` such as cosine similarity, angle
//!   computation, and (spherical) interpolation.
//! - `lattice`: E₈-inspired lattice quantization utilities and shell projections
//!   around the `Gf8` representation.
//! - `rotation`: Simple 8×8 orthogonal operators (`Gf8Rotation`) for rotating
//!   `Gf8` vectors in ℝ⁸.
//!
//! The intent is to keep `Gf8` itself as a small, focused gf8, while this
//! module houses reusable, higher-level math building blocks for e8-powered
//! systems.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

pub mod gf8_ops;
pub mod lattice;
pub mod rotation;

// Re-export the most commonly used items for convenience.
pub use gf8_ops::*;
pub use lattice::*;
pub use rotation::*;
