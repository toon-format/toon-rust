

File: src\rune\grammar.pest
===========================

WHITESPACE = _{ " " | "\t" }
NEWLINE = _{ "\r\n" | "\n" }

COMMENT = _{ "#" ~ (!NEWLINE ~ ANY)* }

// --- LEXICAL PRIMITIVES ---
ident = @{ (ASCII_ALPHA | "_") ~ (ASCII_ALPHANUMERIC | "_" )* }

// Semantic prefix: single uppercase letter followed by colon (A:, T:, V:, R:, etc.)
semantic_prefix = @{ ASCII_ALPHA_UPPER ~ ":" }

// Semantic identifier: prefix + name (e.g., T:Gf8, V:vector, R:continuum)
semantic_ident = { semantic_prefix ~ ident }

number = @{
    "-"? ~ ASCII_DIGIT+ ~ ("." ~ ASCII_DIGIT+)?   // simple int/float
}

string = @{
    "\"" ~ string_inner ~ "\""
}

string_inner = @{
    (
        !("\"" | "\\") ~ ANY
        | "\\" ~ ("\"" | "\\" | "/" | "b" | "f" | "n" | "r" | "t")
    )*
}

// Boolean literals: B:t (true) or B:f (false)
boolean_literal = { "B:" ~ ("t" | "f") }

// --- OPERATORS (matched in order of length) ---

// 1. Glyph operators (must be ordered longest-first, now included in relation_op for chaining)
// Note: glyph_op removed from grammar, integrated into relation_op for better parsing of chains

// 2. Flow operators (lower precedence - flow between things)
flow_op = {
      "<->"    // FlowBidirectional
    | ">-<"    // FlowConvergent
    | "->"     // FlowRight
    | "<-"     // FlowLeft
}

// 3. Structural / binding operators (higher precedence - create associations)
struct_op = {
            "\\|/"   // SymmetricSplit
        | "/|\\"   // BranchAnchorBranch
        | "/\\"    // SplitJoin
        | "\\/"    // JoinSplit
        | "|/"     // AnchorDescend
        | "/|"     // BranchStabilize
        | "\\|"     // RootStabilize
        | "|\\"     // StabilizeRoot
        | "=:="    // Unify
        | ":=:"    // Match
        | "=:"     // Specializes
        | "::"     // Namespace
        | ":="     // Define
        | ":>"     // Output
        | "<:"     // Input
        | "|>"     // PipelineRight
        | "<|"     // PipelineLeft
        | "<="     // LessEqual
        | ">="     // GreaterEqual
        | "||"     // Parallel
        | ":"      // Bind
        | "="      // Equal
        | "<"      // Less
        | ">"      // Greater
        | "\\"      // Ancestor
        | "|"      // Alias
        | "~"      // Transform
}

// All relation operators combined (for fallback parsing)
relation_op = { flow_op | struct_op }

// Path operators used for hierarchical access (distinct from math)
path_op = { "/" | "\\" }

// Unified operator token (arithmetic operators only within math blocks `[]`)
op = { relation_op }

// --- EXPRESSIONS ---
// Domains: Structural (outside []) vs Arithmetic (inside [])

// Function call: name(arg1, arg2, ...)
fn_call = { ident ~ "(" ~ relation_expr ~ ("," ~ relation_expr)* ~ ")" }

// Array literal: [1,2,3] or [a,b,c] (comma-separated)
// Distinct from math blocks which use operators without commas
array_literal = { "[" ~ relation_expr ~ ("," ~ relation_expr)+ ~ "]" }

term = {
      string
    | number
    | boolean_literal // Boolean literals: B:t, B:f
    | math_block      // Try math block first (has operators/unary)
    | fn_call         // Try function call (has parens)
    | array_literal   // Then try array (has commas)
    | semantic_ident
    | ident
    | "(" ~ relation_expr ~ ")"
}

// Arithmetic within [ ... ] value blocks ---
// Math precedence: PEMDAS (Parentheses, Exponents, Multiply/Divide, Add/Subtract)
math_block  = { "[" ~ math_expr ~ "]" }

math_expr   = { math_add }

math_add    = { math_mul ~ (WHITESPACE* ~ math_add_op ~ WHITESPACE* ~ math_mul)* }
math_add_op = { "+" | "-" }

math_mul    = { math_exp ~ (WHITESPACE* ~ math_mul_op ~ WHITESPACE* ~ math_exp)* }
math_mul_op = { "*" | "/" | "%" }

math_exp    = { math_unary ~ (WHITESPACE* ~ math_exp_op ~ WHITESPACE* ~ math_unary)* }
math_exp_op = { "^" | "√" | "R" }

math_unary  = { math_unary_op? ~ math_atom }
math_unary_op = { "-" | "+" }

// Math atom now supports arrays and semantic identifiers inside math blocks
math_array_literal = { "[" ~ math_expr ~ ("," ~ math_expr)+ ~ "]" }
math_atom   = { number | semantic_ident | math_array_literal | ident | "(" ~ math_expr ~ ")" }

// Structural expressions ---
// Precedence layers: flow_expr < struct_expr < access < term
// Lower precedence (parsed first) = looser binding

// Access (hierarchical navigation - using binary operators below)
access = { term ~ (WHITESPACE* ~ path_op ~ WHITESPACE* ~ term)* }

// Structural operators (tighter binding - associations, definitions)
struct_expr = { access ~ (WHITESPACE* ~ struct_op ~ WHITESPACE* ~ access)* }

// Flow operators (looser binding - data flow between structures)
flow_expr = { struct_expr ~ (WHITESPACE* ~ flow_op ~ WHITESPACE* ~ struct_expr)* }

// Relations: top-level expression (kept for backward compatibility)
relation_expr = { flow_expr }

// Expression: structural operations only (no arithmetic)
expr = { relation_expr }

// --- STATEMENTS ---

// Root declaration (supports namespaces like e8::continuum)
root_decl = { "root:" ~ WHITESPACE* ~ ident ~ ("::" ~ ident)* }

// TOON/RUNE blocks (indentation-based)
// Use $ to disable implicit whitespace, @ for atomic capture
toon_content = @{
    (
        // Allow empty lines for readability while remaining inside the TOON block
        (!NEWLINE ~ ANY)* ~ NEWLINE
    )+
}

toon_block = ${
    ident ~ " "* ~ "~TOON:" ~ NEWLINE ~
    toon_content
}

rune_block = ${
    ident ~ " "* ~ "~RUNE:" ~ NEWLINE ~
    toon_content
}

// Kernel archetype declarations
kernel_param = { ident ~ ":" ~ WHITESPACE* ~ (number | ident | string) }
kernel_archetype = { "CUDA:Archetype:" ~ ident ~ "(" ~ (kernel_param ~ ("," ~ WHITESPACE* ~ kernel_param)*)? ~ ")" }
kernel_decl = { semantic_ident ~ WHITESPACE* ~ ":=" ~ WHITESPACE* ~ kernel_archetype }

// Expression statement (catch-all for operator expressions)
stmt_expr = { relation_expr }

// Top-level statement
stmt = _{ root_decl | rune_block | toon_block | kernel_decl | stmt_expr }

// File: sequence of statements
// Note: No WHITESPACE* before stmt to preserve TOON block indentation
file = { SOI ~ (NEWLINE* ~ stmt ~ WHITESPACE* ~ NEWLINE*)* ~ EOI }



File: Cargo.toml
================
[workspace]
members = [".", "hydron-core", "hydron-ffi", "rune-curs", "rune-hex"]
resolver = "2"

[package]
name = "rune-format"
version = "0.0.1"
edition = "2024"
authors = [
    "Lord Xyn <LordXyn@proton.me", # RUNE Author
    "Johann Schopplich <hello@johannschopplich.com>", # TOON Author 1
    "Shreyas K S <ks.shreyas0@gmail.com>", # TOON Author 2
]
license = "MIT OR Apache-2.0"
description = "Root Universal Notation Encoding (RUNE) - geometric control language with E8 lattice mathematics and Token-Oriented Object Notation (TOON) serialization"
repository = "https://github.com/arcmoonstudios/rune-format"
documentation = "https://docs.rs/rune-format"
keywords = ["rune", "geometry", "e8", "toon", "serialization"]
categories = ["mathematics", "encoding", "parser-implementations", "science"]
readme = "README.md"

[features]
default = []
fory = ["dep:fory", "dep:fory-core", "hydron-core?/fory"]
hydron = ["hydron-core"]  # Geometry Math Engine for RUNE (depends on hydron-core crate)
simd = ["hydron", "hydron-core/simd"]  # SIMD acceleration for Gf8 operations (enables hydron-core simd)
cuda = ["cust", "rune-curs"]

[[example]]
name = "examples"
path = "examples/main.rs"

[[bin]]
name = "rune"
path = "src/cli/main.rs"

[[bin]]
name = "utf8_sanitize"
path = "src/utf8_sanitize.rs"

[dependencies]
serde = { version = "1.0.228", features = ["derive"] }
indexmap = "2.12.1"
serde_json = { version = "1.0.145", features = ["preserve_order"] }
thiserror = "2.0.17"
cust = { version = "0.3.2", optional = true }
rune-curs = { path = "./rune-curs", optional = true }
rune-hex = { path = "./rune-hex" }

# RUNE-specific dependencies
pest = "2.8.4"
pest_derive = "2.8.4"

clap = { version = "4.5.11", features = ["derive"] }
anyhow = "1.0.100"
tiktoken-rs = "0.9.1"
comfy-table = "7.2.1"

# TUI dependencies
ratatui = "0.29"
hydron-core = { path = "./hydron-core", optional = true, features = ["serde", "fory"] }
crossterm = "0.29"
tui-textarea = "0.7"
arboard = "3.6.1"
syntect = "5.3.0"
unicode-width = "0.2"
chrono = "0.4"
fory = { version = "0.13.2", optional = true }
fory-core = { version = "0.13.2", optional = true }

[dev-dependencies]
glob = "0.3.3"
criterion = { version = "0.8.1", features = ["html_reports"] }

[build-dependencies]
ptx-builder = { version = "0.5.3", optional = true }

[[bench]]
name = "rune_parser"
harness = false

[[bench]]
name = "rune_operators"
harness = false

[[bench]]
name = "rune_vs_toon"
harness = false

[[bench]]
name = "hydron_geometry"
harness = false
required-features = ["hydron"]

[[bench]]
name = "fory_ops"
harness = false
required-features = ["fory"]

[[bench]]
name = "serde_hydron"
harness = false
required-features = ["hydron"]

[[bench]]
name = "fory_hydron"
harness = false
required-features = ["fory", "hydron", "simd"]

[profile.dev]
lto = "thin"
opt-level = 3
incremental = true

[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort"
strip = "symbols"

[profile.bench]
opt-level = 3
lto = false
codegen-units = 1

File: build-output.txt
======================
   Compiling unicode-ident v1.0.22
   Compiling proc-macro2 v1.0.103
   Compiling quote v1.0.42
   Compiling autocfg v1.5.0
   Compiling windows-link v0.2.1
   Compiling syn v1.0.109
   Compiling libm v0.2.15
   Compiling cfg-if v1.0.4
   Compiling serde_core v1.0.228
   Compiling rustversion v1.0.22
   Compiling equivalent v1.0.2
   Compiling hashbrown v0.16.1
   Compiling winnow v0.5.40
   Compiling toml_datetime v0.6.11
   Compiling memchr v2.7.6
   Compiling once_cell v1.21.3
   Compiling paste v1.0.15
   Compiling bitflags v2.10.0
   Compiling thiserror v1.0.69
   Compiling windows-sys v0.61.2
   Compiling glob v0.3.3
   Compiling version_check v0.9.5
   Compiling typenum v1.19.0
   Compiling parking_lot_core v0.9.12
   Compiling winapi v0.3.9
   Compiling serde v1.0.228
   Compiling find_cuda_helper v0.2.0
   Compiling num-traits v0.2.19
   Compiling indexmap v2.12.1
   Compiling generic-array v0.14.7
   Compiling simd-adler32 v0.3.7
   Compiling itoa v1.0.15
   Compiling crc32fast v1.5.0
   Compiling semver v1.0.27
   Compiling scopeguard v1.2.0
   Compiling smallvec v1.15.1
   Compiling lock_api v0.4.14
   Compiling rustc_version v0.4.1
   Compiling heck v0.5.0
   Compiling fnv v1.0.7
   Compiling find-msvc-tools v0.1.5
   Compiling toml_edit v0.19.15
   Compiling adler2 v2.0.1
   Compiling strsim v0.11.1
   Compiling unicode-xid v0.2.6
   Compiling regex-syntax v0.8.8
   Compiling wasm-bindgen-shared v0.2.106
   Compiling ident_case v1.0.1
   Compiling failure_derive v0.1.8
   Compiling lazy_static v1.5.0
   Compiling syn v2.0.111
   Compiling shlex v1.3.0
   Compiling vek v0.15.10
   Compiling cc v1.2.49
   Compiling chrono v0.4.42
   Compiling miniz_oxide v0.8.9
   Compiling parking_lot v0.12.5
   Compiling aho-corasick v1.1.4
   Compiling rustc-demangle v0.1.26
   Compiling byteorder v1.5.0
   Compiling thiserror v2.0.17
   Compiling ucd-util v0.1.10
   Compiling pkg-config v0.3.32
   Compiling ryu v1.0.20
   Compiling windows_x86_64_msvc v0.53.1
   Compiling unicode-segmentation v1.12.0
   Compiling regex v0.2.11
   Compiling proc-macro-crate v1.3.1
   Compiling backtrace v0.3.76
   Compiling regex-syntax v0.5.6
   Compiling convert_case v0.10.0
   Compiling approx v0.5.1
   Compiling is-terminal v0.4.17
   Compiling num-integer v0.1.46
   Compiling flate2 v1.1.7
   Compiling crossterm_winapi v0.9.1
   Compiling thread_local v0.3.6
   Compiling cust_raw v0.11.3
   Compiling aho-corasick v0.6.10
   Compiling bytemuck v1.24.0
   Compiling onig_sys v69.9.1
   Compiling synstructure v0.12.6
   Compiling regex-automata v0.4.13
   Compiling either v1.15.0
   Compiling foldhash v0.1.5
   Compiling utf8parse v0.2.2
   Compiling anstyle v1.0.13
   Compiling libc v0.2.178
   Compiling semver-parser v0.7.0
   Compiling once_cell_polyfill v1.70.2
   Compiling powerfmt v0.2.0
   Compiling instability v0.3.10
   Compiling ucd-trie v0.1.7
   Compiling allocator-api2 v0.2.21
   Compiling utf8-ranges v1.0.5
   Compiling pest v2.8.4
   Compiling deranged v0.5.5
   Compiling semver v0.9.0
   Compiling colored v1.9.4
   Compiling anstyle-wincon v3.0.11
   Compiling toml v0.4.10
   Compiling itertools v0.13.0
   Compiling hashbrown v0.15.5
   Compiling anstyle-parse v0.2.7
   Compiling crypto-common v0.1.7
   Compiling block-buffer v0.10.4
   Compiling glam v0.20.5
   Compiling num_enum_derive v0.5.11
   Compiling cust_derive v0.2.0
   Compiling pxfm v0.1.27
   Compiling darling_core v0.20.11
   Compiling castaway v0.2.4
   Compiling fdeflate v0.3.7
   Compiling cust v0.3.2
   Compiling anstyle-query v1.1.5
   Compiling winapi-util v0.1.11
   Compiling failure v0.1.8
   Compiling mint v0.5.9
   Compiling litrs v1.0.0
   Compiling static_assertions v1.1.0
   Compiling colorchoice v1.0.4
   Compiling num-conv v0.1.0
   Compiling anyhow v1.0.100
   Compiling serde_json v1.0.145
   Compiling unicode-width v0.2.0
   Compiling time-core v0.1.6
   Compiling base64 v0.22.1
   Compiling bit-vec v0.6.3
   Compiling indoc v2.0.7
   Compiling is_terminal_polyfill v1.70.2
   Compiling unicode-width v0.1.14
   Compiling anstream v0.6.21
   Compiling time v0.3.44
   Compiling num_enum v0.5.11
   Compiling document-features v0.2.12
   Compiling unicode-truncate v1.1.0
   Compiling bit-set v0.5.3
   Compiling ptx-builder v0.5.3
   Compiling compact_str v0.8.1
   Compiling same-file v1.0.6
   Compiling png v0.18.0
   Compiling pest_meta v2.8.4
   Compiling lru v0.12.5
   Compiling digest v0.10.7
   Compiling windows-targets v0.53.5
   Compiling crossterm v0.28.1
   Compiling quick-xml v0.38.4
   Compiling cassowary v0.3.0
   Compiling bitflags v1.3.2
   Compiling clap_lex v0.7.6
   Compiling byteorder-lite v0.1.0
   Compiling error-code v3.3.2
   Compiling linked-hash-map v0.5.6
   Compiling cpufeatures v0.2.17
   Compiling cust_core v0.1.1
   Compiling yaml-rust v0.4.5
   Compiling sha2 v0.10.9
   Compiling clipboard-win v5.4.1
   Compiling pest_generator v2.8.4
   Compiling clap_builder v4.5.53
   Compiling regex v1.12.2
   Compiling thiserror-impl v1.0.69
   Compiling serde_derive v1.0.228
   Compiling thiserror-impl v2.0.17
   Compiling derive_more-impl v2.1.0
   Compiling strum_macros v0.26.4
   Compiling moxcms v0.7.10
   Compiling clap_derive v4.5.49
   Compiling fancy-regex v0.13.0
   Compiling bstr v1.12.1
   Compiling rune-format v0.0.1 (X:\_Repos\toon-rune)
   Compiling darling_macro v0.20.11
   Compiling windows-sys v0.60.2
   Compiling walkdir v2.5.0
   Compiling derive_more v2.1.0
   Compiling darling v0.20.11
   Compiling crossterm v0.29.0
   Compiling fory-core v0.13.2
   Compiling log v0.4.29
   Compiling rustc-hash v1.1.0
   Compiling bumpalo v3.19.0
   Compiling wasm-bindgen-macro-support v0.2.106
   Compiling tiktoken-rs v0.9.1
   Compiling rune-curs v0.0.1 (X:\_Repos\toon-rune\rune-curs)
   Compiling comfy-table v7.2.1
   Compiling pest_derive v2.8.4
   Compiling strum v0.26.3
   Compiling ratatui v0.29.0
   Compiling wasm-bindgen v0.2.106
   Compiling clap v4.5.53
   Compiling plist v1.8.0
   Compiling bincode v1.3.3
   Compiling rune-hex v0.0.1 (X:\_Repos\toon-rune\rune-hex)
   Compiling onig v6.5.1
   Compiling wasm-bindgen-macro v0.2.106
   Compiling fory-derive v0.13.2
   Compiling image v0.25.9
   Compiling tui-textarea v0.7.0
   Compiling syntect v5.3.0
   Compiling fory v0.13.2
   Compiling hydron-core v0.0.1 (X:\_Repos\toon-rune\hydron-core)
   Compiling arboard v3.6.1
   Compiling hydron-ffi v0.0.1 (X:\_Repos\toon-rune\hydron-ffi)
    Finished `release` profile [optimized] target(s) in 55.13s

File: build.rs
==============
/* build.rs */
//! Build script to compile CUDA kernels (feature-gated).
//! When the `cuda` feature is enabled, this script is intended to invoke
//! `ptx-builder` to compile the kernel sources into PTX for runtime loading.

#[cfg(feature = "cuda")]
fn main() {
    // TODO: wire up ptx-builder once CUDA kernels are implemented.
    // Left as a no-op placeholder so default builds are unaffected.
    // Avoid emitting cargo::warning to keep the build free of warnings.
    println!("cargo:rerun-if-changed=build.rs");
}

#[cfg(not(feature = "cuda"))]
fn main() {
    // No-op when CUDA is not enabled.
}

File: clippy-full-output.txt
============================
    Checking serde v1.0.228
   Compiling fory-derive v0.13.2
    Checking tui-textarea v0.7.0
    Checking rune-curs v0.0.1 (X:\_Repos\toon-rune\rune-curs)
    Checking half v2.7.1
    Checking arboard v3.6.1
    Checking ppv-lite86 v0.2.21
   Compiling wasm-bindgen-macro v0.2.106
error: unnecessary hashes around raw string literal
  --> rune-curs\src\kernels\cuda.rs:17:28
   |
17 |   pub const DOMR_PTX: &str = r#"
   |  ____________________________^
18 | | .version 6.0
19 | | .target sm_89
20 | | .address_size 64
...  |
88 | | "#;
   | |__^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_raw_string_hashes
   = note: `-D clippy::needless-raw-string-hashes` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::needless_raw_string_hashes)]`
help: remove all the hashes around the string literal
   |
17 ~ pub const DOMR_PTX: &str = r"
18 | .version 6.0
...
87 | }
88 ~ ";
   |

error: unnecessary hashes around raw string literal
  --> rune-curs\src\kernels\dom_r.rs:3:28
   |
3  |   pub const DOMR_PTX: &str = r#"
   |  ____________________________^
4  | | .version 6.0
5  | | .target sm_89
6  | | .address_size 64
...  |
74 | | "#;
   | |__^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_raw_string_hashes
help: remove all the hashes around the string literal
   |
3  ~ pub const DOMR_PTX: &str = r"
4  | .version 6.0
...
73 | }
74 ~ ";
   |

error: unnecessary hashes around raw string literal
   --> rune-curs\src\lib.rs:99:24
    |
99  |   const DOMR_PTX: &str = r#"
    |  ________________________^
100 | | .version 6.0
101 | | .target sm_30
102 | | .address_size 64
...   |
170 | | "#;
    | |__^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_raw_string_hashes
help: remove all the hashes around the string literal
    |
99  ~ const DOMR_PTX: &str = r"
100 | .version 6.0
...
169 | }
170 ~ ";
    |

    Checking ciborium-ll v0.2.2
    Checking rand_chacha v0.9.0
    Checking wasm-bindgen v0.2.106
    Checking rand v0.9.2
error: item in documentation is missing backticks
 --> rune-curs\src\archetypes.rs:3:30
  |
3 | //! This module provides the ArchetypeEngine that compiles CUDA kernel templates
  |                              ^^^^^^^^^^^^^^^
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
  = note: `-D clippy::doc-markdown` implied by `-D warnings`
  = help: to override `-D warnings` add `#[allow(clippy::doc_markdown)]`
help: try
  |
3 - //! This module provides the ArchetypeEngine that compiles CUDA kernel templates
3 + //! This module provides the `ArchetypeEngine` that compiles CUDA kernel templates
  |

error: you should consider adding a `Default` implementation for `ArchetypeEngine`
  --> rune-curs\src\archetypes.rs:23:5
   |
23 | /     pub fn new() -> Self {
24 | |         Self {
25 | |             cache_dir: Path::new("target").join("rune").join("cache"),
26 | |         }
27 | |     }
   | |_____^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#new_without_default
   = note: `-D clippy::new-without-default` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::new_without_default)]`
help: try adding this
   |
20 + impl Default for ArchetypeEngine {
21 +     fn default() -> Self {
22 +         Self::new()
23 +     }
24 + }
   |

error: item in documentation is missing backticks
  --> rune-curs\src\archetypes.rs:21:23
   |
21 |     /// Creates a new ArchetypeEngine with default cache directory.
   |                       ^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
21 -     /// Creates a new ArchetypeEngine with default cache directory.
21 +     /// Creates a new `ArchetypeEngine` with default cache directory.
   |

error: item in documentation is missing backticks
  --> rune-curs\src\archetypes.rs:22:23
   |
22 |     /// Creates a new ArchetypeEngine with default cache directory.
   |                       ^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
22 -     /// Creates a new ArchetypeEngine with default cache directory.
22 +     /// Creates a new `ArchetypeEngine` with default cache directory.
   |

error: this method could have a `#[must_use]` attribute
  --> rune-curs\src\archetypes.rs:23:5
   |
23 |     pub fn new() -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate
   = note: `-D clippy::must-use-candidate` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::must_use_candidate)]`

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\archetypes.rs:37:5
   |
37 | /     pub fn compile_archetype(
38 | |         &self,
39 | |         func_name: &str,
40 | |         d_dim: usize,
41 | |     ) -> Result<Module, Box<dyn std::error::Error>> {
   | |___________________________________________________^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc
   = note: `-D clippy::missing-errors-doc` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::missing_errors_doc)]`

error: variables can be used directly in the `format!` string
  --> rune-curs\src\archetypes.rs:56:44
   |
56 |         let ptx_path = self.cache_dir.join(format!("{}.ptx", hash));
   |                                            ^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#uninlined_format_args
   = note: `-D clippy::uninlined-format-args` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::uninlined_format_args)]`
help: change this to
   |
56 -         let ptx_path = self.cache_dir.join(format!("{}.ptx", hash));
56 +         let ptx_path = self.cache_dir.join(format!("{hash}.ptx"));
   |

error: variables can be used directly in the `format!` string
  --> rune-curs\src\archetypes.rs:57:43
   |
57 |         let cu_path = self.cache_dir.join(format!("{}.cu", hash));
   |                                           ^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#uninlined_format_args
help: change this to
   |
57 -         let cu_path = self.cache_dir.join(format!("{}.cu", hash));
57 +         let cu_path = self.cache_dir.join(format!("{hash}.cu"));
   |

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\buffers.rs:15:5
   |
15 |     pub fn new(len: usize) -> CudaResult<Self> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\buffers.rs:21:5
   |
21 |     pub fn from_host(slice: &[T]) -> CudaResult<Self> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\buffers.rs:27:5
   |
27 |     pub fn to_host(&self, slice: &mut [T]) -> CudaResult<()> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: this method could have a `#[must_use]` attribute
  --> rune-curs\src\buffers.rs:33:5
   |
33 |     pub fn len(&self) -> usize {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn len(&self) -> usize`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> rune-curs\src\buffers.rs:37:5
   |
37 |     pub fn is_empty(&self) -> bool {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_empty(&self) -> bool`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> rune-curs\src\buffers.rs:41:5
   |
41 |     pub fn as_device_ptr(&self) -> cust::memory::DevicePointer<T> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn as_device_ptr(&self) -> cust::memory::DevicePointer<T>`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
 --> rune-curs\src\kernels\cuda.rs:7:17
  |
7 | /// PTX for the DomR kernel.
  |                 ^^^^
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
  |
7 - /// PTX for the DomR kernel.
7 + /// PTX for the `DomR` kernel.
  |

error: item in documentation is missing backticks
  --> rune-curs\src\kernels\cuda.rs:14:48
   |
14 | /// - **`coords`:** `const float*` - Flattened AoS coordinates array (`n * 8` floats).
   |                                                ^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
14 - /// - **`coords`:** `const float*` - Flattened AoS coordinates array (`n * 8` floats).
14 + /// - **`coords`:** `const float*` - Flattened `AoS` coordinates array (`n * 8` floats).
   |

error: item in documentation is missing backticks
 --> rune-curs\src\kernels\dom_r.rs:1:22
  |
1 | //! Embedded PTX for DomR kernel.S
  |                      ^^^^
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
  |
1 - //! Embedded PTX for DomR kernel.S
1 + //! Embedded PTX for `DomR` kernel.S
  |

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\runtime.rs:14:1
   |
14 | pub fn ensure_context() -> CudaResult<()> {
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: temporary with significant `Drop` can be early dropped
  --> rune-curs\src\runtime.rs:15:13
   |
14 |   pub fn ensure_context() -> CudaResult<()> {
   |  ___________________________________________-
15 | |     let mut ctx_guard = CTX
   | |             ^^^^^^^^^
16 | |         .lock()
17 | |         .map_err(|_| CudaError::Driver("Mutex poison".to_string()))?;
...  |
27 | |     Ok(())
28 | | }
   | |_- temporary `ctx_guard` is currently being dropped at the end of its contained scope
   |
   = note: this might lead to unnecessary resource contention
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#significant_drop_tightening
   = note: `-D clippy::significant-drop-tightening` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::significant_drop_tightening)]`
help: drop the temporary after the end of its last usage
   |
25 ~         *ctx_guard = Some(Arc::new(context));
26 +         drop(ctx_guard);
   |

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\types.rs:15:5
   |
15 |     pub fn new(energy_host: &[f32], coords_host: &[[f32; 8]]) -> CudaResult<Self> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: item in documentation is missing backticks
  --> rune-curs\src\lib.rs:29:13
   |
29 | /// Compute DomR scores on GPU: scores[x] = Σ_o energy[o] * dot8(coords[o], coords[x]).
   |             ^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
29 - /// Compute DomR scores on GPU: scores[x] = Σ_o energy[o] * dot8(coords[o], coords[x]).
29 + /// Compute `DomR` scores on GPU: scores[x] = Σ_o energy[o] * dot8(coords[o], coords[x]).
   |

error: item in documentation is missing backticks
  --> rune-curs\src\lib.rs:29:45
   |
29 | /// Compute DomR scores on GPU: scores[x] = Σ_o energy[o] * dot8(coords[o], coords[x]).
   |                                             ^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
29 - /// Compute DomR scores on GPU: scores[x] = Σ_o energy[o] * dot8(coords[o], coords[x]).
29 + /// Compute DomR scores on GPU: scores[x] = `Σ_o` energy[o] * dot8(coords[o], coords[x]).
   |

error: docs for function returning `Result` missing `# Errors` section
  --> rune-curs\src\lib.rs:35:1
   |
35 | pub fn domr_scores_gpu(energy: &[f32], coords: &[[f32; 8]]) -> CudaResult<Vec<f32>> {
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
  --> rune-curs\src\lib.rs:65:17
   |
65 |     let grid = ((n as u32) + block - 1) / block;
   |                 ^^^^^^^^^^
   |
   = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
   = note: `-D clippy::cast-possible-truncation` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::cast_possible_truncation)]`
help: ... or use `try_from` and handle the error accordingly
   |
65 -     let grid = ((n as u32) + block - 1) / block;
65 +     let grid = (u32::try_from(n) + block - 1) / block;
   |

error: casting `usize` to `i32` may truncate the value on targets with 64-bit wide pointers
  --> rune-curs\src\lib.rs:75:17
   |
75 |                 n as i32
   |                 ^^^^^^^^
   |
   = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
   |
75 -                 n as i32
75 +                 i32::try_from(n)
   |

error: casting `usize` to `i32` may wrap around the value on targets with 32-bit wide pointers
  --> rune-curs\src\lib.rs:75:17
   |
75 |                 n as i32
   |                 ^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap
   = note: `-D clippy::cast-possible-wrap` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::cast_possible_wrap)]`

error: could not compile `rune-curs` (lib) due to 29 previous errors
warning: build failed, waiting for other jobs to finish...
error: could not compile `rune-curs` (lib test) due to 29 previous errors

File: CHANGELOG.md
==================
# Changelog

<!-- markdownlint-disable MD024 -->
<!--
  Disabling the following rules:
  - MD024/no-duplicate-heading: Multiple headings with the same content
-->

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

### Performance

- **Hydron Geometry Optimizations**: Addressed performance regressions in E8 geometric operations
  - Spherical entropy normalization: -67-68% improvement by eliminating vector allocation in single-pass computation
  - GF8 norm squared: Optimized scalar implementation for small vector operations
  - GF8 matrix-vector: Added AVX SIMD acceleration for matrix-vector multiplication
  - Hyperbolic geometry: Streamlined scalar fallbacks to reduce redundant calculations

## [Unreleased] - 2025-11-26

### Added

- document the TOON -> RUNE fork direction, highlighting the root-centric semantic operators, CLI/TUI supersets, and E8 geometry focus described in the README
- note that the project now exposes the `rune` module, the `rune` CLI, and extends the existing TOON workflow with geosemantic root-specific notation, prefixes, and glyph operators

### Other

- reinforce the attribution for both TOON and RUNE contributors and offer the new guiding philosophy for semantic flow in the ecosystem

---

## [0.0.1](https://github.com/toon-format/toon-rust/compare/v0.3.6...v0.3.7) - 2025-11-21

### Added

- add the new `src/rune` workspace with Hydron geometry helpers for GF8, spherical, and hyperbolic routines
- extend the TUI so rune can be selected as an execution target and load rune-specific commands

### Changed

- align documentation and CLI tooling with the new rune workflow so the TUI can operate rune through the same interface

---

## [0.4.0](https://github.com/toon-format/toon-rust/compare/v0.3.7...v0.4.0) - 2025-11-25

### Added

- update to TOON v3.0 spec (breaking change) ([#36](https://github.com/toon-format/toon-rust/pull/36))

### Fixed

- *(decode)* Handle unquoted strings with parentheses and preserve spacing ([#34](https://github.com/toon-format/toon-rust/pull/34))

### Other

- update TUI documentation ([#31](https://github.com/toon-format/toon-rust/pull/31))

## [0.3.6](https://github.com/toon-format/toon-rust/compare/v0.3.5...v0.3.6) - 2025-11-20

### Added

- implement tui with repl  ([#29](https://github.com/toon-format/toon-rust/pull/29))

## [0.3.5](https://github.com/toon-format/toon-rust/compare/v0.3.4...v0.3.5) - 2025-11-18

### Other

- incorrect delimiter parsing for non-active delimiters in arrays ([#24](https://github.com/toon-format/toon-rust/pull/24))

## [0.3.4](https://github.com/toon-format/toon-rust/compare/v0.3.3...v0.3.4) - 2025-11-17

### Other

- Update PR template and contributing guide for Rust ([#25](https://github.com/toon-format/toon-rust/pull/25))

## [0.3.3](https://github.com/toon-format/toon-rust/compare/v0.3.2...v0.3.3) - 2025-11-14

### Added

- implement generic encode and decode ([#22](https://github.com/toon-format/toon-rust/pull/22))

## [0.3.2](https://github.com/toon-format/toon-rust/compare/v0.3.1...v0.3.2) - 2025-11-13

### Other

- standardize license holders

## [0.3.1](https://github.com/toon-format/toon-rust/compare/v0.3.0...v0.3.1) - 2025-11-12

### Fixed

- *(decode)* prevent sibling fields from being added to nested objects
- *(encode)* correct indentation for nested objects in list items

### Other

- update inline doc
- update changelog

## [0.3.0](https://github.com/toon-format/toon-rust/compare/v0.2.4...v0.3.0) - 2025-11-11

### Added

- implement key folds and expansion in cli
- [**breaking**] implement TOON Spec v2.0 with v1.5 optional features

### Other

- update readme
- update readme

## [0.2.4](https://github.com/toon-format/toon-rust/compare/v0.2.3...v0.2.4) - 2025-11-11

### Fixed

- encoder handling arrays, tabular rows and objects
- validation and parser to handle all the edge cases

### Other

- update ci
- cargo lint
- add fixtures test
- update test assertions
- update string utils
- add spec fixtures

## [0.2.3](https://github.com/toon-format/toon-rust/compare/v0.2.2...v0.2.3) - 2025-11-07

### Fixed

- readme license section

## [0.2.2](https://github.com/toon-format/toon-rust/compare/v0.2.1...v0.2.2) - 2025-11-07

### Added

- implement toon cli and update readme

### Fixed

- cargo clippy
- quoting context update
- update strict validations

### Other

- update changelog

## [0.2.1](https://github.com/toon-format/toon-rust/compare/v0.2.0...v0.2.1) - 2025-11-06

### Other

- update release workflow ([#8](https://github.com/toon-format/toon-rust/pull/8))

File: clippy-full-output2.txt
=============================
    Checking hydron-core v0.0.1 (X:\_Repos\toon-rune\hydron-core)
    Checking rune-hex v0.0.1 (X:\_Repos\toon-rune\rune-hex)
    Checking syntect v5.3.0
    Checking criterion v0.8.1
error: long literal lacking separators
   --> rune-hex\src\hex.rs:970:15
    |
970 |             * 0.0000000001)
    |               ^^^^^^^^^^^^ help: consider: `0.000_000_000_1`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#unreadable_literal
    = note: `-D clippy::unreadable-literal` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::unreadable_literal)]`

error: binding's name is too similar to existing binding
   --> hydron-core\src\gf8.rs:737:13
    |
737 |         let vvec = unsafe { _mm256_loadu_ps(vec.as_ptr()) };
    |             ^^^^
    |
note: existing binding defined here
   --> hydron-core\src\gf8.rs:735:52
    |
735 |     unsafe fn matvec_simd_avx(mat: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8] {
    |                                                    ^^^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#similar_names
    = note: `-D clippy::similar-names` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::similar_names)]`

error: long literal lacking separators
   --> hydron-core\src\gf8.rs:772:21
    |
772 |     let inv_sqrt2 = 0.70710677f32; // 1/sqrt(2)
    |                     ^^^^^^^^^^^^^ help: consider: `0.707_106_77_f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#unreadable_literal
    = note: `-D clippy::unreadable-literal` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::unreadable_literal)]`

error: binding's name is too similar to existing binding
   --> hydron-core\src\hyperbolic.rs:123:13
    |
123 |         let numerator_b_coeff = 1.0 - a_norm_sq;
    |             ^^^^^^^^^^^^^^^^^
    |
note: existing binding defined here
   --> hydron-core\src\hyperbolic.rs:122:13
    |
122 |         let numerator_a_coeff = 1.0 + 2.0 * dot_ab + b_norm_sq;
    |             ^^^^^^^^^^^^^^^^^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#similar_names

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:10:37
   |
10 | //! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
   |                                     ^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
   = note: `-D clippy::doc-markdown` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::doc_markdown)]`
help: try
   |
10 - //! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
10 + //! - Types mirror the RUNE schema (`RootKind`, SemanticDomain, HumanExperience, etc.)
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:10:47
   |
10 | //! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
   |                                               ^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
10 - //! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
10 + //! - Types mirror the RUNE schema (RootKind, `SemanticDomain`, HumanExperience, etc.)
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:10:63
   |
10 | //! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
   |                                                               ^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
10 - //! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
10 + //! - Types mirror the RUNE schema (RootKind, SemanticDomain, `HumanExperience`, etc.)
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:13:24
   |
13 | //! - Graph storage is AoS for coordinates plus CSR for adjacency to ease future
   |                        ^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
13 - //! - Graph storage is AoS for coordinates plus CSR for adjacency to ease future
13 + //! - Graph storage is `AoS` for coordinates plus CSR for adjacency to ease future
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:34:5
   |
34 | /// ErsRootKind – Rust enum projection of `T:RootKind` from hex.rune.
   |     ^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
34 - /// ErsRootKind – Rust enum projection of `T:RootKind` from hex.rune.
34 + /// `ErsRootKind` – Rust enum projection of `T:RootKind` from hex.rune.
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:41:5
   |
41 | /// ErsSemanticDomain – Rust enum projection of `T:SemanticDomain`.
   |     ^^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
41 - /// ErsSemanticDomain – Rust enum projection of `T:SemanticDomain`.
41 + /// `ErsSemanticDomain` – Rust enum projection of `T:SemanticDomain`.
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:56:5
   |
56 | /// ErsEmotionType – projection of `T:EmotionType`.
   |     ^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
56 - /// ErsEmotionType – projection of `T:EmotionType`.
56 + /// `ErsEmotionType` – projection of `T:EmotionType`.
   |

error: item in documentation is missing backticks
  --> rune-hex\src\hex.rs:91:5
   |
91 | /// ErsCognitiveType – projection of `T:CognitiveType`.
   |     ^^^^^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
91 - /// ErsCognitiveType – projection of `T:CognitiveType`.
91 + /// `ErsCognitiveType` – projection of `T:CognitiveType`.
   |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:117:5
    |
117 | /// ErsSocialType – projection of `T:SocialType`.
    |     ^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
117 - /// ErsSocialType – projection of `T:SocialType`.
117 + /// `ErsSocialType` – projection of `T:SocialType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:142:5
    |
142 | /// ErsExistentialType – projection of `T:ExistentialType`.
    |     ^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
142 - /// ErsExistentialType – projection of `T:ExistentialType`.
142 + /// `ErsExistentialType` – projection of `T:ExistentialType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:157:5
    |
157 | /// ErsPhysicalType – projection of `T:PhysicalType`.
    |     ^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
157 - /// ErsPhysicalType – projection of `T:PhysicalType`.
157 + /// `ErsPhysicalType` – projection of `T:PhysicalType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:174:5
    |
174 | /// ErsEthicalType – projection of `T:EthicalType`.
    |     ^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
174 - /// ErsEthicalType – projection of `T:EthicalType`.
174 + /// `ErsEthicalType` – projection of `T:EthicalType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:191:5
    |
191 | /// ErsCreativeType – projection of `T:CreativeType`.
    |     ^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
191 - /// ErsCreativeType – projection of `T:CreativeType`.
191 + /// `ErsCreativeType` – projection of `T:CreativeType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:208:5
    |
208 | /// ErsSpiritualType – projection of `T:SpiritualType`.
    |     ^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
208 - /// ErsSpiritualType – projection of `T:SpiritualType`.
208 + /// `ErsSpiritualType` – projection of `T:SpiritualType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:225:5
    |
225 | /// ErsEconomicType – projection of `T:EconomicType`.
    |     ^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
225 - /// ErsEconomicType – projection of `T:EconomicType`.
225 + /// `ErsEconomicType` – projection of `T:EconomicType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:242:5
    |
242 | /// ErsHealthType – projection of `T:HealthType`.
    |     ^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
242 - /// ErsHealthType – projection of `T:HealthType`.
242 + /// `ErsHealthType` – projection of `T:HealthType`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:259:5
    |
259 | /// ErsGSLFrame – projection of `T:GSLFrame`.
    |     ^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
259 - /// ErsGSLFrame – projection of `T:GSLFrame`.
259 + /// `ErsGSLFrame` – projection of `T:GSLFrame`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:267:5
    |
267 | /// ErsWeylSemanticAddress – projection of `T:WeylSemanticAddress`.
    |     ^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
267 - /// ErsWeylSemanticAddress – projection of `T:WeylSemanticAddress`.
267 + /// `ErsWeylSemanticAddress` – projection of `T:WeylSemanticAddress`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:276:5
    |
276 | /// ErsHumanExperience – projection of `T:HumanExperience`.
    |     ^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
276 - /// ErsHumanExperience – projection of `T:HumanExperience`.
276 + /// `ErsHumanExperience` – projection of `T:HumanExperience`.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:316:5
    |
316 | /// ErsDomR – Rust projection of `T:DomR` from RUNE.
    |     ^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
316 - /// ErsDomR – Rust projection of `T:DomR` from RUNE.
316 + /// `ErsDomR` – Rust projection of `T:DomR` from RUNE.
    |

error: this `if` statement can be collapsed
   --> rune-hex\src\hex.rs:420:13
    |
420 | /             if let Some(ref ty) = current_type {
421 | |                 if trimmed.starts_with(char::is_alphanumeric) {
422 | |                     if let Some((_label, vec_part)) = trimmed.split_once(':') {
423 | |                         let vec_part = vec_part.trim();
...   |
441 | |             }
    | |_____________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#collapsible_if
    = note: `-D clippy::collapsible-if` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::collapsible_if)]`
help: collapse nested if block
    |
420 ~             if let Some(ref ty) = current_type
421 ~                 && trimmed.starts_with(char::is_alphanumeric) {
422 |                     if let Some((_label, vec_part)) = trimmed.split_once(':') {
...
439 |                     }
440 ~                 }
    |

error: this `if` statement can be collapsed
   --> rune-hex\src\hex.rs:421:17
    |
421 | /                 if trimmed.starts_with(char::is_alphanumeric) {
422 | |                     if let Some((_label, vec_part)) = trimmed.split_once(':') {
423 | |                         let vec_part = vec_part.trim();
424 | |                         if vec_part.starts_with('[') && vec_part.ends_with(']') {
...   |
440 | |                 }
    | |_________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#collapsible_if
help: collapse nested if block
    |
421 ~                 if trimmed.starts_with(char::is_alphanumeric)
422 ~                     && let Some((_label, vec_part)) = trimmed.split_once(':') {
423 |                         let vec_part = vec_part.trim();
...
438 |                         }
439 ~                     }
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:455:13
    |
455 | /// Default HexGraph built from the canonical hex.rune asset.
    |             ^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
455 - /// Default HexGraph built from the canonical hex.rune asset.
455 + /// Default `HexGraph` built from the canonical hex.rune asset.
    |

error: docs for function which may panic missing `# Panics` section
   --> rune-hex\src\hex.rs:456:1
    |
456 | pub fn default_graph() -> &'static HexGraph {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
note: first possible panic found here
   --> rune-hex\src\hex.rs:458:9
    |
458 |         HexGraph::from_rune("examples/hex.rune").expect("failed to build default hex graph")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_panics_doc
    = note: `-D clippy::missing-panics-doc` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::missing_panics_doc)]`

error: this function could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:463:1
    |
463 | pub fn to_e8_coordinates(exp: &HumanExperience) -> [f32; 8] {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn to_e8_coordinates(exp: &HumanExperience) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate
    = note: `-D clippy::must-use-candidate` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::must_use_candidate)]`

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:488:5
    |
488 |     pub fn from_rune<P: AsRef<Path>>(path: P) -> Result<Self, HexError> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc
    = note: `-D clippy::missing-errors-doc` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::missing_errors_doc)]`

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:548:36
    |
548 |                     adjacency.push(j as u32);
    |                                    ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
    = note: `-D clippy::cast-possible-truncation` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cast_possible_truncation)]`
help: ... or use `try_from` and handle the error accordingly
    |
548 -                     adjacency.push(j as u32);
548 +                     adjacency.push(u32::try_from(j));
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:552:30
    |
552 |             row_offsets.push(adjacency.len() as u32);
    |                              ^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
552 -             row_offsets.push(adjacency.len() as u32);
552 +             row_offsets.push(u32::try_from(adjacency.len()));
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:569:36
    |
569 |     /// Borrow packed coordinates (AoS) for SIMD/GPU export.
    |                                    ^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
569 -     /// Borrow packed coordinates (AoS) for SIMD/GPU export.
569 +     /// Borrow packed coordinates (`AoS`) for SIMD/GPU export.
    |

error: this method could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:570:5
    |
570 |     pub fn coords(&self) -> &[[f32; 8]] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn coords(&self) -> &[[f32; 8]]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:574:31
    |
574 |     /// Borrow CSR adjacency (row_offsets, adjacency, weights).
    |                               ^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
574 -     /// Borrow CSR adjacency (row_offsets, adjacency, weights).
574 +     /// Borrow CSR adjacency (`row_offsets`, adjacency, weights).
    |

error: this method could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:575:5
    |
575 |     pub fn csr(&self) -> (&[u32], &[u32], &[f32]) {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn csr(&self) -> (&[u32], &[u32], &[f32])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:605:25
    |
605 |                 best = (i as u32, d);
    |                         ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
605 -                 best = (i as u32, d);
605 +                 best = (u32::try_from(i), d);
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:616:27
    |
616 |                 out.push((i as u32, d));
    |                           ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
616 -                 out.push((i as u32, d));
616 +                 out.push((u32::try_from(i), d));
    |

error: this `if` statement can be collapsed
   --> rune-hex\src\hex.rs:618:20
    |
618 |               } else if let Some(last) = out.last_mut() {
    |  ____________________^
619 | |                 if d < last.1 {
620 | |                     *last = (i as u32, d);
621 | |                     out.sort_by(|a, b| a.1.total_cmp(&b.1));
622 | |                 }
623 | |             }
    | |_____________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#collapsible_if
help: collapse nested if block
    |
618 ~             } else if let Some(last) = out.last_mut()
619 ~                 && d < last.1 {
620 |                     *last = (i as u32, d);
621 |                     out.sort_by(|a, b| a.1.total_cmp(&b.1));
622 ~                 }
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:620:30
    |
620 |                     *last = (i as u32, d);
    |                              ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
620 -                     *last = (i as u32, d);
620 +                     *last = (u32::try_from(i), d);
    |

error: you have declared `#[inline(always)]` on `l2`. This is usually a bad idea
   --> rune-hex\src\hex.rs:629:1
    |
629 | #[inline(always)]
    | ^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#inline_always
    = note: `-D clippy::inline-always` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::inline_always)]`

error: this could be rewritten as `let...else`
   --> rune-hex\src\hex.rs:671:13
    |
671 | /             let u = match u {
672 | |                 Some(x) => x,
673 | |                 None => break,
674 | |             };
    | |______________^ help: consider writing: `let Some(u) = u else { break };`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#manual_let_else
    = note: `-D clippy::manual-let-else` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::manual_let_else)]`

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:676:16
    |
676 |             if u as u32 == target {
    |                ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
676 -             if u as u32 == target {
676 +             if u32::try_from(u) == target {
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:696:27
    |
696 |                 path.push(cur as u32);
    |                           ^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
696 -                 path.push(cur as u32);
696 +                 path.push(u32::try_from(cur));
    |

error: this function could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:707:1
    |
707 | / pub fn apply_semantic_gradient(
708 | |     graph: &HexGraph,
709 | |     start: VertexId,
710 | |     steps: usize,
711 | |     step_size: f32,
712 | |     direction: [f32; 8],
713 | | ) -> SemanticTrajectory {
    | |_______________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate
help: add the attribute
    |
707 | #[must_use] pub fn apply_semantic_gradient(
    | +++++++++++

error: this function could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:736:1
    |
736 | pub fn analyze_geometry(graph: &HexGraph) -> GeometryReport {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn analyze_geometry(graph: &HexGraph) -> GeometryReport`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:748:39
    |
748 |                     min_pair = Some(((i as u32, j as u32), d));
    |                                       ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
748 -                     min_pair = Some(((i as u32, j as u32), d));
748 +                     min_pair = Some(((u32::try_from(i), j as u32), d));
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:748:49
    |
748 |                     min_pair = Some(((i as u32, j as u32), d));
    |                                                 ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
748 -                     min_pair = Some(((i as u32, j as u32), d));
748 +                     min_pair = Some(((i as u32, u32::try_from(j)), d));
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:751:35
    |
751 |                 min_pair = Some(((i as u32, j as u32), d));
    |                                   ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
751 -                 min_pair = Some(((i as u32, j as u32), d));
751 +                 min_pair = Some(((u32::try_from(i), j as u32), d));
    |

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> rune-hex\src\hex.rs:751:45
    |
751 |                 min_pair = Some(((i as u32, j as u32), d));
    |                                             ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
751 -                 min_pair = Some(((i as u32, j as u32), d));
751 +                 min_pair = Some(((i as u32, u32::try_from(j)), d));
    |

error: used `cloned` where `copied` could be used instead
   --> rune-hex\src\hex.rs:779:37
    |
779 |         let min_norm = norms.iter().cloned().fold(f32::INFINITY, f32::min);
    |                                     ^^^^^^ help: try: `copied`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cloned_instead_of_copied
    = note: `-D clippy::cloned-instead-of-copied` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cloned_instead_of_copied)]`

error: used `cloned` where `copied` could be used instead
   --> rune-hex\src\hex.rs:780:37
    |
780 |         let max_norm = norms.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
    |                                     ^^^^^^ help: try: `copied`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cloned_instead_of_copied

error: casting `usize` to `f32` causes a loss of precision (`usize` is 32 or 64 bits wide, but `f32`'s mantissa is only 23 bits wide)
   --> rune-hex\src\hex.rs:781:53
    |
781 |         let mean_norm = norms.iter().sum::<f32>() / norms.len() as f32;
    |                                                     ^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss
    = note: `-D clippy::cast-precision-loss` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cast_precision_loss)]`

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:803:19
    |
803 | /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
    |                   ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
803 - /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
803 + /// Reference CPU `DomR` computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:803:48
    |
803 | /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
    |                                                ^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
803 - /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
803 + /// Reference CPU DomR computation: score[x] = `Σ_o` e[o] * dot(root_o, root_x), top N.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:803:59
    |
803 | /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
    |                                                           ^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
803 - /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
803 + /// Reference CPU DomR computation: score[x] = Σ_o e[o] * `dot(root_o`, root_x), top N.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:803:71
    |
803 | /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
    |                                                                       ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
803 - /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
803 + /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, `root_x`), top N.
    |

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:804:5
    |
804 | /// GeoCel trajectory generation implementation.
    |     ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
804 - /// GeoCel trajectory generation implementation.
804 + /// `GeoCel` trajectory generation implementation.
    |

error: first doc comment paragraph is too long
   --> rune-hex\src\hex.rs:803:1
    |
803 | / /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
804 | | /// GeoCel trajectory generation implementation.
805 | | /// Provides dynamic navigation through the E8 semantic lattice using
806 | | /// momentum dynamics and stochastic processes.
    | |_^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#too_long_first_doc_paragraph
    = note: `-D clippy::too-long-first-doc-paragraph` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::too_long_first_doc_paragraph)]`
help: add an empty line
    |
804 | /// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
805 + ///
    |

error: usage of wildcard import
   --> rune-hex\src\hex.rs:808:9
    |
808 |     use super::*;
    |         ^^^^^^^^ help: try: `super::{GSLFrame, HexGraph, HexError, WeylSemanticAddress, normalize, default_graph, SemanticSpace}`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#wildcard_imports
    = note: `-D clippy::wildcard-imports` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::wildcard_imports)]`

error: item in documentation is missing backticks
   --> rune-hex\src\hex.rs:810:17
    |
810 |     /// Primary GeoCel trajectory generator using intent and anima-driven navigation.
    |                 ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
810 -     /// Primary GeoCel trajectory generator using intent and anima-driven navigation.
810 +     /// Primary `GeoCel` trajectory generator using intent and anima-driven navigation.
    |

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:811:5
    |
811 | /     pub fn spawn_surveyor_worm(
812 | |         intent: &str,
813 | |         frame: GSLFrame,
814 | |         anima: f32,
815 | |         graph: &HexGraph,
816 | |     ) -> Result<Vec<[f32; 8]>, HexError> {
    | |________________________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: docs for function which may panic missing `# Panics` section
   --> rune-hex\src\hex.rs:832:9
    |
832 |         pub fn from_text_intent(intent: &str, _anima: f32) -> Result<Self, HexError> {
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
note: first possible panic found here
   --> rune-hex\src\hex.rs:833:29
    |
833 |               let timestamp = std::time::SystemTime::now()
    |  _____________________________^
834 | |                 .duration_since(std::time::UNIX_EPOCH)
835 | |                 .unwrap()
    | |_________________________^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_panics_doc

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:832:9
    |
832 |         pub fn from_text_intent(intent: &str, _anima: f32) -> Result<Self, HexError> {
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: unnecessary structure name repetition
   --> rune-hex\src\hex.rs:858:16
    |
858 |             Ok(WeylSemanticAddress {
    |                ^^^^^^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self
    = note: `-D clippy::use-self` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::use_self)]`

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:867:9
    |
867 |         pub fn apply_momentum_dynamics(&self, anima: f32) -> Result<Vec<[f32; 8]>, HexError> {
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: this function could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:888:5
    |
888 |     pub fn momentum_step(vec: &[f32; 8], anima: f32) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn momentum_step(vec: &[f32; 8], anima: f32) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
   --> rune-hex\src\hex.rs:894:26
    |
894 |             result[i] += anima * normalized[i] + 0.1 * random_unit_vector()[i];
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `anima.mul_add(normalized[i], 0.1 * random_unit_vector()[i])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops
    = note: `-D clippy::suboptimal-flops` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::suboptimal_flops)]`

error: this function could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:901:5
    |
901 |     pub fn noise_injection(vec: &[f32; 8], anima: f32) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn noise_injection(vec: &[f32; 8], anima: f32) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: the loop variable `i` is only used to index `result`
   --> rune-hex\src\hex.rs:904:18
    |
904 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
    = note: `-D clippy::needless-range-loop` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::needless_range_loop)]`
help: consider using an iterator
    |
904 -         for i in 0..8 {
904 +         for <item> in &mut result {
    |

error: this function could have a `#[must_use]` attribute
   --> rune-hex\src\hex.rs:911:5
    |
911 |     pub fn quantize_to_valid_root(vec: &[f32; 8]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn quantize_to_valid_root(vec: &[f32; 8]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:919:5
    |
919 | /     pub fn apply_momentum_dynamics(
920 | |         addr: &WeylSemanticAddress,
921 | |         anima: f32,
922 | |     ) -> Result<Vec<[f32; 8]>, HexError> {
    | |________________________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:927:5
    |
927 | /     pub fn quantize_to_e8_roots(
928 | |         evolution: &[[f32; 8]],
929 | |         _frame: GSLFrame,
930 | |         graph: &HexGraph,
931 | |     ) -> Result<Vec<[f32; 8]>, HexError> {
    | |________________________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:943:5
    |
943 | /     pub fn generate_trajectory(
944 | |         evolution: &[[f32; 8]],
945 | |         _graph: &HexGraph,
946 | |     ) -> Result<Vec<[f32; 8]>, HexError> {
    | |________________________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: the loop variable `i` is used to index `vec`
   --> rune-hex\src\hex.rs:956:18
    |
956 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator and enumerate()
    |
956 -         for i in 0..8 {
956 +         for (i, <item>) in vec.iter_mut().enumerate() {
    |

error: casting `usize` to `f32` causes a loss of precision (`usize` is 32 or 64 bits wide, but `f32`'s mantissa is only 23 bits wide)
   --> rune-hex\src\hex.rs:957:23
    |
957 |             vec[i] = (i as f32 * PI / 4.0).sin() * 0.1; // Deterministic pseudo-random
    |                       ^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: casting `u128` to `f32` causes a loss of precision (`u128` is 128 bits wide, but `f32`'s mantissa is only 23 bits wide)
   --> rune-hex\src\hex.rs:966:10
    |
966 |           (std::time::SystemTime::now()
    |  __________^
967 | |             .duration_since(std::time::UNIX_EPOCH)
968 | |             .unwrap()
969 | |             .as_nanos() as f32
    | |______________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: docs for function returning `Result` missing `# Errors` section
   --> rune-hex\src\hex.rs:975:1
    |
975 | pub fn domr_cpu(graph: &HexGraph, energy: &[f32], n_dr: usize) -> Result<DomR, HexError> {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: casting `usize` to `u8` may truncate the value
    --> rune-hex\src\hex.rs:1007:20
     |
1007 |         roots.push(idx as u8);
     |                    ^^^^^^^^^
     |
     = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
     = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
     |
1007 -         roots.push(idx as u8);
1007 +         roots.push(u8::try_from(idx));
     |

error: could not compile `rune-hex` (lib) due to 76 previous errors
warning: build failed, waiting for other jobs to finish...
error: could not compile `rune-hex` (lib test) due to 75 previous errors
error: item in documentation is missing backticks
  --> hydron-core\src\fisher.rs:23:9
   |
23 |     /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
   |         ^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
   = note: `-D clippy::doc-markdown` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::doc_markdown)]`
help: try
   |
23 -     /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
23 +     /// `F_ij` = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
   |

error: item in documentation is missing backticks
  --> hydron-core\src\fisher.rs:23:19
   |
23 |     /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
   |                   ^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
23 -     /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
23 +     /// F_ij = E[∂`log(p)/∂θ_i` * ∂log(p)/∂θ_j]
   |

error: item in documentation is missing backticks
  --> hydron-core\src\fisher.rs:23:34
   |
23 |     /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
   |                                  ^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
23 -     /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
23 +     /// F_ij = E[∂log(p)/∂θ_i * ∂`log(p)/∂θ_j`]
   |

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\fisher.rs:25:5
   |
25 |     pub fn fisher_matrix(resonance: &[u32; 240]) -> [[f32; 8]; 8] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn fisher_matrix(resonance: &[u32; 240]) -> [[f32; 8]; 8]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate
   = note: `-D clippy::must-use-candidate` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::must_use_candidate)]`

error: casting `u32` to `f32` causes a loss of precision (`u32` is 32 bits wide, but `f32`'s mantissa is only 23 bits wide)
  --> hydron-core\src\fisher.rs:34:23
   |
34 |         let total_f = total as f32;
   |                       ^^^^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss
   = note: `-D clippy::cast-precision-loss` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::cast_precision_loss)]`

error: casting `u32` to `f32` causes a loss of precision (`u32` is 32 bits wide, but `f32`'s mantissa is only 23 bits wide)
  --> hydron-core\src\fisher.rs:35:57
   |
35 |         let probs: Vec<f32> = resonance.iter().map(|&r| r as f32 / total_f).collect();
   |                                                         ^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\fisher.rs:63:5
   |
63 |     pub fn uncertainty(fisher_matrix: &[[f32; 8]; 8]) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn uncertainty(fisher_matrix: &[[f32; 8]; 8]) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\fisher.rs:75:5
   |
75 |     pub fn kl_divergence(p: &[f32], q: &[f32]) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn kl_divergence(p: &[f32], q: &[f32]) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\fisher.rs:93:5
   |
93 |     pub fn information_metric(fisher_matrix: &[[f32; 8]; 8]) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn information_metric(fisher_matrix: &[[f32; 8]; 8]) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: ln(1 + x) can be computed more accurately
  --> hydron-core\src\fisher.rs:95:9
   |
95 |         (1.0 + trace).ln()
   |         ^^^^^^^^^^^^^^^^^^ help: consider using: `trace.ln_1p()`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#imprecise_flops
   = note: `-D clippy::imprecise-flops` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::imprecise_flops)]`

error: item in documentation is missing backticks
  --> hydron-core\src\fisher.rs:99:16
   |
99 |     /// H = -Σ p_i log(p_i)
   |                ^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
99 -     /// H = -Σ p_i log(p_i)
99 +     /// H = -Σ `p_i` log(p_i)
   |

error: item in documentation is missing backticks
  --> hydron-core\src\fisher.rs:99:20
   |
99 |     /// H = -Σ p_i log(p_i)
   |                    ^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
99 -     /// H = -Σ p_i log(p_i)
99 +     /// H = -Σ p_i `log(p_i)`
   |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\fisher.rs:100:5
    |
100 |     pub fn entropy(distribution: &[f32]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn entropy(distribution: &[f32]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
   --> hydron-core\src\fisher.rs:117:9
    |
117 |     /// d_F(θ1, θ2)² ≈ (θ1 - θ2)ᵀ F (θ1 - θ2)
    |         ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
117 -     /// d_F(θ1, θ2)² ≈ (θ1 - θ2)ᵀ F (θ1 - θ2)
117 +     /// `d_F(θ1`, θ2)² ≈ (θ1 - θ2)ᵀ F (θ1 - θ2)
    |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\fisher.rs:118:5
    |
118 | /     pub fn fisher_distance(
119 | |         theta1: &[f32; 8],
120 | |         theta2: &[f32; 8],
121 | |         fisher_matrix: &[[f32; 8]; 8],
122 | |     ) -> f32 {
    | |____________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate
help: add the attribute
    |
118 |     #[must_use] pub fn fisher_distance(
    |     +++++++++++

error: item in documentation is missing backticks
  --> hydron-core\src\gf8.rs:71:12
   |
71 | /// A GF8 (GeoFloat8), an 8-dimensional geometric float gf8.
   |            ^^^^^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
71 - /// A GF8 (GeoFloat8), an 8-dimensional geometric float gf8.
71 + /// A GF8 (`GeoFloat8`), an 8-dimensional geometric float gf8.
   |

error: used underscore-prefixed binding
  --> hydron-core\src\gf8.rs:83:5
   |
83 |     coords: [f32; 8],
   |     ^^^^^^
   |
note: binding is defined here
  --> hydron-core\src\gf8.rs:83:5
   |
83 |     coords: [f32; 8],
   |     ^^^^^^
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#used_underscore_binding
   = note: `-D clippy::used-underscore-binding` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::used_underscore_binding)]`

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\gf8.rs:94:5
   |
94 |     pub fn new(coords: [f32; 8]) -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new(coords: [f32; 8]) -> Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
   --> hydron-core\src\gf8.rs:103:32
    |
103 |     /// math-heavy code where "from_coords" more clearly expresses intent than "new".
    |                                ^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
103 -     /// math-heavy code where "from_coords" more clearly expresses intent than "new".
103 +     /// math-heavy code where "`from_coords`" more clearly expresses intent than "new".
    |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:105:5
    |
105 |     pub fn from_coords(coords: [f32; 8]) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn from_coords(coords: [f32; 8]) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:115:5
    |
115 |     pub fn from_bits_even_parity(bits: [u8; 8]) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn from_bits_even_parity(bits: [u8; 8]) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:142:5
    |
142 |     pub fn from_scalar(x: f32) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn from_scalar(x: f32) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:150:5
    |
150 |     pub fn coords(&self) -> &[f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn coords(&self) -> &[f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
   --> hydron-core\src\gf8.rs:150:5
    |
150 | /     pub fn coords(&self) -> &[f32; 8] {
151 | |         &self.coords
152 | |     }
    | |_____^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
    = note: `-D clippy::missing-const-for-fn` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::missing_const_for_fn)]`
help: make the function `const`
    |
150 |     pub const fn coords(&self) -> &[f32; 8] {
    |         +++++

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:158:5
    |
158 |     pub fn to_scalar(&self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn to_scalar(&self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
   --> hydron-core\src\gf8.rs:158:5
    |
158 | /     pub fn to_scalar(&self) -> f32 {
159 | |         self.coords[0]
160 | |     }
    | |_____^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
    |
158 |     pub const fn to_scalar(&self) -> f32 {
    |         +++++

error: you have declared `#[inline(always)]` on `dot`. This is usually a bad idea
   --> hydron-core\src\gf8.rs:167:5
    |
167 |     #[inline(always)]
    |     ^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#inline_always
    = note: `-D clippy::inline-always` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::inline_always)]`

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:168:5
    |
168 |     pub fn dot(&self, other: &[f32; 8]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn dot(&self, other: &[f32; 8]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:185:5
    |
185 |     pub fn norm2(&self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn norm2(&self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:198:5
    |
198 |     pub fn norm(&self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn norm(&self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:215:5
    |
215 |     pub fn resonance_profile(&self) -> Vec<f32> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn resonance_profile(&self) -> Vec<f32>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:221:5
    |
221 |     pub fn quantize(&self) -> (u8, Gf8) {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn quantize(&self) -> (u8, Gf8)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
   --> hydron-core\src\gf8.rs:221:36
    |
221 |     pub fn quantize(&self) -> (u8, Gf8) {
    |                                    ^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self
    = note: `-D clippy::use-self` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::use_self)]`

error: casting `usize` to `u8` may truncate the value
   --> hydron-core\src\gf8.rs:232:10
    |
232 |         (best_idx as u8, Gf8::new(roots[best_idx]))
    |          ^^^^^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
    = note: `-D clippy::cast-possible-truncation` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cast_possible_truncation)]`
help: ... or use `try_from` and handle the error accordingly
    |
232 -         (best_idx as u8, Gf8::new(roots[best_idx]))
232 +         (u8::try_from(best_idx), Gf8::new(roots[best_idx]))
    |

error: unnecessary structure name repetition
   --> hydron-core\src\gf8.rs:232:26
    |
232 |         (best_idx as u8, Gf8::new(roots[best_idx]))
    |                          ^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:237:5
    |
237 |     pub fn quantize_subset(&self, allowed_roots: &[u8]) -> (u8, Gf8, f32) {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn quantize_subset(&self, allowed_roots: &[u8]) -> (u8, Gf8, f32)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
   --> hydron-core\src\gf8.rs:237:65
    |
237 |     pub fn quantize_subset(&self, allowed_roots: &[u8]) -> (u8, Gf8, f32) {
    |                                                                 ^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: unnecessary structure name repetition
   --> hydron-core\src\gf8.rs:254:20
    |
254 |         (best_idx, Gf8::new(vec), best_dot)
    |                    ^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:260:5
    |
260 |     pub fn spherical_distance_to(&self, other: &Self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn spherical_distance_to(&self, other: &Self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:265:5
    |
265 |     pub fn spherical_slerp(&self, other: &Self, t: f32) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn spherical_slerp(&self, other: &Self, t: f32) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: missing `#[must_use]` attribute on a method returning `Self`
   --> hydron-core\src\gf8.rs:265:5
    |
265 | /     pub fn spherical_slerp(&self, other: &Self, t: f32) -> Self {
266 | |         Self::new(SphericalLayer::slerp(self.coords(), other.coords(), t))
267 | |     }
    | |_____^
    |
    = help: consider adding the `#[must_use]` attribute to the method or directly to the `Self` type
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#return_self_not_must_use
    = note: `-D clippy::return-self-not-must-use` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::return_self_not_must_use)]`

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:270:5
    |
270 |     pub fn spherical_antipodal(&self) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn spherical_antipodal(&self) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: missing `#[must_use]` attribute on a method returning `Self`
   --> hydron-core\src\gf8.rs:270:5
    |
270 | /     pub fn spherical_antipodal(&self) -> Self {
271 | |         Self {
272 | |             coords: SphericalLayer::antipodal(self.coords()),
273 | |         }
274 | |     }
    | |_____^
    |
    = help: consider adding the `#[must_use]` attribute to the method or directly to the `Self` type
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#return_self_not_must_use

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:278:5
    |
278 |     pub fn hyperbolic_distance_to(&self, other: &Self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn hyperbolic_distance_to(&self, other: &Self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:286:5
    |
286 |     pub fn hyperbolic_mobius_add(&self, other: &Self) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn hyperbolic_mobius_add(&self, other: &Self) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: missing `#[must_use]` attribute on a method returning `Self`
   --> hydron-core\src\gf8.rs:286:5
    |
286 | /     pub fn hyperbolic_mobius_add(&self, other: &Self) -> Self {
287 | |         let self_ball = self.coords.map(|x| x * 0.95);
288 | |         let other_ball = other.coords.map(|x| x * 0.95);
289 | |         let result_ball = HyperbolicLayer::mobius_add(&self_ball, &other_ball);
290 | |         // Map back to sphere? Or return as ball coords?
291 | |         Self::new(result_ball)
292 | |     }
    | |_____^
    |
    = help: consider adding the `#[must_use]` attribute to the method or directly to the `Self` type
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#return_self_not_must_use

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:295:5
    |
295 |     pub fn fisher_distance_to(&self, other: &Self, fisher_matrix: &[[f32; 8]; 8]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn fisher_distance_to(&self, other: &Self, fisher_matrix: &[[f32; 8]; 8]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:300:5
    |
300 |     pub fn fisher_uncertainty(fisher_matrix: &[[f32; 8]; 8]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn fisher_uncertainty(fisher_matrix: &[[f32; 8]; 8]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:305:5
    |
305 |     pub fn to_quaternion(&self) -> [f32; 4] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn to_quaternion(&self) -> [f32; 4]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:310:5
    |
310 |     pub fn lorentzian_in_past_light_cone(&self, other: &Self) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn lorentzian_in_past_light_cone(&self, other: &Self) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: casts from `f32` to `f64` can be expressed infallibly using `From`
   --> hydron-core\src\gf8.rs:311:55
    |
311 |         let p1_coords: [f64; 8] = self.coords.map(|x| x as f64);
    |                                                       ^^^^^^^^
    |
    = help: an `as` cast can become silently lossy if the types change in the future
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_lossless
    = note: `-D clippy::cast-lossless` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cast_lossless)]`
help: use `f64::from` instead
    |
311 -         let p1_coords: [f64; 8] = self.coords.map(|x| x as f64);
311 +         let p1_coords: [f64; 8] = self.coords.map(|x| f64::from(x));
    |

error: casts from `f32` to `f64` can be expressed infallibly using `From`
   --> hydron-core\src\gf8.rs:312:56
    |
312 |         let p2_coords: [f64; 8] = other.coords.map(|x| x as f64);
    |                                                        ^^^^^^^^
    |
    = help: an `as` cast can become silently lossy if the types change in the future
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_lossless
help: use `f64::from` instead
    |
312 -         let p2_coords: [f64; 8] = other.coords.map(|x| x as f64);
312 +         let p2_coords: [f64; 8] = other.coords.map(|x| f64::from(x));
    |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:322:5
    |
322 |     pub fn symplectic_hamiltonian(&self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn symplectic_hamiltonian(&self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:332:5
    |
332 |     pub fn spherical_mean(points: &[Self]) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn spherical_mean(points: &[Self]) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:339:5
    |
339 |     pub fn fisher_matrix_from_resonance(resonance: &[u32; 240]) -> [[f32; 8]; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn fisher_matrix_from_resonance(resonance: &[u32; 240]) -> [[f32; 8]; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:344:5
    |
344 |     pub fn quaternion_slerp_from_gf8(a: &Self, b: &Self, t: f32) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn quaternion_slerp_from_gf8(a: &Self, b: &Self, t: f32) -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: usage of wildcard import
   --> hydron-core\src\gf8.rs:475:9
    |
475 |     use std::arch::x86_64::*;
    |         ^^^^^^^^^^^^^^^^^^^^ help: try: `std::arch::x86_64::{_mm256_loadu_ps, _mm256_add_ps, _mm256_storeu_ps, _mm256_sub_ps, _mm256_dp_ps, _mm256_castps256_ps128, _mm256_extractf128_ps, _mm_add_ss, _mm_cvtss_f32}`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#wildcard_imports
    = note: `-D clippy::wildcard-imports` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::wildcard_imports)]`

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:505:5
    |
505 |     pub fn get_available_f32_256_intrinsics() -> Vec<&'static str> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn get_available_f32_256_intrinsics() -> Vec<&'static str>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unneeded `return` statement
   --> hydron-core\src\gf8.rs:508:13
    |
508 | /             return intrinsics_for_f32_width(256)
509 | |                 .filter(|i| {
510 | |                     let tech = i.technology;
511 | |                     (tech.contains("AVX2") && is_x86_feature_detected!("avx2"))
...   |
515 | |                 .map(|i| i.name)
516 | |                 .collect();
    | |__________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_return
    = note: `-D clippy::needless-return` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::needless_return)]`
help: remove `return`
    |
508 ~             intrinsics_for_f32_width(256)
509 +                 .filter(|i| {
510 +                     let tech = i.technology;
511 +                     (tech.contains("AVX2") && is_x86_feature_detected!("avx2"))
512 +                         || (tech.contains("AVX") && is_x86_feature_detected!("avx"))
513 +                         || (tech.contains("FMA") && is_x86_feature_detected!("fma"))
514 +                 })
515 +                 .map(|i| i.name)
516 ~                 .collect()
    |

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:528:5
    |
528 |     pub fn gf8_add_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn gf8_add_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:554:5
    |
554 |     pub fn gf8_sub_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn gf8_sub_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:580:5
    |
580 |     pub fn gf8_dot_simd(a: &[f32; 8], b: &[f32; 8]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn gf8_dot_simd(a: &[f32; 8], b: &[f32; 8]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:587:5
    |
587 |     pub fn gf8_norm2_simd(a: &[f32; 8]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn gf8_norm2_simd(a: &[f32; 8]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:615:5
    |
615 |     pub fn gf8_matvec_simd(mat: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn gf8_matvec_simd(mat: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
   --> hydron-core\src\gf8.rs:687:47
    |
687 |     /// AVX implementation for dot product on x86_64.
    |                                               ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
687 -     /// AVX implementation for dot product on x86_64.
687 +     /// AVX implementation for dot product on `x86_64`.
    |

error: item in documentation is missing backticks
   --> hydron-core\src\gf8.rs:706:51
    |
706 |     /// AVX+FMA implementation for dot product on x86_64.
    |                                                   ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
706 -     /// AVX+FMA implementation for dot product on x86_64.
706 +     /// AVX+FMA implementation for dot product on `x86_64`.
    |

error: the loop variable `k` is used to index `v`
   --> hydron-core\src\gf8.rs:793:18
    |
793 |         for k in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
    = note: `-D clippy::needless-range-loop` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::needless_range_loop)]`
help: consider using an iterator and enumerate()
    |
793 -         for k in 0..8 {
793 +         for (k, <item>) in v.iter_mut().enumerate() {
    |

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\gf8.rs:810:1
    |
810 | pub fn get_e8_roots() -> &'static [[f32; 8]; 240] {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn get_e8_roots() -> &'static [[f32; 8]; 240]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\hyperbolic.rs:23:5
   |
23 |     pub fn project(coords: &[f32; 8]) -> [f32; 8] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn project(coords: &[f32; 8]) -> [f32; 8]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
  --> hydron-core\src\hyperbolic.rs:58:9
   |
58 |     /// d_H(x, y) = arcosh(1 + 2||x - y||² / ((1 - ||x||²)(1 - ||y||²)))
   |         ^^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
58 -     /// d_H(x, y) = arcosh(1 + 2||x - y||² / ((1 - ||x||²)(1 - ||y||²)))
58 +     /// `d_H(x`, y) = arcosh(1 + 2||x - y||² / ((1 - ||x||²)(1 - ||y||²)))
   |

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\hyperbolic.rs:59:5
   |
59 |     pub fn distance(x: &[f32; 8], y: &[f32; 8]) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn distance(x: &[f32; 8], y: &[f32; 8]) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\hyperbolic.rs:108:5
    |
108 |     pub fn mobius_add(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn mobius_add(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\hyperbolic.rs:122:33
    |
122 |         let numerator_a_coeff = 1.0 + 2.0 * dot_ab + b_norm_sq;
    |                                 ^^^^^^^^^^^^^^^^^^ help: consider using: `2.0f32.mul_add(dot_ab, 1.0)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops
    = note: `-D clippy::suboptimal-flops` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::suboptimal_flops)]`

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\hyperbolic.rs:124:27
    |
124 |         let denominator = 1.0 + 2.0 * dot_ab + a_norm_sq * b_norm_sq;
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `a_norm_sq.mul_add(b_norm_sq, 1.0 + 2.0 * dot_ab)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\hyperbolic.rs:124:27
    |
124 |         let denominator = 1.0 + 2.0 * dot_ab + a_norm_sq * b_norm_sq;
    |                           ^^^^^^^^^^^^^^^^^^ help: consider using: `2.0f32.mul_add(dot_ab, 1.0)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\hyperbolic.rs:132:25
    |
132 |             result[i] = (numerator_a_coeff * a[i] + numerator_b_coeff * b[i]) / denominator;
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `numerator_a_coeff.mul_add(a[i], numerator_b_coeff * b[i])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\hyperbolic.rs:139:5
    |
139 |     pub fn norm(x: &[f32; 8]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn norm(x: &[f32; 8]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\hyperbolic.rs:146:5
    |
146 |     pub fn interpolate(x: &[f32; 8], y: &[f32; 8], t: f32) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn interpolate(x: &[f32; 8], y: &[f32; 8], t: f32) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\intrinsics.rs:57:5
   |
57 |     pub fn is_f32_vector(&self) -> bool {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_f32_vector(&self) -> bool`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\intrinsics.rs:65:5
   |
65 |     pub fn is_f64_vector(&self) -> bool {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_f64_vector(&self) -> bool`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\intrinsics.rs:73:5
   |
73 |     pub fn simd_width_bits(&self) -> Option<u32> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn simd_width_bits(&self) -> Option<u32>`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
   --> hydron-core\src\intrinsics.rs:231:48
    |
231 | /// Look up an intrinsic by exact name (e.g. "_mm256_add_ps").
    |                                                ^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
231 - /// Look up an intrinsic by exact name (e.g. "_mm256_add_ps").
231 + /// Look up an intrinsic by exact name (e.g. "_`mm256_add_ps`").
    |

error: this function could have a `#[must_use]` attribute
   --> hydron-core\src\intrinsics.rs:232:1
    |
232 | pub fn find_intrinsic_by_name(name: &str) -> Option<&'static Gf8Intrinsic> {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn find_intrinsic_by_name(name: &str) -> Option<&'static Gf8Intrinsic>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:31:5
   |
31 |     pub fn new(coords: [f64; 8]) -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new(coords: [f64; 8]) -> Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
  --> hydron-core\src\lorentzian.rs:31:5
   |
31 | /     pub fn new(coords: [f64; 8]) -> Self {
32 | |         Self { coords }
33 | |     }
   | |_____^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
   |
31 |     pub const fn new(coords: [f64; 8]) -> Self {
   |         +++++

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:36:5
   |
36 |     pub fn time(&self) -> f64 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn time(&self) -> f64`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
  --> hydron-core\src\lorentzian.rs:36:5
   |
36 | /     pub fn time(&self) -> f64 {
37 | |         self.coords[0]
38 | |     }
   | |_____^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
   |
36 |     pub const fn time(&self) -> f64 {
   |         +++++

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:41:5
   |
41 |     pub fn spatial(&self) -> &[f64] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn spatial(&self) -> &[f64]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:47:5
   |
47 |     pub fn minkowski_interval(&self, other: &SpacetimePoint) -> f64 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn minkowski_interval(&self, other: &SpacetimePoint) -> f64`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
  --> hydron-core\src\lorentzian.rs:47:46
   |
47 |     pub fn minkowski_interval(&self, other: &SpacetimePoint) -> f64 {
   |                                              ^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\lorentzian.rs:56:9
   |
56 |         -dt * dt + spatial_dist_sq
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `(-dt).mul_add(dt, spatial_dist_sq)`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:61:5
   |
61 |     pub fn proper_time(&self, other: &SpacetimePoint) -> Option<f64> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn proper_time(&self, other: &SpacetimePoint) -> Option<f64>`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
  --> hydron-core\src\lorentzian.rs:61:39
   |
61 |     pub fn proper_time(&self, other: &SpacetimePoint) -> Option<f64> {
   |                                       ^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:71:5
   |
71 |     pub fn is_timelike(&self, other: &SpacetimePoint) -> bool {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_timelike(&self, other: &SpacetimePoint) -> bool`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
  --> hydron-core\src\lorentzian.rs:71:39
   |
71 |     pub fn is_timelike(&self, other: &SpacetimePoint) -> bool {
   |                                       ^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:76:5
   |
76 |     pub fn is_spacelike(&self, other: &SpacetimePoint) -> bool {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_spacelike(&self, other: &SpacetimePoint) -> bool`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
  --> hydron-core\src\lorentzian.rs:76:40
   |
76 |     pub fn is_spacelike(&self, other: &SpacetimePoint) -> bool {
   |                                        ^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:81:5
   |
81 |     pub fn is_lightlike(&self, other: &SpacetimePoint) -> bool {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_lightlike(&self, other: &SpacetimePoint) -> bool`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
  --> hydron-core\src\lorentzian.rs:81:40
   |
81 |     pub fn is_lightlike(&self, other: &SpacetimePoint) -> bool {
   |                                        ^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\lorentzian.rs:86:5
   |
86 |     pub fn causal_relation(&self, other: &SpacetimePoint) -> CausalRelation {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn causal_relation(&self, other: &SpacetimePoint) -> CausalRelation`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
  --> hydron-core\src\lorentzian.rs:86:43
   |
86 |     pub fn causal_relation(&self, other: &SpacetimePoint) -> CausalRelation {
   |                                           ^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: you are deriving `PartialEq` and can implement `Eq`
   --> hydron-core\src\lorentzian.rs:112:24
    |
112 | #[derive(Clone, Debug, PartialEq)]
    |                        ^^^^^^^^^ help: consider deriving `Eq` as well: `PartialEq, Eq`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#derive_partial_eq_without_eq
    = note: `-D clippy::derive-partial-eq-without-eq` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::derive_partial_eq_without_eq)]`

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:137:5
    |
137 |     pub fn new() -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
   --> hydron-core\src\lorentzian.rs:137:5
    |
137 | /     pub fn new() -> Self {
138 | |         Self { points: Vec::new() }
139 | |     }
    | |_____^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
    |
137 |     pub const fn new() -> Self {
    |         +++++

error: docs for function returning `Result` missing `# Errors` section
   --> hydron-core\src\lorentzian.rs:142:5
    |
142 |     pub fn add_point(&mut self, point: SpacetimePoint) -> Result<(), &'static str> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc
    = note: `-D clippy::missing-errors-doc` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::missing_errors_doc)]`

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:153:5
    |
153 |     pub fn proper_time(&self) -> f64 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn proper_time(&self) -> f64`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:164:5
    |
164 |     pub fn four_velocity(&self, index: usize) -> Option<[f64; 8]> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn four_velocity(&self, index: usize) -> Option<[f64; 8]>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:200:5
    |
200 |     pub fn new() -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
   --> hydron-core\src\lorentzian.rs:200:5
    |
200 | /     pub fn new() -> Self {
201 | |         Self {
202 | |             worldlines: Vec::new(),
203 | |             signature: [-1, 1, 1, 1, 1, 1, 1, 1],
204 | |         }
205 | |     }
    | |_____^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
    |
200 |     pub const fn new() -> Self {
    |         +++++

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:213:5
    |
213 |     pub fn geodesic_distance(&self, p1: &SpacetimePoint, p2: &SpacetimePoint) -> Option<f64> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn geodesic_distance(&self, p1: &SpacetimePoint, p2: &SpacetimePoint) -> Option<f64>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:218:5
    |
218 |     pub fn in_past_light_cone(&self, point: &SpacetimePoint, reference: &SpacetimePoint) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn in_past_light_cone(&self, point: &SpacetimePoint, reference: &SpacetimePoint) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:225:5
    |
225 |     pub fn in_future_light_cone(&self, point: &SpacetimePoint, reference: &SpacetimePoint) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn in_future_light_cone(&self, point: &SpacetimePoint, reference: &SpacetimePoint) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:233:5
    |
233 |     pub fn lorentz_boost(&self, point: &SpacetimePoint, velocity: f64) -> SpacetimePoint {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn lorentz_boost(&self, point: &SpacetimePoint, velocity: f64) -> SpacetimePoint`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\lorentzian.rs:238:27
    |
238 |         let gamma = 1.0 / (1.0 - velocity * velocity).sqrt();
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `velocity.mul_add(-velocity, 1.0)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\lorentzian.rs:244:30
    |
244 |         boosted[0] = gamma * (t - velocity * x);
    |                              ^^^^^^^^^^^^^^^^^^ help: consider using: `velocity.mul_add(-x, t)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\lorentzian.rs:245:30
    |
245 |         boosted[1] = gamma * (x - velocity * t);
    |                              ^^^^^^^^^^^^^^^^^^ help: consider using: `velocity.mul_add(-t, x)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:261:61
    |
261 | /// Causal node representing an event in spacetime (extends SpacetimePoint)
    |                                                             ^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
261 - /// Causal node representing an event in spacetime (extends SpacetimePoint)
261 + /// Causal node representing an event in spacetime (extends `SpacetimePoint`)
    |

error: this could be a `const fn`
   --> hydron-core\src\lorentzian.rs:279:5
    |
279 | /     pub fn new(event_id: u64, location: SpacetimePoint, e8_root: usize, payload: T) -> Self {
280 | |         Self {
281 | |             location,
282 | |             event_id,
...   |
286 | |     }
    | |_____^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
    |
279 |     pub const fn new(event_id: u64, location: SpacetimePoint, e8_root: usize, payload: T) -> Self {
    |         +++++

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:288:67
    |
288 |     /// Compute spacetime interval to another event (delegates to SpacetimePoint)
    |                                                                   ^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
288 -     /// Compute spacetime interval to another event (delegates to SpacetimePoint)
288 +     /// Compute spacetime interval to another event (delegates to `SpacetimePoint`)
    |

error: unnecessary structure name repetition
   --> hydron-core\src\lorentzian.rs:289:46
    |
289 |     pub fn spacetime_interval(&self, other: &CausalNode<T>) -> f64 {
    |                                              ^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: unnecessary structure name repetition
   --> hydron-core\src\lorentzian.rs:294:45
    |
294 |     pub fn is_causally_after(&self, other: &CausalNode<T>) -> bool {
    |                                             ^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: unnecessary structure name repetition
   --> hydron-core\src\lorentzian.rs:302:50
    |
302 |     pub fn is_spacelike_separated(&self, other: &CausalNode<T>) -> bool {
    |                                                  ^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:313:24
    |
313 |     /// Causal edges: (cause_id, effect_id)
    |                        ^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
313 -     /// Causal edges: (cause_id, effect_id)
313 +     /// Causal edges: (`cause_id`, effect_id)
    |

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:313:34
    |
313 |     /// Causal edges: (cause_id, effect_id)
    |                                  ^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
313 -     /// Causal edges: (cause_id, effect_id)
313 +     /// Causal edges: (cause_id, `effect_id`)
    |

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:316:49
    |
316 |     /// Adjacency list for efficient traversal: event_id -> [effect_ids]
    |                                                 ^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
316 -     /// Adjacency list for efficient traversal: event_id -> [effect_ids]
316 +     /// Adjacency list for efficient traversal: `event_id` -> [effect_ids]
    |

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:316:62
    |
316 |     /// Adjacency list for efficient traversal: event_id -> [effect_ids]
    |                                                              ^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
316 -     /// Adjacency list for efficient traversal: event_id -> [effect_ids]
316 +     /// Adjacency list for efficient traversal: event_id -> [`effect_ids`]
    |

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:319:28
    |
319 |     /// Reverse adjacency: event_id -> [cause_ids]
    |                            ^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
319 -     /// Reverse adjacency: event_id -> [cause_ids]
319 +     /// Reverse adjacency: `event_id` -> [cause_ids]
    |

error: item in documentation is missing backticks
   --> hydron-core\src\lorentzian.rs:319:41
    |
319 |     /// Reverse adjacency: event_id -> [cause_ids]
    |                                         ^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
319 -     /// Reverse adjacency: event_id -> [cause_ids]
319 +     /// Reverse adjacency: event_id -> [`cause_ids`]
    |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:325:5
    |
325 |     pub fn new() -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:358:5
    |
358 |     pub fn has_event(&self, event_id: u64) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn has_event(&self, event_id: u64) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:373:5
    |
373 |     pub fn past_light_cone(&self, event_id: u64) -> Vec<u64> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn past_light_cone(&self, event_id: u64) -> Vec<u64>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: usage of `HashSet::insert` after `HashSet::contains`
   --> hydron-core\src\lorentzian.rs:384:33
    |
384 |                     if !visited.contains(&cause_id) {
    |                                 ^^^^^^^^^^^^^^^^^^^
...
387 |                         visited.insert(cause_id);
    |                                 ^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#set_contains_or_insert
    = note: `-D clippy::set-contains-or-insert` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::set_contains_or_insert)]`

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:397:5
    |
397 |     pub fn future_light_cone(&self, event_id: u64) -> Vec<u64> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn future_light_cone(&self, event_id: u64) -> Vec<u64>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: usage of `HashSet::insert` after `HashSet::contains`
   --> hydron-core\src\lorentzian.rs:408:33
    |
408 |                     if !visited.contains(&effect_id) {
    |                                 ^^^^^^^^^^^^^^^^^^^^
...
411 |                         visited.insert(effect_id);
    |                                 ^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#set_contains_or_insert

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:421:5
    |
421 |     pub fn is_causal_past(&self, a: u64, b: u64) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_causal_past(&self, a: u64, b: u64) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:426:5
    |
426 |     pub fn is_causal_future(&self, a: u64, b: u64) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_causal_future(&self, a: u64, b: u64) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:431:5
    |
431 |     pub fn get_node(&self, event_id: u64) -> Option<&CausalNode<T>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn get_node(&self, event_id: u64) -> Option<&CausalNode<T>>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: docs for function which may panic missing `# Panics` section
   --> hydron-core\src\lorentzian.rs:436:5
    |
436 |     pub fn verify_consistency(&self) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
note: first possible panic found here
   --> hydron-core\src\lorentzian.rs:446:14
    |
446 |             *in_degree.get_mut(&effect).unwrap() += 1;
    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_panics_doc
    = note: `-D clippy::missing-panics-doc` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::missing_panics_doc)]`

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:436:5
    |
436 |     pub fn verify_consistency(&self) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn verify_consistency(&self) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: docs for function which may panic missing `# Panics` section
   --> hydron-core\src\lorentzian.rs:477:5
    |
477 |     pub fn topological_order(&self) -> Option<Vec<u64>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
note: first possible panic found here
   --> hydron-core\src\lorentzian.rs:489:14
    |
489 |             *in_degree.get_mut(&effect).unwrap() += 1;
    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_panics_doc

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:477:5
    |
477 |     pub fn topological_order(&self) -> Option<Vec<u64>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn topological_order(&self) -> Option<Vec<u64>>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:541:5
    |
541 |     pub fn new() -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: casting `usize` to `f64` causes a loss of precision on targets with 64-bit wide pointers (`usize` is 64 bits wide, but `f64`'s mantissa is only 52 bits wide)
   --> hydron-core\src\lorentzian.rs:573:26
    |
573 |                 *coord = ((e8_root >> i) & 1) as f64;
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:584:5
    |
584 |     pub fn past_light_cone(&self, event_id: u64) -> Vec<u64> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn past_light_cone(&self, event_id: u64) -> Vec<u64>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:589:5
    |
589 |     pub fn future_light_cone(&self, event_id: u64) -> Vec<u64> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn future_light_cone(&self, event_id: u64) -> Vec<u64>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:594:5
    |
594 |     pub fn is_causal_past(&self, a: u64, b: u64) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_causal_past(&self, a: u64, b: u64) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:599:5
    |
599 |     pub fn is_causal_future(&self, a: u64, b: u64) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_causal_future(&self, a: u64, b: u64) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: docs for function returning `Result` missing `# Errors` section
   --> hydron-core\src\lorentzian.rs:604:5
    |
604 |     pub fn add_link(&mut self, cause: u64, effect: u64) -> Result<(), &'static str> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_errors_doc

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:613:5
    |
613 |     pub fn verify_consistency(&self) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn verify_consistency(&self) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:618:5
    |
618 |     pub fn topological_order(&self) -> Option<Vec<u64>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn topological_order(&self) -> Option<Vec<u64>>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\lorentzian.rs:623:5
    |
623 |     pub fn get_event(&self, event_id: u64) -> Option<&CausalNode<T>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn get_event(&self, event_id: u64) -> Option<&CausalNode<T>>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\quaternion.rs:17:5
   |
17 |     pub fn normalize(q: &[f32; 4]) -> [f32; 4] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn normalize(q: &[f32; 4]) -> [f32; 4]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:18:20
   |
18 |         let norm = (q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3]).sqrt();
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q[3].mul_add(q[3], q[0] * q[0] + q[1] * q[1] + q[2] * q[2])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:18:21
   |
18 |         let norm = (q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3]).sqrt();
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q[2].mul_add(q[2], q[0] * q[0] + q[1] * q[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:18:21
   |
18 |         let norm = (q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3]).sqrt();
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q[0].mul_add(q[0], q[1] * q[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\quaternion.rs:28:5
   |
28 |     pub fn multiply(q1: &[f32; 4], q2: &[f32; 4]) -> [f32; 4] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn multiply(q1: &[f32; 4], q2: &[f32; 4]) -> [f32; 4]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:35:17
   |
35 |         let w = w1 * w2 - (v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]);
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `w1.mul_add(w2, -(v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]))`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:35:27
   |
35 |         let w = w1 * w2 - (v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]);
   |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `v1[2].mul_add(v2[2], v1[0] * v2[0] + v1[1] * v2[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:35:28
   |
35 |         let w = w1 * w2 - (v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]);
   |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `v1[0].mul_add(v2[0], v1[1] * v2[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:38:17
   |
38 |         let i = w1 * v2[0] + w2 * v1[0] + (v1[1] * v2[2] - v1[2] * v2[1]);
   |                 ^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `w1.mul_add(v2[0], w2 * v1[0])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:38:43
   |
38 |         let i = w1 * v2[0] + w2 * v1[0] + (v1[1] * v2[2] - v1[2] * v2[1]);
   |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `v1[1].mul_add(v2[2], -(v1[2] * v2[1]))`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:39:17
   |
39 |         let j = w1 * v2[1] + w2 * v1[1] + (v1[2] * v2[0] - v1[0] * v2[2]);
   |                 ^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `w1.mul_add(v2[1], w2 * v1[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:39:43
   |
39 |         let j = w1 * v2[1] + w2 * v1[1] + (v1[2] * v2[0] - v1[0] * v2[2]);
   |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `v1[2].mul_add(v2[0], -(v1[0] * v2[2]))`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:40:17
   |
40 |         let k = w1 * v2[2] + w2 * v1[2] + (v1[0] * v2[1] - v1[1] * v2[0]);
   |                 ^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `w1.mul_add(v2[2], w2 * v1[2])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:40:43
   |
40 |         let k = w1 * v2[2] + w2 * v1[2] + (v1[0] * v2[1] - v1[1] * v2[0]);
   |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `v1[0].mul_add(v2[1], -(v1[1] * v2[0]))`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\quaternion.rs:46:5
   |
46 |     pub fn conjugate(q: &[f32; 4]) -> [f32; 4] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn conjugate(q: &[f32; 4]) -> [f32; 4]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\quaternion.rs:51:5
   |
51 |     pub fn inverse(q: &[f32; 4]) -> [f32; 4] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn inverse(q: &[f32; 4]) -> [f32; 4]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:52:23
   |
52 |         let norm_sq = q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3];
   |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q[3].mul_add(q[3], q[0] * q[0] + q[1] * q[1] + q[2] * q[2])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:52:23
   |
52 |         let norm_sq = q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3];
   |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q[2].mul_add(q[2], q[0] * q[0] + q[1] * q[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:52:23
   |
52 |         let norm_sq = q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3];
   |                       ^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q[0].mul_add(q[0], q[1] * q[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\quaternion.rs:68:5
   |
68 |     pub fn slerp(q1: &[f32; 4], q2: &[f32; 4], t: f32) -> [f32; 4] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn slerp(q1: &[f32; 4], q2: &[f32; 4], t: f32) -> [f32; 4]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:73:23
   |
73 |           let mut dot = q1_norm[0] * q2_norm[0]
   |  _______________________^
74 | |             + q1_norm[1] * q2_norm[1]
75 | |             + q1_norm[2] * q2_norm[2]
76 | |             + q1_norm[3] * q2_norm[3];
   | |_____________________________________^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops
help: consider using
   |
73 ~         let mut dot = q1_norm[3].mul_add(q2_norm[3], q1_norm[0] * q2_norm[0]
74 ~             + q1_norm[1] * q2_norm[1] + q1_norm[2] * q2_norm[2]);
   |

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:73:23
   |
73 |           let mut dot = q1_norm[0] * q2_norm[0]
   |  _______________________^
74 | |             + q1_norm[1] * q2_norm[1]
75 | |             + q1_norm[2] * q2_norm[2]
   | |_____________________________________^ help: consider using: `q1_norm[2].mul_add(q2_norm[2], q1_norm[0] * q2_norm[0] + q1_norm[1] * q2_norm[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:73:23
   |
73 |           let mut dot = q1_norm[0] * q2_norm[0]
   |  _______________________^
74 | |             + q1_norm[1] * q2_norm[1]
   | |_____________________________________^ help: consider using: `q1_norm[0].mul_add(q2_norm[0], q1_norm[1] * q2_norm[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:90:17
   |
90 |                 q1_norm[0] + t * (q2_norm[0] - q1_norm[0]),
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `t.mul_add(q2_norm[0] - q1_norm[0], q1_norm[0])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:91:17
   |
91 |                 q1_norm[1] + t * (q2_norm[1] - q1_norm[1]),
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `t.mul_add(q2_norm[1] - q1_norm[1], q1_norm[1])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:92:17
   |
92 |                 q1_norm[2] + t * (q2_norm[2] - q1_norm[2]),
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `t.mul_add(q2_norm[2] - q1_norm[2], q1_norm[2])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\quaternion.rs:93:17
   |
93 |                 q1_norm[3] + t * (q2_norm[3] - q1_norm[3]),
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `t.mul_add(q2_norm[3] - q1_norm[3], q1_norm[3])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:107:13
    |
107 |             scale1 * q1_norm[0] + scale2 * q2_norm[0],
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `scale1.mul_add(q1_norm[0], scale2 * q2_norm[0])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:108:13
    |
108 |             scale1 * q1_norm[1] + scale2 * q2_norm[1],
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `scale1.mul_add(q1_norm[1], scale2 * q2_norm[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:109:13
    |
109 |             scale1 * q1_norm[2] + scale2 * q2_norm[2],
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `scale1.mul_add(q1_norm[2], scale2 * q2_norm[2])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:110:13
    |
110 |             scale1 * q1_norm[3] + scale2 * q2_norm[3],
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `scale1.mul_add(q1_norm[3], scale2 * q2_norm[3])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\quaternion.rs:116:5
    |
116 |     pub fn from_axis_angle(axis: &[f32; 3], angle: f32) -> [f32; 4] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn from_axis_angle(axis: &[f32; 3], angle: f32) -> [f32; 4]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:121:25
    |
121 |         let axis_norm = (axis[0] * axis[0] + axis[1] * axis[1] + axis[2] * axis[2]).sqrt();
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `axis[2].mul_add(axis[2], axis[0] * axis[0] + axis[1] * axis[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:121:26
    |
121 |         let axis_norm = (axis[0] * axis[0] + axis[1] * axis[1] + axis[2] * axis[2]).sqrt();
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `axis[0].mul_add(axis[0], axis[1] * axis[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\quaternion.rs:140:5
    |
140 |     pub fn rotate_vector(q: &[f32; 4], v: &[f32; 3]) -> [f32; 3] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn rotate_vector(q: &[f32; 4], v: &[f32; 3]) -> [f32; 3]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\quaternion.rs:155:5
    |
155 |     pub fn dot(q1: &[f32; 4], q2: &[f32; 4]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn dot(q1: &[f32; 4], q2: &[f32; 4]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:156:9
    |
156 |         q1[0] * q2[0] + q1[1] * q2[1] + q1[2] * q2[2] + q1[3] * q2[3]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q1[3].mul_add(q2[3], q1[0] * q2[0] + q1[1] * q2[1] + q1[2] * q2[2])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:156:9
    |
156 |         q1[0] * q2[0] + q1[1] * q2[1] + q1[2] * q2[2] + q1[3] * q2[3]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q1[2].mul_add(q2[2], q1[0] * q2[0] + q1[1] * q2[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:156:9
    |
156 |         q1[0] * q2[0] + q1[1] * q2[1] + q1[2] * q2[2] + q1[3] * q2[3]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `q1[0].mul_add(q2[0], q1[1] * q2[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\quaternion.rs:161:5
    |
161 |     pub fn from_e8_spinor(e8_coords: &[f32; 8]) -> [f32; 4] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn from_e8_spinor(e8_coords: &[f32; 8]) -> [f32; 4]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\spherical.rs:21:5
   |
21 |     pub fn project(coords: &[f32; 8]) -> [f32; 8] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn project(coords: &[f32; 8]) -> [f32; 8]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\spherical.rs:37:5
   |
37 |     pub fn distance(x: &[f32; 8], y: &[f32; 8]) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn distance(x: &[f32; 8], y: &[f32; 8]) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\spherical.rs:55:5
   |
55 |     pub fn slerp(x: &[f32; 8], y: &[f32; 8], t: f32) -> [f32; 8] {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn slerp(x: &[f32; 8], y: &[f32; 8], t: f32) -> [f32; 8]`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\spherical.rs:73:29
   |
73 |                 result[i] = x[i] + t_clamped * (y[i] - x[i]);
   |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `t_clamped.mul_add(y[i] - x[i], x[i])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
  --> hydron-core\src\spherical.rs:91:25
   |
91 |             result[i] = scale1 * x[i] + scale2 * y[i];
   |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `scale1.mul_add(x[i], scale2 * y[i])`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\spherical.rs:100:5
    |
100 |     pub fn normalized_entropy(distribution: &[f32]) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn normalized_entropy(distribution: &[f32]) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: casting `usize` to `f32` causes a loss of precision (`usize` is 32 or 64 bits wide, but `f32`'s mantissa is only 23 bits wide)
   --> hydron-core\src\spherical.rs:107:17
    |
107 |         let n = distribution.len() as f32;
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\spherical.rs:129:5
    |
129 |     pub fn antipodal(x: &[f32; 8]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn antipodal(x: &[f32; 8]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\spherical.rs:135:5
    |
135 |     pub fn mean(points: &[[f32; 8]]) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn mean(points: &[[f32; 8]]) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\spherical.rs:157:5
    |
157 |     pub fn geodesic(point: &[f32; 8], direction: &[f32; 8], t: f32) -> [f32; 8] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn geodesic(point: &[f32; 8], direction: &[f32; 8], t: f32) -> [f32; 8]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: the loop variable `i` is used to index `resonance`
   --> hydron-core\src\fisher.rs:148:18
    |
148 |         for i in 0..240 {
    |                  ^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
    = note: `-D clippy::needless-range-loop` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::needless_range_loop)]`
help: consider using an iterator and enumerate()
    |
148 -         for i in 0..240 {
148 +         for (i, <item>) in resonance.iter_mut().enumerate() {
    |

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\spherical.rs:167:26
    |
167 |             tangent[i] = direction[i] - dot * point[i];
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `dot.mul_add(-point[i], direction[i])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: the loop variable `i` is used to index `fisher`
   --> hydron-core\src\fisher.rs:162:18
    |
162 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator and enumerate()
    |
162 -         for i in 0..8 {
162 +         for (i, <item>) in fisher.iter_mut().enumerate() {
    |

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\spherical.rs:186:25
    |
186 |             result[i] = point[i] * cos_t + tangent[i] * sin_t;
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: consider using: `point[i].mul_add(cos_t, tangent[i] * sin_t)`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\symplectic.rs:27:5
   |
27 |     pub fn new() -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: the loop variable `i` is used to index `fisher`
   --> hydron-core\src\fisher.rs:190:18
    |
190 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator and enumerate()
    |
190 -         for i in 0..8 {
190 +         for (i, <item>) in fisher.iter_mut().enumerate() {
    |

error: item in documentation is missing backticks
  --> hydron-core\src\symplectic.rs:40:17
   |
40 |     /// H = ½ Σ p_i² + V(q)
   |                 ^^^^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
   |
40 -     /// H = ½ Σ p_i² + V(q)
40 +     /// H = ½ Σ `p_i²` + V(q)
   |

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\symplectic.rs:42:5
   |
42 |     pub fn hamiltonian(&self, _q: &[f32; 8], p: &[f32; 8]) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn hamiltonian(&self, _q: &[f32; 8], p: &[f32; 8]) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: used underscore-prefixed binding
  --> hydron-core\src\symplectic.rs:57:28
   |
57 |             gf8_norm2_simd(_q) * 0.5 * k
   |                            ^^
   |
note: binding is defined here
  --> hydron-core\src\symplectic.rs:42:31
   |
42 |     pub fn hamiltonian(&self, _q: &[f32; 8], p: &[f32; 8]) -> f32 {
   |                               ^^
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#used_underscore_binding

error: unused `self` argument
  --> hydron-core\src\symplectic.rs:66:22
   |
66 |     fn compute_force(&self, q: &[f32; 8]) -> [f32; 8] {
   |                      ^^^^^
   |
   = help: consider refactoring to an associated function
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#unused_self
   = note: `-D clippy::unused-self` implied by `-D warnings`
   = help: to override `-D warnings` add `#[allow(clippy::unused_self)]`

error: the loop variable `i` is used to index `fisher`
   --> hydron-core\src\fisher.rs:219:18
    |
219 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator and enumerate()
    |
219 -         for i in 0..8 {
219 +         for (i, <item>) in fisher.iter_mut().enumerate() {
    |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\symplectic.rs:149:5
    |
149 |     pub fn to_phase_space(&self, q: &[f32; 8], p: &[f32; 8]) -> [f32; 16] {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn to_phase_space(&self, q: &[f32; 8], p: &[f32; 8]) -> [f32; 16]`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\symplectic.rs:157:5
    |
157 |     pub fn from_phase_space(&self, phase: &[f32; 16]) -> ([f32; 8], [f32; 8]) {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn from_phase_space(&self, phase: &[f32; 16]) -> ([f32; 8], [f32; 8])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: item in documentation is missing backticks
   --> hydron-core\src\symplectic.rs:166:10
    |
166 |     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
    |          ^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
166 -     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
166 +     /// {`q_i`, p_i} = 1, {p_i, q_i} = -1, others = 0
    |

error: item in documentation is missing backticks
   --> hydron-core\src\symplectic.rs:166:15
    |
166 |     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
    |               ^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
166 -     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
166 +     /// {q_i, `p_i`} = 1, {p_i, q_i} = -1, others = 0
    |

error: item in documentation is missing backticks
   --> hydron-core\src\symplectic.rs:166:26
    |
166 |     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
    |                          ^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
166 -     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
166 +     /// {q_i, p_i} = 1, {`p_i`, q_i} = -1, others = 0
    |

error: item in documentation is missing backticks
   --> hydron-core\src\symplectic.rs:166:31
    |
166 |     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
    |                               ^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#doc_markdown
help: try
    |
166 -     /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
166 +     /// {q_i, p_i} = 1, {p_i, `q_i`} = -1, others = 0
    |

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\symplectic.rs:167:5
    |
167 |     pub fn poisson_bracket(&self, i: usize, j: usize) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn poisson_bracket(&self, i: usize, j: usize) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\symplectic.rs:178:5
    |
178 | /     pub fn verify_energy_conservation(
179 | |         &self,
180 | |         before: &([f32; 8], [f32; 8]),
181 | |         after: &([f32; 8], [f32; 8]),
182 | |     ) -> bool {
    | |_____________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate
help: add the attribute
    |
178 |     #[must_use] pub fn verify_energy_conservation(
    |     +++++++++++

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\topological.rs:35:5
   |
35 |     pub fn persistence(&self) -> f32 {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn persistence(&self) -> f32`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
  --> hydron-core\src\topological.rs:54:5
   |
54 |     pub fn new() -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn new() -> Self`
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this could be a `const fn`
  --> hydron-core\src\topological.rs:54:5
   |
54 | /     pub fn new() -> Self {
55 | |         Self {
56 | |             diagrams: [Vec::new(), Vec::new(), Vec::new()],
57 | |             betti: [1, 0, 0], // Start with single connected component
...  |
60 | |     }
   | |_____^
   |
   = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_const_for_fn
help: make the function `const`
   |
54 |     pub const fn new() -> Self {
   |         +++++

error: casting `usize` to `f32` causes a loss of precision (`usize` is 32 or 64 bits wide, but `f32`'s mantissa is only 23 bits wide)
   --> hydron-core\src\topological.rs:103:38
    |
103 |         let step_size = max_radius / steps as f32;
    |                                      ^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: casting `usize` to `f32` causes a loss of precision (`usize` is 32 or 64 bits wide, but `f32`'s mantissa is only 23 bits wide)
   --> hydron-core\src\topological.rs:106:29
    |
106 |             let threshold = step as f32 * step_size;
    |                             ^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_precision_loss

error: collection is never read
   --> hydron-core\src\topological.rs:137:9
    |
137 |         let mut beta0_history = Vec::new();
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#collection_is_never_read
    = note: `-D clippy::collection-is-never-read` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::collection_is_never_read)]`

error: casting `usize` to `u32` may truncate the value on targets with 64-bit wide pointers
   --> hydron-core\src\topological.rs:148:25
    |
148 |         self.betti[0] = uf.count_components() as u32;
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
148 -         self.betti[0] = uf.count_components() as u32;
148 +         self.betti[0] = u32::try_from(uf.count_components());
    |

error: casting `usize` to `i32` may truncate the value on targets with 64-bit wide pointers
   --> hydron-core\src\topological.rs:154:21
    |
154 |             let v = n as i32;
    |                     ^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
154 -             let v = n as i32;
154 +             let v = i32::try_from(n);
    |

error: casting `usize` to `i32` may wrap around the value on targets with 32-bit wide pointers
   --> hydron-core\src\topological.rs:154:21
    |
154 |             let v = n as i32;
    |                     ^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap
    = note: `-D clippy::cast-possible-wrap` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cast_possible_wrap)]`

error: casting `usize` to `i32` may truncate the value on targets with 64-bit wide pointers
   --> hydron-core\src\topological.rs:155:21
    |
155 |             let e = final_edges.len() as i32;
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
155 -             let e = final_edges.len() as i32;
155 +             let e = i32::try_from(final_edges.len());
    |

error: casting `usize` to `i32` may wrap around the value on targets with 32-bit wide pointers
   --> hydron-core\src\topological.rs:155:21
    |
155 |             let e = final_edges.len() as i32;
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap

error: used `sort` on primitive type `usize`
   --> hydron-core\src\topological.rs:170:25
    |
170 |                         vertices.sort();
    |                         ^^^^^^^^^^^^^^^ help: try: `vertices.sort_unstable()`
    |
    = note: an unstable sort typically performs faster without any observable difference for this data type
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#stable_sort_primitive
    = note: `-D clippy::stable-sort-primitive` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::stable_sort_primitive)]`

error: casting `usize` to `i32` may truncate the value on targets with 64-bit wide pointers
   --> hydron-core\src\topological.rs:181:21
    |
181 |             let f = triangle_count as i32;
    |                     ^^^^^^^^^^^^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation
help: ... or use `try_from` and handle the error accordingly
    |
181 -             let f = triangle_count as i32;
181 +             let f = i32::try_from(triangle_count);
    |

error: casting `usize` to `i32` may wrap around the value on targets with 32-bit wide pointers
   --> hydron-core\src\topological.rs:181:21
    |
181 |             let f = triangle_count as i32;
    |                     ^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap

error: casting `u32` to `i32` may wrap around the value
   --> hydron-core\src\topological.rs:183:35
    |
183 |             let beta1_estimate = (self.betti[0] as i32 - chi).max(0);
    |                                   ^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap

error: casting `i32` to `u32` may lose the sign of the value
   --> hydron-core\src\topological.rs:184:29
    |
184 |             self.betti[1] = beta1_estimate as u32;
    |                             ^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_sign_loss
    = note: `-D clippy::cast-sign-loss` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::cast_sign_loss)]`

error: casting `u32` to `i32` may wrap around the value
   --> hydron-core\src\topological.rs:219:48
    |
219 |                 let beta2_estimate = (chi_3d - self.betti[0] as i32 + self.betti[1] as i32).max(0);
    |                                                ^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap

error: casting `u32` to `i32` may wrap around the value
   --> hydron-core\src\topological.rs:219:71
    |
219 |                 let beta2_estimate = (chi_3d - self.betti[0] as i32 + self.betti[1] as i32).max(0);
    |                                                                       ^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_wrap

error: casting `i32` to `u32` may lose the sign of the value
   --> hydron-core\src\topological.rs:220:33
    |
220 |                 self.betti[2] = beta2_estimate as u32;
    |                                 ^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_sign_loss

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\topological.rs:229:5
    |
229 |     pub fn signature(&self) -> u64 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn signature(&self) -> u64`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: casting `f32` to `u64` may truncate the value
   --> hydron-core\src\topological.rs:241:35
    |
241 |                 let persistence = (pair.persistence() * 1000.0) as u64;
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: if this is intentional allow the lint with `#[allow(clippy::cast_possible_truncation)]` ...
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_possible_truncation

error: casting `f32` to `u64` may lose the sign of the value
   --> hydron-core\src\topological.rs:241:35
    |
241 |                 let persistence = (pair.persistence() * 1000.0) as u64;
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cast_sign_loss

error: docs for function which may panic missing `# Panics` section
   --> hydron-core\src\topological.rs:305:5
    |
305 |     pub fn significant_features(&self, min_persistence: f32) -> Vec<PersistencePair> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
note: first possible panic found here
   --> hydron-core\src\topological.rs:316:33
    |
316 |         features.sort_by(|a, b| b.persistence().partial_cmp(&a.persistence()).unwrap());
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#missing_panics_doc

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\topological.rs:305:5
    |
305 |     pub fn significant_features(&self, min_persistence: f32) -> Vec<PersistencePair> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn significant_features(&self, min_persistence: f32) -> Vec<PersistencePair>`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\topological.rs:321:5
    |
321 |     pub fn total_persistence(&self) -> f32 {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn total_persistence(&self) -> f32`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: this method could have a `#[must_use]` attribute
   --> hydron-core\src\topological.rs:337:5
    |
337 |     pub fn is_similar(&self, other: &TopologicalLayer, tolerance: u32) -> bool {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: add the attribute: `#[must_use] pub fn is_similar(&self, other: &TopologicalLayer, tolerance: u32) -> bool`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#must_use_candidate

error: unnecessary structure name repetition
   --> hydron-core\src\topological.rs:337:38
    |
337 |     pub fn is_similar(&self, other: &TopologicalLayer, tolerance: u32) -> bool {
    |                                      ^^^^^^^^^^^^^^^^ help: use the applicable keyword: `Self`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#use_self

error: `if` chain can be rewritten with `match`
   --> hydron-core\src\topological.rs:380:13
    |
380 | /             if self.rank[root_x] < self.rank[root_y] {
381 | |                 self.parent[root_x] = root_y;
382 | |             } else if self.rank[root_x] > self.rank[root_y] {
383 | |                 self.parent[root_y] = root_x;
...   |
386 | |                 self.rank[root_x] += 1;
387 | |             }
    | |_____________^ help: consider rewriting the `if` chain with `match`: `match self.rank[root_x].cmp(&self.rank[root_y]) {...}`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#comparison_chain
    = note: `-D clippy::comparison-chain` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::comparison_chain)]`

error: could not compile `hydron-core` (lib) due to 247 previous errors
error: the loop variable `k` is used to index `v`
   --> hydron-core\src\gf8.rs:793:18
    |
793 |         for k in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator and enumerate()
    |
793 -         for k in 0..8 {
793 +         for (k, <item>) in v.iter_mut().enumerate() {
    |

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:652:9
    |
652 |         assert_eq!(interval, 0.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: `-D clippy::float-cmp` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::float_cmp)]`
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:706:9
    |
706 |         assert_ne!(boosted.coords[0], p.coords[0]);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_ne` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:707:9
    |
707 |         assert_ne!(boosted.coords[1], p.coords[1]);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_ne` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:709:9
    |
709 |         assert_eq!(boosted.coords[2], p.coords[2]);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:716:9
    |
716 |         assert_eq!(layer.proper_time, 0.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:733:9
    |
733 |         assert_eq!(layer.proper_time, 1.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\lorentzian.rs:745:9
    |
745 |         assert_eq!(layer.proper_time, 2.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:180:20
    |
180 |           let norm = (q_norm[0] * q_norm[0]
    |  ____________________^
181 | |             + q_norm[1] * q_norm[1]
182 | |             + q_norm[2] * q_norm[2]
183 | |             + q_norm[3] * q_norm[3])
    | |____________________________________^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops
help: consider using
    |
180 ~         let norm = q_norm[3].mul_add(q_norm[3], q_norm[0] * q_norm[0]
181 +             + q_norm[1] * q_norm[1] + q_norm[2] * q_norm[2])
    |

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:180:21
    |
180 |           let norm = (q_norm[0] * q_norm[0]
    |  _____________________^
181 | |             + q_norm[1] * q_norm[1]
182 | |             + q_norm[2] * q_norm[2]
    | |___________________________________^ help: consider using: `q_norm[2].mul_add(q_norm[2], q_norm[0] * q_norm[0] + q_norm[1] * q_norm[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: multiply and add expressions can be calculated more efficiently and accurately
   --> hydron-core\src\quaternion.rs:180:21
    |
180 |           let norm = (q_norm[0] * q_norm[0]
    |  _____________________^
181 | |             + q_norm[1] * q_norm[1]
    | |___________________________________^ help: consider using: `q_norm[0].mul_add(q_norm[0], q_norm[1] * q_norm[1])`
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#suboptimal_flops

error: strict comparison of `f32` or `f64` arrays
   --> hydron-core\src\quaternion.rs:193:9
    |
193 |         assert_eq!(result, [0.0, 1.0, 0.0, 0.0]);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64` arrays
   --> hydron-core\src\quaternion.rs:205:9
    |
205 |         assert_eq!(conj, [1.0, -2.0, -3.0, -4.0]);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: adding items after statements is confusing, since items exist from the start of the scope
   --> hydron-core\src\spherical.rs:218:9
    |
218 |         use std::f32::consts::FRAC_PI_2;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#items_after_statements
    = note: `-D clippy::items-after-statements` implied by `-D warnings`
    = help: to override `-D warnings` add `#[allow(clippy::items_after_statements)]`

error: adding items after statements is confusing, since items exist from the start of the scope
   --> hydron-core\src\spherical.rs:264:9
    |
264 |         use std::f32::consts::PI;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#items_after_statements

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:208:17
    |
208 |                 assert_eq!(sym.omega[i][j], -sym.omega[j][i]);
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:214:13
    |
214 |             assert_eq!(sym.omega[i][i + 8], 1.0);
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:215:13
    |
215 |             assert_eq!(sym.omega[i + 8][i], -1.0);
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:252:9
    |
252 |         assert_eq!(sym.poisson_bracket(0, 8), 1.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:255:9
    |
255 |         assert_eq!(sym.poisson_bracket(8, 0), -1.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:258:9
    |
258 |         assert_eq!(sym.poisson_bracket(0, 1), 0.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\symplectic.rs:261:9
    |
261 |         assert_eq!(sym.poisson_bracket(8, 9), 0.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: the loop variable `i` is only used to index `q`
   --> hydron-core\src\symplectic.rs:291:18
    |
291 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator
    |
291 -         for i in 0..8 {
291 +         for <item> in &q {
    |

error: the loop variable `i` is only used to index `p`
   --> hydron-core\src\symplectic.rs:298:18
    |
298 |         for i in 0..8 {
    |                  ^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#needless_range_loop
help: consider using an iterator
    |
298 -         for i in 0..8 {
298 +         for <item> in &p {
    |

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\topological.rs:509:9
    |
509 |         assert_eq!(features[0].persistence(), 2.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: strict comparison of `f32` or `f64`
   --> hydron-core\src\topological.rs:528:9
    |
528 |         assert_eq!(total, 4.0);
    |         ^^^^^^^^^^^^^^^^^^^^^^
    |
    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#float_cmp
    = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info)

error: could not compile `hydron-core` (lib test) due to 275 previous errors

File: clippy-output.txt
=======================
   Compiling unicode-ident v1.0.22
   Compiling proc-macro2 v1.0.103
   Compiling quote v1.0.42
   Compiling autocfg v1.5.0
    Checking cfg-if v1.0.4
    Checking windows-link v0.2.1
   Compiling syn v1.0.109
   Compiling libm v0.2.15
   Compiling serde_core v1.0.228
   Compiling serde v1.0.228
   Compiling hashbrown v0.16.1
   Compiling equivalent v1.0.2
   Compiling rustversion v1.0.22
   Compiling toml_datetime v0.6.11
   Compiling winnow v0.5.40
    Checking memchr v2.7.6
   Compiling thiserror v1.0.69
   Compiling once_cell v1.21.3
   Compiling paste v1.0.15
   Compiling find-msvc-tools v0.1.5
    Checking windows-sys v0.61.2
    Checking bitflags v2.10.0
   Compiling shlex v1.3.0
   Compiling winapi v0.3.9
    Checking itoa v1.0.15
   Compiling version_check v0.9.5
   Compiling glob v0.3.3
   Compiling cc v1.2.49
   Compiling typenum v1.19.0
   Compiling indexmap v2.12.1
   Compiling num-traits v0.2.19
   Compiling semver v1.0.27
   Compiling generic-array v0.14.7
   Compiling find_cuda_helper v0.2.0
   Compiling parking_lot_core v0.9.12
    Checking either v1.15.0
    Checking ryu v1.0.20
   Compiling rustc_version v0.4.1
    Checking scopeguard v1.2.0
    Checking regex-syntax v0.8.8
   Compiling zerocopy v0.8.31
   Compiling byteorder v1.5.0
   Compiling crc32fast v1.5.0
   Compiling syn v2.0.111
    Checking smallvec v1.15.1
   Compiling thiserror v2.0.17
   Compiling toml_edit v0.19.15
    Checking simd-adler32 v0.3.7
   Compiling heck v0.5.0
    Checking lock_api v0.4.14
   Compiling vek v0.15.10
    Checking aho-corasick v1.1.4
   Compiling strsim v0.11.1
   Compiling fnv v1.0.7
    Checking adler2 v2.0.1
   Compiling chrono v0.4.42
   Compiling lazy_static v1.5.0
   Compiling unicode-xid v0.2.6
   Compiling failure_derive v0.1.8
   Compiling ident_case v1.0.1
    Checking miniz_oxide v0.8.9
    Checking parking_lot v0.12.5
    Checking itertools v0.13.0
   Compiling cust_raw v0.11.3
   Compiling windows_x86_64_msvc v0.53.1
   Compiling unicode-segmentation v1.12.0
    Checking approx v0.5.1
    Checking num-integer v0.1.46
    Checking anstyle v1.0.13
   Compiling ucd-util v0.1.10
    Checking bytemuck v1.24.0
    Checking once_cell_polyfill v1.70.2
   Compiling regex v0.2.11
   Compiling serde_json v1.0.145
    Checking crossterm_winapi v0.9.1
    Checking utf8parse v0.2.2
   Compiling pkg-config v0.3.32
   Compiling rustc-demangle v0.1.26
    Checking anstyle-parse v0.2.7
    Checking anstyle-wincon v3.0.11
   Compiling proc-macro-crate v1.3.1
   Compiling convert_case v0.10.0
   Compiling regex-syntax v0.5.6
    Checking flate2 v1.1.7
    Checking regex-automata v0.4.13
   Compiling synstructure v0.12.6
   Compiling backtrace v0.3.76
    Checking glam v0.20.5
    Checking block-buffer v0.10.4
    Checking crypto-common v0.1.7
   Compiling thread_local v0.3.6
   Compiling is-terminal v0.4.17
   Compiling cust v0.3.2
   Compiling aho-corasick v0.6.10
    Checking anstyle-query v1.1.5
   Compiling onig_sys v69.9.1
    Checking winapi-util v0.1.11
    Checking powerfmt v0.2.0
   Compiling semver-parser v0.7.0
   Compiling utf8-ranges v1.0.5
   Compiling instability v0.3.10
    Checking mint v0.5.9
    Checking allocator-api2 v0.2.21
   Compiling ucd-trie v0.1.7
    Checking is_terminal_polyfill v1.70.2
    Checking colorchoice v1.0.4
    Checking foldhash v0.1.5
   Compiling libc v0.2.178
   Compiling crossbeam-utils v0.8.21
    Checking anstream v0.6.21
   Compiling pest v2.8.4
   Compiling semver v0.9.0
    Checking deranged v0.5.5
    Checking same-file v1.0.6
    Checking hashbrown v0.15.5
    Checking digest v0.10.7
    Checking pxfm v0.1.27
    Checking fdeflate v0.3.7
    Checking castaway v0.2.4
    Checking bit-vec v0.6.3
    Checking unicode-width v0.2.0
   Compiling colored v1.9.4
    Checking static_assertions v1.1.0
    Checking unicode-width v0.1.14
    Checking clap_lex v0.7.6
    Checking time-core v0.1.6
   Compiling num_enum_derive v0.5.11
   Compiling cust_derive v0.2.0
    Checking cpufeatures v0.2.17
    Checking base64 v0.22.1
    Checking num-conv v0.1.0
   Compiling litrs v1.0.0
   Compiling anyhow v1.0.100
   Compiling indoc v2.0.7
   Compiling toml v0.4.10
    Checking bitflags v1.3.2
    Checking sha2 v0.10.9
    Checking unicode-truncate v1.1.0
   Compiling darling_core v0.20.11
   Compiling pest_meta v2.8.4
    Checking clap_builder v4.5.53
    Checking png v0.18.0
    Checking cust_core v0.1.1
   Compiling failure v0.1.8
    Checking time v0.3.44
    Checking lru v0.12.5
    Checking compact_str v0.8.1
    Checking bit-set v0.5.3
   Compiling document-features v0.2.12
    Checking windows-targets v0.53.5
    Checking walkdir v2.5.0
    Checking crossterm v0.28.1
    Checking quick-xml v0.38.4
    Checking cassowary v0.3.0
   Compiling ptx-builder v0.5.3
    Checking error-code v3.3.2
    Checking byteorder-lite v0.1.0
    Checking linked-hash-map v0.5.6
   Compiling num_enum v0.5.11
    Checking clipboard-win v5.4.1
    Checking regex v1.12.2
    Checking bstr v1.12.1
    Checking yaml-rust v0.4.5
    Checking fancy-regex v0.13.0
    Checking crossbeam-epoch v0.9.18
   Compiling pest_generator v2.8.4
    Checking windows-sys v0.60.2
    Checking rustc-hash v1.1.0
    Checking log v0.4.29
   Compiling rayon-core v1.13.0
   Compiling alloca v0.4.0
   Compiling rune-format v0.0.1 (X:\_Repos\toon-rune)
    Checking ciborium-io v0.2.2
    Checking plotters-backend v0.3.7
    Checking cast v0.3.0
    Checking crossbeam-deque v0.8.6
    Checking page_size v0.6.0
    Checking anes v0.1.6
    Checking oorandom v11.1.5
   Compiling wasm-bindgen-shared v0.2.106
    Checking tiktoken-rs v0.9.1
error: package `hydron-core` is missing `package.repository` metadata
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cargo_common_metadata
  = note: `-D clippy::cargo-common-metadata` implied by `-D warnings`
  = help: to override `-D warnings` add `#[allow(clippy::cargo_common_metadata)]`

error: package `hydron-core` is missing `package.keywords` metadata
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cargo_common_metadata

error: package `hydron-core` is missing `package.categories` metadata
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cargo_common_metadata

error: package `hydron-ffi` is missing `package.repository` metadata
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cargo_common_metadata

error: package `hydron-ffi` is missing `package.keywords` metadata
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cargo_common_metadata

error: package `hydron-ffi` is missing `package.categories` metadata
  |
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#cargo_common_metadata

    Checking criterion-plot v0.8.1
    Checking plotters-svg v0.3.7
   Compiling getrandom v0.3.4
   Compiling bumpalo v3.19.0
    Checking moxcms v0.7.10
   Compiling wasm-bindgen v0.2.106
    Checking plotters v0.3.7
error: could not compile `rune-format` (build script) due to 6 previous errors
warning: build failed, waiting for other jobs to finish...

File: clippy-short-output.txt
=============================
rune-hex\src\hex.rs:420:13: warning: this `if` statement can be collapsed
rune-hex\src\hex.rs:421:17: warning: this `if` statement can be collapsed
rune-hex\src\hex.rs:618:20: warning: this `if` statement can be collapsed
rune-hex\src\hex.rs:904:18: warning: the loop variable `i` is only used to index `result`
rune-hex\src\hex.rs:956:18: warning: the loop variable `i` is used to index `vec`
src\rune\ast.rs:124:1: warning: an implementation of `From` is preferred since it gives you `Into<_>` for free where the reverse isn't true
src\rune\parser.rs:279:21: warning: this `if` statement can be collapsed

File: CONTRIBUTING.md
=====================
# Contributing to RUNE

Thank you for your interest in contributing to RUNE, a root-centric semantic operator system built on the TOON data format!

## Project Setup

This project uses Cargo for dependency management.

```bash
# Clone the repository
git clone https://github.com/toon-format/toon-rust.git
cd toon-rust

# Build the project
cargo build

# Initialize and clone the spec submodule (required for tests)
git submodule update --init --recursive

# Run tests
cargo test
```

## Development Workflow

1. **Fork the repository** and create a feature branch
2. **Make your changes** following the coding standards below
3. **Add tests** for any new functionality
4. **Ensure all tests pass** and coverage remains high
5. **Submit a pull request** with a clear description

## Coding Standards

### Code Style

- Follow Rust standard formatting conventions
- Run `cargo fmt` before committing
- Run `cargo clippy` to catch common mistakes

### Testing

- All new features must include tests
- Maintain test coverage at **85%+ line coverage**
- Tests should cover edge cases and spec compliance
- Run the full test suite:

  ```bash
  cargo test
  ```

## SPEC Compliance

All implementations must comply with the [TOON specification](https://github.com/toon-format/spec/blob/main/SPEC.md).

Before submitting changes that affect encoding/decoding behavior:

1. Verify against the official SPEC.md
2. Add tests for the specific spec sections you're implementing
3. Document any spec version requirements

## Pull Request Guidelines

- **Title**: Use a clear, descriptive title
- **Description**: Explain what changes you made and why
- **Tests**: Include tests for your changes
- **Documentation**: Update README or documentation if needed
- **Commits**: Use clear commit messages ([Conventional Commits](https://www.conventionalcommits.org/) preferred)

Your pull request will use our standard template which guides you through the required information.

## Communication

- **GitHub Issues**: For bug reports and feature requests
- **GitHub Discussions**: For questions and general discussion
- **Pull Requests**: For code reviews and implementation discussion

## Maintainers

This is a collaborative project. Current maintainers:

- [@shreyasbhat0](https://github.com/shreyasbhat0)
- [@johannschopplich](https://github.com/johannschopplich)

All maintainers have equal and consensual decision-making power. For major architectural decisions, please open a discussion issue first.

## License

By contributing, you agree that your contributions will be licensed under the MIT License.

File: final-clippy-output.txt
=============================
rune-hex\src\hex.rs:420:13: warning: this `if` statement can be collapsed
rune-hex\src\hex.rs:421:17: warning: this `if` statement can be collapsed
rune-hex\src\hex.rs:618:20: warning: this `if` statement can be collapsed
rune-hex\src\hex.rs:904:18: warning: the loop variable `i` is only used to index `result`
rune-hex\src\hex.rs:956:18: warning: the loop variable `i` is used to index `vec`
src\rune\ast.rs:124:1: warning: an implementation of `From` is preferred since it gives you `Into<_>` for free where the reverse isn't true
src\rune\parser.rs:279:21: warning: this `if` statement can be collapsed

File: rustfmt.toml
==================
edition = "2024"
max_width = 100
hard_tabs = false
tab_spaces = 4
newline_style = "Unix"

# Import organization
imports_granularity = "Crate"
group_imports = "StdExternalCrate"
imports_layout = "Vertical"

# Function and struct formatting
fn_params_layout = "Tall"
brace_style = "SameLineWhere"
control_brace_style = "AlwaysSameLine"
match_arm_blocks = true
match_arm_leading_pipes = "Never"
force_explicit_abi = true

# Comments and documentation
wrap_comments = true
comment_width = 80
normalize_comments = true
normalize_doc_attributes = true

# String and literal formatting
format_strings = true
format_code_in_doc_comments = true

# Trailing commas and semicolons
trailing_comma = "Vertical"
trailing_semicolon = true
use_field_init_shorthand = true

# Spacing and alignment
space_before_colon = false
space_after_colon = true
spaces_around_ranges = false
binop_separator = "Front"
remove_nested_parens = true

# Error handling and control flow
empty_item_single_line = true
fn_single_line = false
where_single_line = false

# Type formatting
type_punctuation_density = "Wide"
struct_field_align_threshold = 0

# Macro formatting
format_macro_matchers = true
format_generated_files = false

# Miscellaneous
unstable_features = false
disable_all_formatting = false
skip_children = false

File: README.md
===============
# RUNE: Root Universal Notation Encoding

[![Crates.io](https://img.shields.io/crates/v/rune-format.svg)](https://crates.io/crates/rune-format)
[![Documentation](https://docs.rs/rune-format/badge.svg)](https://docs.rs/rune-format)
[![Built on TOON](https://img.shields.io/badge/built%20on-TOON-purple.svg)](https://github.com/toon-format/toon)
[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)

**RUNE (Root Universal Notation Encoding)** is a root-centric, semantic operator system for the E8 ecosystem. It wraps the **TOON** data format to provide geometric flow, hierarchical definitions, and explicit semantic wiring for LLMs and generative systems.

> **Attribution Note:**
> RUNE is built upon the foundational work of **[Token-Oriented Object Notation (TOON)](https://github.com/toon-format/toon)**.
> It extends the TOON serialization format with root-oriented operators (`/`, `->`, `:=`) and topological glyphs.
> We gratefully acknowledge Johann Schopplich and Shreyas S Bhat for their excellent work on the underlying data format.

---

## The RUNE Philosophy

While **TOON** solves the problem of *efficient data serialization* for LLMs, **RUNE** solves the problem of *semantic structure and flow*.

RUNE treats data blocks as **Nodes** in a root-oriented hierarchy. It introduces a notation to:

1. **Define Roots:** Explicitly anchor data to a context (`root: context`).
2. **Embed Data:** Use TOON syntax for efficient, token-cheap data payloads.
3. **Define Flow:** Use directed operators (`->`) and glyphs (`\|/`) to describe relationships between data nodes.

### RUNE = Root + Operators + TOON Data

```rune
# 1. Define the Root Context
root: e8_continuum

# 2. Embed Data (using RUNE syntax)
layers ~RUNE:
  config[2]{id, type}:
    1,Lattice
    2,Projection

# 3. Define Semantic Flow (RUNE Operators)
layers / 1 -> type := Lattice
layers / 2 -> type := Projection

# 4. Semantic Prefixes (A-Z domain notation)
T:Gf8 * V:velocity -> R:continuum

# 5. Array Literals and Math
[1, 2, 3] + [4, 5, 6]  # Array operations
[[3,3,3]*[3,3,3]]      # Math on nested arrays

# 6. Topological Relations (Glyphs)
layers / 1 \|/ layers / 2   # Symmetric split relation
```

---

## Features

- **Root-Centric Architecture**: Every document is anchored to a specific root/context.
- **TOON Data Layer**: Uses the spec-compliant TOON format for all data blocks (see below).
- **Semantic Operators**: First-class support for flow (`->`), definition (`:=`), and hierarchy (`/`).
- **Token Efficiency**: Inherits TOON's 18-40% token savings over JSON.
- **E8 Geometry**: Native support for E8 primitives (Gf8, XUID) in the AST.

---

## Installation

### As a Library

```bash
cargo add geo-rune
```

### As a CLI Tool

```bash
cargo install geo-rune
```

---

## Data Layer: TOON Format

*RUNE uses TOON v2.0 as its native data serialization format. The following documentation applies to data blocks within RUNE.*

### Quick Example (Data Layer)

**JSON** (16 tokens, 40 bytes):

```json
{
  "users": [
    { "id": 1, "name": "Alice" },
    { "id": 2, "name": "Bob" }
  ]
}
```

**RUNE** (13 tokens, 28 bytes) - **18.75% token savings**:

```rune
users[2]{id,name}:
  1,Alice
  2,Bob
```

### RUNE Semantic Extensions

**Traditional notation** (verbose, unclear domain):

```json
{
  "tensor_Gf8": {"value": 2.5},
  "vector_velocity": {"value": 3.0},
  "result": 7.5
}
```

**RUNE with semantic prefixes** (concise, domain-explicit):

```rune
T:Gf8: 2.5
V:velocity: 3.0
R:result: T:Gf8 * V:velocity
```

Semantic prefixes (A-Z) provide explicit domain context while maintaining token efficiency.

### Benchmarks

RUNE extends TOON with semantic operators while maintaining competitive efficiency:

| Format | Token Savings | Byte Savings | Example Size |
|--------|---------------|--------------|----------------|
| **TOON** | **13.9%** | **62.7%** | **31 tokens / 194 bytes** |
| **RUNE** | **5.6%** | **65.6%** | **34 tokens / 179 bytes** |
| JSON Compact | baseline | baseline | 36 tokens / 243 bytes |
| JSON Pretty | baseline | -114% | 36 tokens / 520 bytes |

**Key Insight**: RUNE adds 3 semantic prefix tokens (`T:`, `V:`, `M:`) for domain clarity while saving 15 bytes through compact notation. The semantic overhead is minimal (~9% more tokens than TOON) but provides explicit domain context that improves LLM understanding.

**Complex Structures**: On nested tensor data, RUNE achieves 17.2% token savings and 68.9% byte savings vs JSON.

---

## Library Usage

The `rune` crate exposes APIs to parse full RUNE documents as well as raw TOON blocks.

### Parsing RUNE

```rust
use rune_format::{RuneParser, Stmt};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let input = r#"
        root: system_config

        users ~RUNE:
          users[2]{id,role}:
            1,admin
            2,viewer

        users / 1 -> role := admin

        # Semantic prefixes for domain-specific notation
        T:Gf8 * 2.5
        V:velocity: [1, 2, 3]
    "#;

    let file = RuneParser::parse(input)?;

    for stmt in file.statements {
        match stmt {
            Stmt::RootDef(root) => println!("Root: {}", root),
            Stmt::ToonBlock(block) => {
                println!("Found data block '{}'", block.name);
                // Parse the inner content using the standard TOON decoder
                let data: serde_json::Value = rune_format::decode(&block.raw_content)?;
                println!("Data: {:?}", data);
            }
            Stmt::Def { name, value } => println!("Defined {} := {}", name, value),
            _ => {}
        }
    }

    Ok(())
}
```

---

## RUNE Language Features

RUNE extends TOON with semantic operators and domain-specific notation.

### Semantic Prefixes (A-Z)

Use capital letters with colon syntax for domain-specific identifiers:

```rune
T:Gf8        # Tensor in Gf8 space
V:velocity   # Vector quantity
R:continuum  # Result in continuum
M:transform  # Matrix transformation
```

### Array Literals

Comma-separated values for arrays:

```rune
[1, 2, 3]           # Numeric array
[a, b, c]           # Identifier array
[T:Gf8, V:velocity] # Semantic array
```

Math blocks use single brackets:

```rune
[a + b]             # Math expression
[[3,3,3]*[3,3,3]]   # Nested array math
```

### v1.5 Features (Supported in Data Blocks)

RUNE supports all modern TOON features within `~RUNE:` blocks.

### Key Folding

Collapse single-key object chains into dotted paths.

```rune
config ~RUNE:
  data.metadata.items[2]: a,b
```

### Path Expansion

Automatically expand dotted keys into nested objects during decoding.

```rune
settings ~RUNE:
  a.b.c: 1
  a.b.d: 2
```

Expands to:

```json
{"a": {"b": {"c": 1, "d": 2}}}
```

---

## CLI Usage

The `rune` CLI works as a superset of the `toon` CLI.

```bash
# Parse a RUNE file and output the resolved JSON tree
rune input.rune --json

# Interactive TUI mode (inherited from TOON)
rune -i
```

### Options

```bash
# Custom indentation for data blocks
rune data.rune --indent 4

# Key folding for data blocks
rune data.rune --fold-keys

# Show statistics
rune data.rune --stats
```

---

## License & Attribution

This project is a fork and extension of [toon-format](https://github.com/arcmoonstudios/rune).

- **RUNE Extensions & Modifications**: Copyright © 2025 ArcMoon Studios
- **Original TOON Format & Code**: Copyright © 2025-PRESENT Johann Schopplich and Shreyas S Bhat

Licensed under the **MIT License**.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

File: benches\fory_hydron.rs
============================
use criterion::{Criterion, criterion_group, criterion_main};
use fory::Fory;
use hydron_core::Gf8;
use std::hint::black_box;

fn bench_fory_hydron(c: &mut Criterion) {
    let mut fory = Fory::default();
    // Register types
    fory.register::<Gf8>(10).unwrap();

    let gf8 = Gf8::from_scalar(0.5);

    let mut group = c.benchmark_group("fory_hydron");

    group.bench_function("serialize_gf8", |b| {
        b.iter(|| fory.serialize(black_box(&gf8)).unwrap())
    });

    let bytes_gf8 = fory.serialize(&gf8).unwrap();
    group.bench_function("deserialize_gf8", |b| {
        b.iter(|| fory.deserialize::<Gf8>(black_box(&bytes_gf8)).unwrap())
    });

    group.finish();
}

criterion_group!(benches, bench_fory_hydron);
criterion_main!(benches);

File: benches\rune_operators.rs
===============================
/* benches/rune_operators.rs */
//! RUNE operator and value evaluation performance benchmarks.
//!
//! # TOON-RUNE – RUNE Operator Benchmarks
//!▫~•◦--------------------------------------‣
//!
//! This benchmark suite measures performance of RUNE operator evaluation,
//! value arithmetic, and built-in function execution for E8 ecosystem operations.
//!
//! ### Key Capabilities
//! - **Value Arithmetic**: Performance of scalar, vector, and finite field operations.
//! - **Built-in Functions**: Geometric operations (S7, quaternions, symplectic, etc.).
//! - **Octonion Algebra**: Non-associative multiplication and normalization.
//! - **Operator Evaluation**: Expression parsing and semantic execution.
//!
//! ### Architectural Notes
//! Benchmarks use the Hydron computation layer with conditional compilation
//! (`#[cfg(feature = "hydron")]`). Performance metrics help optimize the
//! E8 runtime execution pipeline.
//!
//! ### Example
//! ```bash
//! cargo bench --features hydron --bench rune_operators
//! ```
//!
//! Benchmarks identify computational bottlenecks in E8 geometric calculations.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use criterion::{Criterion, criterion_group, criterion_main};

#[cfg(feature = "hydron")]
mod operator_benches {
    use super::*;
    use rune_format::rune::hydron::Gf8;
    use rune_format::rune::hydron::values::{EvalContext, RuneBuiltin, Value};

    pub fn bench_value_arithmetic(c: &mut Criterion) {
        let mut group = c.benchmark_group("value_arithmetic");

        let a = Value::Scalar(42.0);
        let val_b = Value::Scalar(7.0);

        group.bench_function("scalar_add", |b| {
            b.iter(|| a.add(std::hint::black_box(&val_b)).unwrap());
        });

        group.bench_function("scalar_mul", |b| {
            b.iter(|| a.mul(std::hint::black_box(&val_b)).unwrap());
        });

        group.bench_function("scalar_sub", |b| {
            b.iter(|| a.sub(std::hint::black_box(&val_b)).unwrap());
        });

        // Vec8 operations
        let v1 = Value::Vec8([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]);
        let v2 = Value::Vec8([8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0]);

        group.bench_function("vec8_add", |b| {
            b.iter(|| v1.add(std::hint::black_box(&v2)).unwrap());
        });

        group.bench_function("vec8_mul_scalar", |b| {
            let scalar = Value::Scalar(2.0);
            b.iter(|| v1.mul(std::hint::black_box(&scalar)).unwrap());
        });

        // GF(8) operations
        let gf1 = Value::Gf8(Gf8::from_scalar(3.0));
        let gf2 = Value::Gf8(Gf8::from_scalar(5.0));

        group.bench_function("gf8_add", |b| {
            b.iter(|| gf1.add(std::hint::black_box(&gf2)).unwrap());
        });

        let scalar = Value::Scalar(2.0);
        group.bench_function("gf8_scale", |b| {
            b.iter(|| gf1.mul(std::hint::black_box(&scalar)).unwrap());
        });

        group.finish();
    }

    pub fn bench_builtin_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("builtin_ops");
        let ctx = EvalContext::new();

        // S7 operations
        let v1 = Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let v2 = Value::Vec8([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let t = Value::Scalar(0.5);

        group.bench_function("s7_project", |b| {
            b.iter(|| {
                ctx.apply_builtin(RuneBuiltin::S7Project, std::hint::black_box(&[v1.clone()]))
                    .unwrap()
            });
        });

        group.bench_function("s7_distance", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::S7Distance,
                    std::hint::black_box(&[v1.clone(), v2.clone()]),
                )
                .unwrap()
            });
        });

        group.bench_function("s7_slerp", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::S7Slerp,
                    std::hint::black_box(&[v1.clone(), v2.clone(), t.clone()]),
                )
                .unwrap()
            });
        });

        // Quaternion operations
        let q1 = Value::Quaternion([1.0, 0.0, 0.0, 0.0]);
        let q2 = Value::Quaternion([0.707, 0.707, 0.0, 0.0]);

        group.bench_function("quat_slerp", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::QuatSlerp,
                    std::hint::black_box(&[q1.clone(), q2.clone(), t.clone()]),
                )
                .unwrap()
            });
        });

        // Symplectic operations
        let state = Value::Vec16([
            1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // position
            0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // momentum
        ]);
        let dt = Value::Scalar(0.01);

        group.bench_function("symplectic_hamiltonian", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::SymHamiltonian,
                    std::hint::black_box(&[state.clone()]),
                )
                .unwrap()
            });
        });

        group.bench_function("symplectic_evolve", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::SymEvolveStep,
                    std::hint::black_box(&[state.clone(), dt.clone()]),
                )
                .unwrap()
            });
        });

        // Topological operations
        let points = Value::Vec16([
            1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // point 1
            0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // point 2
        ]);

        group.bench_function("topo_betti", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::TopoBetti,
                    std::hint::black_box(&[points.clone()]),
                )
                .unwrap()
            });
        });

        group.bench_function("topo_signature", |b| {
            b.iter(|| {
                ctx.apply_builtin(
                    RuneBuiltin::TopoSignature,
                    std::hint::black_box(&[points.clone()]),
                )
                .unwrap()
            });
        });

        group.finish();
    }

    pub fn bench_octonion_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("octonion");

        use rune_format::rune::hydron::values::Octonion;

        let o1 = Octonion::new(1.0, [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let o2 = Octonion::new(0.707, [0.707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        group.bench_function("multiply", |b| {
            b.iter(|| o1.mul(std::hint::black_box(&o2)));
        });

        group.bench_function("conjugate", |b| {
            b.iter(|| o1.conjugate());
        });

        group.bench_function("norm", |b| {
            b.iter(|| o1.norm());
        });

        group.finish();
    }
}

#[cfg(feature = "hydron")]
criterion_group!(
    benches,
    operator_benches::bench_value_arithmetic,
    operator_benches::bench_builtin_ops,
    operator_benches::bench_octonion_ops
);

#[cfg(not(feature = "hydron"))]
fn dummy_bench(_c: &mut Criterion) {}

#[cfg(not(feature = "hydron"))]
criterion_group!(benches, dummy_bench);

criterion_main!(benches);

File: benches\rune_parser.rs
============================
/* benches/rune_parser.rs */
//! Performance benchmarks for the RUNE parser engine.
//!
//! # TOON-RUNE – RUNE Parser Benchmarks
//!▫~•◦----------------------------------‣
//!
//! This benchmark suite measures parsing performance across different RUNE
//! expression types and script sizes using the Criterion benchmarking framework.
//!
//! ### Key Capabilities
//! - **Literal Benchmarks**: Performance of basic literals and identifiers.
//! - **Math Expression Benchmarks**: Arithmetic parsing in math blocks.
//! - **Operator Benchmarks**: Structural, glyph, and path operator performance.
//! - **Script Size Benchmarks**: Scaling performance for small to large RUNE scripts.
//! - **Comparative Analysis**: Memory and CPU usage patterns for different constructs.
//!
//! ### Architectural Notes
//! Benchmarks use criterion for statistical rigor and cover the parser::functions
//! and AST construction. Results help guide optimization priorities and validate
//! performance targets for E8 ecosystem integration.
//!
//! ### Example
//! ```rust
//! use criterion::{criterion_group, criterion_main, Criterion};
//!
//! fn bench_simple(c: &mut Criterion) {
//!     c.bench_function("simple", |b| b.iter(|| parse_rune("42").unwrap()));
//! }
//!
//! criterion_group!(benches, bench_simple);
//! criterion_main!(benches);
//!
//! // Results show baseline performance for optimization targets.
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use criterion::{Criterion, criterion_group, criterion_main};
use rune_format::rune::parse_rune;

fn bench_rune_parsing(c: &mut Criterion) {
    let mut group = c.benchmark_group("rune_parser");

    // Simple literal
    group.bench_function("literal", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("42")).unwrap();
        });
    });

    // Variable reference
    group.bench_function("variable", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("x")).unwrap();
        });
    });

    // Math expression in brackets
    group.bench_function("math_expr", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("[a + b * c]")).unwrap();
        });
    });

    // Root declaration
    group.bench_function("root_declaration", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("root: sphere_7")).unwrap();
        });
    });

    // Structural operators
    group.bench_function("structural_ops", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("a -> b <- c")).unwrap();
        });
    });

    // Path access
    group.bench_function("path_access", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("a/b/c")).unwrap();
        });
    });

    // Glyph operators
    group.bench_function("glyph_ops", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("a \\|/ b /|\\ c")).unwrap();
        });
    });

    // Complex math block
    group.bench_function("complex_math", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box("[(a + b) * (c - d) / e]")).unwrap();
        });
    });

    group.finish();
}

fn bench_rune_script_sizes(c: &mut Criterion) {
    let mut group = c.benchmark_group("rune_script_sizes");

    // Small script (10 lines)
    let small_script = r#"root: sphere_7
x -> 1
y -> 2
result := [x + y]
a | b
c -> d
e := f
final -> [result * 2]
"#;

    group.bench_function("small_10_lines", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box(small_script)).unwrap();
        });
    });

    // Medium script (50 lines)
    let mut medium_script = String::from("root: quaternion\n");
    for i in 0..48 {
        medium_script.push_str(&format!("var{} := [{} + {}]\n", i, i, i + 1));
    }
    medium_script.push_str("final -> result\n");

    group.bench_function("medium_50_lines", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box(&medium_script)).unwrap();
        });
    });

    // Large script (200 lines)
    let mut large_script = String::from("root: e8::continuum\n");
    for i in 0..198 {
        large_script.push_str(&format!("compute{} := [a{} * b{} + c{}]\n", i, i, i, i));
    }
    large_script.push_str("output -> final\n");

    group.bench_function("large_200_lines", |b| {
        b.iter(|| {
            parse_rune(std::hint::black_box(&large_script)).unwrap();
        });
    });

    group.finish();
}

criterion_group!(benches, bench_rune_parsing, bench_rune_script_sizes);
criterion_main!(benches);

File: benches\rune_vs_toon.rs
=============================
use criterion::{Criterion, criterion_group, criterion_main};
use rune_format::rune;

// Sample data representing typical RUNE usage with semantic prefixes and arrays
const RUNE_SAMPLE: &str = r#"
root: e8_continuum

# Semantic prefix usage (domain-specific identifiers)
T:Gf8: 2.5
V:velocity: [1.0, 2.0, 3.0]
M:transform: [[1,0,0],[0,1,0],[0,0,1]]

# Array operations
coords: [10, 20, 30]
weights: [0.5, 0.3, 0.2]

# Traditional TOON data block
layers ~RUNE:
  config[3]{id, type, active}:
    1,Lattice,true
    2,Projection,true
    3,Transform,false

# Semantic flow
T:Gf8 * V:velocity -> R:result
"#;

const TOON_EQUIVALENT: &str = r#"
root: e8_continuum

tensor_Gf8: 2.5
vector_velocity: [1.0, 2.0, 3.0]
matrix_transform: [[1,0,0],[0,1,0],[0,0,1]]

coords: [10, 20, 30]
weights: [0.5, 0.3, 0.2]

layers:
  config[3]{id, type, active}:
    1,Lattice,true
    2,Projection,true
    3,Transform,false
"#;

// Complex nested structure
const RUNE_COMPLEX: &str = r#"
root: tensor_network

# Multi-dimensional tensor with semantic prefix
T:Gf8_primary: [
  [1.0, 2.0, 3.0],
  [4.0, 5.0, 6.0],
  [7.0, 8.0, 9.0]
]

# Vector array with domain notation
V:velocities: [
  [0.5, 0.5, 0.5],
  [1.0, 1.0, 1.0],
  [1.5, 1.5, 1.5]
]

# Semantic operations
T:result: T:Gf8_primary * V:velocities

# Metadata block
metadata ~RUNE:
  dimensions: [3, 3]
  timestamp: 1638835200
  layers[5]{id, name, type}:
    1,input,vector
    2,hidden1,tensor
    3,hidden2,tensor
    4,hidden3,tensor
    5,output,scalar
"#;

fn benchmark_rune_parse(c: &mut Criterion) {
    c.bench_function("parse_rune_simple", |b| {
        b.iter(|| rune::parse(std::hint::black_box(RUNE_SAMPLE)))
    });

    c.bench_function("parse_rune_complex", |b| {
        b.iter(|| rune::parse(std::hint::black_box(RUNE_COMPLEX)))
    });
}

fn benchmark_toon_equivalent(c: &mut Criterion) {
    c.bench_function("parse_toon_equivalent", |b| {
        b.iter(|| rune::parse(std::hint::black_box(TOON_EQUIVALENT)))
    });
}

fn benchmark_semantic_features(c: &mut Criterion) {
    let mut group = c.benchmark_group("semantic_features");

    // Semantic prefix parsing
    group.bench_function("semantic_prefix", |b| {
        b.iter(|| rune::parse(std::hint::black_box("T:Gf8 * V:velocity -> R:result")))
    });

    // Array literal parsing
    group.bench_function("array_literal", |b| {
        b.iter(|| rune::parse(std::hint::black_box("[1, 2, 3, 4, 5]")))
    });

    // Nested array math
    group.bench_function("nested_array_math", |b| {
        b.iter(|| rune::parse(std::hint::black_box("[[3,3,3]*[3,3,3]]")))
    });

    // Combined semantic + arrays
    group.bench_function("semantic_with_arrays", |b| {
        b.iter(|| {
            rune::parse(std::hint::black_box(
                "T:tensor: [1, 2, 3]\nV:vector: [4, 5, 6]",
            ))
        })
    });

    group.finish();
}

fn benchmark_token_comparison(c: &mut Criterion) {
    let mut group = c.benchmark_group("token_comparison");

    // Measure relative token counts (simulated via string length as proxy)
    group.bench_function("rune_format_size", |b| {
        b.iter(|| std::hint::black_box(RUNE_SAMPLE.len()))
    });

    group.bench_function("toon_format_size", |b| {
        b.iter(|| std::hint::black_box(TOON_EQUIVALENT.len()))
    });

    group.finish();
}

criterion_group!(
    benches,
    benchmark_rune_parse,
    benchmark_toon_equivalent,
    benchmark_semantic_features,
    benchmark_token_comparison
);
criterion_main!(benches);

File: benches\fory_ops.rs
=========================
use criterion::{Criterion, criterion_group, criterion_main};
use fory::Fory;
use rune_format::rune::{MathOp, OpCategory, RuneOp};
use std::hint::black_box;

fn bench_fory_ops(c: &mut Criterion) {
    let mut fory = Fory::default();
    // Register types
    fory.register::<OpCategory>(1).unwrap();
    fory.register::<RuneOp>(2).unwrap();
    fory.register::<MathOp>(3).unwrap();

    let op_category = OpCategory::Relation;
    let rune_op = RuneOp::FlowRight;
    let math_op = MathOp::Add;

    let mut group = c.benchmark_group("fory_ops");

    group.bench_function("serialize_op_category", |b| {
        b.iter(|| fory.serialize(black_box(&op_category)).unwrap())
    });

    let bytes_cat = fory.serialize(&op_category).unwrap();
    group.bench_function("deserialize_op_category", |b| {
        b.iter(|| {
            fory.deserialize::<OpCategory>(black_box(&bytes_cat))
                .unwrap()
        })
    });

    group.bench_function("serialize_rune_op", |b| {
        b.iter(|| fory.serialize(black_box(&rune_op)).unwrap())
    });

    let bytes_rune = fory.serialize(&rune_op).unwrap();
    group.bench_function("deserialize_rune_op", |b| {
        b.iter(|| fory.deserialize::<RuneOp>(black_box(&bytes_rune)).unwrap())
    });

    group.bench_function("serialize_math_op", |b| {
        b.iter(|| fory.serialize(black_box(&math_op)).unwrap())
    });

    let bytes_math = fory.serialize(&math_op).unwrap();
    group.bench_function("deserialize_math_op", |b| {
        b.iter(|| fory.deserialize::<MathOp>(black_box(&bytes_math)).unwrap())
    });

    group.finish();
}

criterion_group!(benches, bench_fory_ops);
criterion_main!(benches);

File: examples\main.rs
======================
use rune_format::rune::parts::{
    arrays, arrays_of_arrays, decode_strict, delimiters, empty_and_root, mixed_arrays, objects,
    round_trip, structs, tabular,
};

fn main() {
    println!("=== R-Toon Consolidated Examples ===\n");

    println!("-- array examples --");
    arrays::arrays();

    println!("\n-- arrays of arrays --");
    arrays_of_arrays::arrays_of_arrays();

    println!("\n-- objects --");
    objects::objects();

    println!("\n-- delimiters --");
    delimiters::delimiters();

    println!("\n-- mixed arrays --");
    mixed_arrays::mixed_arrays();

    println!("\n-- round trip --");
    round_trip::round_trip();

    println!("\n-- tabular --");
    tabular::tabular();

    println!("\n-- empty and root --");
    empty_and_root::empty_and_root();

    println!("\n-- decode strict --");
    decode_strict::decode_strict();

    println!("\n-- serde structs --");
    structs::serde_structs();

    println!("\n=== Examples Complete ===");
}

File: examples\rune_advanced_concepts.rs
========================================
//! Advanced RUNE Concepts: E8 Geometry and Root Operations
//!
//! This example explores conceptual advanced operations that RUNE's
//! operator system could support for E8 lattice geometry, including:
//!
//! - Root lattice navigation and transformations
//! - Glyph operators representing geometric flows
//! - Type-aware arithmetic with E8 primitives
//! - Hierarchical transformations through root contexts
//!
//! Note: This demonstrates CONCEPTUAL possibilities. Full E8 geometric
//! operations would require runtime evaluation with proper E8 algebra.
//!
//! RUNE builds on TOON: Copyright © 2025 Shreyas S Bhat, Johann Schopplich (MIT License)
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::rune;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("🌌 Advanced RUNE Concepts: E8 & Root Operations\n");
    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Section 1: Root-based context switching
    println!("📌 Root Context & Hierarchical Navigation:");
    println!("   Roots define semantic anchors in E8 space\n");

    let root_examples = vec![
        "root: e8::lattice",
        "root: continuum",
        "root: identity::xuid_space",
    ];

    for expr in root_examples {
        parse_and_display(expr);
    }

    println!("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Section 2: Glyph operators as geometric transformations
    println!("📌 Glyph Operators: Topological Flow Patterns:");
    println!("   Glyphs represent geometric relationships in E8 lattice\n");

    let glyph_examples = vec![
        (
            "vector /\\ basis",
            "Split: vector branches to dual basis spaces",
        ),
        (
            "point \\|/ symmetries",
            "SymmetricSplit: unfold symmetry group from point",
        ),
        (
            "field ~ transformed",
            "Transform: apply geometric transformation",
        ),
        ("a /|\\ b", "BranchAnchorBranch: complex lattice navigation"),
    ];

    for (expr, desc) in glyph_examples {
        print!("  {} ", expr);
        match rune::parse_rune(expr) {
            Ok(_) => println!("✓\n    → {}", desc),
            Err(_) => println!("✗"),
        }
    }

    println!("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Section 3: Type-annotated operations (conceptual E8 types)
    println!("📌 E8 Type System (Conceptual):");
    println!("   Type annotations guide geometric interpretation\n");

    let typed_examples = vec![
        ("T::Gf8 element", "Galois Field GF(8) element"),
        ("T::XUID identity", "Extended Unique Identifier in E8 space"),
        ("T::Vec8 position", "8-dimensional vector in E8 lattice"),
        ("T::Octonion q", "Octonion (non-associative algebra)"),
    ];

    for (expr, desc) in typed_examples {
        print!("  {} ", expr);
        match rune::parse_rune(expr) {
            Ok(_) => println!("✓\n    → {}", desc),
            Err(_) => println!("✗"),
        }
    }

    println!("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Section 4: Combining roots, paths, and transformations
    println!("📌 Complex Geometric Operations:");
    println!("   Combining structural navigation with transformations\n");

    let complex_examples = vec![
        (
            "lattice / vertex -> neighbors ~ projection",
            "Navigate to vertex, flow to neighbors, apply projection",
        ),
        (
            "basis / e1 /\\ basis / e2 := [cross_product]",
            "Split basis vectors and define cross product",
        ),
        (
            "point \\|/ orbit := [group_action * element]",
            "Unfold orbit from point via group action",
        ),
        (
            "T::Gf8 a | T::Gf8 b",
            "Alias equivalence between GF(8) elements",
        ),
    ];

    for (expr, desc) in complex_examples {
        print!("  {} ", expr);
        match rune::parse_rune(expr) {
            Ok(_) => println!("✓\n    → {}", desc),
            Err(e) => println!("✗ ({})", e),
        }
        println!();
    }

    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Section 5: Advanced possibilities with full E8 runtime
    println!("🔮 Future Possibilities (Requires E8 Runtime):\n");

    println!("1. Octonion Arithmetic:");
    println!("   • Non-associative multiplication: a * (b * c) ≠ (a * b) * c");
    println!("   • [q1 * q2] with octonion multiplication rules");
    println!("   • Cross-product via E8 lattice geometry\n");

    println!("2. Root Lattice Operations:");
    println!("   • Weyl group reflections through root hyperplanes");
    println!("   • Coxeter transformations: root -> reflection := [weyl * root]");
    println!("   • Simple root decomposition\n");

    println!("3. Geometric Flows:");
    println!("   • /\\ : Split into dual spaces (tangent/cotangent)");
    println!("   • \\/ : Join (fiber bundle projection)");
    println!("   • \\|/ : Orbit decomposition under symmetry group\n");

    println!("4. Type-Aware Arithmetic:");
    println!("   • Gf8 field operations with characteristic 8");
    println!("   • XUID collision-resistant operations");
    println!("   • Vector space operations in E8 lattice\n");

    println!("5. Hierarchical Context:");
    println!("   • Root switches change geometric interpretation");
    println!("   • root: tangent_space → vectors as tangent vectors");
    println!("   • root: dual_space → vectors as covectors\n");

    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    println!("💡 Key Insights:\n");
    println!("Current State:");
    println!("  ✓ Operator syntax is defined and parsed");
    println!("  ✓ Root declarations establish context");
    println!("  ✓ Basic math blocks support arithmetic");
    println!("  ✓ Structural operators express relationships\n");

    println!("What's Needed for Advanced E8 Operations:");
    println!("  ⚙ Runtime evaluation engine with E8 algebra");
    println!("  ⚙ Type system enforcing geometric constraints");
    println!("  ⚙ Octonion/quaternion multiplication");
    println!("  ⚙ Root lattice and Weyl group operations");
    println!("  ⚙ Glyph operators mapped to geometric transformations\n");

    println!("The Foundation is Ready:");
    println!("  → RUNE's operator syntax can express these concepts");
    println!("  → Parser creates AST for complex geometric expressions");
    println!("  → Root system provides contextual anchoring");
    println!("  → Type annotations (T::Gf8, T::XUID) are placeholders");
    println!("  → Implementation awaits E8 geometric runtime");

    Ok(())
}

/// Parse and display a RUNE expression
fn parse_and_display(expr: &str) {
    print!("  {} ", expr);

    match rune::parse_rune(expr) {
        Ok(stmts) => {
            if !stmts.is_empty() {
                println!("✓");
            } else {
                println!("✗ (empty)");
            }
        }
        Err(e) => {
            println!("✗ {}", e);
        }
    }
}

File: examples\rune_arithmetics.rs
==================================
//! RUNE Arithmetic Examples
//!
//! Demonstrates arithmetic operations in RUNE using math blocks.
//!
//! In RUNE, arithmetic happens inside [brackets] to separate
//! mathematical evaluation from structural/topological operations:
//! - Math blocks: [a + b * c]
//! - Operators: +, -, *, /
//! - Precedence: */ before +-
//! - Integration with RUNE: items / 0 := [base + offset]
//!
//! RUNE builds on TOON: Copyright © 2025 Shreyas S Bhat, Johann Schopplich (MIT License)
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::rune;

/// Demonstrate arithmetic operations in RUNE
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("🧮 RUNE Arithmetic Examples\n");
    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Example 1: Basic arithmetic in math blocks
    println!("📌 Basic Arithmetic in Math Blocks [...]:");
    let basic_examples = vec![
        "[a + b]",
        "[x - y]",
        "[width * height]",
        "[2 + 3]",
        "[10 - 7]",
        "[4 * 5]",
        "[a / b]",
    ];

    for expr in basic_examples {
        parse_and_display(expr);
    }

    println!("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Example 2: Operator precedence
    println!("📌 Operator Precedence (*/ before +-):");
    let precedence_examples = vec![
        "[a + b * c]", // a + (b * c)
        "[x * y + z]", // (x * y) + z
        "[2 + 3 * 4]", // 2 + (3 * 4) = 14
        "[5 * 2 - 3]", // (5 * 2) - 3 = 7
        "[a - b + c]", // (a - b) + c
        "[x * y / z]", // (x * y) / z
        "[a / b * c]", // (a / b) * c
    ];

    for expr in precedence_examples {
        parse_and_display(expr);
    }

    println!("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Example 3: Mixing structural operators with math blocks
    println!("📌 Structural Operations + Math Blocks:");
    let mixed_examples = vec![
        "items / 0 := [base + offset]",
        "matrix / row := [index * cols]",
        "x -> value := [a * 2 + b]",
        "vec / i ~ [x + y * scale]",
        "data / point := [x * x + y * y]",
    ];

    for expr in mixed_examples {
        parse_and_display(expr);
    }

    println!("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n");

    // Example 4: Complex expressions
    println!("📌 Complex Math Expressions:");
    let complex_examples = vec![
        "[a + b * c - d]",
        "[width * height / 2]",
        "[a + b * c - d / e]",
        "[(a + b) * c]",
        "result := [sum * 100 / total]",
    ];

    for expr in complex_examples {
        parse_and_display(expr);
    }

    println!("\n🔍 Key Concepts:");
    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
    println!("Math Blocks:");
    println!("  • Arithmetic uses [brackets]: [a + b * c]");
    println!("  • Separates math from structural ops");
    println!("  • Outside []: RUNE operators (/, \\, ->, :=, etc.)");
    println!("  • Inside []: Math operators (+, -, *, /)");
    println!();
    println!("Precedence within [...]:");
    println!("  1. *, / (multiply, divide) - highest");
    println!("  2. +, - (add, subtract) - lower");
    println!("  3. Parentheses () for grouping");
    println!();
    println!("Associativity:");
    println!("  • Left-to-right for same precedence");
    println!("  • [a + b + c] → [(a + b) + c]");
    println!("  • [x / y / z] → [(x / y) / z]");
    println!();
    println!("Integration:");
    println!("  • Use math blocks as values:");
    println!("    items / 0 := [base + offset]");
    println!("  • Combine navigation with computation:");
    println!("    data / point := [x * x + y * y]");

    Ok(())
}

/// Parse and display a RUNE expression
fn parse_and_display(expr: &str) {
    print!("  {} ", expr);

    match rune::parse_rune(expr) {
        Ok(stmts) => {
            if let Some(rune::Stmt::Expr(_)) = stmts.first() {
                println!("✓");
            } else {
                println!("✗ (unexpected statement type)");
            }
        }
        Err(e) => {
            println!("✗ {}", e);
        }
    }
}

File: examples\rune_basic.rs
============================
//! Basic RUNE Example
//!
//! This example demonstrates the core RUNE syntax: root declarations,
//! TOON blocks, and operator expressions over that data.
//! RUNE builds on TOON: Copyright © 2025 Shreyas S Bhat, Johann Schopplich (MIT License)
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::rune;

/// Basic RUNE usage showing root declarations and TOON integration
fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Sample RUNE source code
    let rune_source = r#"
# Declare the semantic root context for this data
root: continuum

# Embed raw TOON data with full fidelity
data ~TOON:
  users[3]{id,name,role}:
    1,Ada,admin
    2,Bob,user
    3,Eve,viewer

# RUNE operators work with TOON paths
users / 0 -> role := admin
users / 1 -> name ~ ValidString()
"#;

    // Parse the RUNE file into statements
    let statements = rune::parse_rune(rune_source)?;

    println!("Parsed {} statements:", statements.len());

    // Process each statement
    for stmt in &statements {
        match stmt {
            rune::Stmt::RootDecl(name) => {
                println!("✓ Root declared: {}", name);
            }
            rune::Stmt::ToonBlock { name, content } => {
                println!(
                    "✓ TOON block '{}': {} lines of raw data",
                    name,
                    content.lines().count()
                );
                // This raw TOON content can be passed to the TOON crate for decoding
                println!(
                    "  TOON content: \"{}\" (first 50 chars)",
                    content.chars().take(50).collect::<String>()
                );
            }
            rune::Stmt::RuneBlock { name, content } => {
                println!(
                    "✓ RUNE block '{}': {} lines of raw data",
                    name,
                    content.lines().count()
                );
                // This raw RUNE content can be processed by the RUNE crate
                println!(
                    "  RUNE content: \"{}\" (first 50 chars)",
                    content.chars().take(50).collect::<String>()
                );
            }
            rune::Stmt::Expr(expr) => {
                println!("✓ Expression: {}", expr);
            }
            rune::Stmt::KernelDecl { name, archetype } => {
                println!("✓ Kernel declared: {} := {}", name, archetype.name);
            }
        }
    }

    // Demonstrate re-encoding
    let encoded = rune::encode_rune(&statements);
    println!("\nRe-encoded RUNE:\n{}", encoded);

    Ok(())
}

File: examples\rune_operators.rs
================================
//! RUNE Operator Examples
//!
//! Demonstrates the complete operator registry and E8-specific semantics.
//! Shows how glyph operators represent complex relationships.
//!
//! RUNE builds on TOON: Copyright © 2025 Shreyas S Bhat, Johann Schopplich (MIT License)
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::rune::{self, OpCategory, RuneOp};

/// Display the complete operator catalog for RUNE
fn show_operator_catalog() {
    println!("🌌 RUNE Operator Catalog\n");

    let operators = vec![
        // Glyph Operators (Topology/Shapes)
        RuneOp::SplitJoin,          // /\
        RuneOp::JoinSplit,          // \/
        RuneOp::AnchorDescend,      // |/
        RuneOp::BranchStabilize,    // /|
        RuneOp::RootStabilize,      // \|
        RuneOp::StabilizeRoot,      // |\
        RuneOp::SymmetricSplit,     // \|/
        RuneOp::BranchAnchorBranch, // /|\

        // Relation Operators
        RuneOp::Bind,               // :
        RuneOp::Specializes,        // =:
        RuneOp::Namespace,          // ::
        RuneOp::Define,             // :=
        RuneOp::Match,              // :=:
        RuneOp::Unify,              // =:=
        RuneOp::Equal,              // =
        RuneOp::FlowRight,          // ->
        RuneOp::FlowLeft,           // <-
        RuneOp::FlowBidirectional,  // <->
        RuneOp::FlowConvergent,     // >-<
        RuneOp::Descendant,         // /
        RuneOp::Ancestor,           // \
        RuneOp::Alias,              // |
        RuneOp::Parallel,           // ||
        RuneOp::Transform,          // ~
        RuneOp::PipelineRight,      // |>
        RuneOp::PipelineLeft,       // <|
        RuneOp::Output,             // :>
        RuneOp::Input,              // <:

        // Comparison Operators
        RuneOp::Less,               // <
        RuneOp::LessEqual,          // <=
        RuneOp::Greater,            // >
        RuneOp::GreaterEqual,       // >=
    ];

    println!("📐 GLYPH OPERATORS (Topology):");
    for op in &operators {
        if op.category() == OpCategory::Glyph {
            let (bp1, bp2) = op.binding_power();
            println!(
                "  {:4} → {} (BP: {},{})",
                op.as_str(),
                format_category(op.category()),
                bp1,
                bp2
            );
        }
    }

    println!("\n🔗 RELATION OPERATORS:");
    for op in &operators {
        if op.category() == OpCategory::Relation {
            let (bp1, bp2) = op.binding_power();
            println!(
                "  {:3} → {} (BP: {},{})",
                op.as_str(),
                format_category(op.category()),
                bp1,
                bp2
            );
        }
    }

    println!("\n📊 MATH & COMPARE:");
    for op in &operators {
        if op.category() == OpCategory::Math || op.category() == OpCategory::Compare {
            let (bp1, bp2) = op.binding_power();
            println!(
                "  {:3} → {} (BP: {},{})",
                op.as_str(),
                format_category(op.category()),
                bp1,
                bp2
            );
        }
    }
}

fn format_category(cat: OpCategory) -> &'static str {
    match cat {
        OpCategory::Glyph => "Geometric Topology",
        OpCategory::Relation => "Structural Relations",
        OpCategory::Compare => "Value Comparison",
        OpCategory::Math => "Arithmetic",
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    show_operator_catalog();

    println!("\n🌟 RUNE Expression Examples:");
    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");

    // Example RUNE source demonstrating operator precedence
    let examples = vec![
        "fiber_net / hub /\\ endpoint",     // Split topology
        "data /\\ validation ~ normalized", // Branch then transform
        "root \\|/ modes",                  // Symmetric splitting
        "users / 0 -> role := admin",       // Navigation + definition
        "vec_a + vec_b * 2",                // Math precedence
        "T::Gf8 terms * 2 + offset",        // Type annotation + math
        "NeuralNet =: specialization |> classifier", // Pattern + pipeline
        "inputs <- preprocessing =:= validation",    // Input + match pattern";
        "data_stream <-> bidirectional_sync",        // Bidirectional flow"
        "convergence >-< transformation_focus",      // Convergent flow"
        "model :> predictions <: feedback",          // Output/Input flow"
    ];

    for example in examples {
        println!("Expression: {}", example);

        // Parse the expression (our parser focuses on full statements)
        if let Ok(stmts) = rune::parse_rune(&format!("dummy {}", example)) {
            if let Some(rune::Stmt::Expr(_)) = stmts.first() {
                println!("  ✓ Parsed successfully (statement-level)");
            }
        } else {
            println!("  → Parser note (expected for partial examples)");
        }
        println!();
    }

    println!("🔍 Operator Semantics:");
    println!("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
    println!("Glyph Ops (Topology):");
    println!("  /\\  → Split then converge (detour + rejoin)");
    println!("  \\/  → Converge then split (merge + diverge)");
    println!("  |/   → Stable → branch away");
    println!("  /|   → Branch → stabilize");
    println!("  \\|  → Approach root → stabilize");
    println!("  |\\  → Stabilize → approach root");
    println!("  \\|/ → Symmetric fork from stable center");
    println!("  /|\\ → Complex branch-anchor-branch");
    println!();
    println!("Structural Relations:");
    println!("  :   → Bind/annotation (key-value, type hints)");
    println!("  =:  → Specialization/instance of (emergent from)");
    println!("  ::  → Namespace/type tag (semantic classification)");
    println!("  :=  → Definition/allocation (assignment)");
    println!("  :=: → Pattern match/recognition (structural equality)");
    println!("  =:= → Structural unification/isomorphism");
    println!("  =   → Equality/constraint (invariant relation)");
    println!("  /   → Child/descendant (E8 lattice)");
    println!("  \\   → Parent/ancestor (root approach)");
    println!("  |   → Alias/equivalence");
    println!("  ||  → Parallel/peer relationship");
    println!("  ~   → Transform/view conversion");
    println!();
    println!("Flow & Function:");
    println!("  ->  → Flow/directed edge right-wards");
    println!("  <-  → Reverse flow left-wards");
    println!("  <-> → Bidirectional flow/oscillation/exchange");
    println!("  >-< → Convergent flow/transformation focus");
    println!("  |>  → Pipeline right/function composition (left→right)");
    println!("  <|  → Pipeline left/reverse composition (right→left)");
    println!("  :>  → Output/produces/generates");
    println!("  <:  → Input/requires/accepts");
    println!();
    println!("Comparison:");
    println!("  <   → Less/Precedes/Deeper");
    println!("  <=  → Less than or equal");
    println!("  >   → Greater/Succeeds/Higher");
    println!("  >=  → Greater than or equal");

    Ok(())
}

File: hydron-core\Cargo.toml
============================
[package]
name = "hydron-core"
version = "0.0.1"
edition = "2024"
description = "Core Hydron geometry library extracted from rune-format; minimal standalone modules (start with S7 spherical layer)."
license = "MIT OR Apache-2.0"
repository = "https://github.com/arcmoonstudios/rune-format"
keywords = ["geometry", "e8", "mathematics", "hydron", "lattice"]
categories = ["mathematics", "science", "algorithms"]

[dependencies]
serde = { version = "1.0", features = ["derive"], optional = true }
fory = { version = "0.13.2", optional = true }
fory-core = { version = "0.13.2", optional = true }

[features]
# Optional simd optimizations for high-performance hosts
default = ["serde"]
simd = []
fory = ["dep:fory", "dep:fory-core"]
serde = ["dep:serde"]

File: benches\serde_hydron.rs
=============================
use criterion::{Criterion, criterion_group, criterion_main};
use hydron_core::Gf8;
use std::hint::black_box;

fn bench_serde_hydron(c: &mut Criterion) {
    let gf8 = Gf8::from_scalar(0.5);

    let mut group = c.benchmark_group("serde_hydron");

    group.bench_function("serialize_gf8", |b| {
        b.iter(|| serde_json::to_vec(black_box(&gf8)).unwrap())
    });

    let bytes_gf8 = serde_json::to_vec(&gf8).unwrap();
    group.bench_function("deserialize_gf8", |b| {
        b.iter(|| serde_json::from_slice::<Gf8>(black_box(&bytes_gf8)).unwrap())
    });

    group.finish();
}

criterion_group!(benches, bench_serde_hydron);
criterion_main!(benches);

File: hydron-ffi\Cargo.toml
===========================
[package]
name = "hydron-ffi"
version = "0.0.1"
edition = "2024"
description = "FFI wrapper crate for hydron geometry core (exports C ABI and wasm-bindgen wrappers)"
license = "MIT OR Apache-2.0"
repository = "https://github.com/arcmoonstudios/rune-format"
keywords = ["ffi", "wasm", "geometry", "hydron", "bindings"]
categories = ["api-bindings", "wasm", "mathematics"]

[lib]
crate-type = ["cdylib"]

[dependencies]
# Depend on the hydron-core crate via path to keep the FFI minimal and Wasm-friendly
hydron-core = { path = "../hydron-core" }

# Optional wasm-bindgen for JS glue
wasm-bindgen = { version = "0.2.106", optional = true }

[features]
# feature to enable JS-friendly wasm bindings
wasm = ["wasm-bindgen"]

[dev-dependencies]
# for testing convenience
rand = "0.9.2"

File: benches\hydron_geometry.rs
================================
/* benches/hydron_geometry.rs */
//! Hydron geometric layer performance benchmarks.
//!
//! # TOON-RUNE – Hydron Geometry Benchmarks
//!▫~•◦---------------------------------------‣
//!
//! This benchmark suite measures performance of E8 geometric operations across
//! different mathematical geometries (spherical, hyperbolic, symplectic, etc.).
//!
//! ### Key Capabilities
//! - **Fisher Information**: Statistical geometry and information metrics.
//! - **Spherical S7 Operations**: Projection, distance, slerp interpolation.
//! - **Quaternion Algebra**: Multiplication, normalization, SLERP operations.
//! - **Hyperbolic Geometry**: Möbius transformations and geodesic operations.
//! - **Symplectic Mechanics**: Hamiltonian evolution and phase space operations.
//! - **Topological Analysis**: Betti numbers, persistence diagrams, signatures.
//! - **Lorentzian Geometry**: Minkowski metrics and causal structure analysis.
//!
//! ### Architectural Notes
//! Benchmarks run conditionally with `#[cfg(feature = "hydron")]` and use Criterion
//! for statistical rigor. Performance results guide optimization of geometric
//! primitives for E8 ecosystem simulations.
//!
//! ### Example
//! ```bash
//! cargo bench --features hydron --bench hydron_geometry
//! ```
//!
//! Results help identify bottlenecks in geometric computations for real-time E8 applications.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

#[cfg(feature = "hydron")]
use criterion::{Criterion, criterion_group, criterion_main};

#[cfg(feature = "hydron")]
mod hydron_benches {
    use super::*;
    use rune_format::rune::hydron::{
        FisherLayer, Gf8, HyperbolicLayer, LorentzianCausalLayer, LorentzianLayer, QuaternionOps,
        SpacetimePoint, SphericalLayer, SymplecticLayer, TopologicalLayer,
    };

    pub fn bench_spherical_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("spherical_s7");

        let v1 = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let v2 = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];

        // Benchmark with current configuration (SIMD if enabled)
        group.bench_function("distance", |b| {
            b.iter(|| {
                SphericalLayer::distance(std::hint::black_box(&v1), std::hint::black_box(&v2))
            });
        });

        group.bench_function("slerp", |b| {
            b.iter(|| {
                SphericalLayer::slerp(
                    std::hint::black_box(&v1),
                    std::hint::black_box(&v2),
                    std::hint::black_box(0.5),
                )
            });
        });

        // Scalar fallback for comparison
        group.bench_function("distance_scalar_fallback", |b| {
            b.iter(|| {
                let dot: f32 = v1.iter().zip(v2.iter()).map(|(xi, yi)| xi * yi).sum();
                let dot_clamped = dot.clamp(-1.0, 1.0);
                dot_clamped.acos()
            });
        });

        group.bench_function("project", |b| {
            b.iter(|| SphericalLayer::project(std::hint::black_box(&v1)));
        });

        group.bench_function("normalized_entropy", |b| {
            b.iter(|| SphericalLayer::normalized_entropy(std::hint::black_box(&v1)));
        });

        group.bench_function("mean_multiple_points", |b| {
            let points = vec![v1, v2, [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]];
            b.iter(|| SphericalLayer::mean(std::hint::black_box(&points)));
        });

        group.finish();
    }

    pub fn bench_quaternion_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("quaternion");

        let q1 = [1.0, 0.0, 0.0, 0.0];
        let q2 = [0.707, 0.707, 0.0, 0.0];

        group.bench_function("multiply", |b| {
            b.iter(|| {
                QuaternionOps::multiply(std::hint::black_box(&q1), std::hint::black_box(&q2))
            });
        });

        group.bench_function("conjugate", |b| {
            b.iter(|| QuaternionOps::conjugate(std::hint::black_box(&q1)));
        });

        group.bench_function("normalize", |b| {
            b.iter(|| QuaternionOps::normalize(std::hint::black_box(&q1)));
        });

        group.bench_function("slerp", |b| {
            b.iter(|| {
                QuaternionOps::slerp(
                    std::hint::black_box(&q1),
                    std::hint::black_box(&q2),
                    std::hint::black_box(0.5),
                )
            });
        });

        group.bench_function("from_axis_angle", |b| {
            let axis = [1.0, 0.0, 0.0];
            b.iter(|| {
                QuaternionOps::from_axis_angle(
                    std::hint::black_box(&axis),
                    std::hint::black_box(1.57),
                )
            });
        });

        group.finish();
    }

    pub fn bench_hyperbolic_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("hyperbolic");

        let v1 = [0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let v2 = [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];

        // Current implementation (SIMD if enabled)
        group.bench_function("project", |b| {
            b.iter(|| HyperbolicLayer::project(std::hint::black_box(&v1)));
        });

        group.bench_function("distance", |b| {
            b.iter(|| {
                HyperbolicLayer::distance(std::hint::black_box(&v1), std::hint::black_box(&v2))
            });
        });

        group.bench_function("mobius_add", |b| {
            b.iter(|| {
                HyperbolicLayer::mobius_add(std::hint::black_box(&v1), std::hint::black_box(&v2))
            });
        });

        // Scalar fallback for comparison
        group.bench_function("mobius_add_scalar_fallback", |b| {
            b.iter(|| {
                let a_norm_sq: f32 = v1.iter().map(|x| x * x).sum();
                let b_norm_sq: f32 = v2.iter().map(|x| x * x).sum();
                let dot_ab: f32 = v1.iter().zip(v2.iter()).map(|(ai, bi)| ai * bi).sum();
                let numerator_a_coeff = 1.0 + 2.0 * dot_ab + b_norm_sq;
                let numerator_b_coeff = 1.0 - a_norm_sq;
                let denominator = 1.0 + 2.0 * dot_ab + a_norm_sq * b_norm_sq;
                if denominator.abs() < 1e-8 {
                    [0.0; 8]
                } else {
                    let mut result = [0.0f32; 8];
                    for i in 0..8 {
                        result[i] =
                            (numerator_a_coeff * v1[i] + numerator_b_coeff * v2[i]) / denominator;
                    }
                    result
                }
            });
        });

        group.bench_function("norm", |b| {
            b.iter(|| HyperbolicLayer::norm(std::hint::black_box(&v1)));
        });

        group.bench_function("interpolate", |b| {
            b.iter(|| {
                HyperbolicLayer::interpolate(
                    std::hint::black_box(&v1),
                    std::hint::black_box(&v2),
                    std::hint::black_box(0.5),
                )
            });
        });

        group.finish();
    }

    pub fn bench_symplectic_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("symplectic");

        let layer = SymplecticLayer::new();
        let q = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let p = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];

        // Current implementation (SIMD if enabled)
        group.bench_function("hamiltonian", |b| {
            b.iter(|| layer.hamiltonian(std::hint::black_box(&q), std::hint::black_box(&p)));
        });

        group.bench_function("evolve_single_step", |b| {
            b.iter(|| {
                let mut q_copy = q;
                let mut p_copy = p;
                layer.evolve(
                    std::hint::black_box(&mut q_copy),
                    std::hint::black_box(&mut p_copy),
                    std::hint::black_box(0.01),
                );
            });
        });

        group.bench_function("evolve_100_steps", |b| {
            b.iter(|| {
                let mut q_copy = q;
                let mut p_copy = p;
                for _ in 0..100 {
                    layer.evolve(
                        std::hint::black_box(&mut q_copy),
                        std::hint::black_box(&mut p_copy),
                        std::hint::black_box(0.01),
                    );
                }
            });
        });

        // Scalar fallback for hamiltonian comparison
        group.bench_function("hamiltonian_scalar_fallback", |b| {
            b.iter(|| {
                let kinetic: f32 = p.iter().map(|&pi| pi * pi).sum::<f32>() * 0.5;
                let k = 0.1;
                let potential: f32 = q.iter().map(|&qi| qi * qi).sum::<f32>() * 0.5 * k;
                kinetic + potential
            });
        });

        group.finish();
    }

    pub fn bench_fisher_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("fisher_information");

        let dist1 = [0.25, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0];
        let dist2 = [0.5, 0.3, 0.15, 0.05, 0.0, 0.0, 0.0, 0.0];
        let fisher_matrix = [[1.0; 8]; 8];

        group.bench_function("information_metric", |b| {
            b.iter(|| FisherLayer::information_metric(std::hint::black_box(&fisher_matrix)));
        });

        group.bench_function("fisher_distance", |b| {
            b.iter(|| {
                FisherLayer::fisher_distance(
                    std::hint::black_box(&dist1),
                    std::hint::black_box(&dist2),
                    std::hint::black_box(&fisher_matrix),
                )
            });
        });

        group.bench_function("kl_divergence", |b| {
            b.iter(|| {
                FisherLayer::kl_divergence(
                    std::hint::black_box(&dist1),
                    std::hint::black_box(&dist2),
                )
            });
        });

        group.bench_function("entropy", |b| {
            b.iter(|| FisherLayer::entropy(std::hint::black_box(&dist1)));
        });

        group.bench_function("uncertainty", |b| {
            b.iter(|| FisherLayer::uncertainty(std::hint::black_box(&fisher_matrix)));
        });

        group.finish();
    }

    pub fn bench_topological_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("topological");

        // Small point cloud (10 points)
        for i in 0..10 {
            let _p = [
                i as f32 * 0.1,
                (i as f32 * 0.1).sin(),
                (i as f32 * 0.1).cos(),
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
            ];
            group.bench_function(&format!("betti_10_points"), |b| {
                b.iter(|| {
                    let mut layer = TopologicalLayer::new();
                    for j in 0..10 {
                        layer.add_point([
                            j as f32 * 0.1,
                            (j as f32 * 0.1).sin(),
                            (j as f32 * 0.1).cos(),
                            0.0,
                            0.0,
                            0.0,
                            0.0,
                            0.0,
                        ]);
                    }
                    layer
                        .compute_betti_numbers(std::hint::black_box(2.0), std::hint::black_box(10));
                });
            });
            break; // Only benchmark once
        }

        // Medium point cloud (50 points)
        group.bench_function("betti_50_points", |b| {
            b.iter(|| {
                let mut layer = TopologicalLayer::new();
                for i in 0..50 {
                    layer.add_point([
                        i as f32 * 0.02,
                        (i as f32 * 0.1).sin(),
                        (i as f32 * 0.1).cos(),
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ]);
                }
                layer.compute_betti_numbers(std::hint::black_box(2.0), std::hint::black_box(10));
            });
        });

        // Persistence diagram
        group.bench_function("persistence_diagram_50_points", |b| {
            b.iter(|| {
                let mut layer = TopologicalLayer::new();
                for i in 0..50 {
                    layer.add_point([
                        i as f32 * 0.02,
                        (i as f32 * 0.1).sin(),
                        (i as f32 * 0.1).cos(),
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ]);
                }
                layer.compute_persistence_diagram_dim0(
                    std::hint::black_box(2.0),
                    std::hint::black_box(10),
                );
            });
        });

        // Signature
        group.bench_function("signature", |b| {
            b.iter(|| {
                let mut layer = TopologicalLayer::new();
                for i in 0..10 {
                    layer.add_point([
                        i as f32 * 0.1,
                        (i as f32 * 0.1).sin(),
                        (i as f32 * 0.1).cos(),
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ]);
                }
                layer.signature()
            });
        });

        group.finish();
    }

    pub fn bench_lorentzian_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("lorentzian");

        let p1 = SpacetimePoint::new([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p2 = SpacetimePoint::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]);
        let velocity = 0.5;

        let layer = LorentzianLayer::new();

        group.bench_function("minkowski_interval", |b| {
            b.iter(|| p1.minkowski_interval(std::hint::black_box(&p2)));
        });

        group.bench_function("causal_relation", |b| {
            b.iter(|| p1.causal_relation(std::hint::black_box(&p2)));
        });

        group.bench_function("lorentz_boost", |b| {
            b.iter(|| {
                layer.lorentz_boost(std::hint::black_box(&p1), std::hint::black_box(velocity))
            });
        });

        // Causal DAG operations
        let mut dag = LorentzianCausalLayer::new();
        for i in 0..10 {
            let root_idx = i;
            dag.add_event(
                root_idx,
                EventType::Emergence {
                    concept_id: i as u64,
                },
                &[],
            );
        }

        group.bench_function("causal_dag_10_events", |b| {
            b.iter(|| {
                let mut new_dag = LorentzianCausalLayer::new();
                for i in 0..10 {
                    new_dag.add_event(
                        i,
                        EventType::Emergence {
                            concept_id: i as u64,
                        },
                        &[],
                    );
                }
                std::hint::black_box(new_dag);
            });
        });

        group.bench_function("topological_order_10_events", |b| {
            b.iter(|| dag.dag.topological_order());
        });

        group.finish();
    }

    pub fn bench_simd_gf8_ops(c: &mut Criterion) {
        let mut group = c.benchmark_group("simd_gf8");

        // Create test data - normalized 8D vectors
        let a = Gf8::new([1.0, 0.5, 0.3, 0.2, 0.1, 0.0, 0.0, 0.0]);
        let b = Gf8::new([0.0, 1.0, 0.5, 0.3, 0.2, 0.1, 0.0, 0.0]);

        // Benchmark Gf8 addition
        #[cfg(feature = "simd")]
        group.bench_function("add_simd", |bencher| {
            bencher.iter(|| {
                use hydron_core::gf8::gf8_add_simd;
                gf8_add_simd(std::hint::black_box(&a), std::hint::black_box(&b))
            });
        });

        group.bench_function("add_scalar", |bencher| {
            bencher.iter(|| *std::hint::black_box(&a) + *std::hint::black_box(&b));
        });

        // Benchmark Gf8 subtraction
        #[cfg(feature = "simd")]
        group.bench_function("sub_simd", |bencher| {
            bencher.iter(|| {
                use hydron_core::gf8::gf8_sub_simd;
                gf8_sub_simd(std::hint::black_box(&a), std::hint::black_box(&b))
            });
        });

        group.bench_function("sub_scalar", |bencher| {
            bencher.iter(|| *std::hint::black_box(&a) - *std::hint::black_box(&b));
        });

        // Benchmark dot product
        #[cfg(feature = "simd")]
        group.bench_function("dot_simd", |bencher| {
            bencher.iter(|| {
                use hydron_core::gf8::gf8_dot_simd;
                gf8_dot_simd(std::hint::black_box(&a), std::hint::black_box(&b))
            });
        });

        group.bench_function("dot_scalar", |bencher| {
            bencher.iter(|| a.dot(std::hint::black_box(b.coords())));
        });

        // Benchmark norm squared (which uses dot product internally)
        #[cfg(feature = "simd")]
        group.bench_function("norm2_simd", |bencher| {
            bencher.iter(|| {
                use hydron_core::gf8::gf8_norm2_simd;
                gf8_norm2_simd(std::hint::black_box(&a))
            });
        });

        group.bench_function("norm2_scalar", |bencher| {
            bencher.iter(|| a.norm2());
        });

        // Benchmark in-place addition
        #[cfg(feature = "simd")]
        group.bench_function("add_inplace_simd", |bencher| {
            bencher.iter(|| {
                use hydron_core::gf8::gf8_add_inplace_slice_simd;
                let mut dst = *std::hint::black_box(a.coords());
                gf8_add_inplace_slice_simd(&mut dst, std::hint::black_box(b.coords()));
                dst
            });
        });

        group.bench_function("add_inplace_scalar", |bencher| {
            bencher.iter(|| {
                let mut dst = *std::hint::black_box(a.coords());
                for i in 0..8 {
                    dst[i] += b.coords()[i];
                }
                dst
            });
        });

        // Benchmark matrix-vector multiplication
        #[cfg(feature = "simd")]
        group.bench_function("matvec_simd", |bencher| {
            let matrix = [[1.0; 8]; 8];
            bencher.iter(|| {
                use hydron_core::gf8::gf8_matvec_simd;
                gf8_matvec_simd(std::hint::black_box(&matrix), std::hint::black_box(&a))
            });
        });

        group.bench_function("matvec_scalar", |bencher| {
            let matrix = [[1.0; 8]; 8];
            bencher.iter(|| {
                let mut result_coords = [0.0f32; 8];
                for (i, row) in matrix.iter().enumerate() {
                    result_coords[i] = a.dot(row);
                }
                Gf8::new(result_coords)
            });
        });

        group.finish();
    }
}

#[cfg(feature = "hydron")]
criterion_group!(
    benches,
    hydron_benches::bench_spherical_ops,
    hydron_benches::bench_quaternion_ops,
    hydron_benches::bench_hyperbolic_ops,
    hydron_benches::bench_symplectic_ops,
    hydron_benches::bench_fisher_ops,
    hydron_benches::bench_topological_ops,
    hydron_benches::bench_lorentzian_ops,
    hydron_benches::bench_simd_gf8_ops
);

#[cfg(not(feature = "hydron"))]
fn dummy_bench(_c: &mut Criterion) {}

#[cfg(not(feature = "hydron"))]
criterion_group!(benches, dummy_bench);

criterion_main!(benches);

File: rune-curs\Cargo.toml
==========================
[package]
name = "rune-curs"
version = "0.0.1"
edition = "2024"
publish = false

[lib]
path = "src/lib.rs"

[dependencies]
thiserror = "2.0"
cust = { version = "0.3.2", optional = true }
sha2 = "0.10"

[features]
default = []
cuda = ["cust"]

File: rune-hex\Cargo.toml
=========================
[package]
name = "rune-hex"
version = "0.0.1"
edition = "2024"
publish = false

[lib]
path = "src/lib.rs"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
thiserror = "2.0"

File: scripts\lint-markdown.ps1
===============================
param($file)

if ($file) {
    # Lint and auto-fix the specific file
    markdownlint --fix $file
} else {
    # Lint and auto-fix all .md files in the workspace
    Get-ChildItem -Recurse -Filter *.md | ForEach-Object { markdownlint --fix $_.FullName }
}

File: hydron-core\README.md
===========================
# Hydron-Core: E8 Geometric Mathematics Engine

A pure, high-performance Rust library for advanced E8 lattice geometry and differential geometry computations. Provides nine interconnected geometric layers for representing and manipulating 8-dimensional geometric data.

## Features

**Nine Geometric Computation Modules:**

- **Gf8 (GeoFloat8):** 8-dimensional normalized geometric floats on the unit hypersphere S⁷
- **Spherical Geometry (S⁷):** Geodesic distances, spherical linear interpolation (SLERP), antipodal points, and great circle arcs
- **Hyperbolic Geometry (H⁸):** Poincaré ball model with Möbius group operations and hyperbolic metrics
- **Fisher Information Geometry:** Statistical manifolds, Fisher information matrices, KL divergence, and information-theoretic metrics
- **Symplectic Geometry (T*E⁸):** Hamiltonian mechanics on the cotangent bundle, phase space dynamics, and canonical transformations
- **Lorentzian Geometry:** Spacetime metrics, causal structure, light cone analysis, and relativistic invariants
- **Quaternion Algebra:** 4D rotation algebra, quaternion composition, SLERP, and axis-angle conversions
- **Topological Analysis:** Persistent homology computation, Betti numbers, and cohomology groups
- **SIMD Intrinsics:** Runtime feature detection and scalar fallbacks for portable performance

## Quick Start

### Adding to Your Project

```toml
[dependencies]
hydron-core = { path = "hydron-core" }
```

### Basic Usage

```rust
use hydron_core::{Gf8, Gf8Tensor, SphericalLayer};

// Create normalized 8D geometric floats
let a = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
let b = Gf8::new([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

// Compute spherical geodesic distance
let distance = SphericalLayer::distance(a.as_slice(), b.as_slice());
println!("Geodesic distance on S⁷: {}", distance);

// Spherical interpolation (SLERP)
let interpolated = SphericalLayer::slerp(a.as_slice(), b.as_slice(), 0.5);
println!("Midpoint: {:?}", interpolated);

// Dot product (cosine similarity)
let similarity = a.dot(b.coords());
println!("Cosine similarity: {}", similarity);
```

### All Nine Modules

```rust
use hydron_core::{
    Gf8, SphericalLayer, HyperbolicLayer, FisherLayer,
    SymplecticLayer, LorentzianLayer, QuaternionOps,
    TopologicalLayer, PersistencePair
};

// Hyperbolic distance (Poincaré ball)
let h_dist = HyperbolicLayer::distance(&a_coords, &b_coords);

// Fisher information metric
let fisher_dist = FisherLayer::fisher_distance(&a_coords, &b_coords);

// Quaternion rotation
let rotation = QuaternionOps::slerp(&[1.0, 0.0, 0.0, 0.0], &[0.0, 1.0, 0.0, 0.0], 0.5);

// Topological analysis
let betti = TopologicalLayer::compute_betti_numbers(&point_cloud);
println!("Betti numbers (b₀, b₁, b₂): {:?}", betti);
```

## Module Overview

### Gf8 (GeoFloat8)

The foundational type representing an 8-dimensional unit vector on the hypersphere S⁷. All coordinates are automatically normalized to unit length, providing:

- Inherent numerical stability
- Perfect alignment with 256-bit SIMD registers (AVX, AVX2)
- Efficient representation for E8 lattice geometry

```rust
let v = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
let coords: [f32; 8] = v.coords();  // Access as array
let slice: &[f32] = v.as_slice();   // Access as slice
```

### Spherical Geometry (S⁷)

Operations on the 7-sphere embedded in 8-dimensional Euclidean space:

- `distance()` — Geodesic distance via arccos of dot product
- `slerp()` — Spherical linear interpolation maintaining geodesic paths
- `antipodal()` — Antipodal point (negation on sphere)
- `mean()` — Riemannian mean of point clouds
- `project()` — Orthogonal projection onto sphere

### Hyperbolic Geometry (H⁸)

Poincaré ball model of hyperbolic space in 8 dimensions:

- `distance()` — Hyperbolic distance metric
- `mobius_add()` — Möbius group addition operation
- Suitable for hierarchical data and tree-like structures

### Fisher Information Geometry

Statistical manifold of probability distributions:

- `fisher_matrix()` — Compute Fisher information matrix
- `kl_divergence()` — Kullback-Leibler divergence between distributions
- `information_metric()` — Riemannian metric on manifold
- `entropy()` — Differential entropy calculation
- `fisher_distance()` — Distance via Fisher metric

### Symplectic Geometry (T*E⁸)

Hamiltonian mechanics on the cotangent bundle of E⁸:

- `hamiltonian()` — Total energy (kinetic + potential)
- Preserves symplectic structure and canonical transformations
- Foundation for phase space dynamics

### Lorentzian Geometry

Spacetime geometry with relativistic invariants:

- `in_past_light_cone()` — Causality predicate
- `in_future_light_cone()` — Forward causality
- `spacelike_separation()` — Spacelike interval check
- Minkowski metric with signature (−,+,+,+,+,+,+,+)

### Quaternion Algebra

4D rotation algebra for rigid body kinematics:

- `slerp()` — Spherical linear interpolation of rotations
- `compose()` — Quaternion multiplication (rotation composition)
- `conjugate()` — Inverse rotation
- Smooth interpolation without gimbal lock

### Topological Analysis

Persistent homology and topological invariants:

- `compute_betti_numbers()` — Count topological features
- `PersistencePair` — Birth-death pairs of topological features
- Robust to noise via persistence filtering

### SIMD Intrinsics

Runtime CPU feature detection and portable SIMD:

- `intrinsics_for_f32_width()` — Query available SIMD widths
- Automatic fallback to scalar implementations
- Support for AVX, NEON, and other SIMD targets

## Architecture

All modules operate on **pure mathematics** without dependencies on:

- Application-specific evaluation logic
- Serialization formats
- Runtime value systems

This enables:

1. **Reusability** across different contexts (RUNE, WASM, C/C++, etc.)
2. **Portability** to embedded systems and specialized hardware
3. **Testability** with pure mathematical specifications
4. **Performance** through aggressive optimization without framework overhead

┌────────────────────────────────────────┐
│  High-Level Applications (RUNE, etc.)  │
└────────────────┬───────────────────────┘
                 │ Optional dependency
┌────────────────▼───────────────────────┐
│         Hydron-Core (this crate)       │
│  Pure E8 Geometry + Linear Algebra     │
│  (9 interconnected modules)            │
└────────────────────────────────────────┘

## Building & Testing

### Build

```powershell
cargo build
```

### Run Tests

```powershell
cargo test
```

### Generate Documentation

```powershell
cargo doc --open
```

## Performance Characteristics

- **Vectorized:** Targets 256-bit SIMD (AVX/AVX2 on x86_64, NEON on ARM)
- **Normalized:** Unit-sphere representation provides numerical stability
- **Zero-allocation:** Pure stack-based computation in most operations
- **Portable:** Scalar fallbacks ensure compatibility across all platforms

## Dependencies

**No external dependencies** — pure Rust with optional standard library features.

## Crate Versions

- **Edition:** 2024
- **MSRV:** 1.80+ (tested on Rust 1.89.0)

## Integration Points

Hydron-core is used by:

- **hydron-ffi:** FFI wrapper for C/C++ and WebAssembly
- **rune-format:** RUNE evaluation engine and expression evaluator
- Standalone projects requiring pure geometric computation

## Mathematical References

The geometric foundations draw from:

- **E8 Lattice:** Coxeter's regular polytope theory
- **Differential Geometry:** Riemannian manifolds and geodesics
- **Information Geometry:** Amari & Nagaoka's statistical manifold framework
- **Symplectic Geometry:** Arnold's classical mechanics formulation
- **Hyperbolic Geometry:** Poincaré models and Möbius transformations
- **Persistent Homology:** Edelsbrunner & Harer's topological data analysis

## License

MIT OR Apache-2.0

## Contributing

Hydron-core is part of the ArcMoon Studios E8 ecosystem. Contributions should maintain:

- Pure mathematical semantics
- Zero external dependencies
- Portable, standards-compliant Rust
- Comprehensive documentation and doctests

---

**For FFI bindings and application integration, see:** [hydron-ffi](../hydron-ffi/README.md)

**For RUNE language integration, see:** [rune-format](../README.md)

File: src\constants.rs
======================
//! Constants
use crate::types::Delimiter;

/// Characters that have structural meaning in TOON format.
pub const STRUCTURAL_CHARS: &[char] = &['[', ']', '{', '}', ':', '-'];

/// TOON keywords that must be quoted when used as strings.
pub const KEYWORDS: &[&str] = &["null", "true", "false"];

/// Default indentation size (2 spaces).
pub const DEFAULT_INDENT: usize = 2;

/// Default delimiter (comma).
pub const DEFAULT_DELIMITER: Delimiter = Delimiter::Comma;

/// Maximum nesting depth to prevent stack overflow.
pub const MAX_DEPTH: usize = 256;

/// Internal marker prefix for quoted keys containing dots.
/// Used during path expansion to distinguish quoted keys (which should remain
/// literal) from unquoted keys (which may be expanded).
/// This marker is added during parsing and removed during expansion.
pub(crate) const QUOTED_KEY_MARKER: char = '\x00';

#[inline]
pub fn is_structural_char(ch: char) -> bool {
    STRUCTURAL_CHARS.contains(&ch)
}

#[inline]
pub fn is_keyword(s: &str) -> bool {
    KEYWORDS.contains(&s)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_is_structural_char() {
        assert!(is_structural_char('['));
        assert!(is_structural_char(']'));
        assert!(is_structural_char('{'));
        assert!(is_structural_char('}'));
        assert!(is_structural_char(':'));
        assert!(is_structural_char('-'));
        assert!(!is_structural_char('a'));
        assert!(!is_structural_char(','));
    }

    #[test]
    fn test_is_keyword() {
        assert!(is_keyword("null"));
        assert!(is_keyword("true"));
        assert!(is_keyword("false"));
        assert!(!is_keyword("hello"));
        assert!(!is_keyword("TRUE"));
    }
}

File: src\lib.rs
================
#![warn(rustdoc::missing_crate_level_docs)]
//! # TOON Format for Rust
//!
//! Token-Oriented Object Notation (TOON) is a compact, human-readable format
//! designed for passing structured data to Large Language Models with
//! significantly reduced token usage.
//!
//! This crate reserves the `toon-format` namespace for the official Rust
//! implementation. Full implementation coming soon!
//!
//! ## Resources
//!
//! - [TOON Specification](https://github.com/johannschopplich/toon/blob/main/SPEC.md)
//! - [Main Repository](https://github.com/johannschopplich/toon)
//! - [Other Implementations](https://github.com/johannschopplich/toon#other-implementations)
//!
//! ## Example Usage
//! ```rust
//! use rune_format::{encode_default, decode_default};
//! use serde_json::json;
//!
//! let data = json!({"name": "Alice", "age": 30});
//! let toon_string = encode_default(&data).unwrap();
//! let decoded: serde_json::Value = decode_default(&toon_string).unwrap();
//! assert_eq!(decoded["name"], "Alice");
//! assert_eq!(decoded["age"], 30);
//! ```
//! TOKEN_FORMAT is Copyright (c) 2025-PRESENT Shreyas S Bhat, Johann Schopplich
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

pub mod constants;
pub mod decode;
pub mod encode;
pub mod rune;
pub mod tui;
pub mod types;
pub mod utils;

pub use decode::{
    decode, decode_default, decode_no_coerce, decode_no_coerce_with_options, decode_strict,
    decode_strict_with_options,
};
pub use encode::{encode, encode_array, encode_default, encode_object};
pub use types::{DecodeOptions, Delimiter, EncodeOptions, Indent, ToonError};
pub use utils::{
    literal::{is_keyword, is_literal_like},
    normalize,
    string::{escape_string, is_valid_unquoted_key, needs_quoting},
};

#[cfg(test)]
mod tests {
    use serde_json::{Value, json};

    use crate::{
        constants::is_keyword,
        decode::{decode_default, decode_strict},
        encode::{encode, encode_default},
        types::{Delimiter, EncodeOptions},
        utils::{escape_string, is_literal_like, needs_quoting, normalize},
    };

    #[test]
    fn test_round_trip_simple() {
        let original = json!({"name": "Alice", "age": 30});
        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(original, decoded);
    }

    #[test]
    fn test_round_trip_array() {
        let original = json!({"tags": ["reading", "gaming", "coding"]});
        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(original, decoded);
    }

    #[test]
    fn test_round_trip_tabular() {
        let original = json!({
            "users": [
                {"id": 1, "name": "Alice", "role": "admin"},
                {"id": 2, "name": "Bob", "role": "user"}
            ]
        });
        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(original, decoded);
    }

    #[test]
    fn test_custom_delimiter() {
        let original = json!({"tags": ["a", "b", "c"]});
        let opts = EncodeOptions::new().with_delimiter(Delimiter::Pipe);
        let encoded = encode(&original, &opts).unwrap();
        assert!(encoded.contains("|"));

        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(original, decoded);
    }

    #[test]
    fn test_decode_strict_helper() {
        let input = "items[2]: a,b";
        assert!(decode_strict::<Value>(input).is_ok());

        let input = "items[3]: a,b";
        assert!(decode_strict::<Value>(input).is_err());
    }

    #[test]
    fn test_normalize_exported() {
        let value = json!(f64::NAN);
        let normalized = normalize(value.into());
        assert_eq!(serde_json::Value::from(normalized), json!(null));
    }

    #[test]
    fn test_utilities_exported() {
        assert!(is_keyword("null"));
        assert!(is_literal_like("true"));
        assert_eq!(escape_string("hello\nworld"), "hello\\nworld");
        assert!(needs_quoting("true", Delimiter::Comma.as_char()));
    }

    use serde::{Deserialize, Serialize};

    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct TestUser {
        name: String,
        age: u32,
        active: bool,
    }

    #[test]
    fn test_encode_decode_simple_struct() {
        use crate::{decode_default, encode_default};

        let user = TestUser {
            name: "Alice".to_string(),
            age: 30,
            active: true,
        };

        let toon = encode_default(&user).unwrap();
        assert!(toon.contains("name: Alice"));
        assert!(toon.contains("age: 30"));
        assert!(toon.contains("active: true"));

        let decoded: TestUser = decode_default(&toon).unwrap();
        assert_eq!(user, decoded);
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct TestProduct {
        id: u64,
        name: String,
        tags: Vec<String>,
    }

    #[test]
    fn test_encode_decode_with_array() {
        use crate::{decode_default, encode_default};

        let product = TestProduct {
            id: 42,
            name: "Widget".to_string(),
            tags: vec!["electronics".to_string(), "gadgets".to_string()],
        };

        let toon = encode_default(&product).unwrap();
        let decoded: TestProduct = decode_default(&toon).unwrap();
        assert_eq!(product, decoded);
    }

    #[test]
    fn test_encode_decode_vec_of_structs() {
        use crate::{decode_default, encode_default};

        let users = vec![
            TestUser {
                name: "Alice".to_string(),
                age: 30,
                active: true,
            },
            TestUser {
                name: "Bob".to_string(),
                age: 25,
                active: false,
            },
        ];

        let toon = encode_default(&users).unwrap();
        let decoded: Vec<TestUser> = decode_default(&toon).unwrap();
        assert_eq!(users, decoded);
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct Nested {
        outer: OuterStruct,
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct OuterStruct {
        inner: InnerStruct,
        value: i32,
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct InnerStruct {
        data: String,
    }

    #[test]
    fn test_encode_decode_nested_structs() {
        use crate::{decode_default, encode_default};

        let nested = Nested {
            outer: OuterStruct {
                inner: InnerStruct {
                    data: "test".to_string(),
                },
                value: 42,
            },
        };

        let toon = encode_default(&nested).unwrap();
        let decoded: Nested = decode_default(&toon).unwrap();
        assert_eq!(nested, decoded);
    }

    #[test]
    fn test_round_trip_list_item_tabular_v3() {
        use crate::{decode_default, encode_default};

        let original = json!({
            "items": [
                {
                    "users": [
                        {"id": 1, "name": "Alice", "role": "admin"},
                        {"id": 2, "name": "Bob", "role": "user"}
                    ],
                    "status": "active",
                    "count": 2
                }
            ]
        });

        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();

        assert_eq!(original, decoded);
    }

    #[test]
    fn test_round_trip_complex_list_item_tabular_v3() {
        use crate::{decode_default, encode_default};

        let original = json!({
            "data": [
                {
                    "records": [
                        {"id": 1, "value": "x", "score": 100},
                        {"id": 2, "value": "y", "score": 200}
                    ],
                    "total": 2,
                    "status": "active"
                },
                {
                    "records": [
                        {"id": 3, "value": "z", "score": 300}
                    ],
                    "total": 1,
                    "status": "pending"
                }
            ]
        });

        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();

        assert_eq!(original, decoded);
    }

    #[test]
    fn test_round_trip_mixed_list_items_v3() {
        use crate::{decode_default, encode_default};

        let original = json!({
            "entries": [
                {
                    "type": "simple",
                    "value": 42
                },
                {
                    "people": [
                        {"name": "Alice", "age": 30},
                        {"name": "Bob", "age": 25}
                    ],
                    "type": "complex"
                },
                {
                    "tags": ["a", "b", "c"],
                    "type": "array"
                }
            ]
        });

        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();

        assert_eq!(original, decoded);
    }
}

File: tests\arrays.rs
=====================
use std::f64;

use rune_format::{decode_default, encode_default};
use serde_json::{Value, json};

#[test]
fn test_tabular_arrays() {
    let cases = vec![
        json!({
            "users": [
                {"id": 1, "name": "Alice"},
                {"id": 2, "name": "Bob"}
            ]
        }),
        json!({
            "products": [
                {"sku": "A1", "name": "Widget", "price": 9.99, "stock": 100},
                {"sku": "B2", "name": "Gadget", "price": 19.99, "stock": 50}
            ]
        }),
        json!({
            "items": [
                {"a": 1, "b": 2, "c": 3}
            ]
        }),
        json!({
            "data": (0..10).map(|i| json!({"id": i, "value": i * 2})).collect::<Vec<_>>()
        }),
    ];

    for case in cases {
        let encoded = encode_default(&case).unwrap();
        assert!(encoded.contains("{"));
        assert!(encoded.contains("}"));
        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(case, decoded);
    }
}

#[test]
fn test_mixed_arrays() {
    let data = json!({
        "mixed": [1, "two", true, null, f64::consts::PI]
    });

    let encoded = encode_default(&data).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(data, decoded);
}

#[test]
fn test_empty_values() {
    let cases = vec![
        json!({"array": []}),
        json!({"object": {}}),
        json!({"string": ""}),
        json!({"null": null}),
    ];

    for case in cases {
        let encoded = encode_default(&case).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(case, decoded);
    }
}

#[test]
fn test_large_arrays() {
    let large_array = json!({
        "numbers": (0..1000).collect::<Vec<i32>>()
    });

    let encoded = encode_default(&large_array).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(large_array, decoded);

    let large_tabular = json!({
        "records": (0..500).map(|i| json!({
            "id": i,
            "name": format!("user_{}", i),
            "value": i * 2
        })).collect::<Vec<_>>()
    });

    let encoded = encode_default(&large_tabular).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(large_tabular, decoded);
}

File: src\utf8_sanitize.rs
==========================
/* src/utf8_sanitizer.rs */
//! UTF-8 content sanitization utility for handling invalid byte sequences.
//!
//! # UTF-8 Sanitizer Module
//!▫~•◦------------------------------------------------‣
//!
//! This module provides robust UTF-8 validation and sanitization capabilities,
//! ensuring text files contain valid UTF-8 encodings by replacing invalid
//! sequences with the Unicode replacement character (U+FFFD).
//!
//! ### Key Capabilities
//! - **Lossless Valid Content Preservation:** All valid UTF-8 sequences remain unchanged.
//! - **Invalid Sequence Replacement:** Non-compliant bytes are replaced with � (U+FFFD).
//! - **Detailed Diagnostics:** Reports the number of invalid sequences encountered.
//!
//! ### Architectural Notes
//! This module operates as a standalone utility and CLI tool. It can be integrated
//! into larger pipelines requiring UTF-8 compliance enforcement. The sanitization
//! leverages Rust's standard library `String::from_utf8_lossy` for deterministic,
//! safe conversion.
//!
//! ### Example
//! ```rust
//! use utf8_sanitizer::sanitize_utf8;
//!
//! let raw_bytes = b"Hello\xFFWorld";
//! let (sanitized, invalid_count) = sanitize_utf8(raw_bytes);
//!
//! assert_eq!(invalid_count, 1);
//! assert!(sanitized.contains('\u{FFFD}'));
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use std::fs;
use std::io;

/// Sanitizes UTF-8 content by replacing invalid bytes with the Unicode replacement character (�).
///
/// This function processes raw byte sequences and produces a valid UTF-8 string. Invalid
/// sequences are replaced with U+FFFD (�), and the function reports the total count of
/// such replacements.
///
/// # Arguments
/// * `input` - A byte slice potentially containing invalid UTF-8 sequences.
///
/// # Returns
/// A tuple containing:
/// - The sanitized UTF-8 string
/// - The count of invalid sequences replaced
///
/// # Examples
/// ```rust
/// use utf8_sanitizer::sanitize_utf8;
///
/// let valid = b"Hello, world!";
/// let (result, count) = sanitize_utf8(valid);
/// assert_eq!(count, 0);
/// assert_eq!(result, "Hello, world!");
///
/// let invalid = b"Hello\xFFWorld";
/// let (result, count) = sanitize_utf8(invalid);
/// assert_eq!(count, 1);
/// assert!(result.contains('\u{FFFD}'));
/// ```
pub fn sanitize_utf8(input: &[u8]) -> (String, usize) {
    let s = String::from_utf8_lossy(input);

    let invalid_count = match s {
        std::borrow::Cow::Borrowed(_) => 0,
        std::borrow::Cow::Owned(ref content) => {
            content.chars().filter(|&c| c == '\u{FFFD}').count()
        }
    };

    (s.into_owned(), invalid_count)
}

/// Main entry point for the UTF-8 sanitization CLI tool.
///
/// Reads the target file as raw bytes, sanitizes invalid UTF-8 sequences,
/// and writes the sanitized content back to the original file. Provides
/// diagnostic output indicating the number of invalid sequences replaced.
///
/// # Errors
/// Returns `io::Error` if file read or write operations fail.
fn main() -> io::Result<()> {
    let file_path = "src/rune/.runeFiles/rune.txt";

    let bytes = fs::read(file_path)?;

    println!("Read {} bytes from {}", bytes.len(), file_path);

    let (sanitized, invalid_count) = sanitize_utf8(&bytes);

    println!("UTF-8 sanitization completed:");
    println!("- Invalid sequences replaced: {}", invalid_count);
    println!(
        "- Total characters in output: {}",
        sanitized.chars().count()
    );

    fs::write(file_path, sanitized)?;

    if invalid_count > 0 {
        println!(
            "Warning: {} invalid UTF-8 sequences were replaced with �",
            invalid_count
        );
    } else {
        println!("✓ File was already valid UTF-8 - no changes made");
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_valid_utf8() {
        let input = "Hello, 世界!".as_bytes();
        let (result, count) = sanitize_utf8(input);
        assert_eq!(count, 0);
        assert_eq!(result, "Hello, 世界!");
    }

    #[test]
    fn test_invalid_utf8() {
        let invalid_bytes = b"Hello\xFFWorld";
        let (result, count) = sanitize_utf8(invalid_bytes);
        assert_eq!(count, 1);
        assert!(result.contains('\u{FFFD}'));
    }

    #[test]
    fn test_multiple_invalid_sequences() {
        let invalid_bytes = b"Test\xFF\xFE\xFDData";
        let (result, count) = sanitize_utf8(invalid_bytes);
        assert_eq!(count, 3);
        assert_eq!(result.chars().filter(|&c| c == '\u{FFFD}').count(), 3);
    }

    #[test]
    fn test_empty_input() {
        let (result, count) = sanitize_utf8(&[]);
        assert_eq!(count, 0);
        assert_eq!(result, "");
    }

    #[test]
    fn test_all_invalid() {
        let invalid_bytes = b"\xFF\xFE\xFD";
        let (result, count) = sanitize_utf8(invalid_bytes);
        assert_eq!(count, 3);
        assert_eq!(result.len(), '\u{FFFD}'.len_utf8() * 3);
    }

    #[test]
    fn test_mixed_valid_invalid() {
        let mixed = b"Valid\xFFText\xFE\xFDHere";
        let (result, count) = sanitize_utf8(mixed);
        assert_eq!(count, 3);
        assert!(result.starts_with("Valid"));
        assert!(result.contains("Text"));
        assert!(result.ends_with("Here"));
    }
}

File: tests\delimiters.rs
=========================
use rune_format::{Delimiter, EncodeOptions, decode_default, encode, encode_default};
use serde_json::{Value, json};

#[test]
fn test_delimiter_variants() {
    let data = json!({"tags": ["a", "b", "c"]});

    let encoded = encode_default(&data).unwrap();
    assert!(encoded.contains("a,b,c"));
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(data, decoded);

    let opts = EncodeOptions::new().with_delimiter(Delimiter::Pipe);
    let encoded = encode(&data, &opts).unwrap();
    assert!(encoded.contains("a|b|c"));
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(data, decoded);

    let opts = EncodeOptions::new().with_delimiter(Delimiter::Tab);
    let encoded = encode(&data, &opts).unwrap();
    assert!(encoded.contains("a\tb\tc"));
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(data, decoded);
}

#[test]
fn test_delimiter_in_values() {
    let data = json!({"tags": ["a,b", "c|d", "e\tf"]});

    let encoded = encode_default(&data).unwrap();
    assert!(encoded.contains("\"a,b\""));
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(data, decoded);

    let opts = EncodeOptions::new().with_delimiter(Delimiter::Pipe);
    let encoded = encode(&data, &opts).unwrap();
    assert!(encoded.contains("\"c|d\""));
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(data, decoded);
}

#[test]
fn test_non_active_delimiters_in_tabular_arrays() {
    // When comma is the active delimiter, pipe and tab should be treated as regular
    // data Per TOON spec §11: "non-active delimiters MUST NOT cause splits"

    // Test 1: Pipe character in value when comma is active delimiter (default)
    let data = r#"item-list[1]{a,b}:
  ":",|
"#;
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["item-list"][0]["a"], ":");
    assert_eq!(decoded["item-list"][0]["b"], "|");

    // Test 2: Both values quoted
    let data = r#"item-list[1]{a,b}:
  ":","|"
"#;
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["item-list"][0]["a"], ":");
    assert_eq!(decoded["item-list"][0]["b"], "|");

    // Test 3: Tab character in value when comma is active
    let data = "item-list[1]{a,b}:\n  \":\",\t\n";
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["item-list"][0]["a"], ":");
    assert_eq!(decoded["item-list"][0]["b"], "\t");

    // Test 4: Comma in value when pipe is active delimiter - should quote the comma
    let data = r#"item-list[1|]{a|b}:
  ":"|","
"#;
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["item-list"][0]["a"], ":");
    assert_eq!(decoded["item-list"][0]["b"], ",");
}

#[test]
fn test_non_active_delimiters_in_inline_arrays() {
    // Test pipe in inline array when comma is active
    let data = r#"tags[3]: a,|,c"#;
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["tags"], json!(["a", "|", "c"]));

    // Test comma in inline array when pipe is active - comma needs quoting
    let data = "tags[3|]: a|\",\"|c";
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["tags"], json!(["a", ",", "c"]));

    // Test multiple non-active delimiters - pipes when comma is active
    let data = r#"items[4]: |,|,|,"#;
    let decoded: Value = decode_default(data).unwrap();
    assert_eq!(decoded["items"], json!(["|", "|", "|", ""]));
}

#[test]
fn test_delimiter_mismatch_error() {
    // Per TOON spec §6: delimiter in brackets must match delimiter in braces
    // This should error: pipe in brackets, comma in braces
    let data = r#"item-list[1|]{a,b}:
  ":",|
"#;
    let result: Result<Value, _> = decode_default(data);
    assert!(result.is_err(), "Mismatched delimiters should error");
}

File: tests\array_literals.rs
=============================
/* tests/arrays.rs */
//! Tests for RUNE array literals and nested arithmetic operations.
//!
//! # TOON-RUNE – Array Literal Tests
//!▫~•◦-------------------------------‣
//!
//! This test suite validates array literal syntax in RUNE:
//! - [1,2,3] = array of numbers
//! - [a,b,c] = array of identifiers/expressions
//! - [[expr * expr]] = nested math on arrays
//!
//! Arrays use commas, math blocks don't.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::rune::*;

#[test]
fn test_numeric_array_literal() {
    let input = "[1,2,3]";
    let stmts = parse_rune(input).unwrap();

    assert_eq!(stmts.len(), 1);

    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(elements)))) = &stmts[0] {
        assert_eq!(elements.len(), 3);

        // Check each element
        for (i, elem) in elements.iter().enumerate() {
            if let Expr::Term(Term::Literal(Literal::Number(n))) = elem {
                assert_eq!(*n, (i + 1) as f64);
            } else {
                panic!("Expected number literal");
            }
        }

        // Verify round-trip
        let displayed = format!("{}", stmts[0]);
        assert_eq!(displayed, input);
    } else {
        panic!("Expected array literal");
    }
}

#[test]
fn test_identifier_array_literal() {
    let input = "[a,b,c]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(elements)))) = &stmts[0] {
        assert_eq!(elements.len(), 3);

        let expected_names = ["a", "b", "c"];
        for (i, elem) in elements.iter().enumerate() {
            if let Expr::Term(Term::Ident(id)) = elem {
                assert_eq!(id.0, expected_names[i]);
            } else {
                panic!("Expected identifier");
            }
        }
    }
}

#[test]
fn test_mixed_array_literal() {
    let input = "[1,a,2,b]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(elements)))) = &stmts[0] {
        assert_eq!(elements.len(), 4);

        // First element: 1
        matches!(&elements[0], Expr::Term(Term::Literal(Literal::Number(_))));
        // Second element: a
        matches!(&elements[1], Expr::Term(Term::Ident(_)));
        // Third element: 2
        matches!(&elements[2], Expr::Term(Term::Literal(Literal::Number(_))));
        // Fourth element: b
        matches!(&elements[3], Expr::Term(Term::Ident(_)));
    }
}

#[test]
fn test_array_with_expressions() {
    let input = "[a / 0, b / 1, c / 2]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(elements)))) = &stmts[0] {
        assert_eq!(elements.len(), 3);

        // Each element should be a binary expression (a / 0, etc.)
        for elem in elements {
            if let Expr::Binary { op, .. } = elem {
                assert_eq!(*op, RuneOp::Descendant); // / operator
            } else {
                panic!("Expected binary expression");
            }
        }
    }
}

#[test]
fn test_semantic_prefix_with_array() {
    let input = "V:[1,2,3]";
    let stmts = parse_rune(input).unwrap();

    // Should parse as: V (semantic prefix) with name '[1,2,3]'? No!
    // Actually, semantic_ident requires an ident after the colon
    // So this should fail to parse as semantic_ident and instead parse as...
    // Actually, let's check what happens

    // It should be: semantic_ident 'V' with name that starts with '['
    // But ident can't start with '[', so this should fail
    // OR it parses as V: followed by array [1,2,3]

    // Let me check the actual structure
    println!("Parsed: {:?}", stmts);
}

#[test]
fn test_math_block_vs_array() {
    // Array: comma-separated
    let array = "[1,2,3]";
    let arr_stmts = parse_rune(array).unwrap();
    assert!(matches!(
        &arr_stmts[0],
        Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(_))))
    ));

    // Math block: operator-based
    let math = "[1 + 2]";
    let math_stmts = parse_rune(math).unwrap();
    assert!(matches!(
        &math_stmts[0],
        Stmt::Expr(Expr::Term(Term::Math(_)))
    ));

    // Not ambiguous!
    assert_ne!(format!("{}", arr_stmts[0]), format!("{}", math_stmts[0]));
}

#[test]
fn test_nested_math_on_array() {
    // [[3,3,3] * [3,3,3]] - math block containing array multiplication
    // Wait, this doesn't make sense with current design
    // The inner [3,3,3] would be parsed as array
    // But math_block expects math_expr inside

    // Let's test what we CAN do:
    // [expr] where expr contains arrays
    let input = "[[1,2,3], [4,5,6]]";
    let stmts = parse_rune(input).unwrap();

    // This is an array of arrays
    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(outer)))) = &stmts[0] {
        assert_eq!(outer.len(), 2);

        for elem in outer {
            assert!(matches!(elem, Expr::Term(Term::Literal(Literal::Array(_)))));
        }
    }
}

#[test]
fn test_array_in_expression() {
    let input = "data := [1,2,3]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Binary { op, left, right }) = &stmts[0] {
        assert_eq!(*op, RuneOp::Define);
        assert!(matches!(left.as_ref(), Expr::Term(Term::Ident(_))));
        assert!(matches!(
            right.as_ref(),
            Expr::Term(Term::Literal(Literal::Array(_)))
        ));
    }
}

#[test]
fn test_array_with_semantic_elements() {
    let input = "[T:Gf8, V:vector, R:root]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(elements)))) = &stmts[0] {
        assert_eq!(elements.len(), 3);

        // Each element should be a semantic identifier
        for elem in elements {
            assert!(matches!(elem, Expr::Term(Term::SemanticIdent(_))));
        }
    }
}

#[test]
fn test_empty_array() {
    // Should we support empty arrays? Let's try
    let input = "[]";
    let result = parse_rune(input);

    // This might fail because array_literal requires at least one element
    // Let's see what happens
    println!("Empty array result: {:?}", result);
}

#[test]
fn test_single_element_array() {
    // Single-element arrays are not supported by design
    // [42] is parsed as a math block, not an array
    // Arrays must have commas, i.e., 2+ elements
    let input = "[42]";
    let stmts = parse_rune(input).unwrap();

    // Should parse as math block, not array
    if let Stmt::Expr(Expr::Term(Term::Math(_))) = &stmts[0] {
        // Expected: math block
    } else {
        panic!("Expected math block for single-element bracket notation");
    }

    // If you want a single-element collection, use array with trailing comma
    // or just use the bare value
}

#[test]
fn test_array_with_strings() {
    let input = r#"["hello", "world", "test"]"#;
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Term(Term::Literal(Literal::Array(elements)))) = &stmts[0] {
        assert_eq!(elements.len(), 3);

        for elem in elements {
            assert!(matches!(
                elem,
                Expr::Term(Term::Literal(Literal::String(_)))
            ));
        }
    }
}

File: tests\errors.rs
=====================
use rune_format::{DecodeOptions, ToonError, decode, decode_default, decode_strict};
use serde_json::{Value, json};

#[test]
fn test_invalid_syntax_errors() {
    let cases = vec![
        ("items[]: a,b", "Expected array length"),
        ("items[2]{name: a,b", "Expected '}'"),
        ("key value", "Expected"),
    ];

    for (input, expected_msg) in cases {
        let result = decode_default::<Value>(input);
        if let Err(err) = result {
            let err_str = err.to_string();
            assert!(
                err_str.contains(expected_msg)
                    || err_str.contains("Parse error")
                    || err_str.contains("Invalid"),
                "Expected error containing '{expected_msg}' but got: {err_str}"
            );
        } else if input == "key value" {
            assert!(result.is_ok(), "'key value' is valid as a root string");
        }
    }

    let invalid_cases = vec![
        ("items[2: a,b", "Expected ']'"),
        ("items[abc]: 1,2", "Expected array length"),
    ];

    for (input, expected_msg) in invalid_cases {
        let result = decode_default::<Value>(input);
        assert!(result.is_err(), "Expected error for input: {input}");

        let err = result.unwrap_err();
        let err_str = err.to_string();
        assert!(
            err_str.contains(expected_msg) || err_str.contains("Parse error"),
            "Expected error containing '{expected_msg}' but got: {err_str}"
        );
    }
}

#[test]
fn test_type_mismatch_errors() {
    let cases = vec![
        ("value: ", "Empty value"),
        ("items[abc]: 1,2", "Invalid array length"),
    ];

    for (input, description) in cases {
        let result = decode_default::<Value>(input);
        println!("Test case '{description}': {result:?}");
    }
}

#[test]
fn test_length_mismatch_strict_mode() {
    let test_cases = vec![("items[3]: a,b", 3, 2), ("items[5]: x", 5, 1)];

    for (input, expected, actual) in test_cases {
        let result = decode_strict::<Value>(input);

        assert!(
            result.is_err(),
            "Expected error for input '{input}' (expected: {expected}, actual: {actual})",
        );

        if let Err(ToonError::LengthMismatch {
            expected: exp,
            found: fnd,
            ..
        }) = result
        {
            assert_eq!(
                exp, expected,
                "Expected length {expected} but got {exp} for input '{input}'"
            );
            assert_eq!(
                fnd, actual,
                "Expected found {actual} but got {fnd} for input '{input}'"
            );
        }
    }

    let result = decode_strict::<Value>("items[1]: a,b,c");

    if let Ok(val) = result {
        assert_eq!(val["items"], json!(["a"]));
    }
}

#[test]
fn test_length_mismatch_non_strict_mode() {
    let test_cases = vec![
        ("items[3]: a,b", json!({"items": ["a", "b"]})),
        ("items[1]: a,b", json!({"items": ["a", "b"]})),
    ];

    for (input, _expected) in test_cases {
        let result = decode_default::<Value>(input);
        println!("Non-strict test for '{input}': {result:?}");
    }
}

#[test]
fn test_delimiter_errors() {
    let mixed_delimiters = "items[3]: a,b|c";
    let result = decode_default::<Value>(mixed_delimiters);

    println!("Mixed delimiter test: {result:?}");
}

#[test]
fn test_quoting_errors() {
    let test_cases = vec![
        ("value: \"unclosed", "Unclosed string"),
        ("value: \"invalid\\x\"", "Invalid escape"),
    ];

    for (input, description) in test_cases {
        let result = decode_default::<Value>(input);
        println!("Quoting error test '{description}': {result:?}");
    }
}

#[test]
fn test_tabular_array_errors() {
    let result = decode_default::<Value>("items[2]{id,name}:\n  1,Alice\n  2");
    assert!(result.is_err(), "Should error on incomplete row");

    if let Err(e) = result {
        let err_str = e.to_string();
        assert!(
            err_str.contains("Parse")
                || err_str.contains("cloumn")
                || err_str.contains("expected")
                || err_str.contains("primitive"),
            "Error should mention missing field or delimiter: {err_str}"
        );
    }

    let result = decode_default::<Value>("items[2]{id,name}:\n  1,Alice\n  2,Bob,Extra");
    if let Err(err) = result {
        let err_str = err.to_string();
        assert!(
            err_str.contains("Parse") || err_str.contains("Expected") || err_str.contains("field"),
            "Should mention unexpected content: {err_str}"
        );
    } else {
        println!("Note: Extra fields are ignored in tabular arrays");
    }

    let result = decode_strict::<Value>("items[3]{id,name}:\n  1,Alice\n  2,Bob");
    assert!(
        result.is_err(),
        "Should error on row count mismatch in strict mode"
    );

    if let Err(ToonError::LengthMismatch {
        expected, found, ..
    }) = result
    {
        assert_eq!(expected, 3);
        assert_eq!(found, 2);
    }
}

#[test]
fn test_nested_structure_errors() {
    let result = decode_default::<Value>("obj:\n  key");
    assert!(result.is_err(), "Should error on incomplete nested object");

    let result = decode_default::<Value>("arr[2]:\n  - item");
    assert!(result.is_err(), "Should error on incomplete nested array");
}

#[test]
fn test_depth_limit_errors() {
    let mut nested = "a:\n".to_string();
    for i in 0..60 {
        nested.push_str(&format!("{}b:\n", "  ".repeat(i + 1)));
    }
    nested.push_str(&format!("{}c: value", "  ".repeat(61)));

    let result = decode_default::<Value>(&nested);
    println!("Deep nesting test: {result:?}");
}

#[test]
fn test_empty_structure_errors() {
    let cases = vec![
        ("items[]:", "Empty array with colon"),
        ("obj{}:", "Empty object with colon"),
        ("{}", "Just braces"),
        ("[]", "Just brackets"),
    ];

    for (input, description) in cases {
        let result = decode_default::<Value>(input);
        println!("Empty structure test '{description}': {result:?}");
    }
}

#[test]
fn test_error_messages_are_helpful() {
    let result = decode_strict::<Value>("items[5]: a,b,c");

    if let Err(err) = result {
        let err_msg = err.to_string();

        assert!(
            err_msg.contains("5")
                || err_msg.contains("3")
                || err_msg.contains("expected")
                || err_msg.contains("found"),
            "Error message should contain length information: {err_msg}"
        );
    }
}

#[test]
fn test_parse_error_line_column() {
    let input = "line1: value\nline2: bad syntax!\nline3: value";
    let result = decode_default::<Value>(input);

    if let Err(ToonError::ParseError { line, column, .. }) = result {
        println!("Parse error at line {line}, column {column}");
        assert!(line > 0, "Line number should be positive");
        assert!(column > 0, "Column number should be positive");
    }
}

#[test]
fn test_multiple_errors_in_input() {
    let input = "items[10]: a,b\nobj{missing,fields: x,y";
    let result = decode_default::<Value>(input);

    assert!(result.is_err(), "Should error on malformed input");
}

#[test]
fn test_coercion_errors() {
    let opts = DecodeOptions::new().with_coerce_types(true);

    let result = decode::<Value>("value: 123", &opts);
    assert!(result.is_ok());

    let result = decode::<Value>("value: true", &opts);
    assert!(result.is_ok());

    let result = decode::<Value>("value: 3.14", &opts);
    assert!(result.is_ok());
}

#[test]
fn test_no_coercion_preserves_strings() {
    let opts = DecodeOptions::new().with_coerce_types(false);

    let result = decode::<Value>("value: hello", &opts).unwrap();
    assert!(result["value"].is_string());
    assert_eq!(result["value"], json!("hello"));

    let result = decode::<Value>(r#"value: "123""#, &opts).unwrap();
    assert!(result["value"].is_string());
    assert_eq!(result["value"], json!("123"));

    let result = decode::<Value>(r#"value: "true""#, &opts).unwrap();
    assert!(result["value"].is_string());
    assert_eq!(result["value"], json!("true"));

    let result = decode::<Value>("value: 123", &opts).unwrap();
    assert!(result["value"].is_number());
    assert_eq!(result["value"], json!(123));

    let result = decode::<Value>("value: true", &opts).unwrap();
    assert!(result["value"].is_boolean());
    assert_eq!(result["value"], json!(true));
}

#[test]
fn test_edge_case_values() {
    let cases = vec![
        ("value: 0", json!({"value": 0})),
        ("value: null", json!({"value": null})),
    ];

    for (input, expected) in cases {
        let result = decode_default::<Value>(input);
        match result {
            Ok(val) => assert_eq!(val, expected, "Failed for input: {input}"),
            Err(e) => println!("Edge case '{input}' error: {e:?}"),
        }
    }

    let result = decode_default::<Value>("value: -0");
    match result {
        Ok(val) => {
            assert_eq!(
                val["value"],
                json!(0),
                "Negative zero is normalized to zero in JSON"
            );
        }
        Err(e) => println!("Edge case '-0' error: {e:?}"),
    }
}

#[test]
fn test_unicode_in_errors() {
    let input = "emoji: 😀🎉\nkey: value\nbad: @syntax!";
    let result = decode_default::<Value>(input);

    if let Err(err) = result {
        let err_msg = err.to_string();
        println!("Unicode error handling: {err_msg}");
        assert!(!err_msg.is_empty());
    }
}

#[test]
fn test_recovery_from_errors() {
    let valid_after_invalid = vec!["good: value\nbad syntax here\nalso_good: value"];

    for input in valid_after_invalid {
        let result = decode_default::<Value>(input);
        println!("Recovery test for: {result:?}");
    }
}

#[test]
fn test_strict_mode_indentation_errors() {
    let result = decode_strict::<Value>("items[2]: a");
    assert!(
        result.is_err(),
        "Should error on insufficient items in strict mode"
    );

    if let Err(ToonError::LengthMismatch {
        expected, found, ..
    }) = result
    {
        assert_eq!(expected, 2);
        assert_eq!(found, 1);
    }
}

#[test]
fn test_quoted_key_without_colon() {
    let result = decode_default::<Value>(r#""key" value"#);
    println!("Quoted key test: {result:?}");
}

#[test]
fn test_nested_array_length_mismatches() {
    let result = decode_strict::<Value>("outer[1]:\n  - items[2]: a,b\n  - items[3]: x,y");
    if let Err(err) = result {
        let err_str = err.to_string();
        assert!(err_str.contains("3") || err_str.contains("2") || err_str.contains("length"));
    }
}

#[test]
fn test_empty_array_with_length() {
    let result = decode_strict::<Value>("items[2]:");
    assert!(
        result.is_err(),
        "Should error when array header specifies length but no items provided"
    );

    let result = decode_strict::<Value>("items[0]:");
    assert!(
        result.is_ok(),
        "Empty array with length 0 should parse successfully"
    );

    if let Ok(val) = result {
        assert_eq!(val["items"], json!([]));
    }
}

#[test]
fn test_tabular_array_field_count_mismatch() {
    let result = decode_default::<Value>("items[2]{id,name}:\n  1\n  2,Bob");
    assert!(
        result.is_err(),
        "Should error when row has fewer fields than header"
    );
}

#[test]
fn test_invalid_array_header_syntax() {
    let cases = vec![
        ("items[", "Expected array length"),
        ("items[: a,b", "Expected array length"),
    ];

    for (input, expected_msg) in cases {
        let result = decode_default::<Value>(input);
        assert!(
            result.is_err(),
            "Should error on invalid array header: {input}"
        );

        if let Err(e) = result {
            let err_str = e.to_string();
            assert!(
                err_str.contains(expected_msg) || err_str.contains("Parse error"),
                "Expected error about '{expected_msg}' but got: {err_str}",
            );
        }
    }

    let result = decode_default::<Value>("items{id}: a,b");
    println!("Braces without brackets test: {result:?}");

    let result = decode_default::<Value>("items]2[: a,b");
    println!("Quirky bracket syntax test: {result:?}");
}

#[test]
fn test_missing_colon_after_key() {
    let _result = decode_default::<Value>("key value");

    let result = decode_default::<Value>("obj:\n  key value");
    println!("Missing colon in object: {result:?}");
}

#[test]
fn test_error_context_information() {
    let result = decode_strict::<Value>("items[5]: a,b");

    if let Err(e) = result {
        let err_str = e.to_string();

        assert!(
            err_str.contains("5")
                || err_str.contains("2")
                || err_str.contains("length")
                || err_str.contains("expected")
                || err_str.contains("found"),
            "Error should contain length information: {err_str}",
        );

        match e {
            ToonError::ParseError {
                context: Some(ctx), ..
            } => {
                println!(
                    "Error context has {} preceding lines, {} following lines",
                    ctx.preceding_lines.len(),
                    ctx.following_lines.len()
                );
            }
            ToonError::LengthMismatch {
                context: Some(ctx), ..
            } => {
                println!("Length mismatch context available:{ctx}");
            }
            _ => {}
        }
    }
}

File: tests\numeric.rs
======================
use core::f64;

use rune_format::{decode_default, encode_default};
use serde_json::{Value, json};

#[test]
fn test_numeric_edge_cases() {
    let numbers = json!({
        "zero": 0,
        "negative": -42,
        "large": 9999999999i64,
        "small": -9999999999i64,
        "decimal": f64::consts::PI,
        "scientific": 1.23e10,
        "tiny": 0.0000001
    });

    let encoded = encode_default(&numbers).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();

    assert_eq!(decoded["zero"], json!(0));
    assert_eq!(decoded["negative"], json!(-42));
}

File: tests\objects.rs
======================
use rune_format::{decode_default, encode_default};
use serde_json::{Value, json};

#[test]
fn test_special_characters_and_quoting() {
    let cases = vec![
        json!({"value": "true"}),
        json!({"value": "false"}),
        json!({"value": "42"}),
        json!({"value": "3.14"}),
        json!({"value": "hello, world"}),
        json!({"value": "hello|world"}),
        json!({"value": "say \"hello\""}),
        json!({"value": "line1\nline2"}),
        json!({"value": ""}),
        json!({"value": " hello "}),
    ];

    for case in cases {
        let encoded = encode_default(&case).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();
        assert_eq!(case, decoded, "Failed for: {case}");
    }
}

#[test]
fn test_nested_structures() {
    let nested = json!({
        "level1": {
            "level2": {
                "level3": {
                    "value": "deep"
                }
            }
        }
    });

    let encoded = encode_default(&nested).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(nested, decoded);
}

File: tests\real_world.rs
=========================
use rune_format::{decode_default, encode_default};
use serde_json::{Value, json};

#[test]
fn test_real_world_github_data() {
    let github_repos = json!({
        "repositories": [
            {
                "id": 28457823,
                "name": "freeCodeCamp",
                "full_name": "freeCodeCamp/freeCodeCamp",
                "stars": 430886,
                "watchers": 8583,
                "forks": 42146,
                "language": "TypeScript",
                "has_issues": true,
                "has_wiki": true
            },
            {
                "id": 132750724,
                "name": "build-your-own-x",
                "full_name": "codecrafters-io/build-your-own-x",
                "stars": 430877,
                "watchers": 6332,
                "forks": 40453,
                "language": "Markdown",
                "has_issues": true,
                "has_wiki": false
            }
        ]
    });

    let encoded = encode_default(&github_repos).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(github_repos, decoded);

    assert!(encoded.contains("repositories[2]{"));
    assert!(encoded.contains("}:"));
}

#[test]
fn test_real_world_e_commerce_data() {
    let order = json!({
        "order_id": "ORD-12345",
        "customer": {
            "id": 5678,
            "name": "John Doe",
            "email": "john@example.com"
        },
        "items": [
            {
                "sku": "WIDGET-001",
                "name": "Premium Widget",
                "quantity": 2,
                "price": 29.99,
                "discount": 0.1
            },
            {
                "sku": "GADGET-042",
                "name": "Super Gadget",
                "quantity": 1,
                "price": 149.99,
                "discount": 0.0
            }
        ],
        "shipping": {
            "method": "express",
            "cost": 15.50,
            "address": "123 Main St, City, State 12345"
        },
        "total": 224.46
    });

    let encoded = encode_default(&order).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(decoded["order_id"], order["order_id"]);
    assert_eq!(decoded["customer"], order["customer"]);
    assert_eq!(decoded["shipping"], order["shipping"]);
    assert_eq!(decoded["total"], order["total"]);
    assert_eq!(decoded["items"].as_array().unwrap().len(), 2);
}

File: tests\round_trip.rs
=========================
use std::f64;

use rune_format::{decode_default, encode_default};
use serde_json::{Value, json};

#[test]
fn test_comprehensive_round_trips() {
    let test_cases = vec![
        json!(null),
        json!(true),
        json!(false),
        json!(42),
        json!(-42),
        json!(f64::consts::PI),
        json!("hello"),
        json!(""),
        json!({"key": "value"}),
        json!({"a": 1, "b": 2, "c": 3}),
        json!({"nested": {"key": "value"}}),
        json!({"array": [1, 2, 3]}),
        json!({"mixed": [1, "two", true, null]}),
        json!({"users": [
            {"id": 1, "name": "Alice"},
            {"id": 2, "name": "Bob"}
        ]}),
        json!({"empty_array": []}),
        json!({"empty_object": {}}),
    ];

    for (i, case) in test_cases.iter().enumerate() {
        let encoded =
            encode_default(case).unwrap_or_else(|e| panic!("Failed to encode case {i}: {e:?}"));
        let decoded: Value = decode_default::<Value>(&encoded)
            .unwrap_or_else(|e| panic!("Failed to decode case {i}: {e}"));
        assert_eq!(
            case, &decoded,
            "Round-trip failed for case {i}: Original: {case}, Decoded: {decoded}"
        );
    }
}

File: tests\rune.rs
===================
/* tests/rune.rs */
//! Comprehensive integration tests for the RUNE parsing engine.
//!
//! # TOON-RUNE – RUNE Integration Tests
//!▫~•◦------------------------------------------------‣
//! [NOTE: The underline above must underline the "Remarks:" line only.]
//!
//! This test suite validates the complete RUNE parsing, AST construction,
//! and integration with TOON data blocks for the E8 ecosystem.
//!
//! ### Key Capabilities
//! - **Parser Validation**: Tests complete RUNE source code parsing and AST generation.
//! - **TOON Integration**: Verifies TOON block extraction and round-trip compatibility.
//! - **Operator Precedence**: Validates mathematical and semantic operator precedence rules.
//! - **Root Semantics**: Tests root declaration parsing and namespace handling.
//! - **Round-trip Fidelity**: Ensures parse ↔ encode consistency.
//!
//! ### Architectural Notes
//! Tests cover the parser::ParsingError, AST types, and rune::encode_rune functionality.
//! Integration tests use serde_json for TOON data validation and ensure clean compilation.
//!
//! ### Example
//! ```rust
//! use rune_format::rune::*;
//!
//! let rune_code = "root: test\nitems / 0 -> name := value";
//! let statements = parse_rune(rune_code).unwrap();
//! assert_eq!(statements.len(), 2);
//!
//! // Tests validate that parsing produces expected AST structures.
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::decode_default;
use rune_format::rune::*;
use serde_json::json;

#[test]
fn test_rune_parsing_basic() {
    let input = r#"
root: test_context

data ~TOON:
  items[2]{id,name}:
    1,hello
    2,world

items / 1 -> name := world
"#;

    let stmts = parse_rune(input).unwrap();

    // Should have 3 statements: root, toon_block, expr
    assert_eq!(stmts.len(), 3);

    match &stmts[0] {
        Stmt::RootDecl(root) => assert_eq!(root.0.as_str(), "test_context"),
        _ => panic!("Expected root declaration"),
    }

    match &stmts[1] {
        Stmt::ToonBlock { name, content } => {
            assert_eq!(name.0.as_str(), "data");
            // Should contain the TOON data
            assert!(content.contains("items[2]"));
        }
        _ => panic!("Expected TOON block"),
    }

    match &stmts[2] {
        Stmt::Expr(expr) => {
            // Should be items / 1 -> name := world
            // With precedence: flow_op (-> ) < struct_op (:=)
            // Parses as: items / 1 -> (name := world)
            match expr {
                Expr::Binary { op, left, right } => {
                    assert_eq!(*op, RuneOp::FlowRight);
                    assert_eq!(format!("{}", left), "items / 1");
                    assert_eq!(format!("{}", right), "name := world");
                }
                _ => panic!("Expected binary expression with ->"),
            }
        }
        _ => panic!("Expected expression statement"),
    }
}

#[test]
fn test_toon_integration() {
    let input = r#"
users ~TOON:
  list[3]{id,name,role}:
    1,"Alice",admin
    2,"Bob",user
    3,"Charlie",moderator

list / 0 -> role := admin
"#;

    let stmts = parse_rune(input).unwrap();
    assert_eq!(stmts.len(), 2);

    // Extract TOON content and verify it parses as valid TOON
    if let Stmt::ToonBlock { content, .. } = &stmts[0] {
        let decoded: serde_json::Value = decode_default(content).unwrap();
        let expected = json!({
            "list": [
                {"id": 1, "name": "Alice", "role": "admin"},
                {"id": 2, "name": "Bob", "role": "user"},
                {"id": 3, "name": "Charlie", "role": "moderator"}
            ]
        });
        assert_eq!(decoded, expected);
    }
}

#[test]
fn test_operator_precedence() {
    // Test math precedence: * before + (inside math block)
    let input = "[a + b * c]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(expr) = &stmts[0] {
        // Should be a math block term
        match expr {
            Expr::Term(Term::Math(math_expr)) => {
                // Inside should be addition at top level
                match math_expr.as_ref() {
                    MathExpr::Binary { op, left, right } => {
                        assert_eq!(*op, MathOp::Add);
                        // Left should be 'a'
                        match left.as_ref() {
                            MathExpr::Atom(MathAtom::Ident(id)) => assert_eq!(id.0, "a"),
                            _ => panic!("Expected identifier 'a'"),
                        }
                        // Right side should be (b * c)
                        match right.as_ref() {
                            MathExpr::Binary { op, left, right } => {
                                assert_eq!(*op, MathOp::Multiply);
                                match left.as_ref() {
                                    MathExpr::Atom(MathAtom::Ident(id)) => assert_eq!(id.0, "b"),
                                    _ => panic!("Expected identifier 'b'"),
                                }
                                match right.as_ref() {
                                    MathExpr::Atom(MathAtom::Ident(id)) => assert_eq!(id.0, "c"),
                                    _ => panic!("Expected identifier 'c'"),
                                }
                            }
                            _ => panic!("Expected nested multiplication"),
                        }
                    }
                    _ => panic!("Expected addition at top level"),
                }
            }
            _ => panic!("Expected math block"),
        }
    }
}

#[test]
fn test_complex_glyphs() {
    let input = r#"
fiber_net / hub /\ endpoint
data \|/ modes
"#;

    let stmts = parse_rune(input).unwrap();
    assert_eq!(stmts.len(), 2);

    // Check first expression: fiber_net / hub /\ endpoint
    if let Stmt::Expr(expr) = &stmts[0] {
        // Should parse fiber_net / hub first, then /\ operator
        println!("Parsed: {}", expr);
    }
}

#[test]
fn test_root_and_namespace_operators() {
    let input = r#"
root: e8::continuum
T::Gf8 -> vec := "[+1,-1,+1,-1,+1,-1,+1,-1]"
embeddings / 0 | input_vec
"#;

    let stmts = parse_rune(input).unwrap();
    assert_eq!(stmts.len(), 3);

    // First statement should be root declaration
    match &stmts[0] {
        Stmt::RootDecl(root) => assert_eq!(root.0.as_str(), "e8::continuum"),
        _ => panic!("Expected root declaration with namespace"),
    }

    // Check type annotation: T::Gf8 -> vec
    if let Stmt::Expr(expr) = &stmts[1] {
        match expr {
            Expr::Binary { op, left, right } => {
                assert_eq!(*op, RuneOp::FlowRight);
                assert_eq!(format!("{}", left), "T::Gf8");
                assert_eq!(format!("{}", right), "vec := \"[+1,-1,+1,-1,+1,-1,+1,-1]\"");
            }
            _ => panic!("Expected type -> value flow"),
        }
    }
}

#[test]
fn test_round_trip_encoding() {
    // Create some statements programmatically
    let original = vec![
        Stmt::root("test_root"),
        Stmt::expr(Expr::binary(
            Expr::ident("data"),
            RuneOp::FlowRight,
            Expr::literal(42.0),
        )),
    ];

    // Encode to string
    let encoded = encode_rune(&original);

    // Parse back
    let decoded = parse_rune(&encoded).unwrap();

    // Should be structurally equivalent
    assert_eq!(original.len(), decoded.len());

    // Check first statement (root)
    match (&original[0], &decoded[0]) {
        (Stmt::RootDecl(orig), Stmt::RootDecl(dec)) => assert_eq!(orig, dec),
        _ => panic!("Root declaration mismatch"),
    }

    // Check second statement (expression)
    match (&original[1], &decoded[1]) {
        (Stmt::Expr(orig), Stmt::Expr(dec)) => {
            // Both should contain data -> 42.0
            assert_eq!(format!("{}", orig), format!("{}", dec));
        }
        _ => panic!("Expression mismatch"),
    }
}

#[test]
fn test_invalid_operators_rejected() {
    // These should fail parsing due to operators not in registry
    let bad_inputs = vec![
        "a => b",      // => not a valid operator
        "a |-> b",     // |-> is invalid fusion
        "value :++ x", // ++ not valid
    ];

    for input in bad_inputs {
        assert!(
            parse_rune(input).is_err(),
            "Input '{}' should fail parsing",
            input
        );
    }
}

#[test]
fn test_pemdas_exponentiation() {
    // Test exponent operator has highest precedence
    let input = "[2 + 3 * 4 ^ 2]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(expr) = &stmts[0] {
        match expr {
            Expr::Term(Term::Math(math_expr)) => {
                // Should parse as: 2 + (3 * (4 ^ 2))
                match math_expr.as_ref() {
                    MathExpr::Binary { op, left, right } => {
                        assert_eq!(*op, MathOp::Add);
                        // Left is 2
                        match left.as_ref() {
                            MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 2.0),
                            _ => panic!("Expected 2"),
                        }
                        // Right is (3 * (4 ^ 2))
                        match right.as_ref() {
                            MathExpr::Binary { op, left, right } => {
                                assert_eq!(*op, MathOp::Multiply);
                                // Left is 3
                                match left.as_ref() {
                                    MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 3.0),
                                    _ => panic!("Expected 3"),
                                }
                                // Right is (4 ^ 2)
                                match right.as_ref() {
                                    MathExpr::Binary { op, left, right } => {
                                        assert_eq!(*op, MathOp::Power);
                                        match left.as_ref() {
                                            MathExpr::Atom(MathAtom::Number(n)) => {
                                                assert_eq!(*n, 4.0)
                                            }
                                            _ => panic!("Expected 4"),
                                        }
                                        match right.as_ref() {
                                            MathExpr::Atom(MathAtom::Number(n)) => {
                                                assert_eq!(*n, 2.0)
                                            }
                                            _ => panic!("Expected 2"),
                                        }
                                    }
                                    _ => panic!("Expected exponent operation"),
                                }
                            }
                            _ => panic!("Expected multiplication"),
                        }
                    }
                    _ => panic!("Expected addition at top level"),
                }
            }
            _ => panic!("Expected math block"),
        }
    } else {
        panic!("Expected expression statement");
    }
}

#[test]
fn test_pemdas_unary_operators() {
    // Test unary minus
    let input = "[-5]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(expr) = &stmts[0] {
        match expr {
            Expr::Term(Term::Math(math_expr)) => match math_expr.as_ref() {
                MathExpr::Unary { op, operand } => {
                    assert_eq!(*op, MathUnaryOp::Negate);
                    match operand.as_ref() {
                        MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 5.0),
                        _ => panic!("Expected 5"),
                    }
                }
                _ => panic!("Expected unary expression"),
            },
            _ => panic!("Expected math block"),
        }
    } else {
        panic!("Expected expression statement");
    }

    // Test unary with identifier
    let input2 = "[-x + 5]";
    let stmts2 = parse_rune(input2).unwrap();

    if let Stmt::Expr(expr) = &stmts2[0] {
        match expr {
            Expr::Term(Term::Math(math_expr)) => {
                // Should be addition at top level
                match math_expr.as_ref() {
                    MathExpr::Binary { op, left, right } => {
                        assert_eq!(*op, MathOp::Add);
                        // Left should be unary minus x
                        match left.as_ref() {
                            MathExpr::Unary { op, operand } => {
                                assert_eq!(*op, MathUnaryOp::Negate);
                                match operand.as_ref() {
                                    MathExpr::Atom(MathAtom::Ident(id)) => assert_eq!(id.0, "x"),
                                    _ => panic!("Expected identifier x"),
                                }
                            }
                            _ => panic!("Expected unary expression"),
                        }
                        // Right should be 5
                        match right.as_ref() {
                            MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 5.0),
                            _ => panic!("Expected 5"),
                        }
                    }
                    _ => panic!("Expected addition"),
                }
            }
            _ => panic!("Expected math block"),
        }
    } else {
        panic!("Expected expression statement");
    }
}

#[test]
fn test_pemdas_arithmetic_outside_brackets_fails() {
    // Arithmetic operators should NOT work outside math blocks
    // These should fail because +, *, ^ are not valid operators outside [...]
    let invalid_inputs = vec![
        "2 + 3", "a * b",
        "x ^ 2",
        // Note: "a R 2" is actually valid (R is parsed as identifier, not operator)
    ];

    for input in invalid_inputs {
        let result = parse_rune(input);
        assert!(
            result.is_err(),
            "Input '{}' should fail (arithmetic outside brackets)",
            input
        );
    }
}

#[test]
fn test_pemdas_root_operator() {
    // Test n-th root operator with R
    let input = "[x R n]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(expr) = &stmts[0] {
        match expr {
            Expr::Term(Term::Math(math_expr)) => match math_expr.as_ref() {
                MathExpr::Binary { op, left, right } => {
                    assert_eq!(*op, MathOp::Root);
                    match left.as_ref() {
                        MathExpr::Atom(MathAtom::Ident(id)) => assert_eq!(id.0, "x"),
                        _ => panic!("Expected identifier x"),
                    }
                    match right.as_ref() {
                        MathExpr::Atom(MathAtom::Ident(id)) => assert_eq!(id.0, "n"),
                        _ => panic!("Expected identifier n"),
                    }
                }
                _ => panic!("Expected binary root operation"),
            },
            _ => panic!("Expected math block"),
        }
    } else {
        panic!("Expected expression statement");
    }

    // Test another root operation
    let input2 = "[27 R 3]";
    let stmts2 = parse_rune(input2).unwrap();

    if let Stmt::Expr(expr) = &stmts2[0] {
        match expr {
            Expr::Term(Term::Math(math_expr)) => match math_expr.as_ref() {
                MathExpr::Binary { op, left, right } => {
                    assert_eq!(*op, MathOp::Root);
                    match left.as_ref() {
                        MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 27.0),
                        _ => panic!("Expected 27"),
                    }
                    match right.as_ref() {
                        MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 3.0),
                        _ => panic!("Expected 3"),
                    }
                }
                _ => panic!("Expected binary root operation"),
            },
            _ => panic!("Expected math block"),
        }
    } else {
        panic!("Expected expression statement");
    }
}

#[test]
fn test_pemdas_root_precedence() {
    // Root should have same precedence as exponentiation
    // Test: [2 + 8 R 3] should parse as 2 + (8 R 3)
    let input = "[2 + 8 R 3]";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(expr) = &stmts[0] {
        match expr {
            Expr::Term(Term::Math(math_expr)) => {
                match math_expr.as_ref() {
                    MathExpr::Binary { op, left, right } => {
                        assert_eq!(*op, MathOp::Add);
                        // Left is 2
                        match left.as_ref() {
                            MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 2.0),
                            _ => panic!("Expected 2"),
                        }
                        // Right is (8 R 3)
                        match right.as_ref() {
                            MathExpr::Binary { op, left, right } => {
                                assert_eq!(*op, MathOp::Root);
                                match left.as_ref() {
                                    MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 8.0),
                                    _ => panic!("Expected 8"),
                                }
                                match right.as_ref() {
                                    MathExpr::Atom(MathAtom::Number(n)) => assert_eq!(*n, 3.0),
                                    _ => panic!("Expected 3"),
                                }
                            }
                            _ => panic!("Expected root operation"),
                        }
                    }
                    _ => panic!("Expected addition at top level"),
                }
            }
            _ => panic!("Expected math block"),
        }
    } else {
        panic!("Expected expression statement");
    }
}

File: tests\semantic_prefixes.rs
================================
/* tests/semantic_prefixes.rs */
//! Tests for RUNE single-letter semantic namespace prefixes.
//!
//! # TOON-RUNE – Semantic Prefix Tests
//!▫~•◦------------------------------------------------‣
//!
//! This test suite validates the complete single-letter semantic alphabet
//! for RUNE (A-Z), ensuring each prefix can be parsed and displayed correctly.
//!
//! ### Semantic Alphabet
//! - A: Address, Axis
//! - B: Binary, Basis
//! - C: Compute, Cache, Cell
//! - D: Data, Delta, Dimension
//! - E: Entity, Edge, Expression
//! - F: Function, Frame, Field
//! - G: Geometry, Graph, Group
//! - H: Hash, Heap, Hyper
//! - I: Index, Instruction, Identity
//! - J: Jump, Join
//! - K: Key, Kernel
//! - L: Lattice, Layer, Left
//! - M: Memory, Matrix, Module
//! - N: Node, Number, Namespace
//! - O: Object, Op, Offset
//! - P: Pointer, Process, Page
//! - Q: Quantized, Query
//! - R: Root, Register, Reference
//! - S: State, Stack, Scalar
//! - T: Tensor, Type, Thread
//! - U: Unit, Unary, Universal
//! - V: Vector, Value, Vertex
//! - W: Write, Word, Warp
//! - X: XUID, Cross, Transform
//! - Y: Yield, YAML-like
//! - Z: Zero, Zone, Zenith
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use rune_format::rune::*;

#[test]
fn test_all_semantic_prefixes() {
    // Test all 26 single-letter semantic prefixes
    let prefixes = [
        ('A', "addr"),    // Address
        ('B', "basis"),   // Binary/Basis
        ('C', "cache"),   // Compute/Cache
        ('D', "data"),    // Data/Delta
        ('E', "entity"),  // Entity/Edge
        ('F', "func"),    // Function
        ('G', "geo"),     // Geometry
        ('H', "hash"),    // Hash
        ('I', "index"),   // Index
        ('J', "join"),    // Join
        ('K', "key"),     // Key
        ('L', "lattice"), // Lattice
        ('M', "mem"),     // Memory
        ('N', "node"),    // Node
        ('O', "obj"),     // Object
        ('P', "ptr"),     // Pointer
        ('Q', "quant"),   // Quantized
        ('R', "root"),    // Root
        ('S', "state"),   // State
        ('T', "tensor"),  // Tensor/Type
        ('U', "unit"),    // Unit
        ('V', "vector"),  // Vector
        ('W', "warp"),    // Warp
        ('X', "xuid"),    // XUID
        ('Y', "yield"),   // Yield
        ('Z', "zero"),    // Zero
    ];

    for (prefix, name) in prefixes {
        let input = format!("{}:{}", prefix, name);
        let stmts = parse_rune(&input).unwrap();

        assert_eq!(stmts.len(), 1, "Failed to parse {}", input);

        if let Stmt::Expr(expr) = &stmts[0] {
            if let Expr::Term(Term::SemanticIdent(sid)) = expr {
                assert_eq!(sid.prefix, prefix);
                assert_eq!(sid.name.0, name);

                // Verify display round-trip
                let displayed = format!("{}", expr);
                assert_eq!(displayed, input);
            } else {
                panic!("Expected semantic ident for {}", input);
            }
        } else {
            panic!("Expected expression statement for {}", input);
        }
    }
}

#[test]
fn test_semantic_in_expressions() {
    // Test semantic identifiers in real expressions
    let test_cases = vec![
        (
            "T:Gf8 -> vec := V:[1,2,3]",
            "Type flows to vector definition",
        ),
        ("R:continuum", "Root declaration style"),
        ("Q:e32l -> compressed", "Quantization mode"),
        ("X:session -> uid", "XUID anchor"),
        ("L:lattice / G:cell", "Lattice path to geometry cell"),
        ("T:Tensor := M:matrix", "Type defined as matrix"),
        ("A:pos -> V:velocity", "Address to vector flow"),
    ];

    for (input, description) in test_cases {
        let result = parse_rune(input);
        assert!(result.is_ok(), "Failed to parse {}: {}", description, input);

        let stmts = result.unwrap();
        assert!(
            !stmts.is_empty(),
            "No statements parsed for: {}",
            description
        );

        // Verify round-trip through display
        let displayed = format!("{}", stmts[0]);
        assert!(
            displayed.contains(':'),
            "Display should preserve semantic prefix: {}",
            description
        );
    }
}

#[test]
fn test_semantic_vs_regular_ident() {
    // Semantic identifier
    let semantic = "T:Gf8";
    let stmts = parse_rune(semantic).unwrap();
    if let Stmt::Expr(Expr::Term(Term::SemanticIdent(sid))) = &stmts[0] {
        assert_eq!(sid.prefix, 'T');
        assert_eq!(sid.name.0, "Gf8");
    } else {
        panic!("Expected semantic ident");
    }

    // Regular identifier (lowercase)
    let regular = "tensor";
    let stmts = parse_rune(regular).unwrap();
    if let Stmt::Expr(Expr::Term(Term::Ident(id))) = &stmts[0] {
        assert_eq!(id.0, "tensor");
    } else {
        panic!("Expected regular ident");
    }

    // Capital letter without colon is still a regular identifier
    let capital = "T";
    let stmts = parse_rune(capital).unwrap();
    if let Stmt::Expr(Expr::Term(Term::Ident(id))) = &stmts[0] {
        assert_eq!(id.0, "T");
    } else {
        panic!("Expected regular ident for bare capital");
    }
}

#[test]
fn test_semantic_with_namespace_operator() {
    // T::Gf8 uses :: operator, not semantic prefix
    let input = "T::Gf8";
    let stmts = parse_rune(input).unwrap();

    if let Stmt::Expr(Expr::Binary { op, left, right }) = &stmts[0] {
        assert_eq!(*op, RuneOp::Namespace);
        assert_eq!(format!("{}", left), "T");
        assert_eq!(format!("{}", right), "Gf8");
    } else {
        panic!("Expected namespace operator expression");
    }

    // T:Gf8 is semantic prefix (single colon)
    let input2 = "T:Gf8";
    let stmts2 = parse_rune(input2).unwrap();

    if let Stmt::Expr(Expr::Term(Term::SemanticIdent(sid))) = &stmts2[0] {
        assert_eq!(sid.prefix, 'T');
        assert_eq!(sid.name.0, "Gf8");
    } else {
        panic!("Expected semantic ident");
    }
}

#[test]
fn test_complex_semantic_expression() {
    let input = r#"
T:Gf8 -> V:vector := "[+1,-1,+1,-1,+1,-1,+1,-1]"
Q:e32l / L:lattice -> R:continuum
"#;

    let stmts = parse_rune(input).unwrap();
    assert_eq!(stmts.len(), 2);

    // First expression: T:Gf8 -> V:vector := "..."
    if let Stmt::Expr(expr) = &stmts[0] {
        let displayed = format!("{}", expr);
        assert!(displayed.contains("T:Gf8"));
        assert!(displayed.contains("V:vector"));
    }

    // Second expression: Q:e32l / L:lattice -> R:continuum
    if let Stmt::Expr(expr) = &stmts[1] {
        let displayed = format!("{}", expr);
        assert!(displayed.contains("Q:e32l"));
        assert!(displayed.contains("L:lattice"));
        assert!(displayed.contains("R:continuum"));
    }
}

#[test]
fn test_semantic_prefix_invalid() {
    // Lowercase prefix should not work as semantic
    let invalid = "t:tensor";
    let result = parse_rune(invalid);
    // This should parse as 't', then fail on unexpected ':'
    // Or parse as ident 't' and fail on leftover ':tensor'
    assert!(
        result.is_err() || {
            // If it parses, it should NOT be a semantic ident
            if let Ok(stmts) = result {
                !matches!(stmts[0], Stmt::Expr(Expr::Term(Term::SemanticIdent(_))))
            } else {
                true
            }
        }
    );
}

File: tests\token_benchmark.rs
==============================
/// Token counting benchmark to compare RUNE vs TOON vs JSON formats
///
/// This test calculates actual token counts using a simple tokenization approach
/// to demonstrate RUNE's efficiency with semantic prefixes and array literals.
use serde_json::json;

fn count_tokens(text: &str) -> usize {
    text.split_whitespace()
        .flat_map(|word| {
            // Split on punctuation and operators
            word.split(|c: char| {
                matches!(
                    c,
                    ',' | ':'
                        | '{'
                        | '}'
                        | '['
                        | ']'
                        | '('
                        | ')'
                        | '/'
                        | '\\'
                        | '|'
                        | '*'
                        | '+'
                        | '-'
                        | '='
                        | '>'
                        | '<'
                )
            })
            .filter(|s| !s.is_empty())
        })
        .count()
}

#[test]
fn test_rune_vs_toon_token_efficiency() {
    // Sample data: E8 continuum configuration
    let json_data = json!({
        "tensor_Gf8": 2.5,
        "vector_velocity": [1.0, 2.0, 3.0],
        "matrix_transform": [[1,0,0],[0,1,0],[0,0,1]],
        "layers": {
            "config": [
                {"id": 1, "type": "Lattice", "active": true},
                {"id": 2, "type": "Projection", "active": true},
                {"id": 3, "type": "Transform", "active": false}
            ]
        }
    });

    // JSON format (standard)
    let json_str = serde_json::to_string_pretty(&json_data).unwrap();
    let json_tokens = count_tokens(&json_str);
    let json_bytes = json_str.len();

    // JSON compact format
    let json_compact = serde_json::to_string(&json_data).unwrap();
    let json_compact_tokens = count_tokens(&json_compact);
    let json_compact_bytes = json_compact.len();

    // TOON format (traditional without semantic prefixes)
    let toon_str = r#"tensor_Gf8: 2.5
vector_velocity: [1.0, 2.0, 3.0]
matrix_transform: [[1,0,0],[0,1,0],[0,0,1]]
layers:
  config[3]{id, type, active}:
    1,Lattice,true
    2,Projection,true
    3,Transform,false"#;
    let toon_tokens = count_tokens(toon_str);
    let toon_bytes = toon_str.len();

    // RUNE format (with semantic prefixes)
    let rune_str = r#"T:Gf8: 2.5
V:velocity: [1.0, 2.0, 3.0]
M:transform: [[1,0,0],[0,1,0],[0,0,1]]
layers:
  config[3]{id, type, active}:
    1,Lattice,true
    2,Projection,true
    3,Transform,false"#;
    let rune_tokens = count_tokens(rune_str);
    let rune_bytes = rune_str.len();

    // Calculate savings
    let rune_token_savings = ((json_tokens - rune_tokens) as f64 / json_tokens as f64) * 100.0;
    let rune_byte_savings = ((json_bytes - rune_bytes) as f64 / json_bytes as f64) * 100.0;

    let toon_token_savings = ((json_tokens - toon_tokens) as f64 / json_tokens as f64) * 100.0;
    let toon_byte_savings = ((json_bytes - toon_bytes) as f64 / json_bytes as f64) * 100.0;

    println!("\n=== TOKEN BENCHMARK RESULTS ===");
    println!("\nJSON (pretty):");
    println!("  Tokens: {}", json_tokens);
    println!("  Bytes:  {}", json_bytes);

    println!("\nJSON (compact):");
    println!("  Tokens: {}", json_compact_tokens);
    println!("  Bytes:  {}", json_compact_bytes);

    println!("\nTOON:");
    println!(
        "  Tokens: {} ({:.1}% savings vs JSON)",
        toon_tokens, toon_token_savings
    );
    println!(
        "  Bytes:  {} ({:.1}% savings vs JSON)",
        toon_bytes, toon_byte_savings
    );

    println!("\nRUNE (with semantic prefixes):");
    println!(
        "  Tokens: {} ({:.1}% savings vs JSON)",
        rune_tokens, rune_token_savings
    );
    println!(
        "  Bytes:  {} ({:.1}% savings vs JSON)",
        rune_bytes, rune_byte_savings
    );

    println!("\nRUNE vs TOON:");
    println!(
        "  Token difference: {} tokens",
        rune_tokens as i32 - toon_tokens as i32
    );
    println!(
        "  Byte difference: {} bytes",
        rune_bytes as i32 - toon_bytes as i32
    );
    println!("  Semantic clarity: +{} semantic markers", 3); // T:, V:, M:

    // Verify RUNE maintains efficiency despite semantic additions
    // RUNE adds semantic clarity with minimal token overhead (~3 tokens for semantic prefixes)
    assert!(rune_token_savings > 0.0, "RUNE should save tokens vs JSON");
    assert!(
        rune_byte_savings > 60.0,
        "RUNE should save >60% bytes vs JSON"
    );

    // The semantic prefixes add ~3 tokens but provide explicit domain context
    let semantic_overhead = rune_tokens - toon_tokens;
    assert!(
        semantic_overhead <= 5,
        "Semantic prefixes should add minimal token overhead"
    );
}

#[test]
fn test_complex_rune_efficiency() {
    // More complex example with arrays and semantic operations
    let json_data = json!({
        "tensor_network": {
            "Gf8_primary": [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]],
            "velocities": [[0.5, 0.5, 0.5], [1.0, 1.0, 1.0], [1.5, 1.5, 1.5]],
            "metadata": {
                "dimensions": [3, 3],
                "timestamp": 1638835200,
                "layers": [
                    {"id": 1, "name": "input", "type": "vector"},
                    {"id": 2, "name": "hidden1", "type": "tensor"},
                    {"id": 3, "name": "hidden2", "type": "tensor"},
                    {"id": 4, "name": "hidden3", "type": "tensor"},
                    {"id": 5, "name": "output", "type": "scalar"}
                ]
            }
        }
    });

    let json_str = serde_json::to_string_pretty(&json_data).unwrap();
    let json_tokens = count_tokens(&json_str);
    let json_bytes = json_str.len();

    let rune_str = r#"T:Gf8_primary: [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]
V:velocities: [[0.5, 0.5, 0.5], [1.0, 1.0, 1.0], [1.5, 1.5, 1.5]]
metadata:
  dimensions: [3, 3]
  timestamp: 1638835200
  layers[5]{id, name, type}:
    1,input,vector
    2,hidden1,tensor
    3,hidden2,tensor
    4,hidden3,tensor
    5,output,scalar"#;

    let rune_tokens = count_tokens(rune_str);
    let rune_bytes = rune_str.len();

    let token_savings = ((json_tokens - rune_tokens) as f64 / json_tokens as f64) * 100.0;
    let byte_savings = ((json_bytes - rune_bytes) as f64 / json_bytes as f64) * 100.0;

    println!("\n=== COMPLEX STRUCTURE BENCHMARK ===");
    println!("\nJSON:");
    println!("  Tokens: {}", json_tokens);
    println!("  Bytes:  {}", json_bytes);

    println!("\nRUNE:");
    println!("  Tokens: {} ({:.1}% savings)", rune_tokens, token_savings);
    println!("  Bytes:  {} ({:.1}% savings)", rune_bytes, byte_savings);

    // RUNE's semantic prefixes add clarity with modest token overhead
    assert!(token_savings > 10.0, "Complex RUNE should save >10% tokens");
    assert!(byte_savings > 60.0, "Complex RUNE should save >60% bytes");
}

File: tests\unicode.rs
======================
use rune_format::{decode_default, encode_default};
use serde_json::{Value, json};

#[test]
fn test_unicode_strings() {
    let unicode = json!({
        "emoji": "😀🎉🦀",
        "chinese": "你好世界",
        "arabic": "مرحبا",
        "mixed": "Hello 世界 🌍"
    });

    let encoded = encode_default(&unicode).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();
    assert_eq!(unicode, decoded);
}

File: hydron-core\src\fisher.rs
===============================
/* src/fisher.rs */
//! Fisher Information Layer - Information Geometry
//!
//! Implements Fisher information geometry and statistical manifolds.
//! The Fisher information matrix measures the amount of information
//! that observable data carries about unknown parameters in a statistical model.
//!
//! Key operations:
//! - Fisher matrix computation from probability distributions
//! - Uncertainty quantification
//! - KL divergence for statistical distance
//! - Entropy calculations
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Fisher information layer for information geometry
pub struct FisherLayer;

impl FisherLayer {
    /// Compute Fisher information matrix from resonance distribution
    /// F_ij = E[∂log(p)/∂θ_i * ∂log(p)/∂θ_j]
    /// Simplified: uses variance as proxy
    pub fn fisher_matrix(resonance: &[u32; 240]) -> [[f32; 8]; 8] {
        let mut fisher = [[0.0f32; 8]; 8];

        // Normalize resonance to probability distribution
        let total: u32 = resonance.iter().sum();
        if total == 0 {
            return fisher; // Zero matrix if no resonance
        }

        let total_f = total as f32;
        let probs: Vec<f32> = resonance.iter().map(|&r| r as f32 / total_f).collect();

        // Compute Fisher matrix elements using simplified covariance
        // Map 240 roots to 8D coordinates and compute covariance
        for (i, row) in fisher.iter_mut().enumerate() {
            for (j, elem) in row.iter_mut().enumerate() {
                let mut sum = 0.0f32;

                // Use simplified mapping: each coordinate contributes to 30 roots
                let start = i * 30;
                let end = (start + 30).min(240);

                for p in probs.iter().take(end).skip(start).copied() {
                    if p > 1e-8 {
                        // Fisher information: 1/p (for single parameter)
                        sum += 1.0 / p;
                    }
                }

                *elem = if i == j { sum / 30.0 } else { 0.0 };
            }
        }

        fisher
    }

    /// Compute uncertainty from Fisher matrix
    /// Uncertainty = 1 / sqrt(trace(F))
    pub fn uncertainty(fisher_matrix: &[[f32; 8]; 8]) -> f32 {
        let trace: f32 = (0..8).map(|i| fisher_matrix[i][i]).sum();

        if trace < 1e-8 {
            return f32::INFINITY; // Maximum uncertainty
        }

        1.0 / trace.sqrt()
    }

    /// Compute Kullback-Leibler divergence: KL(P || Q) = Σ P(i) log(P(i)/Q(i))
    /// Measures statistical distance between distributions
    pub fn kl_divergence(p: &[f32], q: &[f32]) -> f32 {
        if p.len() != q.len() {
            return f32::INFINITY; // Invalid comparison
        }

        let mut kl = 0.0f32;

        for i in 0..p.len() {
            if p[i] > 1e-8 && q[i] > 1e-8 {
                kl += p[i] * (p[i] / q[i]).ln();
            }
        }

        kl.max(0.0) // KL divergence is non-negative
    }

    /// Compute information metric from Fisher matrix
    /// Metric = log(1 + trace(F))
    pub fn information_metric(fisher_matrix: &[[f32; 8]; 8]) -> f32 {
        let trace: f32 = (0..8).map(|i| fisher_matrix[i][i]).sum();
        (1.0 + trace).ln()
    }

    /// Compute entropy from distribution
    /// H = -Σ p_i log(p_i)
    pub fn entropy(distribution: &[f32]) -> f32 {
        let sum: f32 = distribution.iter().sum();

        if sum < 1e-8 {
            return 0.0;
        }

        let normalized: Vec<f32> = distribution.iter().map(|x| x / sum).collect();

        normalized
            .iter()
            .filter(|&&p| p > 1e-8)
            .map(|&p| -p * p.ln())
            .sum()
    }

    /// Compute Fisher information metric distance
    /// d_F(θ1, θ2)² ≈ (θ1 - θ2)ᵀ F (θ1 - θ2)
    pub fn fisher_distance(
        theta1: &[f32; 8],
        theta2: &[f32; 8],
        fisher_matrix: &[[f32; 8]; 8],
    ) -> f32 {
        let mut diff = [0.0f32; 8];
        for i in 0..8 {
            diff[i] = theta1[i] - theta2[i];
        }

        // Compute diff^T * F * diff
        let mut result = 0.0f32;
        for i in 0..8 {
            for j in 0..8 {
                result += diff[i] * fisher_matrix[i][j] * diff[j];
            }
        }

        result.sqrt().max(0.0)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fisher_matrix() {
        let mut resonance = [0u32; 240];
        // Create peaked distribution
        for i in 0..240 {
            resonance[i] = if i < 30 { 10 } else { 1 };
        }

        let fisher = FisherLayer::fisher_matrix(&resonance);

        // Fisher matrix should be diagonal and positive
        let trace: f32 = (0..8).map(|i| fisher[i][i]).sum();
        assert!(trace > 0.0, "Fisher matrix should have positive trace");
    }

    #[test]
    fn test_uncertainty() {
        let mut fisher = [[0.0f32; 8]; 8];
        for i in 0..8 {
            fisher[i][i] = 1.0;
        }

        let uncertainty = FisherLayer::uncertainty(&fisher);

        // Uncertainty should be 1/sqrt(8) ≈ 0.35
        assert!((uncertainty - 0.353).abs() < 0.01);
    }

    #[test]
    fn test_kl_divergence() {
        let p = [0.5, 0.5];
        let q = [0.5, 0.5];

        // KL(P || P) = 0
        let kl = FisherLayer::kl_divergence(&p, &q);
        assert!(kl.abs() < 1e-6);

        // Different distributions
        let q2 = [0.8, 0.2];
        let kl2 = FisherLayer::kl_divergence(&p, &q2);
        assert!(kl2 > 0.0);
    }

    #[test]
    fn test_information_metric() {
        let mut fisher = [[0.0f32; 8]; 8];
        for i in 0..8 {
            fisher[i][i] = 2.0;
        }

        let metric = FisherLayer::information_metric(&fisher);

        // metric = ln(1 + 8*2) = ln(17) ≈ 2.83
        assert!((metric - 2.833).abs() < 0.01);
    }

    #[test]
    fn test_entropy() {
        // Uniform distribution has maximum entropy
        let uniform = vec![0.25, 0.25, 0.25, 0.25];
        let h_uniform = FisherLayer::entropy(&uniform);

        // Peaked distribution has lower entropy
        let peaked = vec![0.8, 0.1, 0.05, 0.05];
        let h_peaked = FisherLayer::entropy(&peaked);

        assert!(h_uniform > h_peaked);
    }

    #[test]
    fn test_fisher_distance() {
        let theta1 = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let theta2 = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];

        let mut fisher = [[0.0f32; 8]; 8];
        for i in 0..8 {
            fisher[i][i] = 1.0;
        }

        let distance = FisherLayer::fisher_distance(&theta1, &theta2, &fisher);

        // Distance should be sqrt(2) ≈ 1.414
        assert!((distance - 1.414).abs() < 0.01);
    }
}

File: hydron-core\src\gf8.rs
============================
/* src/gf8.rs */
//! A foundational 8-dimensional geometric float gf8, inspired by E₈ lattice properties.
//!
//! # e8 Primitives – Gf8 Module
//!▫~•◦-----------------------------‣
//!
//! This module provides the `Gf8` type, a core numeric gf8 for the e8 ecosystem.
//! It is designed to replace standard floating-point numbers in contexts where geometric
//! stability, intrinsic normalization, and binary-addressable states are paramount.
//!
//! ### Key Capabilities
//! - **Geometric Representation:** `Gf8` represents a value as a normalized 8D vector on the unit sphere (S⁷).
//! - **Binary Encoding:** Provides a constructor from 8 bits that maps to a unique, stable direction in 8D space, enforcing an E₈-like even parity constraint.
//! - **Geometric Arithmetic:** All arithmetic operations (add, sub) are geometric, preserving the unit-norm constraint by re-projecting results onto the sphere.
//! - **Tensor-like API:** Implements `Deref` and a `Gf8Tensor` trait, allowing it to be used seamlessly as a small, fixed-size tensor.
//!
//! ### Architectural Notes
//! `Gf8` is the cornerstone of the e8 compute and data model. Its fixed dimensionality is a perfect
//! match for 256-bit SIMD registers (e.g., AVX), enabling highly efficient hardware acceleration.
//! It serves as the basis for E8B codes, E8DB keys, and the E8 LLM's numerical representation.
//!
//! ### Example
//! ```rust
//! use hydron_core::{Gf8, Gf8Tensor};
//!
//! // Create a Gf8 from a binary pattern (0b10101010)
//! let bits = [0, 1, 0, 1, 0, 1, 0, 1];
//! let a = Gf8::from_bits_even_parity(bits);
//!
//! // Create another Gf8 from a different pattern
//! let b = Gf8::from_scalar(-0.5);
//!
//! // Compute the dot product (cosine similarity)
//! let similarity = a.dot(b.coords());
//!
//! // `Gf8` can be treated like a slice
//! println!("Gf8 'a' has {} dimensions.", a.as_slice().len());
//! println!("Similarity between a and b: {}", similarity);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

#[cfg(feature = "fory")]
use fory::ForyObject;
#[cfg(feature = "serde")]
use serde::{Deserialize, Serialize};
use std::ops::{Add, AddAssign, Deref, DerefMut, Mul, MulAssign, Neg, Sub, SubAssign};
use std::sync::OnceLock;

use crate::{
    fisher::FisherLayer,
    hyperbolic::HyperbolicLayer,
    lorentzian::{LorentzianLayer, SpacetimePoint},
    quaternion::QuaternionOps,
    spherical::SphericalLayer,
    symplectic::SymplecticLayer,
};

/// A tiny tensor-like trait for GF8.
///
/// This provides an explicit contract for types that can be viewed as a slice of floats,
/// intended for use in generic, tensor-aware code.
pub trait Gf8Tensor {
    /// Returns the underlying data as an immutable slice.
    fn as_slice(&self) -> &[f32];
    /// Returns the underlying data as a mutable slice.
    fn as_mut_slice(&mut self) -> &mut [f32];
}

/// A GF8 (GeoFloat8), an 8-dimensional geometric float gf8.
///
/// It is internally represented by an array of 8 `f32`s, which is always
/// normalized to have a unit L2 norm (i.e., it lies on the surface of an
/// 8D hypersphere). This property provides intrinsic stability and makes it suitable
/// for representing directions, rotations, and normalized semantic states.
///
/// The only exception to the unit-norm rule is the zero vector, which has a norm of 0.
#[derive(Clone, Copy, Debug, PartialEq)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub struct Gf8 {
    coords: [f32; 8],
}

impl Gf8 {
    /// The zero vector, representing a neutral or null state.
    pub const ZERO: Self = Self { coords: [0.0; 8] };

    /// Constructs a `Gf8` from raw 8D coordinates, normalizing them to unit length.
    ///
    /// If the input vector has a magnitude of zero, the zero `Gf8` is returned.
    #[inline]
    pub fn new(coords: [f32; 8]) -> Self {
        let mut v = Self { coords };
        v.renormalize();
        v
    }

    /// Constructs a `Gf8` from raw 8D coordinates.
    ///
    /// This is an alias for [`Gf8::new`], provided for clarity when working in
    /// math-heavy code where "from_coords" more clearly expresses intent than "new".
    #[inline]
    pub fn from_coords(coords: [f32; 8]) -> Self {
        Self::new(coords)
    }

    /// Constructs a `Gf8` from 8 bits, mapping them to an E₈-like ±1 pattern.
    ///
    /// The mapping is `0 -> +1.0` and `1 -> -1.0`. To satisfy an E₈-like constraint,
    /// the number of `-1.0` entries is forced to be even by flipping the sign of
    /// the last coordinate if necessary. The resulting vector is then normalized
    /// to unit length.
    pub fn from_bits_even_parity(bits: [u8; 8]) -> Self {
        let mut coords = [0.0f32; 8];
        let mut neg_count = 0usize;

        for (i, &b) in bits.iter().enumerate() {
            if b == 0 {
                coords[i] = 1.0;
            } else {
                coords[i] = -1.0;
                neg_count += 1;
            }
        }

        if neg_count % 2 == 1 {
            // Flip the sign of the last coordinate to enforce even parity.
            coords[7] = -coords[7];
        }

        // Normalize the resulting vector to place it on the unit sphere.
        // A pure ±1 vector has a norm of sqrt(8).
        Self::new(coords)
    }

    /// Constructs a `Gf8` by embedding a scalar along the first axis.
    ///
    /// The resulting `Gf8` will be `[signum(x), 0.0, ..., 0.0]`. This provides a simple
    /// way to represent scalar magnitudes directionally.
    pub fn from_scalar(x: f32) -> Self {
        let mut coords = [0.0; 8];
        coords[0] = x;
        Self::new(coords)
    }

    /// Retrieves the raw coordinate data as a slice.
    #[inline]
    pub fn coords(&self) -> &[f32; 8] {
        &self.coords
    }

    /// Approximates a scalar value by projecting the `Gf8` onto the first axis.
    ///
    /// Since `Gf8` is a unit vector, this value will be in the range `[-1.0, 1.0]`.
    #[inline]
    pub fn to_scalar(&self) -> f32 {
        self.coords[0]
    }

    /// Computes the dot product with another 8D vector.
    ///
    /// For two unit vectors, this is equivalent to their cosine similarity.
    /// This method is backed by a runtime-dispatching SIMD implementation
    /// for maximum performance.
    #[inline(always)]
    pub fn dot(&self, other: &[f32; 8]) -> f32 {
        #[cfg(feature = "simd")]
        {
            self::simd::dot_product(self.coords, *other)
        }
        #[cfg(not(feature = "simd"))]
        {
            self.coords
                .iter()
                .zip(other.iter())
                .map(|(&a, &b)| a * b)
                .sum()
        }
    }

    /// Computes the squared L2 norm. For a valid `Gf8`, this is always `1.0` (or `0.0` for zero).
    #[inline]
    pub fn norm2(&self) -> f32 {
        #[cfg(feature = "simd")]
        {
            self::simd::norm2_scalar(&self.coords)
        }
        #[cfg(not(feature = "simd"))]
        {
            self.coords.iter().map(|x| x * x).sum::<f32>()
        }
    }

    /// Computes the L2 norm. For a valid `Gf8`, this is always `1.0` (or `0.0` for zero).
    #[inline]
    pub fn norm(&self) -> f32 {
        self.norm2().sqrt()
    }

    /// Re-normalizes the `Gf8` in-place to ensure it remains a unit vector.
    /// This is useful after performing arithmetic operations that may alter the magnitude.
    pub fn renormalize(&mut self) {
        let n2 = self.norm2();
        if n2 > 0.0 {
            let inv_norm = 1.0 / n2.sqrt();
            for x in &mut self.coords {
                *x *= inv_norm;
            }
        }
    }

    /// Resonance profile against the 240 E8 roots (dot products).
    pub fn resonance_profile(&self) -> Vec<f32> {
        let roots = e8_roots();
        roots.iter().map(|r| self.dot(r)).collect()
    }

    /// Quantize this vector to the nearest E8 root (argmax dot).
    pub fn quantize(&self) -> (u8, Gf8) {
        let roots = e8_roots();
        let mut best_dot = f32::NEG_INFINITY;
        let mut best_idx = 0usize;
        for (i, r) in roots.iter().enumerate() {
            let d = self.dot(r);
            if d > best_dot {
                best_dot = d;
                best_idx = i;
            }
        }
        (best_idx as u8, Gf8::new(roots[best_idx]))
    }

    /// Quantize to the nearest E8 root constrained by an allow-list.
    /// Returns (root index, root vector, cosine similarity).
    pub fn quantize_subset(&self, allowed_roots: &[u8]) -> (u8, Gf8, f32) {
        let roots = e8_roots();
        let mut best_dot = f32::NEG_INFINITY;
        let mut best_idx = 0u8;
        for &idx in allowed_roots {
            let i = idx as usize;
            if i >= roots.len() {
                continue;
            }
            let r = roots[i];
            let d = self.dot(&r);
            if d > best_dot {
                best_dot = d;
                best_idx = idx;
            }
        }
        let vec = roots[best_idx as usize];
        (best_idx, Gf8::new(vec), best_dot)
    }

    // --- Geometry Operations ---

    /// Spherical geometry: computes geodesic distance to another Gf8 (unit sphere).
    pub fn spherical_distance_to(&self, other: &Self) -> f32 {
        SphericalLayer::distance(self.coords(), other.coords())
    }

    /// Spherical geometry: spherical linear interpolation between two Gf8 values.
    pub fn spherical_slerp(&self, other: &Self, t: f32) -> Self {
        Self::new(SphericalLayer::slerp(self.coords(), other.coords(), t))
    }

    /// Spherical geometry: computes the antipodal (opposite) point on the sphere.
    pub fn spherical_antipodal(&self) -> Self {
        Self {
            coords: SphericalLayer::antipodal(self.coords()),
        }
    }

    /// Hyperbolic geometry: computes distance in the Poincaré ball model.
    /// Since Gf8 coords are on the unit sphere, we map them to the interior ball first.
    pub fn hyperbolic_distance_to(&self, other: &Self) -> f32 {
        // Map sphere coords to ball interior by scaling down
        let self_ball = self.coords.map(|x| x * 0.95);
        let other_ball = other.coords.map(|x| x * 0.95);
        HyperbolicLayer::distance(&self_ball, &other_ball)
    }

    /// Hyperbolic geometry: Möbius addition in Poincaré ball.
    pub fn hyperbolic_mobius_add(&self, other: &Self) -> Self {
        let self_ball = self.coords.map(|x| x * 0.95);
        let other_ball = other.coords.map(|x| x * 0.95);
        let result_ball = HyperbolicLayer::mobius_add(&self_ball, &other_ball);
        // Map back to sphere? Or return as ball coords?
        Self::new(result_ball)
    }

    /// Fisher information geometry: distance with Fisher information matrix.
    pub fn fisher_distance_to(&self, other: &Self, fisher_matrix: &[[f32; 8]; 8]) -> f32 {
        FisherLayer::fisher_distance(self.coords(), other.coords(), fisher_matrix)
    }

    /// Fisher information: uncertainty from Fisher matrix.
    pub fn fisher_uncertainty(fisher_matrix: &[[f32; 8]; 8]) -> f32 {
        FisherLayer::uncertainty(fisher_matrix)
    }

    /// Quaternion operations: convert Gf8 to quaternion.
    pub fn to_quaternion(&self) -> [f32; 4] {
        QuaternionOps::from_e8_spinor(self.coords())
    }

    /// Lorentzian geometry: check if other point is in past light cone.
    pub fn lorentzian_in_past_light_cone(&self, other: &Self) -> bool {
        let p1_coords: [f64; 8] = self.coords.map(|x| x as f64);
        let p2_coords: [f64; 8] = other.coords.map(|x| x as f64);
        let p1 = SpacetimePoint::new(p1_coords);
        let p2 = SpacetimePoint::new(p2_coords);

        // Create a temporary LorentzianLayer to check causality
        let layer = LorentzianLayer::new();
        layer.in_past_light_cone(&p1, &p2)
    }

    /// Symplectic geometry: compute Hamiltonian treating Gf8 as position, momentum as zero.
    pub fn symplectic_hamiltonian(&self) -> f32 {
        let zero_momentum = [0.0f32; 8];
        SymplecticLayer::new().hamiltonian(self.coords(), &zero_momentum)
    }
}

impl Gf8 {
    // --- Associated Geometry Functions ---

    /// Spherical geometry: compute Fréchet mean of multiple Gf8 values.
    pub fn spherical_mean(points: &[Self]) -> Self {
        let coords: Vec<[f32; 8]> = points.iter().map(|p| *p.coords()).collect();
        let mean_coords = SphericalLayer::mean(&coords);
        Self::new(mean_coords)
    }

    /// Fisher information: compute Fisher matrix from resonance data.
    pub fn fisher_matrix_from_resonance(resonance: &[u32; 240]) -> [[f32; 8]; 8] {
        FisherLayer::fisher_matrix(resonance)
    }

    /// Quaternion: SLERP between two quaternions derived from Gf8 values.
    pub fn quaternion_slerp_from_gf8(a: &Self, b: &Self, t: f32) -> Self {
        let qa = a.to_quaternion();
        let qb = b.to_quaternion();
        let slerped = QuaternionOps::slerp(&qa, &qb, t);
        // Map quaternion back to Gf8 somehow - this is a bit hacky
        // Use the first 4 quaternion components as coords, pad with 0s, normalize
        let mut coords = [0.0f32; 8];
        coords[0..4].copy_from_slice(&slerped);
        Self::new(coords)
    }
}

impl Gf8Tensor for Gf8 {
    #[inline]
    fn as_slice(&self) -> &[f32] {
        &self.coords
    }
    #[inline]
    fn as_mut_slice(&mut self) -> &mut [f32] {
        &mut self.coords
    }
}

#[cfg(not(feature = "fory"))]
impl Default for Gf8 {
    /// The default `Gf8` is the zero vector.
    fn default() -> Self {
        Self::ZERO
    }
}

impl Deref for Gf8 {
    type Target = [f32; 8];
    #[inline]
    fn deref(&self) -> &Self::Target {
        &self.coords
    }
}

impl DerefMut for Gf8 {
    #[inline]
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.coords
    }
}

/// Geometric addition: performs element-wise vector addition and then
/// re-normalizes the result, projecting it back onto the unit sphere.
impl Add for Gf8 {
    type Output = Self;
    fn add(self, rhs: Self) -> Self::Output {
        let mut coords = [0.0f32; 8];
        for (i, (&a, &b)) in self.coords.iter().zip(rhs.coords.iter()).enumerate() {
            coords[i] = a + b;
        }
        Self::new(coords)
    }
}

impl AddAssign for Gf8 {
    fn add_assign(&mut self, rhs: Self) {
        for (i, &v) in rhs.coords.iter().enumerate() {
            self.coords[i] += v;
        }
        self.renormalize();
    }
}

/// Geometric subtraction: performs element-wise vector subtraction and then
/// re-normalizes the result, projecting it back onto the unit sphere.
impl Sub for Gf8 {
    type Output = Self;
    fn sub(self, rhs: Self) -> Self::Output {
        let mut coords = [0.0f32; 8];
        for (i, (&a, &b)) in self.coords.iter().zip(rhs.coords.iter()).enumerate() {
            coords[i] = a - b;
        }
        Self::new(coords)
    }
}

impl SubAssign for Gf8 {
    fn sub_assign(&mut self, rhs: Self) {
        for (i, &v) in rhs.coords.iter().enumerate() {
            self.coords[i] -= v;
        }
        self.renormalize();
    }
}

/// Scalar multiplication. The result is re-normalized, so this operation primarily
/// affects the vector's direction (flipping it if the scalar is negative).
impl Mul<f32> for Gf8 {
    type Output = Self;
    fn mul(self, rhs: f32) -> Self::Output {
        let mut coords = self.coords;
        for x in &mut coords {
            *x *= rhs;
        }
        Self::new(coords)
    }
}

impl MulAssign<f32> for Gf8 {
    fn mul_assign(&mut self, rhs: f32) {
        for x in &mut self.coords {
            *x *= rhs;
        }
        self.renormalize();
    }
}

/// Negation: flips the direction of the vector. The norm remains unchanged.
impl Neg for Gf8 {
    type Output = Self;
    fn neg(self) -> Self::Output {
        let mut coords = self.coords;
        for x in &mut coords {
            *x = -*x;
        }
        Self { coords }
    }
}

/// Embedded SIMD module
#[cfg(feature = "simd")]
mod simd {
    use crate::intrinsics::intrinsics_for_f32_width;

    // Gate architecture-specific modules.
    #[cfg(target_arch = "x86_64")]
    use std::arch::x86_64::*;

    #[cfg(target_arch = "aarch64")]
    use core::arch::aarch64::*;

    /// Prints a summary of available SIMD capabilities for debugging.
    #[allow(dead_code)]
    pub fn print_simd_capabilities() {
        println!("--- SIMD Capabilities ---");
        #[cfg(target_arch = "x86_64")]
        {
            println!("Architecture: x86_64");
            println!("AVX enabled: {}", is_x86_feature_detected!("avx"));
            println!("AVX2 enabled: {}", is_x86_feature_detected!("avx2"));
            println!("FMA enabled: {}", is_x86_feature_detected!("fma"));
        }
        #[cfg(target_arch = "aarch64")]
        {
            println!("Architecture: aarch64");
            println!("NEON enabled: {}", is_aarch64_feature_detected!("neon"));
        }
        #[cfg(not(any(target_arch = "x86_64", target_arch = "aarch64")))]
        {
            println!("Architecture: Not x86_64 or aarch64. Scalar fallback only.");
        }
        println!("-------------------------");
    }

    /// Returns a list of available 256-bit f32 intrinsic names for analysis.
    #[allow(dead_code)]
    pub fn get_available_f32_256_intrinsics() -> Vec<&'static str> {
        #[cfg(target_arch = "x86_64")]
        {
            return intrinsics_for_f32_width(256)
                .filter(|i| {
                    let tech = i.technology;
                    (tech.contains("AVX2") && is_x86_feature_detected!("avx2"))
                        || (tech.contains("AVX") && is_x86_feature_detected!("avx"))
                        || (tech.contains("FMA") && is_x86_feature_detected!("fma"))
                })
                .map(|i| i.name)
                .collect();
        }
        // Return an empty vector for non-x86 architectures.
        #[cfg(not(target_arch = "x86_64"))]
        {
            Vec::new()
        }
    }

    /// Performs SIMD-accelerated addition of two raw f32 arrays.
    #[cfg(feature = "simd")]
    #[inline]
    pub fn gf8_add_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("avx") {
                unsafe {
                    let va = _mm256_loadu_ps(a.as_ptr());
                    let vb = _mm256_loadu_ps(b.as_ptr());
                    let sum = _mm256_add_ps(va, vb);

                    let mut result = [0.0f32; 8];
                    _mm256_storeu_ps(result.as_mut_ptr(), sum);
                    return result;
                }
            }
        }
        // Fallback
        let mut result = [0.0f32; 8];
        for i in 0..8 {
            result[i] = a[i] + b[i];
        }
        result
    }

    /// Performs SIMD-accelerated subtraction of two raw f32 arrays.
    #[cfg(feature = "simd")]
    #[inline]
    pub fn gf8_sub_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("avx") {
                unsafe {
                    let va = _mm256_loadu_ps(a.as_ptr());
                    let vb = _mm256_loadu_ps(b.as_ptr());
                    let diff = _mm256_sub_ps(va, vb);

                    let mut result = [0.0f32; 8];
                    _mm256_storeu_ps(result.as_mut_ptr(), diff);
                    return result;
                }
            }
        }
        // Fallback
        let mut result = [0.0f32; 8];
        for i in 0..8 {
            result[i] = a[i] - b[i];
        }
        result
    }

    /// Computes the dot product of two raw f32 arrays using SIMD.
    #[cfg(feature = "simd")]
    #[inline]
    pub fn gf8_dot_simd(a: &[f32; 8], b: &[f32; 8]) -> f32 {
        dot_product(*a, *b)
    }

    /// Computes the squared L2 norm of a raw f32 array using SIMD.
    #[cfg(feature = "simd")]
    #[inline]
    pub fn gf8_norm2_simd(a: &[f32; 8]) -> f32 {
        dot_product(*a, *a)
    }

    /// Performs SIMD-accelerated in-place addition for raw f32 arrays: `dst[i] += src[i]`.
    #[cfg(feature = "simd")]
    #[inline]
    pub fn gf8_add_inplace_slice_simd(dst: &mut [f32; 8], src: &[f32; 8]) {
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("avx") {
                unsafe {
                    let vdst = _mm256_loadu_ps(dst.as_ptr());
                    let vsrc = _mm256_loadu_ps(src.as_ptr());
                    let sum = _mm256_add_ps(vdst, vsrc);
                    _mm256_storeu_ps(dst.as_mut_ptr(), sum);
                }
                return;
            }
        }
        // Fallback to scalar
        for i in 0..8 {
            dst[i] += src[i];
        }
    }

    /// SIMD-accelerated matrix-vector multiplication for raw arrays.
    #[cfg(feature = "simd")]
    pub fn gf8_matvec_simd(mat: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8] {
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("avx") {
                unsafe {
                    return matvec_simd_avx(mat, vec);
                }
            }
        }
        // Fallback to using dot product
        let mut result = [0.0f32; 8];
        for (i, row) in mat.iter().enumerate() {
            result[i] = dot_product(*row, *vec);
        }
        result
    }

    // --- Private Implementation Details ---

    /// The primary, runtime-dispatching dot product implementation.
    ///
    /// This function is the single source of truth for dot products. It checks for CPU
    /// features at runtime and calls the most optimal available kernel.
    #[inline]
    pub fn dot_product(a: [f32; 8], b: [f32; 8]) -> f32 {
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("fma") {
                // FMA is fastest on modern CPUs that support it (implies AVX/AVX2).
                return unsafe { dot_product_fma(a, b) };
            }
            if is_x86_feature_detected!("avx") {
                return unsafe { dot_product_avx(a, b) };
            }
        }

        #[cfg(target_arch = "aarch64")]
        {
            if is_aarch64_feature_detected!("neon") {
                return unsafe { dot_product_neon(a, b) };
            }
        }

        // Scalar fallback for all other cases.
        dot_product_scalar(a, b)
    }

    /// Scalar dot product implementation (fallback).
    #[inline]
    fn dot_product_scalar(a: [f32; 8], b: [f32; 8]) -> f32 {
        let mut sum = 0.0;
        for i in 0..8 {
            sum += a[i] * b[i];
        }
        sum
    }

    /// NEON implementation for dot product on aarch64.
    #[cfg(target_arch = "aarch64")]
    #[target_feature(enable = "neon")]
    #[inline]
    unsafe fn dot_product_neon(a: [f32; 8], b: [f32; 8]) -> f32 {
        let a1 = vld1q_f32(a.as_ptr());
        let a2 = vld1q_f32(a.as_ptr().add(4));
        let b1 = vld1q_f32(b.as_ptr());
        let b2 = vld1q_f32(b.as_ptr().add(4));
        let acc1 = vmulq_f32(a1, b1);
        let acc2 = vmulq_f32(a2, b2);
        let sum = vaddq_f32(acc1, acc2);
        vaddvq_f32(sum)
    }

    /// AVX implementation for dot product on x86_64.
    #[cfg(target_arch = "x86_64")]
    #[target_feature(enable = "avx")]
    #[inline]
    unsafe fn dot_product_avx(a: [f32; 8], b: [f32; 8]) -> f32 {
        unsafe {
            let va = _mm256_loadu_ps(a.as_ptr());
            let vb = _mm256_loadu_ps(b.as_ptr());
            // Use the `_mm256_dp_ps` intrinsic for a combined dot product.
            // The 0xf1 mask means: multiply lanes 0-3, sum them, and place in lane 0;
            // multiply lanes 4-7, sum them, and place in lane 4.
            let prod = _mm256_dp_ps(va, vb, 0xf1);
            let lo = _mm256_castps256_ps128(prod); // Low 128 bits
            let hi = _mm256_extractf128_ps(prod, 1); // High 128 bits
            let sum = _mm_add_ss(lo, hi); // Add the two sums
            _mm_cvtss_f32(sum)
        }
    }

    /// AVX+FMA implementation for dot product on x86_64.
    #[cfg(target_arch = "x86_64")]
    #[target_feature(enable = "fma")]
    #[inline]
    unsafe fn dot_product_fma(a: [f32; 8], b: [f32; 8]) -> f32 {
        unsafe {
            let va = _mm256_loadu_ps(a.as_ptr());
            let vb = _mm256_loadu_ps(b.as_ptr());
            // This is identical to the AVX version but allows the compiler to use FMA.
            // The `_mm256_dp_ps` is often the most efficient way to do this.
            let prod = _mm256_dp_ps(va, vb, 0xf1);
            let lo = _mm256_castps256_ps128(prod);
            let hi = _mm256_extractf128_ps(prod, 1);
            let sum = _mm_add_ss(lo, hi);
            _mm_cvtss_f32(sum)
        }
    }

    /// Scalar norm2 implementation for small arrays where SIMD overhead is not worth it.
    #[inline]
    pub fn norm2_scalar(a: &[f32; 8]) -> f32 {
        a.iter().map(|x| x * x).sum()
    }

    /// AVX implementation for matrix-vector multiplication.
    #[cfg(target_arch = "x86_64")]
    #[target_feature(enable = "avx")]
    #[inline]
    #[allow(dead_code)]
    unsafe fn matvec_simd_avx(mat: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8] {
        let mut result = [0.0f32; 8];
        let vec_simd = unsafe { _mm256_loadu_ps(vec.as_ptr()) };

        // Process each row
        for i in 0..8 {
            let row = &mat[i];
            let vrow = unsafe { _mm256_loadu_ps(row.as_ptr()) };
            let prod = _mm256_dp_ps(vrow, vec_simd, 0xf1); // Dot product with mask 0xf1
            let lo = _mm256_castps256_ps128(prod);
            let hi = _mm256_extractf128_ps(prod, 1);
            let sum = _mm_add_ss(lo, hi);
            result[i] = _mm_cvtss_f32(sum);
        }

        result
    }
}

// Re-export SIMD functions when feature is enabled
#[cfg(feature = "simd")]
pub use simd::{
    get_available_f32_256_intrinsics, gf8_add_inplace_slice_simd, gf8_add_simd, gf8_dot_simd,
    gf8_matvec_simd, gf8_norm2_simd, gf8_sub_simd, print_simd_capabilities,
};

/// Generate and cache the 240 E8 roots (normalized).
fn e8_roots() -> &'static [[f32; 8]; 240] {
    static ROOTS: OnceLock<[[f32; 8]; 240]> = OnceLock::new();
    ROOTS.get_or_init(build_e8_roots)
}

fn build_e8_roots() -> [[f32; 8]; 240] {
    let mut roots = [[0.0f32; 8]; 240];
    let mut idx = 0usize;

    // Type 1 roots: permutations of (±1, ±1, 0, ..., 0) / sqrt(2)
    let inv_sqrt2 = 0.70710677f32; // 1/sqrt(2)
    for i in 0..8 {
        for j in (i + 1)..8 {
            for &si in &[-1.0f32, 1.0] {
                for &sj in &[-1.0f32, 1.0] {
                    let mut v = [0.0f32; 8];
                    v[i] = si * inv_sqrt2;
                    v[j] = sj * inv_sqrt2;
                    roots[idx] = v;
                    idx += 1;
                }
            }
        }
    }

    // Type 2 roots: (±1/2, ..., ±1/2) with even number of negatives
    for bits in 0u16..256 {
        if bits.count_ones() % 2 == 1 {
            continue;
        }
        let mut v = [0.0f32; 8];
        for k in 0..8 {
            let sign = if (bits >> k) & 1 == 1 {
                -0.5f32
            } else {
                0.5f32
            };
            v[k] = sign;
        }
        roots[idx] = v;
        idx += 1;
    }

    debug_assert_eq!(idx, 240);
    roots
}

/// Public accessor for the E8 root table.
pub fn get_e8_roots() -> &'static [[f32; 8]; 240] {
    e8_roots()
}

File: hydron-core\src\intrinsics.rs
===================================
/* src/intrinsics.rs */
//! A queryable registry of x86 SIMD intrinsics for backend code generation.
//!
//! # e8 Primitives – Gf8 Intrinsics Module
//!▫~•◦-----------------------------------------‣
//!
//! This module contains a comprehensive, static list of x86 intrinsics, auto-generated
//! from external documentation. It is designed to be used by the `simd` backend
//! and future procedural code generators to reason about available hardware instructions.
//!
//! ### Key Capabilities
//! - **Static Registry:** Provides `GF8_INTRINSICS`, a constant slice of `Gf8Intrinsic` structs.
//! - **Queryable API:** Offers helper functions to filter and find intrinsics by name, technology, or SIMD width.
//! - **Metadata Rich:** Each entry includes the intrinsic's name, required technology (e.g., AVX2), header, and C prototype.
//!
//! ### Architectural Notes
//! This module acts as a "database" for the compiler backend. Instead of hard-coding
//! intrinsic names, higher-level modules can query this registry to make dynamic
//! decisions about which instructions to use, enabling more flexible and future-proof
//! code generation.
//!
//! ### Example
//! ```rust
//! // This example assumes this module is part of the e8_gf8 crate.
//! // use e8_gf8::intrinsics::{find_intrinsic_by_name, intrinsics_for_f32_width};
//!
//! // fn main() {
//!     // Find a specific intrinsic by name
//!     // if let Some(intrinsic) = find_intrinsic_by_name("_mm256_add_ps") {
//!     //     println!("Found AVX add for f32: {}", intrinsic.prototype);
//!     // }
//!
//!     // Find all 256-bit f32 intrinsics
//!     // let avx_f32_intrinsics = intrinsics_for_f32_width(256).count();
//!     // println!("There are {} relevant 256-bit f32 intrinsics.", avx_f32_intrinsics);
//! // }
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Represents the metadata for a single x86 hardware intrinsic.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct Gf8Intrinsic {
    /// The C/C++ name of the intrinsic function (e.g., `_mm256_add_ps`).
    pub name: &'static str,
    /// The required CPU feature flag or technology (e.g., "AVX2", "SSE4.1").
    pub technology: &'static str,
    /// The C header file where the intrinsic is typically defined (e.g., "immintrin.h").
    pub header: &'static str,
    /// The C function prototype for the intrinsic.
    pub prototype: &'static str,
}

impl Gf8Intrinsic {
    /// Returns `true` if this intrinsic's prototype suggests it operates on `f32` vectors.
    pub fn is_f32_vector(&self) -> bool {
        self.prototype.contains("__m128")
            || self.prototype.contains("__m256")
            || self.prototype.contains("__m512")
            || self.prototype.contains("ps") // Packed Single
    }

    /// Returns `true` if this intrinsic's prototype suggests it operates on `f64` vectors.
    pub fn is_f64_vector(&self) -> bool {
        self.prototype.contains("__m128d")
            || self.prototype.contains("__m256d")
            || self.prototype.contains("__m512d")
            || self.prototype.contains("pd") // Packed Double
    }

    /// Returns the SIMD vector width in bits, if it can be inferred from the prototype.
    pub fn simd_width_bits(&self) -> Option<u32> {
        if self.prototype.contains("__m512") {
            Some(512)
        } else if self.prototype.contains("__m256") {
            Some(256)
        } else if self.prototype.contains("__m128") {
            Some(128)
        } else if self.prototype.contains("__m64") {
            Some(64)
        } else {
            None
        }
    }
}

/// A static, compile-time registry of all known x86 intrinsics from the source file.
pub const GF8_INTRINSICS: &[Gf8Intrinsic] = &[
    Gf8Intrinsic {
        name: "_m_from_float",
        technology: "3DNOW",
        header: "intrin.h",
        prototype: "__m64 _m_from_float(float);",
    },
    Gf8Intrinsic {
        name: "_m_from_int",
        technology: "MMX",
        header: "intrin.h",
        prototype: "__m64 _m_from_int(int);",
    },
    Gf8Intrinsic {
        name: "_m_maskmovq",
        technology: "SSE",
        header: "intrin.h",
        prototype: "void _m_maskmovq(__m64, __m64, char*);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi16",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi16(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi32",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi32(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_abs_epi8",
        technology: "SSSE3",
        header: "intrin.h",
        prototype: "__m128i _mm_abs_epi8(__m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi32",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi32(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi64",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi64(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_add_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_add_pd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_add_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_add_ps",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_add_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_add_sd",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128d _mm_add_sd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_add_ss",
        technology: "SSE",
        header: "intrin.h",
        prototype: "__m128 _mm_add_ss(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epi16",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epi16(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_adds_epi8",
        technology: "SSE2",
        header: "intrin.h",
        prototype: "__m128i _mm_adds_epi8(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm_addsub_pd",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128d _mm_addsub_pd(__m128d, __m128d);",
    },
    Gf8Intrinsic {
        name: "_mm_addsub_ps",
        technology: "SSE3",
        header: "intrin.h",
        prototype: "__m128 _mm_addsub_ps(__m128, __m128);",
    },
    Gf8Intrinsic {
        name: "_mm_aesdec_si128",
        technology: "AESNI",
        header: "immintrin.h",
        prototype: "__m128i _mm_aesdec_si128(__m128i, __m128i);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_pd",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256d _mm256_add_pd(__m256d, __m256d);",
    },
    Gf8Intrinsic {
        name: "_mm256_add_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_add_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_sub_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_sub_ps(__m256, __m256);",
    },
    Gf8Intrinsic {
        name: "_mm256_dp_ps",
        technology: "AVX",
        header: "immintrin.h",
        prototype: "__m256 _mm256_dp_ps(__m256, __m256, const int);",
    },
    // Add only essential AVX intrinsics for gf8
];

/// Look up an intrinsic by exact name (e.g. "_mm256_add_ps").
pub fn find_intrinsic_by_name(name: &str) -> Option<&'static Gf8Intrinsic> {
    GF8_INTRINSICS.iter().find(|i| i.name == name)
}

/// All intrinsics for a given technology (e.g. "AVX2", "AVX-512F").
pub fn intrinsics_by_technology(tech: &str) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS.iter().filter(move |i| i.technology == tech)
}

/// All intrinsics that look like f32 SIMD of a particular width (128/256/512).
pub fn intrinsics_for_f32_width(width_bits: u32) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS
        .iter()
        .filter(move |i| i.is_f32_vector() && i.simd_width_bits() == Some(width_bits))
}

/// All intrinsics that look like f64 SIMD of a particular width (128/256/512).
pub fn intrinsics_for_f64_width(width_bits: u32) -> impl Iterator<Item = &'static Gf8Intrinsic> {
    GF8_INTRINSICS
        .iter()
        .filter(move |i| i.is_f64_vector() && i.simd_width_bits() == Some(width_bits))
}

File: hydron-core\src\hyperbolic.rs
===================================
/* src/hyperbolic.rs */
//! Hyperbolic H8 Geometry Layer - Poincaré Ball Model
//!
//! Implements hyperbolic geometry in 8 dimensions using the Poincaré ball model.
//! Points lie inside the unit ball with hyperbolic distance metric.
//!
//! Key operations:
//! - Projection to Poincaré ball interior
//! - Hyperbolic distance using arcosh formula
//! - Möbius addition for hyperbolic translation
//! - Geodesic interpolation
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Hyperbolic H8 layer using Poincaré ball model
pub struct HyperbolicLayer;

impl HyperbolicLayer {
    /// Project an E8 coordinate into the Poincaré ball interior
    /// Ensures ||x|| < 1 by normalization
    pub fn project(coords: &[f32; 8]) -> [f32; 8] {
        #[cfg(feature = "simd")]
        {
            use super::gf8::gf8_norm2_simd;
            let norm_sq = gf8_norm2_simd(coords);

            if norm_sq < 1e-8 {
                return [0.0; 8]; // Origin
            }

            let norm = norm_sq.sqrt();

            // Scale to fit in ball with margin
            let scale = if norm >= 0.95 { 0.95 / norm } else { 1.0 };

            coords.map(|x| x * scale)
        }
        #[cfg(not(feature = "simd"))]
        {
            let norm_sq: f32 = coords.iter().map(|x| x * x).sum();

            if norm_sq < 1e-8 {
                return [0.0; 8]; // Origin
            }

            let norm = norm_sq.sqrt();

            // Scale to fit in ball with margin
            let scale = if norm >= 0.95 { 0.95 / norm } else { 1.0 };

            coords.map(|x| x * scale)
        }
    }

    /// Compute hyperbolic distance in Poincaré ball
    /// d_H(x, y) = arcosh(1 + 2||x - y||² / ((1 - ||x||²)(1 - ||y||²)))
    pub fn distance(x: &[f32; 8], y: &[f32; 8]) -> f32 {
        #[cfg(feature = "simd")]
        {
            use super::gf8::{gf8_norm2_simd, gf8_sub_simd};
            let diff = gf8_sub_simd(x, y);
            let diff_sq = gf8_norm2_simd(&diff);
            let x_norm_sq = gf8_norm2_simd(x);
            let y_norm_sq = gf8_norm2_simd(y);

            // Hyperbolic distance formula
            let numerator = 2.0 * diff_sq;
            let denominator = (1.0 - x_norm_sq) * (1.0 - y_norm_sq);

            if denominator < 1e-8 {
                return f32::INFINITY; // Points on boundary
            }

            let ratio = 1.0 + numerator / denominator;
            ratio.max(1.0).acosh()
        }
        #[cfg(not(feature = "simd"))]
        {
            // Optimized scalar computation - avoid intermediate powi(2)
            let mut diff_sq = 0.0;
            let mut x_norm_sq = 0.0;
            let mut y_norm_sq = 0.0;

            for i in 0..8 {
                let diff = x[i] - y[i];
                diff_sq += diff * diff;
                x_norm_sq += x[i] * x[i];
                y_norm_sq += y[i] * y[i];
            }

            // Hyperbolic distance formula
            let numerator = 2.0 * diff_sq;
            let denominator = (1.0 - x_norm_sq) * (1.0 - y_norm_sq);

            if denominator < 1e-8 {
                return f32::INFINITY; // Points on boundary
            }

            let ratio = 1.0 + numerator / denominator;
            ratio.max(1.0).acosh()
        }
    }

    /// Möbius addition: a ⊕ b (hyperbolic translation)
    /// a ⊕ b = ((1 + 2⟨a,b⟩ + ||b||²)a + (1 - ||a||²)b) / (1 + 2⟨a,b⟩ + ||a||²||b||²)
    pub fn mobius_add(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
        #[cfg(feature = "simd")]
        let (a_norm_sq, b_norm_sq, dot_ab) = {
            use super::gf8::{gf8_dot_simd, gf8_norm2_simd};
            (gf8_norm2_simd(a), gf8_norm2_simd(b), gf8_dot_simd(a, b))
        };
        #[cfg(not(feature = "simd"))]
        let (a_norm_sq, b_norm_sq, dot_ab) = {
            let a_norm_sq: f32 = a.iter().map(|x| x * x).sum();
            let b_norm_sq: f32 = b.iter().map(|x| x * x).sum();
            let dot_ab: f32 = a.iter().zip(b.iter()).map(|(ai, bi)| ai * bi).sum();
            (a_norm_sq, b_norm_sq, dot_ab)
        };

        let numerator_a_coeff = 1.0 + 2.0 * dot_ab + b_norm_sq;
        let numerator_b_coeff = 1.0 - a_norm_sq;
        let denominator = 1.0 + 2.0 * dot_ab + a_norm_sq * b_norm_sq;

        if denominator.abs() < 1e-8 {
            return [0.0; 8]; // Degenerate case
        }

        let mut result = [0.0f32; 8];
        for i in 0..8 {
            result[i] = (numerator_a_coeff * a[i] + numerator_b_coeff * b[i]) / denominator;
        }

        result
    }

    /// Compute hyperbolic distance from origin
    pub fn norm(x: &[f32; 8]) -> f32 {
        let origin = [0.0f32; 8];
        Self::distance(&origin, x)
    }

    /// Interpolate along hyperbolic geodesic between two points
    /// Uses parameter t ∈ [0, 1]
    pub fn interpolate(x: &[f32; 8], y: &[f32; 8], t: f32) -> [f32; 8] {
        let t_clamped = t.clamp(0.0, 1.0);

        // Hyperbolic geodesic: use Möbius addition with scaling
        // First translate to make x the origin, interpolate, then translate back
        let neg_x = x.map(|xi| -xi);

        // Translate y to origin frame: y' = (-x) ⊕ y
        let y_translated = Self::mobius_add(&neg_x, y);

        // Scale y' by t
        let y_scaled = y_translated.map(|yi| yi * t_clamped);

        // Translate back: x ⊕ (t * y')
        Self::mobius_add(x, &y_scaled)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hyperbolic_project() {
        // Test projection keeps points inside ball
        let coords = [2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0];
        let projected = HyperbolicLayer::project(&coords);

        let norm_sq: f32 = projected.iter().map(|x| x * x).sum();
        assert!(norm_sq < 1.0, "Projected point should be inside unit ball");
    }

    #[test]
    fn test_hyperbolic_distance() {
        // Distance from origin
        let x = [0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let origin = [0.0; 8];

        let dist = HyperbolicLayer::distance(&origin, &x);
        assert!(dist > 0.0);
        assert!(dist.is_finite());
    }

    #[test]
    fn test_hyperbolic_distance_symmetry() {
        let x = [0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let y = [0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];

        let dist_xy = HyperbolicLayer::distance(&x, &y);
        let dist_yx = HyperbolicLayer::distance(&y, &x);

        assert!(
            (dist_xy - dist_yx).abs() < 1e-6,
            "Distance should be symmetric"
        );
    }

    #[test]
    fn test_mobius_add_identity() {
        let x = [0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let origin = [0.0; 8];

        // x ⊕ 0 = x
        let result = HyperbolicLayer::mobius_add(&x, &origin);
        for i in 0..8 {
            assert!((result[i] - x[i]).abs() < 1e-6);
        }
    }

    #[test]
    fn test_hyperbolic_interpolate() {
        let x = [0.0; 8];
        let y = [0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];

        // At t=0, should be x
        let interp_0 = HyperbolicLayer::interpolate(&x, &y, 0.0);
        for i in 0..8 {
            assert!((interp_0[i] - x[i]).abs() < 1e-6);
        }

        // At t=1, should be y
        let interp_1 = HyperbolicLayer::interpolate(&x, &y, 1.0);
        for i in 0..8 {
            assert!((interp_1[i] - y[i]).abs() < 1e-5);
        }
    }

    #[test]
    fn test_hyperbolic_norm() {
        let x = [0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let norm = HyperbolicLayer::norm(&x);

        assert!(norm > 0.0);
        assert!(norm.is_finite());

        // Norm at origin should be 0
        let origin = [0.0; 8];
        let norm_origin = HyperbolicLayer::norm(&origin);
        assert!(norm_origin.abs() < 1e-6);
    }
}

File: hydron-core\src\lorentzian.rs
===================================
/* src/lorentzian.rs */
//! Lorentzian Geometry Layer - Spacetime Metrics and Geodesics
//!
//! Implements Lorentzian (pseudo-Riemannian) geometry with signature (-,+,+,+,+,+,+,+).
//! Core mathematical operations:
//! - Minkowski metric: ds² = -dt² + dx₁² + dx₂² + ... + dx₇²
//! - Proper time along timelike worldlines
//! - Geodesic computations
//! - Light cone structure (null surfaces)
//! - Lorentz transformations and boosts
//! - Causal relationships (timelike, spacelike, lightlike separation)
//!
//! Extension: Causal DAG for event ordering (optional, game-specific logic)
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet, VecDeque};

/// Spacetime point in 7+1 dimensional Lorentzian manifold
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct SpacetimePoint {
    /// Coordinates [t, x₁, x₂, x₃, x₄, x₅, x₆, x₇]
    pub coords: [f64; 8],
}

impl SpacetimePoint {
    /// Create new spacetime point
    pub fn new(coords: [f64; 8]) -> Self {
        Self { coords }
    }

    /// Time coordinate
    pub fn time(&self) -> f64 {
        self.coords[0]
    }

    /// Spatial coordinates as slice
    pub fn spatial(&self) -> &[f64] {
        &self.coords[1..8]
    }

    /// Compute Minkowski metric interval to another point
    /// ds² = -dt² + Σ(dxᵢ²)
    pub fn minkowski_interval(&self, other: &SpacetimePoint) -> f64 {
        let dt = self.coords[0] - other.coords[0];
        let spatial_dist_sq: f64 = (1..8)
            .map(|i| {
                let dx = self.coords[i] - other.coords[i];
                dx * dx
            })
            .sum();

        -dt * dt + spatial_dist_sq
    }

    /// Compute proper time (for timelike curves)
    /// τ = √(-ds²) if ds² < 0
    pub fn proper_time(&self, other: &SpacetimePoint) -> Option<f64> {
        let interval = self.minkowski_interval(other);
        if interval < 0.0 {
            Some((-interval).sqrt())
        } else {
            None // Not timelike separated
        }
    }

    /// Check if two points are timelike separated (ds² < 0)
    pub fn is_timelike(&self, other: &SpacetimePoint) -> bool {
        self.minkowski_interval(other) < 0.0
    }

    /// Check if two points are spacelike separated (ds² > 0)
    pub fn is_spacelike(&self, other: &SpacetimePoint) -> bool {
        self.minkowski_interval(other) > 0.0
    }

    /// Check if two points are lightlike/null separated (ds² = 0)
    pub fn is_lightlike(&self, other: &SpacetimePoint) -> bool {
        self.minkowski_interval(other).abs() < 1e-10
    }

    /// Determine causal relationship based on interval and time ordering
    pub fn causal_relation(&self, other: &SpacetimePoint) -> CausalRelation {
        let interval = self.minkowski_interval(other);
        let dt = self.coords[0] - other.coords[0];

        if interval < -1e-10 {
            if dt > 0.0 {
                CausalRelation::Future
            } else {
                CausalRelation::Past
            }
        } else if interval > 1e-10 {
            CausalRelation::Spacelike
        } else {
            // Lightlike
            if dt > 0.0 {
                CausalRelation::LightlikeFuture
            } else if dt < 0.0 {
                CausalRelation::LightlikePast
            } else {
                CausalRelation::Coincident
            }
        }
    }
}

/// Causal relationship between two spacetime points
#[derive(Clone, Debug, PartialEq)]
pub enum CausalRelation {
    /// Timelike future (this event is in the causal future)
    Future,
    /// Timelike past (this event is in the causal past)
    Past,
    /// Spacelike separated (no causal relationship)
    Spacelike,
    /// Null/lightlike future
    LightlikeFuture,
    /// Null/lightlike past
    LightlikePast,
    /// Same event
    Coincident,
}

/// Worldline - timelike curve through spacetime
#[derive(Clone, Debug)]
pub struct Worldline {
    /// Points along the worldline (must be timelike connected)
    pub points: Vec<SpacetimePoint>,
}

impl Worldline {
    /// Create new worldline
    pub fn new() -> Self {
        Self { points: Vec::new() }
    }

    /// Add point to worldline (validates timelike connection)
    pub fn add_point(&mut self, point: SpacetimePoint) -> Result<(), &'static str> {
        if let Some(last) = self.points.last()
            && (!last.is_timelike(&point) || point.time() <= last.time())
        {
            return Err("Point must be timelike future-connected to previous point");
        }
        self.points.push(point);
        Ok(())
    }

    /// Compute total proper time along worldline
    pub fn proper_time(&self) -> f64 {
        let mut tau = 0.0;
        for i in 1..self.points.len() {
            if let Some(dtau) = self.points[i - 1].proper_time(&self.points[i]) {
                tau += dtau;
            }
        }
        tau
    }

    /// Get velocity 4-vector at index (forward difference)
    pub fn four_velocity(&self, index: usize) -> Option<[f64; 8]> {
        if index + 1 >= self.points.len() {
            return None;
        }

        let p1 = &self.points[index];
        let p2 = &self.points[index + 1];

        let dtau = p1.proper_time(p2)?;
        let mut v = [0.0; 8];

        for (v, (c2, c1)) in v.iter_mut().zip(p2.coords.iter().zip(p1.coords.iter())) {
            *v = (c2 - c1) / dtau;
        }

        Some(v)
    }
}

impl Default for Worldline {
    fn default() -> Self {
        Self::new()
    }
}

/// Lorentzian geometry layer
pub struct LorentzianLayer {
    /// Worldlines tracked in this layer
    pub worldlines: Vec<Worldline>,

    /// Metric signature (-1, +1, +1, +1, +1, +1, +1, +1)
    pub signature: [i8; 8],
}

impl LorentzianLayer {
    /// Create new Lorentzian layer with standard signature
    pub fn new() -> Self {
        Self {
            worldlines: Vec::new(),
            signature: [-1, 1, 1, 1, 1, 1, 1, 1],
        }
    }

    /// Add worldline to layer
    pub fn add_worldline(&mut self, worldline: Worldline) {
        self.worldlines.push(worldline);
    }

    /// Compute geodesic distance between two points (proper time for timelike)
    pub fn geodesic_distance(&self, p1: &SpacetimePoint, p2: &SpacetimePoint) -> Option<f64> {
        p1.proper_time(p2)
    }

    /// Check if point is in past light cone of another
    pub fn in_past_light_cone(&self, point: &SpacetimePoint, reference: &SpacetimePoint) -> bool {
        let interval = point.minkowski_interval(reference);
        let dt = reference.time() - point.time();
        interval <= 0.0 && dt > 0.0
    }

    /// Check if point is in future light cone of another
    pub fn in_future_light_cone(&self, point: &SpacetimePoint, reference: &SpacetimePoint) -> bool {
        let interval = point.minkowski_interval(reference);
        let dt = point.time() - reference.time();
        interval <= 0.0 && dt > 0.0
    }

    /// Lorentz boost along x₁ axis
    /// γ = 1/√(1 - v²)
    pub fn lorentz_boost(&self, point: &SpacetimePoint, velocity: f64) -> SpacetimePoint {
        if velocity.abs() >= 1.0 {
            return point.clone(); // Invalid velocity
        }

        let gamma = 1.0 / (1.0 - velocity * velocity).sqrt();
        let mut boosted = point.coords;

        let t = point.coords[0];
        let x = point.coords[1];

        boosted[0] = gamma * (t - velocity * x);
        boosted[1] = gamma * (x - velocity * t);

        SpacetimePoint::new(boosted)
    }
}

impl Default for LorentzianLayer {
    fn default() -> Self {
        Self::new()
    }
}

//====================================================================================
// EXTENSION: CAUSAL DAG (Generic Event Ordering)
//====================================================================================

/// Causal node representing an event in spacetime (extends SpacetimePoint)
#[derive(Clone, Debug)]
pub struct CausalNode<T> {
    /// Spacetime location
    pub location: SpacetimePoint,

    /// Unique event identifier
    pub event_id: u64,

    /// Spatial position (E8 root index, application-specific)
    pub e8_root: usize,

    /// Event payload (application-specific)
    pub payload: T,
}

impl<T> CausalNode<T> {
    /// Create new causal node
    pub fn new(event_id: u64, location: SpacetimePoint, e8_root: usize, payload: T) -> Self {
        Self {
            location,
            event_id,
            e8_root,
            payload,
        }
    }

    /// Compute spacetime interval to another event (delegates to SpacetimePoint)
    pub fn spacetime_interval(&self, other: &CausalNode<T>) -> f64 {
        self.location.minkowski_interval(&other.location)
    }

    /// Check if this event is in the causal future of another
    pub fn is_causally_after(&self, other: &CausalNode<T>) -> bool {
        matches!(
            self.location.causal_relation(&other.location),
            CausalRelation::Future | CausalRelation::LightlikeFuture
        )
    }

    /// Check if this event is spacelike separated from another
    pub fn is_spacelike_separated(&self, other: &CausalNode<T>) -> bool {
        self.location.is_spacelike(&other.location)
    }
}

/// Causal directed acyclic graph (DAG) - Extension for event ordering
#[derive(Clone, Debug)]
pub struct CausalDAG<T> {
    /// All events in the causal history
    pub nodes: Vec<CausalNode<T>>,

    /// Causal edges: (cause_id, effect_id)
    pub edges: Vec<(u64, u64)>,

    /// Adjacency list for efficient traversal: event_id -> [effect_ids]
    adjacency: HashMap<u64, Vec<u64>>,

    /// Reverse adjacency: event_id -> [cause_ids]
    reverse_adjacency: HashMap<u64, Vec<u64>>,
}

impl<T> CausalDAG<T> {
    /// Create empty causal DAG
    pub fn new() -> Self {
        Self {
            nodes: Vec::new(),
            edges: Vec::new(),
            adjacency: HashMap::new(),
            reverse_adjacency: HashMap::new(),
        }
    }

    /// Add event with causal dependencies
    pub fn add_event(&mut self, node: CausalNode<T>, causes: &[u64]) -> u64 {
        let event_id = node.event_id;

        // Add node
        self.nodes.push(node);

        // Add edges
        for &cause_id in causes {
            self.edges.push((cause_id, event_id));

            // Update adjacency lists
            self.adjacency.entry(cause_id).or_default().push(event_id);

            self.reverse_adjacency
                .entry(event_id)
                .or_default()
                .push(cause_id);
        }

        event_id
    }

    /// Check if an event id exists
    pub fn has_event(&self, event_id: u64) -> bool {
        self.nodes.iter().any(|n| n.event_id == event_id)
    }

    /// Add a causal edge between existing events
    pub fn add_edge(&mut self, cause_id: u64, effect_id: u64) {
        self.edges.push((cause_id, effect_id));
        self.adjacency.entry(cause_id).or_default().push(effect_id);
        self.reverse_adjacency
            .entry(effect_id)
            .or_default()
            .push(cause_id);
    }

    /// Get past light cone (all causal ancestors)
    pub fn past_light_cone(&self, event_id: u64) -> Vec<u64> {
        let mut past = Vec::new();
        let mut visited = HashSet::new();
        let mut queue = VecDeque::new();

        queue.push_back(event_id);
        visited.insert(event_id);

        while let Some(current) = queue.pop_front() {
            if let Some(causes) = self.reverse_adjacency.get(&current) {
                for &cause_id in causes {
                    if !visited.contains(&cause_id) {
                        past.push(cause_id);
                        queue.push_back(cause_id);
                        visited.insert(cause_id);
                    }
                }
            }
        }

        past
    }

    /// Get future light cone (all causal descendants)
    pub fn future_light_cone(&self, event_id: u64) -> Vec<u64> {
        let mut future = Vec::new();
        let mut visited = HashSet::new();
        let mut queue = VecDeque::new();

        queue.push_back(event_id);
        visited.insert(event_id);

        while let Some(current) = queue.pop_front() {
            if let Some(effects) = self.adjacency.get(&current) {
                for &effect_id in effects {
                    if !visited.contains(&effect_id) {
                        future.push(effect_id);
                        queue.push_back(effect_id);
                        visited.insert(effect_id);
                    }
                }
            }
        }

        future
    }

    /// Check if event A is in causal past of event B
    pub fn is_causal_past(&self, a: u64, b: u64) -> bool {
        self.past_light_cone(b).contains(&a)
    }

    /// Check if event A is in causal future of event B
    pub fn is_causal_future(&self, a: u64, b: u64) -> bool {
        self.future_light_cone(b).contains(&a)
    }

    /// Find node by event ID
    pub fn get_node(&self, event_id: u64) -> Option<&CausalNode<T>> {
        self.nodes.iter().find(|n| n.event_id == event_id)
    }

    /// Verify causal consistency (no cycles)
    pub fn verify_consistency(&self) -> bool {
        // Use topological sort to detect cycles
        let mut in_degree: HashMap<u64, usize> = HashMap::new();

        // Initialize in-degrees
        for node in &self.nodes {
            in_degree.insert(node.event_id, 0);
        }

        for &(_, effect) in &self.edges {
            *in_degree.get_mut(&effect).unwrap() += 1;
        }

        // Find all nodes with in-degree 0
        let mut queue: VecDeque<u64> = in_degree
            .iter()
            .filter(|&(_, &deg)| deg == 0)
            .map(|(&id, _)| id)
            .collect();

        let mut sorted_count = 0;

        while let Some(node_id) = queue.pop_front() {
            sorted_count += 1;

            if let Some(effects) = self.adjacency.get(&node_id) {
                for &effect_id in effects {
                    let deg = in_degree.get_mut(&effect_id).unwrap();
                    *deg -= 1;
                    if *deg == 0 {
                        queue.push_back(effect_id);
                    }
                }
            }
        }

        // If all nodes were processed, no cycles exist
        sorted_count == self.nodes.len()
    }

    /// Get topological ordering of events
    pub fn topological_order(&self) -> Option<Vec<u64>> {
        if !self.verify_consistency() {
            return None;
        }

        let mut in_degree: HashMap<u64, usize> = HashMap::new();

        for node in &self.nodes {
            in_degree.insert(node.event_id, 0);
        }

        for &(_, effect) in &self.edges {
            *in_degree.get_mut(&effect).unwrap() += 1;
        }

        let mut queue: VecDeque<u64> = in_degree
            .iter()
            .filter(|&(_, &deg)| deg == 0)
            .map(|(&id, _)| id)
            .collect();

        let mut order = Vec::new();

        while let Some(node_id) = queue.pop_front() {
            order.push(node_id);

            if let Some(effects) = self.adjacency.get(&node_id) {
                for &effect_id in effects {
                    let deg = in_degree.get_mut(&effect_id).unwrap();
                    *deg -= 1;
                    if *deg == 0 {
                        queue.push_back(effect_id);
                    }
                }
            }
        }

        Some(order)
    }
}

impl<T> Default for CausalDAG<T> {
    fn default() -> Self {
        Self::new()
    }
}

/// Combined layer with both Lorentzian geometry and causal DAG extension
pub struct LorentzianCausalLayer<T> {
    /// Core Lorentzian geometry
    pub geometry: LorentzianLayer,

    /// Causal DAG extension
    pub dag: CausalDAG<T>,

    /// Current proper time
    pub proper_time: f64,

    /// Next event ID
    next_event_id: u64,
}

impl<T> LorentzianCausalLayer<T> {
    /// Create new combined layer
    pub fn new() -> Self {
        Self {
            geometry: LorentzianLayer::new(),
            dag: CausalDAG::new(),
            proper_time: 0.0,
            next_event_id: 0,
        }
    }

    /// Add event to causal graph
    pub fn add_event(
        &mut self,
        e8_root: usize,
        payload: T,
        causes: &[u64],
        location_override: Option<SpacetimePoint>,
    ) -> u64 {
        let event_id = self.next_event_id;
        self.next_event_id += 1;
        // Create spacetime coordinates [t, x1, ..., x7]
        let location = if let Some(loc) = location_override {
            // Maintain monotonic proper time as max of seen times
            if loc.coords[0] > self.proper_time {
                self.proper_time = loc.coords[0];
            }
            loc
        } else {
            self.proper_time += 1.0;
            let mut coordinates = [0.0f64; 8];
            coordinates[0] = self.proper_time;
            // Spatial coordinates encode E8 root (simplified mapping)
            for (i, coord) in coordinates.iter_mut().enumerate().skip(1) {
                *coord = ((e8_root >> i) & 1) as f64;
            }
            SpacetimePoint::new(coordinates)
        };
        let node = CausalNode::new(event_id, location, e8_root, payload);

        self.dag.add_event(node, causes);
        event_id
    }

    /// Get past light cone of an event
    pub fn past_light_cone(&self, event_id: u64) -> Vec<u64> {
        self.dag.past_light_cone(event_id)
    }

    /// Get future light cone of an event
    pub fn future_light_cone(&self, event_id: u64) -> Vec<u64> {
        self.dag.future_light_cone(event_id)
    }

    /// Check causal ordering
    pub fn is_causal_past(&self, a: u64, b: u64) -> bool {
        self.dag.is_causal_past(a, b)
    }

    /// Check causal future
    pub fn is_causal_future(&self, a: u64, b: u64) -> bool {
        self.dag.is_causal_future(a, b)
    }

    /// Add a causal link between existing events
    pub fn add_link(&mut self, cause: u64, effect: u64) -> Result<(), &'static str> {
        if !self.dag.has_event(cause) || !self.dag.has_event(effect) {
            return Err("Event not found");
        }
        self.dag.add_edge(cause, effect);
        Ok(())
    }

    /// Verify causal consistency
    pub fn verify_consistency(&self) -> bool {
        self.dag.verify_consistency()
    }

    /// Topological order if acyclic
    pub fn topological_order(&self) -> Option<Vec<u64>> {
        self.dag.topological_order()
    }

    /// Get event by ID
    pub fn get_event(&self, event_id: u64) -> Option<&CausalNode<T>> {
        self.dag.get_node(event_id)
    }
}

impl<T> Default for LorentzianCausalLayer<T> {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[derive(Clone, Debug, PartialEq)]
    enum EventType {
        Action { description: String },
        Move { from_root: usize, to_root: usize },
    }

    // Core Lorentzian geometry tests
    #[test]
    fn test_minkowski_interval() {
        let p1 = SpacetimePoint::new([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p2 = SpacetimePoint::new([1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        let interval = p1.minkowski_interval(&p2);
        // ds² = -dt² + dx² = -(1)² + (1)² = 0 (lightlike)
        assert_eq!(interval, 0.0);
    }

    #[test]
    fn test_timelike_separation() {
        let p1 = SpacetimePoint::new([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p2 = SpacetimePoint::new([2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        assert!(p1.is_timelike(&p2));
        assert_eq!(p1.proper_time(&p2), Some((3.0_f64).sqrt()));
    }

    #[test]
    fn test_spacelike_separation() {
        let p1 = SpacetimePoint::new([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p2 = SpacetimePoint::new([1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        assert!(p1.is_spacelike(&p2));
        assert_eq!(p1.proper_time(&p2), None);
    }

    #[test]
    fn test_causal_relation() {
        let p1 = SpacetimePoint::new([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p2 = SpacetimePoint::new([2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        assert_eq!(p2.causal_relation(&p1), CausalRelation::Future);
        assert_eq!(p1.causal_relation(&p2), CausalRelation::Past);
    }

    #[test]
    fn test_worldline() {
        let mut wl = Worldline::new();

        let p1 = SpacetimePoint::new([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p2 = SpacetimePoint::new([2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let p3 = SpacetimePoint::new([4.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        assert!(wl.add_point(p1).is_ok());
        assert!(wl.add_point(p2).is_ok());
        assert!(wl.add_point(p3).is_ok());

        assert!(wl.proper_time() > 0.0);
    }

    #[test]
    fn test_lorentz_boost() {
        let layer = LorentzianLayer::new();
        let p = SpacetimePoint::new([1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let v = 0.5;

        let boosted = layer.lorentz_boost(&p, v);

        // Check that time and x1 are transformed
        assert_ne!(boosted.coords[0], p.coords[0]);
        assert_ne!(boosted.coords[1], p.coords[1]);
        // Other coordinates unchanged
        assert_eq!(boosted.coords[2], p.coords[2]);
    }

    // Extension: Causal DAG tests
    #[test]
    fn test_lorentzian_causal_layer_creation() {
        let layer = LorentzianCausalLayer::<EventType>::new();
        assert_eq!(layer.proper_time, 0.0);
        assert_eq!(layer.next_event_id, 0);
    }

    #[test]
    fn test_add_event() {
        let mut layer = LorentzianCausalLayer::<EventType>::new();

        let event1 = layer.add_event(
            0,
            EventType::Action {
                description: "Start".to_string(),
            },
            &[],
            None,
        );
        assert_eq!(event1, 0);
        assert_eq!(layer.proper_time, 1.0);

        let event2 = layer.add_event(
            1,
            EventType::Move {
                from_root: 0,
                to_root: 1,
            },
            &[event1],
            None,
        );
        assert_eq!(event2, 1);
        assert_eq!(layer.proper_time, 2.0);
    }

    #[test]
    fn test_causal_ordering() {
        let mut layer = LorentzianCausalLayer::<EventType>::new();

        let e1 = layer.add_event(
            0,
            EventType::Action {
                description: "A".to_string(),
            },
            &[],
            None,
        );
        let e2 = layer.add_event(
            1,
            EventType::Action {
                description: "B".to_string(),
            },
            &[e1],
            None,
        );
        let e3 = layer.add_event(
            2,
            EventType::Action {
                description: "C".to_string(),
            },
            &[e2],
            None,
        );

        assert!(layer.is_causal_past(e1, e2));
        assert!(layer.is_causal_past(e1, e3));
        assert!(layer.is_causal_past(e2, e3));

        assert!(!layer.is_causal_past(e2, e1));
        assert!(!layer.is_causal_past(e3, e1));
    }

    #[test]
    fn test_light_cones() {
        let mut layer = LorentzianCausalLayer::<EventType>::new();

        let e1 = layer.add_event(
            0,
            EventType::Action {
                description: "Root".to_string(),
            },
            &[],
            None,
        );
        let e2 = layer.add_event(
            1,
            EventType::Action {
                description: "Child1".to_string(),
            },
            &[e1],
            None,
        );
        let e3 = layer.add_event(
            2,
            EventType::Action {
                description: "Child2".to_string(),
            },
            &[e1],
            None,
        );
        let e4 = layer.add_event(
            3,
            EventType::Action {
                description: "Grandchild".to_string(),
            },
            &[e2, e3],
            None,
        );

        let past = layer.past_light_cone(e4);
        assert!(past.contains(&e1));
        assert!(past.contains(&e2));
        assert!(past.contains(&e3));

        let future = layer.future_light_cone(e1);
        assert!(future.contains(&e2));
        assert!(future.contains(&e3));
        assert!(future.contains(&e4));
    }

    #[test]
    fn test_causal_consistency() {
        let mut layer = LorentzianCausalLayer::<EventType>::new();

        let e1 = layer.add_event(
            0,
            EventType::Action {
                description: "A".to_string(),
            },
            &[],
            None,
        );
        let e2 = layer.add_event(
            1,
            EventType::Action {
                description: "B".to_string(),
            },
            &[e1],
            None,
        );
        let _e3 = layer.add_event(
            2,
            EventType::Action {
                description: "C".to_string(),
            },
            &[e2],
            None,
        );

        assert!(layer.verify_consistency());
    }

    #[test]
    fn test_topological_order() {
        let mut layer = LorentzianCausalLayer::<EventType>::new();

        let e1 = layer.add_event(
            0,
            EventType::Action {
                description: "A".to_string(),
            },
            &[],
            None,
        );
        let e2 = layer.add_event(
            1,
            EventType::Action {
                description: "B".to_string(),
            },
            &[e1],
            None,
        );
        let e3 = layer.add_event(
            2,
            EventType::Action {
                description: "C".to_string(),
            },
            &[e1],
            None,
        );

        let order = layer.dag.topological_order().unwrap();

        // e1 must come before e2 and e3
        let pos1 = order.iter().position(|&x| x == e1).unwrap();
        let pos2 = order.iter().position(|&x| x == e2).unwrap();
        let pos3 = order.iter().position(|&x| x == e3).unwrap();

        assert!(pos1 < pos2);
        assert!(pos1 < pos3);
    }
}

File: hydron-core\src\lib.rs
============================
/* src/lib.rs */
//! Hydron - E8 Geometric Mathematics Engine
//!
//! Pure mathematical implementations of E8 lattice geometry with multi-geometric layers:
//! - Fisher information geometry (statistical manifolds)
//! - Symplectic T*E8 geometry (Hamiltonian dynamics)
//! - Hyperbolic H8 geometry (Poincaré ball model)
//! - Topological analysis (persistent homology)
//! - Lorentzian geometry (spacetime metrics)
//! - Quaternion algebra (rotations, SLERP)
//! - Spherical S7 geometry (unit sphere)
//!
//! All modules provide pure geometric operations. Application-specific extensions
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

pub mod fisher;
pub mod gf8;
pub mod hyperbolic;
pub mod intrinsics;
pub mod lorentzian;
pub mod quaternion;
pub mod spherical;
pub mod symplectic;
pub mod topological;

// Re-export commonly used types from submodules for convenience
pub use fisher::FisherLayer;
pub use gf8::{Gf8, Gf8Tensor, get_e8_roots};
pub use hyperbolic::HyperbolicLayer;
pub use intrinsics::intrinsics_for_f32_width;
pub use lorentzian::{LorentzianCausalLayer, LorentzianLayer, SpacetimePoint};
pub use quaternion::QuaternionOps;
pub use spherical::SphericalLayer;
pub use symplectic::SymplecticLayer;
pub use topological::{PersistencePair, TopologicalLayer};

File: hydron-core\src\spherical.rs
==================================
//! Spherical S7 Geometry Layer - Unit 7-Sphere
//!
//! Implements spherical geometry on the unit 7-sphere in 8-dimensional space.
//! All points satisfy the constraint ||x|| = 1.
//!
//! Key operations:
//! - Projection to unit sphere
//! - Geodesic distance using arccos
//! - SLERP (Spherical Linear Interpolation)
//! - Antipodal points and mean computation
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Spherical S7 layer - unit 7-sphere in 8D
pub struct SphericalLayer;

impl SphericalLayer {
    /// Project coordinates onto the unit 7-sphere (||x|| = 1)
    pub fn project(coords: &[f32; 8]) -> [f32; 8] {
        let norm_sq: f32 = coords.iter().map(|x| x * x).sum();

        if norm_sq < 1e-8 {
            // If at origin, project to arbitrary point on sphere
            let mut result = [0.0f32; 8];
            result[0] = 1.0;
            return result;
        }

        let norm = norm_sq.sqrt();
        coords.map(|x| x / norm)
    }

    /// Compute geodesic distance on S7 using arccos
    /// d(x, y) = arccos(x · y) for unit vectors
    pub fn distance(x: &[f32; 8], y: &[f32; 8]) -> f32 {
        #[cfg(feature = "simd")]
        {
            use super::gf8::gf8_dot_simd;
            let dot = gf8_dot_simd(x, y).clamp(-1.0, 1.0);
            dot.acos()
        }
        #[cfg(not(feature = "simd"))]
        {
            let dot: f32 = x.iter().zip(y.iter()).map(|(xi, yi)| xi * yi).sum();
            let dot_clamped = dot.clamp(-1.0, 1.0);
            dot_clamped.acos()
        }
    }

    /// Spherical linear interpolation (SLERP)
    /// Smoothly interpolate along great circle between x and y
    /// t ∈ [0, 1]
    pub fn slerp(x: &[f32; 8], y: &[f32; 8], t: f32) -> [f32; 8] {
        let t_clamped = t.clamp(0.0, 1.0);

        // Compute angle between vectors
        #[cfg(feature = "simd")]
        let dot = {
            use super::gf8::gf8_dot_simd;
            gf8_dot_simd(x, y)
        };
        #[cfg(not(feature = "simd"))]
        let dot: f32 = x.iter().zip(y.iter()).map(|(xi, yi)| xi * yi).sum();

        let dot_clamped = dot.clamp(-1.0, 1.0);

        // If vectors are very close, use linear interpolation
        if dot_clamped > 0.9995 {
            let mut result = [0.0f32; 8];
            for i in 0..8 {
                result[i] = x[i] + t_clamped * (y[i] - x[i]);
            }
            return Self::project(&result); // Renormalize
        }

        let theta = dot_clamped.acos();
        let sin_theta = theta.sin();

        if sin_theta.abs() < 1e-8 {
            return *x; // Degenerate case
        }

        // SLERP formula: (sin((1-t)*θ) * x + sin(t*θ) * y) / sin(θ)
        let scale1 = ((1.0 - t_clamped) * theta).sin() / sin_theta;
        let scale2 = (t_clamped * theta).sin() / sin_theta;

        let mut result = [0.0f32; 8];
        for i in 0..8 {
            result[i] = scale1 * x[i] + scale2 * y[i];
        }

        result
    }

    /// Compute normalized entropy from probability distribution
    /// Returns value in [0, 1] where 0 = uniform distribution, 1 = concentrated
    /// Optimized to avoid vector allocation and compute in single pass
    pub fn normalized_entropy(distribution: &[f32]) -> f32 {
        let sum: f32 = distribution.iter().sum();

        if sum < 1e-8 {
            return 0.0; // No information
        }

        let n = distribution.len() as f32;
        if n < 1e-8 {
            return 0.0;
        }

        // Compute entropy in single pass without intermediate vector allocation
        let mut entropy = 0.0;
        for &x in distribution {
            if x > 1e-8 {
                let p = x / sum;
                entropy -= p * p.ln();
            }
        }

        // Max entropy for n elements is ln(n)
        let max_entropy = n.ln();

        // Return normalized entropy (0 = uniform, 1 = concentrated)
        1.0 - (entropy / max_entropy)
    }

    /// Get antipodal point (opposite point on sphere)
    pub fn antipodal(x: &[f32; 8]) -> [f32; 8] {
        x.map(|xi| -xi)
    }

    /// Compute Fréchet mean (average on sphere) for multiple points
    /// Uses iterative optimization
    pub fn mean(points: &[[f32; 8]]) -> [f32; 8] {
        if points.is_empty() {
            return Self::project(&[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        }

        if points.len() == 1 {
            return points[0];
        }

        // Start with Euclidean mean, then project
        let mut mean = [0.0f32; 8];
        for point in points {
            for i in 0..8 {
                mean[i] += point[i];
            }
        }

        Self::project(&mean)
    }

    /// Compute geodesic from point in direction (tangent vector)
    /// Returns point at distance t along geodesic
    pub fn geodesic(point: &[f32; 8], direction: &[f32; 8], t: f32) -> [f32; 8] {
        // Project direction to tangent space (remove component parallel to point)
        let dot: f32 = point
            .iter()
            .zip(direction.iter())
            .map(|(pi, di)| pi * di)
            .sum();

        let mut tangent = [0.0f32; 8];
        for i in 0..8 {
            tangent[i] = direction[i] - dot * point[i];
        }

        // Normalize tangent
        let tangent_norm_sq: f32 = tangent.iter().map(|x| x * x).sum();
        if tangent_norm_sq < 1e-8 {
            return *point; // No movement
        }

        let tangent_norm = tangent_norm_sq.sqrt();
        for t in &mut tangent {
            *t /= tangent_norm;
        }

        // Geodesic: point * cos(t) + tangent * sin(t)
        let mut result = [0.0f32; 8];
        let cos_t = t.cos();
        let sin_t = t.sin();
        for i in 0..8 {
            result[i] = point[i] * cos_t + tangent[i] * sin_t;
        }

        result
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_spherical_project() {
        let coords = [2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0];
        let projected = SphericalLayer::project(&coords);

        // Check that result is on unit sphere
        let norm_sq: f32 = projected.iter().map(|x| x * x).sum();
        assert!(
            (norm_sq - 1.0).abs() < 1e-6,
            "Point should be on unit sphere"
        );
    }

    #[test]
    fn test_spherical_distance() {
        let x = SphericalLayer::project(&[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let y = SphericalLayer::project(&[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        let dist = SphericalLayer::distance(&x, &y);

        // Should be π/2 (90 degrees)
        use std::f32::consts::FRAC_PI_2;
        assert!((dist - FRAC_PI_2).abs() < 1e-5);
    }

    #[test]
    fn test_spherical_slerp() {
        let x = SphericalLayer::project(&[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let y = SphericalLayer::project(&[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        // At t=0, should be x
        let interp_0 = SphericalLayer::slerp(&x, &y, 0.0);
        for i in 0..8 {
            assert!((interp_0[i] - x[i]).abs() < 1e-6);
        }

        // At t=1, should be y
        let interp_1 = SphericalLayer::slerp(&x, &y, 1.0);
        for i in 0..8 {
            assert!((interp_1[i] - y[i]).abs() < 1e-5);
        }

        // Midpoint should be on unit sphere
        let mid = SphericalLayer::slerp(&x, &y, 0.5);
        let norm_sq: f32 = mid.iter().map(|x| x * x).sum();
        assert!((norm_sq - 1.0).abs() < 1e-6);
    }

    #[test]
    fn test_spherical_normalized_entropy() {
        // Uniform distribution has high entropy (returns ~0)
        let uniform = vec![1.0; 10];
        let entropy_uniform = SphericalLayer::normalized_entropy(&uniform);
        assert!(entropy_uniform < 0.1);

        // Peaked distribution has low entropy (returns ~1)
        let peaked = vec![0.0, 0.0, 10.0, 0.0, 0.0];
        let entropy_peaked = SphericalLayer::normalized_entropy(&peaked);
        assert!(entropy_peaked > 0.8);
    }

    #[test]
    fn test_spherical_antipodal() {
        let x = SphericalLayer::project(&[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let antipodal = SphericalLayer::antipodal(&x);

        // Distance should be π (180 degrees)
        use std::f32::consts::PI;
        let dist = SphericalLayer::distance(&x, &antipodal);
        assert!((dist - PI).abs() < 1e-5);
    }

    #[test]
    fn test_spherical_mean() {
        let x = SphericalLayer::project(&[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let y = SphericalLayer::project(&[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        let mean = SphericalLayer::mean(&[x, y]);

        // Mean should be on unit sphere
        let norm_sq: f32 = mean.iter().map(|x| x * x).sum();
        assert!((norm_sq - 1.0).abs() < 1e-6);
    }
}

File: hydron-core\src\quaternion.rs
===================================
/* src/quaternion.rs */
//! Quaternion Operations for Phase Transitions
//!
//! Implements quaternion algebra for rotations and phase transitions in E8.
//! Quaternions are used for smooth interpolation (SLERP) and representing
//! rotational symmetries in the E8 lattice.
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Quaternion operations
pub struct QuaternionOps;

impl QuaternionOps {
    /// Normalize a quaternion to unit length
    pub fn normalize(q: &[f32; 4]) -> [f32; 4] {
        let norm = (q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3]).sqrt();
        if norm < 1e-8 {
            [1.0, 0.0, 0.0, 0.0] // Identity quaternion
        } else {
            [q[0] / norm, q[1] / norm, q[2] / norm, q[3] / norm]
        }
    }

    /// Multiply two quaternions (non-commutative)
    /// q1 * q2 = [w1*w2 - v1·v2, w1*v2 + w2*v1 + v1×v2]
    pub fn multiply(q1: &[f32; 4], q2: &[f32; 4]) -> [f32; 4] {
        let w1 = q1[0];
        let v1 = [q1[1], q1[2], q1[3]];
        let w2 = q2[0];
        let v2 = [q2[1], q2[2], q2[3]];

        // Scalar part: w1*w2 - v1·v2
        let w = w1 * w2 - (v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]);

        // Vector part: w1*v2 + w2*v1 + v1×v2
        let i = w1 * v2[0] + w2 * v1[0] + (v1[1] * v2[2] - v1[2] * v2[1]);
        let j = w1 * v2[1] + w2 * v1[1] + (v1[2] * v2[0] - v1[0] * v2[2]);
        let k = w1 * v2[2] + w2 * v1[2] + (v1[0] * v2[1] - v1[1] * v2[0]);

        [w, i, j, k]
    }

    /// Compute quaternion conjugate: q* = [w, -v]
    pub fn conjugate(q: &[f32; 4]) -> [f32; 4] {
        [q[0], -q[1], -q[2], -q[3]]
    }

    /// Compute quaternion inverse: q⁻¹ = q* / |q|²
    pub fn inverse(q: &[f32; 4]) -> [f32; 4] {
        let norm_sq = q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3];
        if norm_sq < 1e-8 {
            [0.0, 0.0, 0.0, 0.0] // Undefined
        } else {
            let conj = Self::conjugate(q);
            [
                conj[0] / norm_sq,
                conj[1] / norm_sq,
                conj[2] / norm_sq,
                conj[3] / norm_sq,
            ]
        }
    }

    /// Spherical linear interpolation (SLERP)
    /// Smoothly interpolate between q1 and q2 by parameter t ∈ [0, 1]
    pub fn slerp(q1: &[f32; 4], q2: &[f32; 4], t: f32) -> [f32; 4] {
        let q1_norm = Self::normalize(q1);
        let mut q2_norm = Self::normalize(q2);

        // Compute dot product
        let mut dot = q1_norm[0] * q2_norm[0]
            + q1_norm[1] * q2_norm[1]
            + q1_norm[2] * q2_norm[2]
            + q1_norm[3] * q2_norm[3];

        // If dot is negative, negate one quaternion to take shorter path
        if dot < 0.0 {
            q2_norm = [-q2_norm[0], -q2_norm[1], -q2_norm[2], -q2_norm[3]];
            dot = -dot;
        }

        // Clamp dot to [-1, 1] for numerical stability
        dot = dot.clamp(-1.0, 1.0);

        // If quaternions are very close, use linear interpolation
        if dot > 0.9995 {
            let result = [
                q1_norm[0] + t * (q2_norm[0] - q1_norm[0]),
                q1_norm[1] + t * (q2_norm[1] - q1_norm[1]),
                q1_norm[2] + t * (q2_norm[2] - q1_norm[2]),
                q1_norm[3] + t * (q2_norm[3] - q1_norm[3]),
            ];
            return Self::normalize(&result);
        }

        // Compute angle between quaternions
        let theta = dot.acos();
        let sin_theta = theta.sin();

        // SLERP formula: (sin((1-t)*θ) * q1 + sin(t*θ) * q2) / sin(θ)
        let scale1 = ((1.0 - t) * theta).sin() / sin_theta;
        let scale2 = (t * theta).sin() / sin_theta;

        [
            scale1 * q1_norm[0] + scale2 * q2_norm[0],
            scale1 * q1_norm[1] + scale2 * q2_norm[1],
            scale1 * q1_norm[2] + scale2 * q2_norm[2],
            scale1 * q1_norm[3] + scale2 * q2_norm[3],
        ]
    }

    /// Create quaternion from axis-angle representation
    /// q = [cos(θ/2), sin(θ/2) * axis]
    pub fn from_axis_angle(axis: &[f32; 3], angle: f32) -> [f32; 4] {
        let half_angle = angle * 0.5;
        let sin_half = half_angle.sin();

        // Normalize axis
        let axis_norm = (axis[0] * axis[0] + axis[1] * axis[1] + axis[2] * axis[2]).sqrt();
        if axis_norm < 1e-8 {
            return [1.0, 0.0, 0.0, 0.0]; // Identity
        }

        let ax = axis[0] / axis_norm;
        let ay = axis[1] / axis_norm;
        let az = axis[2] / axis_norm;

        [
            half_angle.cos(),
            sin_half * ax,
            sin_half * ay,
            sin_half * az,
        ]
    }

    /// Rotate a 3D vector by a quaternion
    /// v' = q * v * q⁻¹ (treating v as quaternion [0, v])
    pub fn rotate_vector(q: &[f32; 4], v: &[f32; 3]) -> [f32; 3] {
        let q_norm = Self::normalize(q);
        let v_quat = [0.0, v[0], v[1], v[2]];

        // Compute q * v
        let qv = Self::multiply(&q_norm, &v_quat);

        // Compute (q * v) * q⁻¹
        let q_inv = Self::conjugate(&q_norm); // For unit quaternions, conjugate = inverse
        let result = Self::multiply(&qv, &q_inv);

        [result[1], result[2], result[3]]
    }

    /// Quaternion dot product
    pub fn dot(q1: &[f32; 4], q2: &[f32; 4]) -> f32 {
        q1[0] * q2[0] + q1[1] * q2[1] + q1[2] * q2[2] + q1[3] * q2[3]
    }

    /// Convert E8 spinor root (indices 112-239) to quaternion
    /// Uses simplified mapping from 8D E8 coordinates to 4D quaternion
    pub fn from_e8_spinor(e8_coords: &[f32; 8]) -> [f32; 4] {
        // Simple projection: map 8D to 4D by averaging pairs
        let w = (e8_coords[0] + e8_coords[1]) * 0.5;
        let i = (e8_coords[2] + e8_coords[3]) * 0.5;
        let j = (e8_coords[4] + e8_coords[5]) * 0.5;
        let k = (e8_coords[6] + e8_coords[7]) * 0.5;

        Self::normalize(&[w, i, j, k])
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_quaternion_normalize() {
        let q = [1.0, 1.0, 1.0, 1.0];
        let q_norm = QuaternionOps::normalize(&q);
        let norm = (q_norm[0] * q_norm[0]
            + q_norm[1] * q_norm[1]
            + q_norm[2] * q_norm[2]
            + q_norm[3] * q_norm[3])
            .sqrt();
        assert!((norm - 1.0).abs() < 1e-6);
    }

    #[test]
    fn test_quaternion_multiply() {
        let q1 = [1.0, 0.0, 0.0, 0.0]; // Identity
        let q2 = [0.0, 1.0, 0.0, 0.0]; // i
        let result = QuaternionOps::multiply(&q1, &q2);
        assert_eq!(result, [0.0, 1.0, 0.0, 0.0]);

        // i * i = -1
        let i = [0.0, 1.0, 0.0, 0.0];
        let result = QuaternionOps::multiply(&i, &i);
        assert!((result[0] + 1.0).abs() < 1e-6); // Scalar part should be -1
    }

    #[test]
    fn test_quaternion_conjugate() {
        let q = [1.0, 2.0, 3.0, 4.0];
        let conj = QuaternionOps::conjugate(&q);
        assert_eq!(conj, [1.0, -2.0, -3.0, -4.0]);
    }

    #[test]
    fn test_quaternion_slerp() {
        let q1 = [1.0, 0.0, 0.0, 0.0]; // Identity
        let q2 = [0.0, 1.0, 0.0, 0.0]; // 180° rotation around x-axis

        let mid = QuaternionOps::slerp(&q1, &q2, 0.5);
        // Should be halfway rotation
        let expected = QuaternionOps::normalize(&[0.5, 0.5, 0.0, 0.0]);
        for i in 0..4 {
            assert!((mid[i] - expected[i]).abs() < 1e-5);
        }
    }

    #[test]
    fn test_quaternion_from_axis_angle() {
        use std::f32::consts::PI;

        // 90° rotation around z-axis
        let q = QuaternionOps::from_axis_angle(&[0.0, 0.0, 1.0], PI / 2.0);

        // Rotate vector [1, 0, 0]
        let v = [1.0, 0.0, 0.0];
        let rotated = QuaternionOps::rotate_vector(&q, &v);

        // Should rotate to [0, 1, 0]
        assert!((rotated[0] - 0.0).abs() < 1e-5);
        assert!((rotated[1] - 1.0).abs() < 1e-5);
        assert!((rotated[2] - 0.0).abs() < 1e-5);
    }
}

File: hydron-core\src\symplectic.rs
===================================
/* src/symplectic.rs */
//! Symplectic T*E8 Layer - Hamiltonian Dynamics
//!
//! Implements symplectic phase space over E8 for Hamiltonian dynamics.
//! Phase space has 16 dimensions: 8 positions (q) + 8 momenta (p).
//!
//! Key operations:
//! - Hamiltonian computation (H = T + V)
//! - Symplectic evolution (Velocity Verlet integrator)
//! - Möbius kicks and drifts
//! - Poisson brackets
//! - Phase space conservation
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

/// Symplectic phase space layer for Hamiltonian dynamics
pub struct SymplecticLayer {
    /// Symplectic 2-form ω (16×16 for 8 positions + 8 momenta)
    /// Standard form: ω[i][i+8] = 1, ω[i+8][i] = -1
    pub omega: [[f32; 16]; 16],
}

impl SymplecticLayer {
    /// Create new symplectic layer with standard symplectic form
    pub fn new() -> Self {
        let mut omega = [[0.0f32; 16]; 16];

        // Standard symplectic form: ω = Σ dp_i ∧ dq_i
        for i in 0..8 {
            omega[i][i + 8] = 1.0; // dq_i ∧ dp_i = 1
            omega[i + 8][i] = -1.0; // dp_i ∧ dq_i = -1
        }

        Self { omega }
    }

    /// Compute Hamiltonian: H = kinetic + potential
    /// H = ½ Σ p_i² + V(q)
    /// where V(q) is a simple harmonic potential
    pub fn hamiltonian(&self, _q: &[f32; 8], p: &[f32; 8]) -> f32 {
        // Kinetic energy: T = ½ Σ p_i² (use SIMD norm2)
        #[cfg(feature = "simd")]
        let kinetic = {
            use super::gf8::gf8_norm2_simd;
            gf8_norm2_simd(p) * 0.5
        };
        #[cfg(not(feature = "simd"))]
        let kinetic: f32 = p.iter().map(|&pi| pi * pi).sum::<f32>() * 0.5;

        // Potential energy: V = ½ k Σ q_i² (harmonic oscillator)
        let k = 0.1;
        #[cfg(feature = "simd")]
        let potential = {
            use super::gf8::gf8_norm2_simd;
            gf8_norm2_simd(_q) * 0.5 * k
        };
        #[cfg(not(feature = "simd"))]
        let potential: f32 = _q.iter().map(|&qi| qi * qi).sum::<f32>() * 0.5 * k;

        kinetic + potential
    }

    /// Compute force F = -∂V/∂q for harmonic potential
    fn compute_force(&self, q: &[f32; 8]) -> [f32; 8] {
        let k = 0.1;
        q.map(|qi| -k * qi)
    }

    /// Evolve system using Velocity Verlet integrator (symplectic)
    /// Preserves phase space volume and energy
    pub fn evolve(&self, q: &mut [f32; 8], p: &mut [f32; 8], dt: f32) {
        #[cfg(feature = "simd")]
        {
            use super::gf8::gf8_add_inplace_slice_simd;
            // Half-step momentum update: p(t+dt/2) = p(t) + (dt/2) * F(t)
            let force = self.compute_force(q);
            let scaled_force = force.map(|fi| 0.5 * dt * fi);
            gf8_add_inplace_slice_simd(p, &scaled_force);

            // Full-step position update: q(t+dt) = q(t) + dt * p(t+dt/2)
            let scaled_p = p.map(|pi| dt * pi);
            gf8_add_inplace_slice_simd(q, &scaled_p);

            // Recompute force at new position
            let force_new = self.compute_force(q);

            // Complete momentum update: p(t+dt) = p(t+dt/2) + (dt/2) * F(t+dt)
            let scaled_force_new = force_new.map(|fi| 0.5 * dt * fi);
            gf8_add_inplace_slice_simd(p, &scaled_force_new);
        }
        #[cfg(not(feature = "simd"))]
        {
            // Half-step momentum update: p(t+dt/2) = p(t) + (dt/2) * F(t)
            let force = self.compute_force(q);
            for i in 0..8 {
                p[i] += 0.5 * dt * force[i];
            }

            // Full-step position update: q(t+dt) = q(t) + dt * p(t+dt/2)
            for i in 0..8 {
                q[i] += dt * p[i];
            }

            // Recompute force at new position
            let force_new = self.compute_force(q);

            // Complete momentum update: p(t+dt) = p(t+dt/2) + (dt/2) * F(t+dt)
            for i in 0..8 {
                p[i] += 0.5 * dt * force_new[i];
            }
        }
    }

    /// Apply symplectic kick (instantaneous momentum change)
    pub fn kick(&self, p: &mut [f32; 8], force: &[f32; 8], dt: f32) {
        #[cfg(feature = "simd")]
        {
            use super::gf8::gf8_add_inplace_slice_simd;
            let scaled_force = force.map(|fi| fi * dt);
            gf8_add_inplace_slice_simd(p, &scaled_force);
        }
        #[cfg(not(feature = "simd"))]
        {
            for i in 0..8 {
                p[i] += force[i] * dt;
            }
        }
    }

    /// Apply symplectic drift (position update from momentum)
    pub fn drift(&self, q: &mut [f32; 8], p: &[f32; 8], dt: f32) {
        #[cfg(feature = "simd")]
        {
            use super::gf8::gf8_add_inplace_slice_simd;
            let scaled_p = p.map(|pi| pi * dt);
            gf8_add_inplace_slice_simd(q, &scaled_p);
        }
        #[cfg(not(feature = "simd"))]
        {
            for i in 0..8 {
                q[i] += p[i] * dt;
            }
        }
    }

    /// Convert position and momentum to phase space coordinates
    pub fn to_phase_space(&self, q: &[f32; 8], p: &[f32; 8]) -> [f32; 16] {
        let mut phase = [0.0f32; 16];
        phase[..8].copy_from_slice(q);
        phase[8..].copy_from_slice(p);
        phase
    }

    /// Extract position and momentum from phase space coordinates
    pub fn from_phase_space(&self, phase: &[f32; 16]) -> ([f32; 8], [f32; 8]) {
        let mut q = [0.0f32; 8];
        let mut p = [0.0f32; 8];
        q.copy_from_slice(&phase[..8]);
        p.copy_from_slice(&phase[8..]);
        (q, p)
    }

    /// Compute Poisson bracket {f, g} for coordinate functions
    /// {q_i, p_i} = 1, {p_i, q_i} = -1, others = 0
    pub fn poisson_bracket(&self, i: usize, j: usize) -> f32 {
        if (0..8).contains(&i) && (8..16).contains(&j) && i + 8 == j {
            1.0 // {q_i, p_i} = 1
        } else if (8..16).contains(&i) && (0..8).contains(&j) && i - 8 == j {
            -1.0 // {p_i, q_i} = -1
        } else {
            0.0 // All other brackets vanish
        }
    }

    /// Verify energy conservation (approximately)
    pub fn verify_energy_conservation(
        &self,
        before: &([f32; 8], [f32; 8]),
        after: &([f32; 8], [f32; 8]),
    ) -> bool {
        let h_before = self.hamiltonian(&before.0, &before.1);
        let h_after = self.hamiltonian(&after.0, &after.1);

        let relative_error = (h_before - h_after).abs() / h_before.abs().max(1e-8);
        relative_error < 0.1 // Allow 10% error
    }
}

impl Default for SymplecticLayer {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_symplectic_form() {
        let sym = SymplecticLayer::new();

        // Check antisymmetry
        for i in 0..16 {
            for j in 0..16 {
                assert_eq!(sym.omega[i][j], -sym.omega[j][i]);
            }
        }

        // Check structure
        for i in 0..8 {
            assert_eq!(sym.omega[i][i + 8], 1.0);
            assert_eq!(sym.omega[i + 8][i], -1.0);
        }
    }

    #[test]
    fn test_hamiltonian() {
        let sym = SymplecticLayer::new();

        let q = [0.0; 8];
        let p = [1.0; 8];

        let h = sym.hamiltonian(&q, &p);
        // H = ½ * 8 * 1.0 = 4.0 (kinetic only)
        assert!((h - 4.0).abs() < 1e-6);
    }

    #[test]
    fn test_phase_space_conversion() {
        let sym = SymplecticLayer::new();

        let q = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
        let p = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8];

        let phase = sym.to_phase_space(&q, &p);
        let (q_back, p_back) = sym.from_phase_space(&phase);

        for i in 0..8 {
            assert!((q[i] - q_back[i]).abs() < 1e-6);
            assert!((p[i] - p_back[i]).abs() < 1e-6);
        }
    }

    #[test]
    fn test_poisson_bracket() {
        let sym = SymplecticLayer::new();

        // {q_0, p_0} = 1
        assert_eq!(sym.poisson_bracket(0, 8), 1.0);

        // {p_0, q_0} = -1
        assert_eq!(sym.poisson_bracket(8, 0), -1.0);

        // {q_0, q_1} = 0
        assert_eq!(sym.poisson_bracket(0, 1), 0.0);

        // {p_0, p_1} = 0
        assert_eq!(sym.poisson_bracket(8, 9), 0.0);
    }

    #[test]
    fn test_symplectic_evolution() {
        let sym = SymplecticLayer::new();

        let mut q = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let mut p = [0.0; 8];

        let before = (q, p);

        // Evolve for small time step
        sym.evolve(&mut q, &mut p, 0.1);

        let after = (q, p);

        // Energy should be approximately conserved
        assert!(sym.verify_energy_conservation(&before, &after));
    }

    #[test]
    fn test_kick_and_drift() {
        let sym = SymplecticLayer::new();

        let mut q = [0.0; 8];
        let mut p = [1.0; 8];

        // Apply drift: q = q + p * dt
        sym.drift(&mut q, &p, 0.1);
        for i in 0..8 {
            assert!((q[i] - 0.1).abs() < 1e-6);
        }

        // Apply kick: p = p + F * dt
        let force = [1.0; 8];
        sym.kick(&mut p, &force, 0.1);
        for i in 0..8 {
            assert!((p[i] - 1.1).abs() < 1e-6);
        }
    }
}

File: hydron-core\src\topological.rs
====================================
/* src/topological.rs */
//! Topological Analysis Layer - Persistent Homology
//!
//! Implements persistent homology for analyzing topological features in point clouds.
//! Computes Betti numbers (β₀, β₁, β₂) representing:
//! - β₀: Connected components
//! - β₁: Loops/cycles
//! - β₂: Voids/cavities
//!
//! Topological features are invariant under continuous deformation,
//! making them robust descriptors of data structure.
//!
//! Key operations:
//! - Topological signature generation
//! - Persistence diagram computation
//! - Filtration-based analysis
//! - Betti number tracking
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use std::collections::HashSet;

/// Persistence diagram entry: (birth, death) for a topological feature
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct PersistencePair {
    pub birth: f32,
    pub death: f32,
    pub dimension: usize,
}

impl PersistencePair {
    /// Lifetime of the topological feature
    pub fn persistence(&self) -> f32 {
        self.death - self.birth
    }
}

/// Topological layer for persistent homology
pub struct TopologicalLayer {
    /// Persistence diagrams by dimension (0, 1, 2)
    pub diagrams: [Vec<PersistencePair>; 3],

    /// Current Betti numbers [β₀, β₁, β₂]
    pub betti: [u32; 3],

    /// Point cloud data for simplicial complex construction
    points: Vec<[f32; 8]>,
}

impl TopologicalLayer {
    /// Create new topological layer
    pub fn new() -> Self {
        Self {
            diagrams: [Vec::new(), Vec::new(), Vec::new()],
            betti: [1, 0, 0], // Start with single connected component
            points: Vec::new(),
        }
    }

    /// Add point to point cloud
    pub fn add_point(&mut self, point: [f32; 8]) {
        self.points.push(point);
    }

    /// Clear all points
    pub fn clear_points(&mut self) {
        self.points.clear();
    }

    /// Compute distance matrix for point cloud
    fn distance_matrix(&self) -> Vec<Vec<f32>> {
        let n = self.points.len();
        let mut distances = vec![vec![0.0f32; n]; n];

        for i in 0..n {
            for j in (i + 1)..n {
                let dist = euclidean_distance(&self.points[i], &self.points[j]);
                distances[i][j] = dist;
                distances[j][i] = dist;
            }
        }

        distances
    }

    /// Build Vietoris-Rips filtration up to given radius
    /// Returns edges that appear at each threshold
    fn vietoris_rips_filtration(
        &self,
        max_radius: f32,
        steps: usize,
    ) -> Vec<(f32, Vec<(usize, usize)>)> {
        let n = self.points.len();
        if n < 2 {
            return Vec::new();
        }

        let distances = self.distance_matrix();
        let mut filtration = Vec::new();

        let step_size = max_radius / steps as f32;

        for step in 0..=steps {
            let threshold = step as f32 * step_size;
            let mut edges = Vec::new();

            #[allow(clippy::needless_range_loop)]
            for (i, row) in distances.iter().enumerate() {
                for j in (i + 1)..n {
                    if row[j] <= threshold {
                        edges.push((i, j));
                    }
                }
            }

            filtration.push((threshold, edges));
        }

        filtration
    }

    /// Compute Betti numbers using Union-Find for β₀
    pub fn compute_betti_numbers(&mut self, max_radius: f32, steps: usize) {
        let n = self.points.len();

        if n == 0 {
            self.betti = [0, 0, 0];
            return;
        }

        let filtration = self.vietoris_rips_filtration(max_radius, steps);

        // Initialize β₀ = number of points (all disconnected)
        let mut uf = UnionFind::new(n);
        let mut beta0_history = Vec::new();

        // Track β₀ through filtration
        for (threshold, edges) in &filtration {
            for &(i, j) in edges {
                uf.union(i, j);
            }
            beta0_history.push((*threshold, uf.count_components()));
        }

        // Current β₀ is final component count
        self.betti[0] = uf.count_components() as u32;

        // Estimate β₁ (loops) from Euler characteristic
        // χ = β₀ - β₁ + β₂
        // For simplicial complexes: χ = V - E + F
        if let Some((_, final_edges)) = filtration.last() {
            let v = n as i32;
            let e = final_edges.len() as i32;

            // Count triangles (2-simplices) for better β₁ estimation
            let mut triangles = std::collections::HashSet::new();
            for i in 0..final_edges.len() {
                for j in (i + 1)..final_edges.len() {
                    for k in (j + 1)..final_edges.len() {
                        let mut vertices = vec![
                            final_edges[i].0,
                            final_edges[i].1,
                            final_edges[j].0,
                            final_edges[j].1,
                            final_edges[k].0,
                            final_edges[k].1,
                        ];
                        vertices.sort();
                        vertices.dedup();
                        if vertices.len() == 3 {
                            // This is a triangle
                            triangles.insert((vertices[0], vertices[1], vertices[2]));
                        }
                    }
                }
            }
            let triangle_count = triangles.len();

            let f = triangle_count as i32;
            let chi = v - e + f;
            let beta1_estimate = (self.betti[0] as i32 - chi).max(0);
            self.betti[1] = beta1_estimate as u32;

            // β₂ (voids) estimation using Euler characteristic
            // For closed surfaces: χ = 2 - 2g where g is genus
            // For 3D complexes: β₂ relates to enclosed voids

            // Count tetrahedra (3-simplices) for void detection
            let mut tetrahedron_count = 0;
            if n >= 4 {
                for i in 0..n {
                    for j in (i + 1)..n {
                        for k in (j + 1)..n {
                            for l in (k + 1)..n {
                                // Check if all 6 edges and 4 faces exist
                                let edges_exist = final_edges.contains(&(i, j))
                                    && final_edges.contains(&(i, k))
                                    && final_edges.contains(&(i, l))
                                    && final_edges.contains(&(j, k))
                                    && final_edges.contains(&(j, l))
                                    && final_edges.contains(&(k, l));

                                if edges_exist {
                                    tetrahedron_count += 1;
                                }
                            }
                        }
                    }
                }
            }

            // χ = β₀ - β₁ + β₂ for 2D surfaces
            // For 3D: χ = V - E + F - T (where T is tetrahedra)
            // β₂ = χ - β₀ + β₁
            if tetrahedron_count > 0 {
                let chi_3d = v - e + f - tetrahedron_count;
                let beta2_estimate = (chi_3d - self.betti[0] as i32 + self.betti[1] as i32).max(0);
                self.betti[2] = beta2_estimate as u32;
            } else {
                // No 3D structure detected, β₂ = 0
                self.betti[2] = 0;
            }
        }
    }

    /// Generate topological signature (hash of Betti numbers and persistence)
    pub fn signature(&self) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        self.betti[0].hash(&mut hasher);
        self.betti[1].hash(&mut hasher);
        self.betti[2].hash(&mut hasher);

        // Include persistence information
        for dim in 0..3 {
            for pair in &self.diagrams[dim] {
                let persistence = (pair.persistence() * 1000.0) as u64;
                persistence.hash(&mut hasher);
            }
        }

        hasher.finish()
    }

    /// Compute persistence diagram for dimension 0 (connected components)
    pub fn compute_persistence_diagram_dim0(&mut self, max_radius: f32, steps: usize) {
        let n = self.points.len();
        if n < 2 {
            return;
        }

        let filtration = self.vietoris_rips_filtration(max_radius, steps);
        let mut uf = UnionFind::new(n);
        let birth_times = vec![0.0f32; n];
        let mut alive = vec![true; n];

        self.diagrams[0].clear();

        for (threshold, edges) in &filtration {
            for &(i, j) in edges {
                let root_i = uf.find(i);
                let root_j = uf.find(j);

                if root_i != root_j {
                    // Merge components: older component survives
                    let (_survivor, victim) = if birth_times[root_i] <= birth_times[root_j] {
                        (root_i, root_j)
                    } else {
                        (root_j, root_i)
                    };

                    if alive[victim] {
                        // Record death of victim component
                        self.diagrams[0].push(PersistencePair {
                            birth: birth_times[victim],
                            death: *threshold,
                            dimension: 0,
                        });
                        alive[victim] = false;
                    }

                    uf.union(root_i, root_j);
                }
            }
        }

        // Surviving components have infinite death time (we use max_radius as proxy)
        for i in 0..n {
            let root = uf.find(i);
            if alive[root] && uf.is_root(i) {
                self.diagrams[0].push(PersistencePair {
                    birth: birth_times[root],
                    death: f32::INFINITY,
                    dimension: 0,
                });
            }
        }
    }

    /// Get persistence pairs with lifetime above threshold
    pub fn significant_features(&self, min_persistence: f32) -> Vec<PersistencePair> {
        let mut features = Vec::new();

        for dim in 0..3 {
            for &pair in &self.diagrams[dim] {
                if pair.persistence() >= min_persistence {
                    features.push(pair);
                }
            }
        }

        features.sort_by(|a, b| b.persistence().partial_cmp(&a.persistence()).unwrap());
        features
    }

    /// Compute total persistence (sum of all feature lifetimes)
    pub fn total_persistence(&self) -> f32 {
        let mut total = 0.0f32;

        for dim in 0..3 {
            for pair in &self.diagrams[dim] {
                let pers = pair.persistence();
                if pers.is_finite() {
                    total += pers;
                }
            }
        }

        total
    }

    /// Check if two point clouds are topologically similar
    pub fn is_similar(&self, other: &TopologicalLayer, tolerance: u32) -> bool {
        for i in 0..3 {
            if self.betti[i].abs_diff(other.betti[i]) > tolerance {
                return false;
            }
        }
        true
    }
}

impl Default for TopologicalLayer {
    fn default() -> Self {
        Self::new()
    }
}

/// Union-Find data structure for connected components
struct UnionFind {
    parent: Vec<usize>,
    rank: Vec<usize>,
}

impl UnionFind {
    fn new(n: usize) -> Self {
        Self {
            parent: (0..n).collect(),
            rank: vec![0; n],
        }
    }

    fn find(&mut self, x: usize) -> usize {
        if self.parent[x] != x {
            self.parent[x] = self.find(self.parent[x]); // Path compression
        }
        self.parent[x]
    }

    fn union(&mut self, x: usize, y: usize) {
        let root_x = self.find(x);
        let root_y = self.find(y);

        if root_x != root_y {
            // Union by rank
            if self.rank[root_x] < self.rank[root_y] {
                self.parent[root_x] = root_y;
            } else if self.rank[root_x] > self.rank[root_y] {
                self.parent[root_y] = root_x;
            } else {
                self.parent[root_y] = root_x;
                self.rank[root_x] += 1;
            }
        }
    }

    fn count_components(&mut self) -> usize {
        let mut roots = HashSet::new();
        for i in 0..self.parent.len() {
            roots.insert(self.find(i));
        }
        roots.len()
    }

    fn is_root(&self, x: usize) -> bool {
        self.parent[x] == x
    }
}

/// Compute Euclidean distance between two 8D points
fn euclidean_distance(a: &[f32; 8], b: &[f32; 8]) -> f32 {
    #[cfg(feature = "simd")]
    {
        use super::gf8::{gf8_norm2_simd, gf8_sub_simd};
        let diff = gf8_sub_simd(a, b);
        gf8_norm2_simd(&diff).sqrt()
    }
    #[cfg(not(feature = "simd"))]
    {
        let sum_sq: f32 = a
            .iter()
            .zip(b.iter())
            .map(|(ai, bi)| (ai - bi).powi(2))
            .sum();
        sum_sq.sqrt()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_topological_layer_creation() {
        let layer = TopologicalLayer::new();
        assert_eq!(layer.betti, [1, 0, 0]);
    }

    #[test]
    fn test_add_points() {
        let mut layer = TopologicalLayer::new();
        layer.add_point([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        layer.add_point([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        assert_eq!(layer.points.len(), 2);
    }

    #[test]
    fn test_betti_numbers_disconnected() {
        let mut layer = TopologicalLayer::new();

        // Add two widely separated points
        layer.add_point([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        layer.add_point([10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        // With small radius, should have 2 components
        layer.compute_betti_numbers(1.0, 10);
        assert_eq!(layer.betti[0], 2);
    }

    #[test]
    fn test_betti_numbers_connected() {
        let mut layer = TopologicalLayer::new();

        // Add two close points
        layer.add_point([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        layer.add_point([0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        // With large radius, should have 1 component
        layer.compute_betti_numbers(10.0, 10);
        assert_eq!(layer.betti[0], 1);
    }

    #[test]
    fn test_signature() {
        let layer1 = TopologicalLayer::new();
        let layer2 = TopologicalLayer::new();

        // Same Betti numbers should give same signature
        assert_eq!(layer1.signature(), layer2.signature());
    }

    #[test]
    fn test_persistence_diagram() {
        let mut layer = TopologicalLayer::new();

        // Add triangle of points
        layer.add_point([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        layer.add_point([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        layer.add_point([0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        layer.compute_persistence_diagram_dim0(5.0, 20);

        // Should have persistence pairs
        assert!(!layer.diagrams[0].is_empty());
    }

    #[test]
    fn test_significant_features() {
        let mut layer = TopologicalLayer::new();

        layer.diagrams[0].push(PersistencePair {
            birth: 0.0,
            death: 2.0,
            dimension: 0,
        });
        layer.diagrams[0].push(PersistencePair {
            birth: 0.0,
            death: 0.1,
            dimension: 0,
        });

        let features = layer.significant_features(1.0);
        assert_eq!(features.len(), 1);
        assert_eq!(features[0].persistence(), 2.0);
    }

    #[test]
    fn test_total_persistence() {
        let mut layer = TopologicalLayer::new();

        layer.diagrams[0].push(PersistencePair {
            birth: 0.0,
            death: 2.0,
            dimension: 0,
        });
        layer.diagrams[1].push(PersistencePair {
            birth: 1.0,
            death: 3.0,
            dimension: 1,
        });

        let total = layer.total_persistence();
        assert_eq!(total, 4.0);
    }

    #[test]
    fn test_is_similar() {
        let mut layer1 = TopologicalLayer::new();
        layer1.betti = [2, 1, 0];

        let mut layer2 = TopologicalLayer::new();
        layer2.betti = [2, 1, 0];

        assert!(layer1.is_similar(&layer2, 0));

        let mut layer3 = TopologicalLayer::new();
        layer3.betti = [5, 1, 0];

        assert!(!layer1.is_similar(&layer3, 1));
    }
}

File: scripts\normalize_md.py
=============================
#!/usr/bin/env python3
"""
Markdown normalization script.

This script normalizes various markdown formatting issues:
- Converts setext headings to ATX headings
- Converts indented code blocks to fenced code blocks
- Handles doc-comment fence markers
- Ensures proper spacing around code fences
- Handles file headers with language-specific fenced blocks (optional)

Usage:
    python normalize_md.py [OPTIONS] file.md [file2.md ...]

Options:
    --debug-indented, -d    Debug indented code blocks (show first occurrence)
    --analyze-fences, -a    Analyze fence markers in the file
    --help, -h              Show this help message

Examples:
    python normalize_md.py README.md
    python normalize_md.py --analyze-fences docs/*.md
    python normalize_md.py --debug-indented myfile.md
"""

import os
import re
import sys

def usage():
    print(__doc__.strip())

def ext_to_lang(ext):
    """Map file extension to language identifier for code blocks."""
    mapping = {
        'rs': 'rust',
        'toml': 'toml',
        'txt': 'text',
        'js': 'javascript',
        'json': 'json',
        'c': 'c',
        'cpp': 'cpp',
        'h': 'c',
        'wasm': 'wasm',
        'd.ts': 'typescript',
        'ts': 'typescript',
        'md': 'markdown',
        'sh': 'bash',
        'py': 'python',
    }
    return mapping.get(ext.lower(), '')

def debug_indented(file_path):
    """Debug function to find the first indented code block line."""
    print(f"Debugging indented code blocks in {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {file_path} not found")
        return
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return

    in_fenced = False
    for idx, line in enumerate(lines):
        if re.match(r"^(\s*)```", line):
            in_fenced = not in_fenced
        if not in_fenced and re.match(r"^(\s{4,}).*", line):
            print(f'Found indented line at {idx+1}: {repr(line[:80])}')
            # Print context
            print("Context:")
            for i in range(max(0, idx-3), min(len(lines), idx+4)):
                marker = "-->" if i == idx else "   "
                print(f"{i+1:3d}: {marker} {repr(lines[i][:120])}")
            break
    else:
        print("No indented code blocks found outside fenced blocks.")

def analyze_fences(file_path):
    """Analyze fence markers in the file."""
    print(f"Analyzing fences in {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {file_path} not found")
        return
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return

    fence_indices = []
    for idx, ln in enumerate(lines):
        if re.match(r"^\s*```", ln):
            fence_indices.append(idx+1)

    print(f'Total fence lines: {len(fence_indices)}')

    # Show first 20 fence contexts
    for i in fence_indices[:20]:
        start = max(1, i-2)
        end = min(len(lines), i+2)
        print(f'\nFence at line {i}:')
        for j in range(start, end+1):
            if j <= len(lines):
                marker = "-->" if j == i else "   "
                print(f"{j:3d}: {marker} {repr(lines[j-1][:120])}")
    if len(fence_indices) > 20:
        print(f"\n... and {len(fence_indices) - 20} more fences")

def normalize_md(content):
    """Normalize markdown content through multiple passes."""
    lines = content.splitlines(keepends=True)

    # Pass 1: Convert doc-comment fences, setext headings, indented code blocks to fenced
    in_fenced = False

    out_lines = []
    i = 0
    while i < len(lines):
        line = lines[i]

        # Detect fenced blocks start/end
        fence_match = re.match(r"^(\s*)```", line)
        if fence_match:
            in_fenced = not in_fenced
            out_lines.append(line)
            i += 1
            continue

        if not in_fenced:
            # Replace doc-comment code fence markers like '//! ```' and '/// ```' with plain '```'
            doc_fence_match = re.match(r"^(\s*)(//+\s*|//!\s*|///\s*)(```.*)$", line)
            if doc_fence_match:
                leading_space, comment_token, fence = doc_fence_match.groups()
                # If previous line is not blank, ensure blank line before fence
                if len(out_lines) > 0 and out_lines[-1].strip() != '':
                    out_lines.append('\n')
                out_lines.append(leading_space + fence + '\n')
                in_fenced = True
                i += 1
                continue

            # Convert setext headings: lookahead to next non-empty line
            if i + 1 < len(lines):
                next_line = lines[i + 1]
                # if next line is all '=' or all '-'
                if re.match(r"^[ ]*={3,}[ ]*$", next_line):
                    # Convert current line to '## ' heading
                    new_line = re.sub(r"^#*\s*", '', line).rstrip('\n')
                    out_lines.append('## ' + new_line + '\n')
                    i += 2
                    continue
                if re.match(r"^[ ]*-{3,}[ ]*$", next_line):
                    # Convert current line to '### ' heading
                    new_line = re.sub(r"^#*\s*", '', line).rstrip('\n')
                    out_lines.append('### ' + new_line + '\n')
                    i += 2
                    continue

            # Detect indented code block (4 spaces) start
            if re.match(r"^(\s{4,}).*", line):
                # Collect block of consecutive indented lines
                code_block_lines = []
                while i < len(lines) and re.match(r"^(\s{4,}).*", lines[i]):
                    code_block_lines.append(re.sub(r"^\s{4}", '', lines[i]))
                    i += 1
                # Output fenced block; insert blank line above if needed
                if len(out_lines) > 0 and out_lines[-1].strip() != '':
                    out_lines.append('\n')
                out_lines.append('```\n')
                out_lines.extend(code_block_lines)
                out_lines.append('```\n')
                # skip normal increment
                continue

        # Default: just copy line
        out_lines.append(line)
        i += 1

    content = ''.join(out_lines)

    # Second-pass replace: Convert File: ... setext headings to ATX globally (catch missed cases)
    content = re.sub(r"(?m)^(File: .+)\r?\n^[=]{3,}\r?\n", r"## \1\n\n", content)
    content = re.sub(r"(?m)^(File: .+)\r?\n^[-]{3,}\r?\n", r"## \1\n\n", content)

    # Third pass: Ensure fenced code blocks are surrounded by blank lines and strip inlined doc-svg fences
    lines = content.splitlines(keepends=True)
    out_lines2 = []
    in_fence = False
    for idx, ln in enumerate(lines):
        striped = ln.rstrip('\n')
        if re.match(r"^\s*```", striped):
            # Ensure previous line blank
            if not in_fence and len(out_lines2) > 0 and out_lines2[-1].strip() != '':
                out_lines2.append('\n')
            out_lines2.append(ln)
            in_fence = not in_fence
            continue

        # For doc comment fence closing like '//! ```' - normalized earlier, but handle just in case
        if not in_fence and re.match(r"^\s*(//+\s*|///\s*)(```.*)", ln):
            if len(out_lines2) > 0 and out_lines2[-1].strip() != '':
                out_lines2.append('\n')
            out_lines2.append(re.sub(r"^\s*(//+\s*|///\s*)", '', ln))
            in_fence = True
            continue

        out_lines2.append(ln)

    content = ''.join(out_lines2)

    # Fourth pass: Close previous code blocks before file headers and open new fenced block with language info
    lines = content.splitlines(keepends=True)

    out_lines3 = []
    i = 0
    open_fence = False
    while i < len(lines):
        ln = lines[i]
        # Track fence toggling to keep open_fence accurate
        if re.match(r"^\s*```", ln):
            out_lines3.append(ln)
            open_fence = not open_fence
            i += 1
            continue

        # Identify headers like '## File: src\gf8.rs'
        m = re.match(r"^(##\s+File:\s+(.+))\r?\n$", ln)
        if m:
            path = m.group(2)
            # If a fence is currently open, close it before the header
            if open_fence:
                out_lines3.append('```\n')
                open_fence = False
            # Append header
            out_lines3.append(ln)
            # Ensure blank line after header
            if i+1 < len(lines) and lines[i+1].strip() != '':
                out_lines3.append('\n')
            # Add opening fence if next non-blank isn't a fence
            k = i+1
            while k < len(lines) and lines[k].strip() == '':
                k += 1
            if k < len(lines) and not re.match(r"^\s*```", lines[k]):
                # get extension
                ext = ''
                if '.' in path:
                    ext = os.path.splitext(path)[1].lstrip('.')
                lang = ext_to_lang(ext)
                if lang:
                    out_lines3.append(f'```{lang}\n')
                else:
                    out_lines3.append('```\n')
                open_fence = True
            i += 1
            continue

        out_lines3.append(ln)
        i += 1

    return ''.join(out_lines3)

def process_file(file_path, debug_indented_flag=False, analyze_fences_flag=False):
    """Process a single markdown file."""
    print(f"Processing {file_path}...")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()
    except FileNotFoundError:
        print(f"Error: File {file_path} not found")
        return
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return

    if debug_indented_flag:
        debug_indented(file_path)
        return

    if analyze_fences_flag:
        analyze_fences(file_path)
        return

    # Perform normalization
    normalized_content = normalize_md(original_content)

    if normalized_content != original_content:
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(normalized_content)
            print(f"Normalized {file_path}: converted setext headings to ATX, indented code blocks to fenced, and processed file headers.")
        except Exception as e:
            print(f"Error writing {file_path}: {e}")
    else:
        print(f"{file_path} is already normalized.")

def main():
    if len(sys.argv) < 2 or '--help' in sys.argv or '-h' in sys.argv:
        usage()
        sys.exit(0)

    debug_indented_flag = '--debug-indented' in sys.argv or '-d' in sys.argv
    analyze_fences_flag = '--analyze-fences' in sys.argv or '-a' in sys.argv

    # Remove flags from arguments
    args = [arg for arg in sys.argv[1:] if not arg.startswith('-')]

    if not args:
        print("Error: No files specified")
        usage()
        sys.exit(1)

    for file_path in args:
        if not file_path.endswith('.md'):
            print(f"Warning: {file_path} does not have .md extension. Processing anyway.")
        process_file(file_path, debug_indented_flag, analyze_fences_flag)

if __name__ == '__main__':
    main()

File: hydron-ffi\pkg\README.md
==============================
# Hydron-FFI: E8 Geometry Engine for WebAssembly & Native Platforms

A high-performance foreign function interface (FFI) for the **Hydron** E8 geometric mathematics engine. Provides seamless access to advanced geometric computing across multiple platforms:

- **WebAssembly (WASM):** Browser and Node.js via `wasm-bindgen`
- **C/C++:** Native code via stable C-ABI exports
- **Rust:** Direct crate dependency with full type safety

## Features

**Hydron-FFI exposes the complete Hydron-core geometric toolkit:**

- **Gf8 (GeoFloat8):** 8-dimensional normalized geometric floats on the unit hypersphere
- **Spherical Geometry (S⁷):** Geodesic distances, spherical interpolation (SLERP), and antipodal operations
- **Hyperbolic Geometry (H⁸):** Poincaré ball model with Möbius arithmetic
- **Fisher Information Geometry:** Statistical manifolds, KL divergence, and information metrics
- **Symplectic Geometry (T*E⁸):** Hamiltonian phase space dynamics and canonical transformations
- **Lorentzian Geometry:** Spacetime metrics, causal structure, and light cone analysis
- **Quaternion Algebra:** 4D rotations, composition, and SLERP
- **Topological Analysis:** Persistent homology, Betti numbers, and cohomology

## Quick Start

### Native Rust

Add to your `Cargo.toml`:

```toml
[dependencies]
hydron-ffi = { path = "hydron-ffi" }
```

Use in your code:

```rust
use hydron_ffi::{Gf8, SphericalLayer, Gf8Tensor};

// Create normalized 8D points
let a = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
let b = Gf8::new([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

// Compute spherical geodesic distance
let distance = SphericalLayer::distance(a.as_slice(), b.as_slice());
println!("S⁷ distance: {}", distance);
```

### Testing

```powershell
cd hydron-ffi
cargo test
```

### WebAssembly

Build the WASM module with `wasm-pack`:

```powershell
# Requires wasm-pack: https://rustwasm.github.io/wasm-pack/installer/

cd hydron-ffi
wasm-pack build --release --target web
```

This generates `pkg/` containing:

- `hydron_ffi.js` — JavaScript bindings
- `hydron_ffi_bg.wasm` — Compiled WebAssembly module

Use in a web project:

```javascript
import * as hydron from './pkg/hydron_ffi.js';

// Access all geometry operations
const distance = hydron.s7_distance_rust([1,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0]);
console.log("S⁷ distance:", distance);
```

### C/C++ FFI

All public Rust functions are C-ABI compatible. Example C code:

```c
#include <stdint.h>

// C declaration
extern float s7_distance(const float *a, const float *b);

int main() {
    float a[8] = {1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f};
    float b[8] = {0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f};

    float distance = s7_distance(a, b);
    printf("S⁷ distance: %f\n", distance);
    return 0;
}
```

## Architecture

**Hydron-FFI** serves as the public API surface for the **Hydron-core** geometry engine:

```
┌─────────────────────────────────────┐
│   Consumer Applications             │
│  (Browser, Node.js, C/C++, Rust)    │
└────────────┬────────────────────────┘
             │ FFI / wasm-bindgen
┌────────────▼────────────────────────┐
│        Hydron-FFI (this crate)      │
│      C-ABI & WASM Bindings          │
└────────────┬────────────────────────┘
             │ Re-exports all types
┌────────────▼────────────────────────┐
│        Hydron-Core                  │
│   Pure E8 Geometry Mathematics      │
│  (9 geometric computation modules)  │
└─────────────────────────────────────┘
```

## Dependencies

- **hydron-core:** E8 geometry engine (path dependency)
- **wasm-bindgen:** (optional) JavaScript integration for WebAssembly

## Build & Runtime Characteristics

All geometric operations are:

- **Vectorized:** Designed for 256-bit SIMD (AVX, NEON) with scalar fallbacks
- **Zero-copy:** Direct pointer access in C mode, minimal allocation in WASM
- **Normalized:** Unit-sphere representations provide numerical stability

## Learn More

For detailed geometric theory and API documentation, see:

- [Hydron-core documentation](../hydron-core/README.md)
- Inline code documentation: `cargo doc --open`

## License

MIT OR Apache-2.0

File: hydron-ffi\pkg\hydron_ffi.d.ts
====================================
/* tslint:disable */
/* eslint-disable */

export type InitInput = RequestInfo | URL | Response | BufferSource | WebAssembly.Module;

export interface InitOutput {
  readonly memory: WebAssembly.Memory;
}

export type SyncInitInput = BufferSource | WebAssembly.Module;

/**
* Instantiates the given `module`, which can either be bytes or
* a precompiled `WebAssembly.Module`.
*
* @param {{ module: SyncInitInput }} module - Passing `SyncInitInput` directly is deprecated.
*
* @returns {InitOutput}
*/
export function initSync(module: { module: SyncInitInput } | SyncInitInput): InitOutput;

/**
* If `module_or_path` is {RequestInfo} or {URL}, makes a request and
* for everything else, calls `WebAssembly.instantiate` directly.
*
* @param {{ module_or_path: InitInput | Promise<InitInput> }} module_or_path - Passing `InitInput` directly is deprecated.
*
* @returns {Promise<InitOutput>}
*/
export default function __wbg_init (module_or_path?: { module_or_path: InitInput | Promise<InitInput> } | InitInput | Promise<InitInput>): Promise<InitOutput>;

File: hydron-ffi\README.md
==========================
# Hydron-FFI: E8 Geometry Engine for WebAssembly & Native Platforms

A high-performance foreign function interface (FFI) for the **Hydron** E8 geometric mathematics engine. Provides seamless access to advanced geometric computing across multiple platforms:

- **WebAssembly (WASM):** Browser and Node.js via `wasm-bindgen`
- **C/C++:** Native code via stable C-ABI exports
- **Rust:** Direct crate dependency with full type safety

## Features

**Hydron-FFI exposes the complete Hydron-core geometric toolkit:**

- **Gf8 (GeoFloat8):** 8-dimensional normalized geometric floats on the unit hypersphere
- **Spherical Geometry (S⁷):** Geodesic distances, spherical interpolation (SLERP), and antipodal operations
- **Hyperbolic Geometry (H⁸):** Poincaré ball model with Möbius arithmetic
- **Fisher Information Geometry:** Statistical manifolds, KL divergence, and information metrics
- **Symplectic Geometry (T*E⁸):** Hamiltonian phase space dynamics and canonical transformations
- **Lorentzian Geometry:** Spacetime metrics, causal structure, and light cone analysis
- **Quaternion Algebra:** 4D rotations, composition, and SLERP
- **Topological Analysis:** Persistent homology, Betti numbers, and cohomology

## Quick Start

### Native Rust

Add to your `Cargo.toml`:

```toml
[dependencies]
hydron-ffi = { path = "hydron-ffi" }
```

Use in your code:

```rust
use hydron_ffi::{Gf8, SphericalLayer, Gf8Tensor};

// Create normalized 8D points
let a = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
let b = Gf8::new([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

// Compute spherical geodesic distance
let distance = SphericalLayer::distance(a.as_slice(), b.as_slice());
println!("S⁷ distance: {}", distance);
```

### Testing

```powershell
cd hydron-ffi
cargo test
```

### WebAssembly

Build the WASM module with `wasm-pack`:

```powershell
# Requires wasm-pack: https://rustwasm.github.io/wasm-pack/installer/

cd hydron-ffi
wasm-pack build --release --target web
```

This generates `pkg/` containing:

- `hydron_ffi.js` — JavaScript bindings
- `hydron_ffi_bg.wasm` — Compiled WebAssembly module

Use in a web project:

```javascript
import * as hydron from './pkg/hydron_ffi.js';

// Access all geometry operations
const distance = hydron.s7_distance_rust([1,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0]);
console.log("S⁷ distance:", distance);
```

### C/C++ FFI

All public Rust functions are C-ABI compatible. Example C code:

```c
#include <stdint.h>

// C declaration
extern float s7_distance(const float *a, const float *b);

int main() {
    float a[8] = {1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f};
    float b[8] = {0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f};

    float distance = s7_distance(a, b);
    printf("S⁷ distance: %f\n", distance);
    return 0;
}
```

## Architecture

**Hydron-FFI** serves as the public API surface for the **Hydron-core** geometry engine:

```
┌─────────────────────────────────────┐
│   Consumer Applications             │
│  (Browser, Node.js, C/C++, Rust)    │
└────────────┬────────────────────────┘
             │ FFI / wasm-bindgen
┌────────────▼────────────────────────┐
│        Hydron-FFI (this crate)      │
│      C-ABI & WASM Bindings          │
└────────────┬────────────────────────┘
             │ Re-exports all types
┌────────────▼────────────────────────┐
│        Hydron-Core                  │
│   Pure E8 Geometry Mathematics      │
│  (9 geometric computation modules)  │
└─────────────────────────────────────┘
```

## Dependencies

- **hydron-core:** E8 geometry engine (path dependency)
- **wasm-bindgen:** (optional) JavaScript integration for WebAssembly

## Build & Runtime Characteristics

All geometric operations are:

- **Vectorized:** Designed for 256-bit SIMD (AVX, NEON) with scalar fallbacks
- **Zero-copy:** Direct pointer access in C mode, minimal allocation in WASM
- **Normalized:** Unit-sphere representations provide numerical stability

## Learn More

For detailed geometric theory and API documentation, see:

- [Hydron-core documentation](../hydron-core/README.md)
- Inline code documentation: `cargo doc --open`

## License

MIT OR Apache-2.0

File: hydron-ffi\src\lib.rs
===========================
#![allow(clippy::missing_safety_doc)]
//! hydron-ffi: Complete FFI and wasm-bindgen wrapper for Hydron geometry
//!
//! This crate exposes the full Hydron geometry engine via:
//! - C-ABI foreign function interface (for native code)
//! - wasm-bindgen JavaScript bindings (for WebAssembly)
//!
//! The objective is to provide full access to the E8 geometry compute engine
//! in a single, well-defined entry point that can be compiled to WebAssembly
//! and used in the browser/Node.js or any other host that supports Wasm.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

// Re-export all hydron-core types and operations
pub use hydron_core::{
    FisherLayer, Gf8, Gf8Tensor, HyperbolicLayer, LorentzianCausalLayer, LorentzianLayer,
    PersistencePair, QuaternionOps, SpacetimePoint, SphericalLayer, SymplecticLayer,
    TopologicalLayer, intrinsics_for_f32_width,
};

/// C-ABI: compute spherical geodesic distance between two 8-element float arrays
/// `a_ptr` and `b_ptr` point to 8 contiguous `f32` values.
pub unsafe extern "C" fn s7_distance(a_ptr: *const f32, b_ptr: *const f32) -> f32 {
    // Basic null pointer checks
    if a_ptr.is_null() || b_ptr.is_null() {
        return f32::NAN;
    }

    // Unsafe block to read raw pointers
    let a_slice = unsafe { std::slice::from_raw_parts(a_ptr, 8) };
    let b_slice = unsafe { std::slice::from_raw_parts(b_ptr, 8) };

    // Copy into fixed arrays expected by SphericalLayer::distance
    let mut a = [0.0f32; 8];
    let mut b = [0.0f32; 8];
    a.copy_from_slice(a_slice);
    b.copy_from_slice(b_slice);

    SphericalLayer::distance(&a, &b)
}

/// Safe Rust wrapper for unit tests and consumers that don't want to use raw
/// pointers.
pub fn s7_distance_rust(a: [f32; 8], b: [f32; 8]) -> f32 {
    SphericalLayer::distance(&a, &b)
}

// Optional wasm-bindgen exported function for JS consumers. This uses a
// Float32Array-compatible signature: two slices of `f32`.
#[cfg(feature = "wasm-bindgen")]
mod wasm_bindings {
    use wasm_bindgen::prelude::*;

    #[wasm_bindgen(js_name = s7_distance)]
    pub fn s7_distance_js(a: &[f32], b: &[f32]) -> f32 {
        // Minimal validation: require length 8
        if a.len() != 8 || b.len() != 8 {
            return f32::NAN;
        }
        let mut aa = [0.0f32; 8];
        let mut bb = [0.0f32; 8];
        aa.copy_from_slice(a);
        bb.copy_from_slice(b);
        crate::s7_distance_rust(aa, bb)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_s7_distance_rust() {
        let a = [
            1.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32,
        ];
        let b = [
            0.0f32, 1.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32, 0.0f32,
        ];
        let d = s7_distance_rust(a, b);
        // With orthogonal unit vectors, distance is π/2
        let expected = std::f32::consts::FRAC_PI_2;
        assert!((d - expected).abs() < 1e-6);
    }

    #[test]
    fn test_s7_distance_null_ptr() {
        // Passing a null pointer returns NaN
        let d = unsafe { s7_distance(std::ptr::null(), std::ptr::null()) };
        assert!(d.is_nan());
    }
}

File: hydron-ffi\pkg\hydron_ffi_bg.wasm.d.ts
============================================
/* tslint:disable */
/* eslint-disable */
export const memory: WebAssembly.Memory;

File: rune-curs\src\buffers.rs
==============================
//! Typed device buffers (feature-gated).

use super::{CudaError, CudaResult};

#[cfg(feature = "cuda")]
use cust::memory::{CopyDestination, DeviceBuffer, DeviceCopy};

#[cfg(feature = "cuda")]
pub struct CudaBuffer<T: DeviceCopy> {
    inner: DeviceBuffer<T>,
}

#[cfg(feature = "cuda")]
impl<T: DeviceCopy> CudaBuffer<T> {
    /// Creates a new uninitialized CUDA buffer of the specified length.
    ///
    /// # Errors
    /// Returns an error if CUDA memory allocation fails.
    pub fn new(len: usize) -> CudaResult<Self> {
        let inner = unsafe { DeviceBuffer::uninitialized(len) }
            .map_err(|e| CudaError::Driver(e.to_string()))?;
        Ok(Self { inner })
    }

    /// Creates a CUDA buffer from a host slice, copying data to the device.
    ///
    /// # Errors
    /// Returns an error if memory allocation or data transfer fails.
    pub fn from_host(slice: &[T]) -> CudaResult<Self> {
        let inner =
            DeviceBuffer::from_slice(slice).map_err(|e| CudaError::Driver(e.to_string()))?;
        Ok(Self { inner })
    }

    /// Copies data from the device buffer back to the host slice.
    ///
    /// # Errors
    /// Returns an error if the data transfer fails.
    pub fn to_host(&self, slice: &mut [T]) -> CudaResult<()> {
        self.inner
            .copy_to(slice)
            .map_err(|e| CudaError::Driver(e.to_string()))
    }

    /// Returns the number of elements in the buffer.
    #[must_use]
    pub fn len(&self) -> usize {
        self.inner.len()
    }

    /// Returns `true` if the buffer contains no elements.
    #[must_use]
    pub fn is_empty(&self) -> bool {
        self.inner.is_empty()
    }

    /// Returns the device pointer for this buffer.
    #[must_use]
    pub fn as_device_ptr(&self) -> cust::memory::DevicePointer<T> {
        self.inner.as_device_ptr()
    }
}

#[cfg(not(feature = "cuda"))]
pub struct CudaBuffer<T> {
    _phantom: std::marker::PhantomData<T>,
}

#[cfg(not(feature = "cuda"))]
impl<T> CudaBuffer<T> {
    pub fn new(_len: usize) -> CudaResult<Self> {
        Err(CudaError::NotEnabled)
    }

    pub fn from_host(_slice: &[T]) -> CudaResult<Self> {
        Err(CudaError::NotEnabled)
    }

    pub fn to_host(&self, _slice: &mut [T]) -> CudaResult<()> {
        Err(CudaError::NotEnabled)
    }

    pub fn len(&self) -> usize {
        0
    }
    pub fn is_empty(&self) -> bool {
        true
    }
}

File: rune-curs\src\archetypes.rs
=================================
//! Generative Archetype Engine for CUDA kernels.
//!
//! This module provides the `ArchetypeEngine` that compiles CUDA kernel templates
//! into PTX modules on demand, with caching for performance.

use std::{
    fs,
    path::{Path, PathBuf},
    process::Command,
};

use cust::module::Module;
use sha2::{Digest, Sha256};

/// Engine for generating and compiling CUDA kernel archetypes from templates.
pub struct ArchetypeEngine {
    cache_dir: PathBuf,
}

impl Default for ArchetypeEngine {
    fn default() -> Self {
        Self::new()
    }
}

impl ArchetypeEngine {
    /// Creates a new `ArchetypeEngine` with default cache directory.
    #[must_use]
    pub fn new() -> Self {
        Self {
            cache_dir: Path::new("target").join("rune").join("cache"),
        }
    }

    /// Compiles an archetype kernel from the template by replacing parameters and caching the PTX.
    ///
    /// # Arguments
    /// * `func_name` - The function name to use in the kernel
    /// * `d_dim` - The dimension parameter for the kernel
    ///
    /// # Returns
    /// A compiled CUDA module ready for kernel execution
    ///
    /// # Errors
    /// Returns an error if template loading, code generation, file I/O, or CUDA compilation fails.
    pub fn compile_archetype(
        &self,
        func_name: &str,
        d_dim: usize,
    ) -> Result<Module, Box<dyn std::error::Error>> {
        // Load the template
        let template = include_str!("archetypes/row_dot.cu.template");

        // Instantiate the template by replacing placeholders
        let code = template
            .replace("$FUNC_NAME", func_name)
            .replace("$D_DIM", &d_dim.to_string());

        // Compute SHA-256 hash of the instantiated code for caching
        let mut hasher = Sha256::new();
        hasher.update(&code);
        let hash = format!("{:x}", hasher.finalize());

        // Define cache paths
        let ptx_path = self.cache_dir.join(format!("{hash}.ptx"));
        let cu_path = self.cache_dir.join(format!("{hash}.cu"));

        // Compile if PTX doesn't exist
        if !ptx_path.exists() {
            // Ensure cache directory exists
            fs::create_dir_all(&self.cache_dir)?;

            // Write the instantiated CUDA code to a temporary file
            fs::write(&cu_path, &code)?;

            // Compile using nvcc
            let output = Command::new("nvcc")
                .args([
                    "-ptx",
                    "-o",
                    &ptx_path.to_string_lossy(),
                    &cu_path.to_string_lossy(),
                ])
                .output()?;

            if !output.status.success() {
                return Err(format!(
                    "nvcc compilation failed: {}",
                    String::from_utf8_lossy(&output.stderr)
                )
                .into());
            }
        }

        // Load the PTX module
        let module = Module::from_file(&ptx_path)?;

        Ok(module)
    }
}

File: hydron-ffi\pkg\package.json
=================================
{
  "name": "hydron-ffi",
  "type": "module",
  "description": "FFI wrapper crate for hydron geometry core (exports C ABI and wasm-bindgen wrappers)",
  "version": "0.0.1",
  "license": "MIT OR Apache-2.0",
  "files": [
    "hydron_ffi_bg.wasm",
    "hydron_ffi.js",
    "hydron_ffi.d.ts"
  ],
  "main": "hydron_ffi.js",
  "types": "hydron_ffi.d.ts",
  "sideEffects": [
    "./snippets/*"
  ]
}

File: rune-curs\src\lib.rs
==========================
//! CUDA/RUNE bridge crate (curs).
//! Provides device runtime wrappers and kernel entry points.

use thiserror::Error;

#[derive(Debug, Error)]
pub enum CudaError {
    #[error("CUDA feature not enabled")]
    NotEnabled,
    #[error("CUDA kernel or feature not implemented")]
    NotImplemented,
    #[error("Invalid operation: {0}")]
    InvalidOperation(String),
    #[error("CUDA driver error: {0}")]
    Driver(String),
    #[error("CUDA kernel error: {0}")]
    Kernel(String),
}

pub type CudaResult<T> = Result<T, CudaError>;

#[cfg(feature = "cuda")]
pub mod archetypes;
pub mod buffers;
pub mod kernels;
pub mod runtime;
pub mod types;

/// Compute `DomR` scores on GPU: scores[x] = `Σ_o` energy[o] * dot8(coords[o], coords[x]).
/// - `energy` length must equal `coords.len()`
/// - `coords` is flattened and sent to device; kernel computes one score per root.
///
/// Returns the scores as a Vec<f32>.
///
/// # Errors
/// Returns an error if input dimensions don't match, CUDA initialization fails,
/// or GPU kernel execution encounters problems.
#[cfg(feature = "cuda")]
pub fn domr_scores_gpu(energy: &[f32], coords: &[[f32; 8]]) -> CudaResult<Vec<f32>> {
    use cust::prelude::*;

    let n = energy.len();
    if n == 0 || coords.len() != n {
        return Err(CudaError::InvalidOperation(format!(
            "Energy len {} must equal coords len {}",
            energy.len(),
            coords.len()
        )));
    }
    // Init CUDA context
    let _ctx = cust::quick_init().map_err(|e| CudaError::Driver(e.to_string()))?;

    // Load embedded PTX
    let module = Module::from_ptx(DOMR_PTX, &[]).map_err(|e| CudaError::Kernel(e.to_string()))?;
    let func = module
        .get_function("domr_kernel")
        .map_err(|e| CudaError::Kernel(e.to_string()))?;

    let flat_coords: Vec<f32> = coords.iter().flat_map(|r| r.iter().copied()).collect();
    let d_energy =
        DeviceBuffer::from_slice(energy).map_err(|e| CudaError::Driver(e.to_string()))?;
    let d_coords =
        DeviceBuffer::from_slice(&flat_coords).map_err(|e| CudaError::Driver(e.to_string()))?;
    let d_scores = unsafe { DeviceBuffer::<f32>::uninitialized(n) }
        .map_err(|e| CudaError::Driver(e.to_string()))?;

    let block = 128u32;
    #[allow(clippy::manual_div_ceil)]
    #[allow(clippy::cast_possible_truncation)]
    let grid = ((n as u32) + block - 1) / block;
    let stream =
        Stream::new(StreamFlags::DEFAULT, None).map_err(|e| CudaError::Driver(e.to_string()))?;

    #[allow(clippy::cast_possible_truncation)]
    #[allow(clippy::cast_possible_wrap)]
    unsafe {
        launch!(
            func<<<grid, block, 0, stream>>>(
                d_energy.as_device_ptr(),
                d_coords.as_device_ptr(),
                d_scores.as_device_ptr(),
                n as i32
            )
        )
        .map_err(|e| CudaError::Kernel(e.to_string()))?;
    }
    stream
        .synchronize()
        .map_err(|e| CudaError::Driver(e.to_string()))?;

    let mut scores = vec![0.0f32; n];
    d_scores
        .copy_to(&mut scores)
        .map_err(|e| CudaError::Driver(e.to_string()))?;
    Ok(scores)
}

/// Fallback when the `cuda` feature is not enabled.
#[cfg(not(feature = "cuda"))]
pub fn domr_scores_gpu(_energy: &[f32], _coords: &[[f32; 8]]) -> CudaResult<Vec<f32>> {
    Err(CudaError::NotEnabled)
}

// Embedded PTX for domr_kernel
#[cfg(feature = "cuda")]
const DOMR_PTX: &str = r"
.version 6.0
.target sm_30
.address_size 64

.visible .entry domr_kernel(
    .param .u64 energy,
    .param .u64 coords,
    .param .u64 scores,
    .param .u32 n
) {
    .reg .pred p;
    .reg .f32 acc, dot, cx0,cx1,cx2,cx3,cx4,cx5,cx6,cx7, co;
    .reg .s32 idx, nval, o;
    .reg .u64 eptr, cptr, sptr, base;

    ld.param.u64 eptr, [energy];
    ld.param.u64 cptr, [coords];
    ld.param.u64 sptr, [scores];
    ld.param.u32 nval, [n];
    mov.u32 idx, %tid.x;
    mad.lo.s32 idx, %ctaid.x, %ntid.x, idx;
    setp.ge.s32 p, idx, nval;
    @p ret;

    // load coords[idx]
    mul.wide.s32 base, idx, 32;
    add.s64 base, cptr, base;
    ld.global.f32 cx0, [base+0];
    ld.global.f32 cx1, [base+4];
    ld.global.f32 cx2, [base+8];
    ld.global.f32 cx3, [base+12];
    ld.global.f32 cx4, [base+16];
    ld.global.f32 cx5, [base+20];
    ld.global.f32 cx6, [base+24];
    ld.global.f32 cx7, [base+28];

    mov.f32 acc, 0f00000000;
    mov.s32 o, 0;
L_loop:
    setp.ge.s32 p, o, nval;
    @p bra L_end;
    mul.wide.s32 base, o, 32;
    add.s64 base, cptr, base;
    ld.global.f32 dot, [base+0];
    mul.f32 dot, dot, cx0;
    ld.global.f32 co, [base+4];
    fma.rn.f32 dot, co, cx1, dot;
    ld.global.f32 co, [base+8];
    fma.rn.f32 dot, co, cx2, dot;
    ld.global.f32 co, [base+12];
    fma.rn.f32 dot, co, cx3, dot;
    ld.global.f32 co, [base+16];
    fma.rn.f32 dot, co, cx4, dot;
    ld.global.f32 co, [base+20];
    fma.rn.f32 dot, co, cx5, dot;
    ld.global.f32 co, [base+24];
    fma.rn.f32 dot, co, cx6, dot;
    ld.global.f32 co, [base+28];
    fma.rn.f32 dot, co, cx7, dot;

    ld.global.f32 co, [eptr + o*4];
    fma.rn.f32 acc, co, dot, acc;
    add.s32 o, o, 1;
    bra L_loop;
L_end:
    mul.wide.s32 base, idx, 4;
    add.s64 base, sptr, base;
    st.global.f32 [base], acc;
    ret;
}
";

File: rune-curs\src\types.rs
============================
//! Device-side data layout descriptors (feature-gated).

use super::buffers::CudaBuffer;
use super::{CudaError, CudaResult};

pub struct CudaDomRData {
    pub energy: CudaBuffer<f32>,
    pub coords: CudaBuffer<f32>, // flattened AoS
    pub scores: CudaBuffer<f32>,
    pub n: usize,
}

impl CudaDomRData {
    /// Creates new CUDA data structures from host memory.
    ///
    /// # Errors
    /// Returns an error if data dimensions don't match or CUDA memory operations fail.
    #[cfg(feature = "cuda")]
    pub fn new(energy_host: &[f32], coords_host: &[[f32; 8]]) -> CudaResult<Self> {
        let n = energy_host.len();
        if coords_host.len() != n {
            return Err(CudaError::InvalidOperation(
                "coords length must match energy length".into(),
            ));
        }
        let energy = CudaBuffer::from_host(energy_host)?;
        let flat: Vec<f32> = coords_host.iter().flat_map(|r| r.iter().copied()).collect();
        let coords = CudaBuffer::from_host(&flat)?;
        let scores = CudaBuffer::new(n)?;
        Ok(Self {
            energy,
            coords,
            scores,
            n,
        })
    }

    #[cfg(not(feature = "cuda"))]
    pub fn new(_energy_host: &[f32], _coords_host: &[[f32; 8]]) -> CudaResult<Self> {
        Err(CudaError::NotEnabled)
    }
}

File: rune-curs\src\mod.rs
==========================
//! `rune-curs`: The CUDA/RUST bridge for the RUNE ecosystem.
//!
//! This crate provides the low-level substrate for compiling and executing
//! CUDA kernels, orchestrated by the `hydron` evaluation engine. It is
//! feature-gated to ensure that projects without a CUDA toolchain can
//! build without issue.
//!
//! The primary capabilities include:
//! - A generative **Archetype Engine** for compiling templated CUDA kernels.
//! - Safe wrappers for CUDA device context, memory buffers, and module loading.
//! - A clear FFI boundary that is not exposed to the end user.

use thiserror::Error;

/// The primary error type for all operations within the `rune-curs` crate.
#[derive(Debug, Error)]
pub enum CudaError {
    #[error("The `cuda` feature is not enabled in this build.")]
    NotEnabled,
    #[error("This CUDA kernel or feature is not yet implemented.")]
    NotImplemented,
    #[error("Invalid operation: {0}")]
    InvalidOperation(String),
    #[error("A CUDA driver API call failed: {0}")]
    Driver(String),
    #[error("A CUDA kernel execution failed: {0}")]
    Kernel(String),
}

/// A specialized `Result` type for `rune-curs` operations.
pub type CudaResult<T> = Result<T, CudaError>;

// Declare all modules, properly gated by the `cuda` feature.
// This ensures a clean build for non-CUDA targets.

#[cfg(feature = "cuda")]
pub mod archetypes;

#[cfg(feature = "cuda")]
pub mod buffers;

#[cfg(feature = "cuda")]
pub mod kernels;

#[cfg(feature = "cuda")]
pub mod runtime;

#[cfg(feature = "cuda")]
pub mod types;

File: rune-curs\src\runtime.rs
==============================
//! CUDA context and module loading (feature-gated).

use super::{CudaError, CudaResult};

#[cfg(feature = "cuda")]
use cust::{context::Context, context::ContextFlags, device::Device};
#[cfg(feature = "cuda")]
use std::sync::{Arc, Mutex};

#[cfg(feature = "cuda")]
static CTX: Mutex<Option<Arc<Context>>> = Mutex::new(None);

#[cfg(feature = "cuda")]
/// Ensures a CUDA context is initialized for the current thread.
///
/// # Errors
/// Returns an error if CUDA initialization, device access, or context creation fails.
pub fn ensure_context() -> CudaResult<()> {
    let mut ctx_guard = CTX
        .lock()
        .map_err(|_| CudaError::Driver("Mutex poison".to_string()))?;
    if ctx_guard.is_none() {
        cust::init(cust::CudaFlags::empty()).map_err(|e| CudaError::Driver(e.to_string()))?;
        let device = Device::get_device(0).map_err(|e| CudaError::Driver(e.to_string()))?;
        let context = Context::new(device).map_err(|e| CudaError::Driver(e.to_string()))?;
        context
            .set_flags(ContextFlags::SCHED_AUTO | ContextFlags::MAP_HOST)
            .map_err(|e| CudaError::Driver(e.to_string()))?;
        *ctx_guard = Some(Arc::new(context));
    }
    drop(ctx_guard);
    Ok(())
}

#[cfg(not(feature = "cuda"))]
pub fn ensure_context() -> CudaResult<()> {
    Err(CudaError::NotEnabled)
}

File: hydron-ffi\pkg\hydron_ffi.js
==================================
let wasm;

const EXPECTED_RESPONSE_TYPES = new Set(['basic', 'cors', 'default']);

async function __wbg_load(module, imports) {
    if (typeof Response === 'function' && module instanceof Response) {
        if (typeof WebAssembly.instantiateStreaming === 'function') {
            try {
                return await WebAssembly.instantiateStreaming(module, imports);
            } catch (e) {
                const validResponse = module.ok && EXPECTED_RESPONSE_TYPES.has(module.type);

                if (validResponse && module.headers.get('Content-Type') !== 'application/wasm') {
                    console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n", e);

                } else {
                    throw e;
                }
            }
        }

        const bytes = await module.arrayBuffer();
        return await WebAssembly.instantiate(bytes, imports);
    } else {
        const instance = await WebAssembly.instantiate(module, imports);

        if (instance instanceof WebAssembly.Instance) {
            return { instance, module };
        } else {
            return instance;
        }
    }
}

function __wbg_get_imports() {
    const imports = {};
    imports.wbg = {};

    return imports;
}

function __wbg_finalize_init(instance, module) {
    wasm = instance.exports;
    __wbg_init.__wbindgen_wasm_module = module;

    return wasm;
}

function initSync(module) {
    if (wasm !== undefined) return wasm;

    if (typeof module !== 'undefined') {
        if (Object.getPrototypeOf(module) === Object.prototype) {
            ({module} = module)
        } else {
            console.warn('using deprecated parameters for `initSync()`; pass a single object instead')
        }
    }

    const imports = __wbg_get_imports();
    if (!(module instanceof WebAssembly.Module)) {
        module = new WebAssembly.Module(module);
    }
    const instance = new WebAssembly.Instance(module, imports);
    return __wbg_finalize_init(instance, module);
}

async function __wbg_init(module_or_path) {
    if (wasm !== undefined) return wasm;

    if (typeof module_or_path !== 'undefined') {
        if (Object.getPrototypeOf(module_or_path) === Object.prototype) {
            ({module_or_path} = module_or_path)
        } else {
            console.warn('using deprecated parameters for the initialization function; pass a single object instead')
        }
    }

    if (typeof module_or_path === 'undefined') {
        module_or_path = new URL('hydron_ffi_bg.wasm', import.meta.url);
    }
    const imports = __wbg_get_imports();

    if (typeof module_or_path === 'string' || (typeof Request === 'function' && module_or_path instanceof Request) || (typeof URL === 'function' && module_or_path instanceof URL)) {
        module_or_path = fetch(module_or_path);
    }

    const { instance, module } = await __wbg_load(await module_or_path, imports);

    return __wbg_finalize_init(instance, module);
}

export { initSync };
export default __wbg_init;

File: rune-hex\src\hex.rs
=========================
/* src/hex.rs */
//! Core implementation of hexadecimal encoding and decoding logic.
//!
//! # ArcMoon Utils – Hexadecimal Transcoding Strategy
//!▫~•◦------------------------------------------------‣
//!
//! This module is designed for integration into ArcMoon Utils to achieve high-performance,
//! reliable transformation between binary data and hexadecimal string representations.
//!
//! ### Key Capabilities
//! - **Zero-Allocation Parsing:** Optimized decoding routines that minimize heap usage.
//! - **Constant-Time Verification:** comparison utilities to mitigate timing attacks during signature verification.
//! - **Embedded Compatibility:** Fully compatible with `#![no_std]` environments via the `alloc` crate.
//!
//! ### Architectural Notes
//! This module serves as the functional core for the crate's public API. It implements
//! the `ToHex` and `FromHex` traits defined in the crate root.
//!
//! ### Example
//! ```rust
//! use rune_hex::hex::{Vertex, RootKind, SemanticDomain};
//!
//! // Create a vertex in E8 semantic space
//! let vertex = Vertex {
//!     id: 0,
//!     kind: RootKind::TypeI,
//!     coords: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
//!     domain: Some(SemanticDomain::Psychology),
//!     confidence: 0.95,
//! };
//! assert_eq!(vertex.id, 0);
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use std::collections::HashMap;
use std::fs;
use std::path::Path;
use std::sync::OnceLock;

use serde::{Deserialize, Serialize};
use thiserror::Error;

#[derive(Debug, Error)]
pub enum HexError {
    #[error("Invalid operation: {0}")]
    InvalidOperation(String),
    #[error("Type mismatch: {0}")]
    TypeMismatch(String),
}

pub type VertexId = u32;

/// ErsRootKind – Rust enum projection of `T:RootKind` from hex.rune.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RootKind {
    TypeI,
    TypeII,
}

/// ErsSemanticDomain – Rust enum projection of `T:SemanticDomain`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SemanticDomain {
    Psychology,
    Relationships,
    Economics,
    Creativity,
    Spirituality,
    Physical,
    Existential,
    Ethics,
    Education,
    Health,
}

/// ErsEmotionType – projection of `T:EmotionType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EmotionType {
    Joy,
    Sorrow,
    Anger,
    Fear,
    Surprise,
    Disgust,
    Love,
    Hate,
    Hope,
    Despair,
    Pride,
    Shame,
    Awe,
    Envy,
    Guilt,
    Gratitude,
    Nostalgia,
    Serenity,
    Empathy,
    Compassion,
    Jealousy,
    Loneliness,
    Belonging,
    Confidence,
    Insecurity,
    Embarrassment,
    Humility,
    Frustration,
    Calm,
    Anxiety,
}

/// ErsCognitiveType – projection of `T:CognitiveType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CognitiveType {
    Attention,
    Memory,
    Learning,
    Perception,
    Reasoning,
    ProblemSolving,
    DecisionMaking,
    Planning,
    Creativity,
    SelfAwareness,
    Reflection,
    Introspection,
    Insight,
    Understanding,
    Confusion,
    Clarity,
    Realization,
    ConfirmationBias,
    Anchoring,
    Availability,
    Overconfidence,
}

/// ErsSocialType – projection of `T:SocialType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SocialType {
    Friendship,
    Romance,
    Family,
    Professional,
    Cooperation,
    Competition,
    Conflict,
    Collaboration,
    Acceptance,
    Rejection,
    Inclusion,
    Exclusion,
    Listening,
    Speaking,
    Arguing,
    Negotiating,
    Leader,
    Follower,
    Mentor,
    Student,
}

/// ErsExistentialType – projection of `T:ExistentialType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ExistentialType {
    Meaning,
    Purpose,
    Identity,
    Freedom,
    Responsibility,
    Mortality,
    Authenticity,
    Absurdity,
    Alienation,
    Transcendence,
}

/// ErsPhysicalType – projection of `T:PhysicalType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PhysicalType {
    Pain,
    Pleasure,
    Hunger,
    Thirst,
    Fatigue,
    Energy,
    Touch,
    Temperature,
    Movement,
    Balance,
    Health,
    Illness,
}

/// ErsEthicalType – projection of `T:EthicalType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EthicalType {
    Righteousness,
    Compassion,
    Justice,
    Fairness,
    Integrity,
    Honesty,
    Empathy,
    Responsibility,
    Duty,
    Virtue,
    Temptation,
    Guilt,
}

/// ErsCreativeType – projection of `T:CreativeType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CreativeType {
    Inspiration,
    Imagination,
    Innovation,
    Expression,
    Design,
    Artistry,
    Invention,
    Discovery,
    Revelation,
    Synthesis,
    Originality,
    Vision,
}

/// ErsSpiritualType – projection of `T:SpiritualType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SpiritualType {
    Meditation,
    Prayer,
    Contemplation,
    Transcendence,
    Enlightenment,
    Devotion,
    Surrender,
    Grace,
    Sacredness,
    Mysticism,
    Presence,
    Unity,
}

/// ErsEconomicType – projection of `T:EconomicType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EconomicType {
    Wealth,
    Poverty,
    Value,
    Exchange,
    Trade,
    Investment,
    Production,
    Consumption,
    Scarcity,
    Abundance,
    Profit,
    Loss,
}

/// ErsHealthType – projection of `T:HealthType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HealthType {
    Wellness,
    Illness,
    Healing,
    Recovery,
    Vitality,
    Fatigue,
    Balance,
    Imbalance,
    Strength,
    Weakness,
    Resilience,
    Fragility,
}

/// ErsGSLFrame – projection of `T:GSLFrame`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum GSLFrame {
    Unrestricted,
    Restricted,
    Constrained,
}

/// ErsWeylSemanticAddress – projection of `T:WeylSemanticAddress`.
#[derive(Debug, Clone)]
pub struct WeylSemanticAddress {
    pub heads: Vec<[f32; 8]>,
    pub tails: Vec<[f32; 8]>,
    pub timestamp: f64,
    pub context: String,
}

/// ErsHumanExperience – projection of `T:HumanExperience`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HumanExperience {
    Emotional(EmotionType),
    Cognitive(CognitiveType),
    Social(SocialType),
    Existential(ExistentialType),
    Physical(PhysicalType),
    Ethical(EthicalType),
    Creative(CreativeType),
    Spiritual(SpiritualType),
    Economic(EconomicType),
    Health(HealthType),
}

#[derive(Debug, Clone)]
pub struct Axis {
    pub id: String,
    pub index: u8,
    pub plus: String,
    pub minus: String,
    pub weight: f32,
}

#[derive(Debug, Clone)]
pub struct Vertex {
    pub id: VertexId,
    pub kind: RootKind,
    pub coords: [f32; 8],
    pub domain: Option<SemanticDomain>,
    pub confidence: f32,
}

impl Vertex {
    /// Get the primary human experience associated with this vertex.
    ///
    /// This is a heuristic mapping based on the vertex's coordinates and domain.
    /// Returns None if no clear primary experience can be determined.
    pub fn primary_experience(&self) -> Option<HumanExperience> {
        // Map domain to a representative experience
        // This is a simplified heuristic - in practice, would use coordinate analysis
        self.domain.and_then(|domain| match domain {
            SemanticDomain::Psychology => Some(HumanExperience::Emotional(EmotionType::Joy)),
            SemanticDomain::Relationships => Some(HumanExperience::Social(SocialType::Friendship)),
            SemanticDomain::Economics => Some(HumanExperience::Economic(EconomicType::Wealth)),
            SemanticDomain::Creativity => Some(HumanExperience::Creative(CreativeType::Innovation)),
            SemanticDomain::Spirituality => Some(HumanExperience::Spiritual(SpiritualType::Meditation)),
            SemanticDomain::Physical => Some(HumanExperience::Physical(PhysicalType::Touch)),
            SemanticDomain::Existential => Some(HumanExperience::Existential(ExistentialType::Meaning)),
            SemanticDomain::Ethics => Some(HumanExperience::Ethical(EthicalType::Justice)),
            SemanticDomain::Education => Some(HumanExperience::Cognitive(CognitiveType::Learning)),
            SemanticDomain::Health => Some(HumanExperience::Health(HealthType::Wellness)),
        })
    }
}

#[derive(Debug, Clone)]
pub struct Edge {
    pub u: VertexId,
    pub v: VertexId,
    pub strength: f32,
}

/// ErsDomR – Rust projection of `T:DomR` from RUNE.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct DomR {
    pub roots: Vec<u8>,   // dominant root indices (0..240)
    pub scores: Vec<f32>, // corresponding scores
}

/// CSR adjacency for fast traversal.
#[derive(Debug, Clone)]
pub struct CsrGraph {
    pub row_offsets: Vec<u32>,
    pub adjacency: Vec<u32>,
    pub weights: Vec<f32>,
}

#[derive(Debug, Clone)]
pub struct HexGraph {
    pub axes: Vec<Axis>,
    pub coords: Vec<[f32; 8]>,
    pub kinds: Vec<RootKind>,
    pub domains: Vec<Option<SemanticDomain>>,
    pub confidence: Vec<f32>,
    pub edges: CsrGraph,
}

/// Parsed, normalized tables from the `.rune` asset.
struct ParsedTables {
    axes: Vec<Axis>,
    coords_by_type: HashMap<&'static str, Vec<[f32; 8]>>,
}

static TABLES: OnceLock<ParsedTables> = OnceLock::new();
static HOLO_GRAPH: OnceLock<HexGraph> = OnceLock::new();

fn parse_hex() -> Result<ParsedTables, HexError> {
    let path = Path::new("examples/hex.rune");
    let content = fs::read_to_string(path)
        .map_err(|e| HexError::InvalidOperation(format!("Failed to read hex.rune: {e}")))?;

    let mut axes = Vec::new();
    let mut coords_by_type: HashMap<&'static str, Vec<[f32; 8]>> = HashMap::new();

    let mut in_axes = false;
    let mut in_coords = false;
    let mut current_type: Option<String> = None;

    for line in content.lines() {
        let trimmed = line.trim();
        if trimmed.starts_with('#') || trimmed.is_empty() {
            continue;
        }
        if trimmed.starts_with("Axes:") {
            in_axes = true;
            in_coords = false;
            continue;
        }
        if trimmed.starts_with("Coordinates:") {
            in_coords = true;
            in_axes = false;
            continue;
        }
        if in_axes && trimmed.starts_with('-') {
            // Example: - { id: "A", index: 0, plus: "...", minus: "...", weight: 1.0 }
            let mut id = String::new();
            let mut plus = String::new();
            let mut minus = String::new();
            let mut index = 0u8;
            let mut weight = 1.0f32;
            let inner = trimmed.trim_start_matches('-').trim();
            let inner = inner.trim_start_matches('{').trim_end_matches('}');
            for part in inner.split(',') {
                let kv: Vec<_> = part.trim().splitn(2, ':').collect();
                if kv.len() != 2 {
                    continue;
                }
                let key = kv[0].trim();
                let val = kv[1].trim().trim_matches('"');
                match key {
                    "id" => id = val.to_string(),
                    "plus" => plus = val.to_string(),
                    "minus" => minus = val.to_string(),
                    "index" => index = val.parse::<u8>().unwrap_or(0),
                    "weight" => weight = val.parse::<f32>().unwrap_or(1.0),
                    _ => {}
                }
            }
            axes.push(Axis {
                id,
                index,
                plus,
                minus,
                weight,
            });
            continue;
        }
        if in_coords {
            if trimmed.starts_with("T:") && trimmed.ends_with(':') {
                let name = trimmed
                    .trim_end_matches(':')
                    .trim_start_matches("T:")
                    .to_string();
                current_type = Some(name);
                continue;
            }
            if let Some(ref ty) = current_type {
                if trimmed.starts_with(char::is_alphanumeric) {
                    if let Some((_label, vec_part)) = trimmed.split_once(':') {
                        let vec_part = vec_part.trim();
                        if vec_part.starts_with('[') && vec_part.ends_with(']') {
                            let inner = vec_part.trim_start_matches('[').trim_end_matches(']');
                            let nums: Vec<f32> = inner
                                .split(',')
                                .filter_map(|s| s.trim().parse::<f32>().ok())
                                .collect();
                            if nums.len() == 8 {
                                let mut arr = [0.0f32; 8];
                                arr.copy_from_slice(&nums[..]);
                                coords_by_type
                                    .entry(Box::leak(ty.clone().into_boxed_str()))
                                    .or_default()
                                    .push(arr);
                            }
                        }
                    }
                }
            }
        }
    }

    Ok(ParsedTables {
        axes,
        coords_by_type,
    })
}

fn tables() -> &'static ParsedTables {
    TABLES.get_or_init(|| parse_hex().expect("hex parse"))
}

/// Default HexGraph built from the canonical hex.rune asset.
pub fn default_graph() -> &'static HexGraph {
    HOLO_GRAPH.get_or_init(|| {
        HexGraph::from_rune("examples/hex.rune").expect("failed to build default hex graph")
    })
}

/// Lookup coordinates for a human experience using the parsed tables.
pub fn to_e8_coordinates(exp: &HumanExperience) -> [f32; 8] {
    let t = tables();
    match exp {
        HumanExperience::Emotional(e) => pick(&t.coords_by_type, "EmotionType", *e as usize),
        HumanExperience::Cognitive(c) => pick(&t.coords_by_type, "CognitiveType", *c as usize),
        HumanExperience::Social(s) => pick(&t.coords_by_type, "SocialType", *s as usize),
        HumanExperience::Existential(x) => pick(&t.coords_by_type, "ExistentialType", *x as usize),
        HumanExperience::Physical(p) => pick(&t.coords_by_type, "PhysicalType", *p as usize),
        HumanExperience::Ethical(e) => pick(&t.coords_by_type, "EthicalType", *e as usize),
        HumanExperience::Creative(c) => pick(&t.coords_by_type, "CreativeType", *c as usize),
        HumanExperience::Spiritual(s) => pick(&t.coords_by_type, "SpiritualType", *s as usize),
        HumanExperience::Economic(e) => pick(&t.coords_by_type, "EconomicType", *e as usize),
        HumanExperience::Health(h) => pick(&t.coords_by_type, "HealthType", *h as usize),
    }
}

fn pick(map: &HashMap<&'static str, Vec<[f32; 8]>>, key: &'static str, idx: usize) -> [f32; 8] {
    map.get(key)
        .and_then(|v| v.get(idx))
        .copied()
        .unwrap_or([0.0; 8])
}

impl HexGraph {
    /// Build the graph from the canonical `.rune` asset.
    pub fn from_rune<P: AsRef<Path>>(path: P) -> Result<Self, HexError> {
        let _ = path; // path is currently advisory; we rely on the canonical asset.
        let t = tables();
        let axes = t.axes.clone();

        // Generate Type-I vertices (axis pairs with sign permutations).
        let mut coords = Vec::new();
        let mut kinds = Vec::new();
        let mut domains = Vec::new();
        let mut confidence = Vec::new();

        for a in 0..axes.len() {
            for b in (a + 1)..axes.len() {
                let (idx_a, w_a) = (axes[a].index as usize, axes[a].weight);
                let (idx_b, w_b) = (axes[b].index as usize, axes[b].weight);
                let signs = [(1.0, 1.0), (1.0, -1.0), (-1.0, 1.0), (-1.0, -1.0)];
                for (sa, sb) in signs {
                    let mut v = [0.0f32; 8];
                    v[idx_a] = sa * w_a;
                    v[idx_b] = sb * w_b;
                    normalize(&mut v);
                    coords.push(v);
                    kinds.push(RootKind::TypeI);
                    domains.push(None);
                    confidence.push(1.0);
                }
            }
        }

        // Type-II spinors (even parity).
        for mask in 0u16..256 {
            if mask.count_ones() % 2 != 0 {
                continue;
            }
            let mut v = [0.0f32; 8];
            for (i, axis) in axes.iter().enumerate() {
                let sign = if (mask & (1 << i)) != 0 { -0.5 } else { 0.5 };
                v[axis.index as usize] = sign * axis.weight;
            }
            normalize(&mut v);
            coords.push(v);
            kinds.push(RootKind::TypeII);
            domains.push(None);
            confidence.push(1.0);
        }

        // Build edges by inner product threshold 0.5.
        let n = coords.len();
        let mut row_offsets = Vec::with_capacity(n + 1);
        let mut adjacency = Vec::new();
        let mut weights = Vec::new();
        row_offsets.push(0);
        for i in 0..n {
            for j in (i + 1)..n {
                let dot: f32 = coords[i]
                    .iter()
                    .zip(coords[j].iter())
                    .map(|(a, b)| a * b)
                    .sum();
                if (dot - 0.5).abs() <= 1e-4 {
                    adjacency.push(j as u32);
                    weights.push(dot);
                }
            }
            row_offsets.push(adjacency.len() as u32);
        }

        Ok(Self {
            axes,
            coords,
            kinds,
            domains,
            confidence,
            edges: CsrGraph {
                row_offsets,
                adjacency,
                weights,
            },
        })
    }

    /// Borrow packed coordinates (AoS) for SIMD/GPU export.
    pub fn coords(&self) -> &[[f32; 8]] {
        &self.coords
    }

    /// Borrow CSR adjacency (row_offsets, adjacency, weights).
    pub fn csr(&self) -> (&[u32], &[u32], &[f32]) {
        (
            &self.edges.row_offsets,
            &self.edges.adjacency,
            &self.edges.weights,
        )
    }

    /// Find k-nearest vertices to given coordinates in semantic space.
    ///
    /// Returns vector of cloned Vertex structs sorted by distance.
    pub fn find_nearest_vertices(&self, coords: &[f32; 8], k: usize) -> Vec<Vertex> {
        let mut candidates: Vec<(usize, f32)> = self
            .coords
            .iter()
            .enumerate()
            .map(|(idx, vertex_coords)| (idx, l2(coords, vertex_coords)))
            .collect();

        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));

        candidates
            .into_iter()
            .take(k)
            .map(|(idx, _dist)| Vertex {
                id: idx as VertexId,
                kind: self.kinds[idx],
                coords: self.coords[idx],
                domain: self.domains[idx],
                confidence: self.confidence[idx],
            })
            .collect()
    }

    /// Calculate semantic confidence score for given coordinates.
    ///
    /// Confidence decreases as distance from nearest vertex increases.
    /// Returns value between 0.0 and 1.0.
    pub fn calculate_semantic_confidence(&self, coords: &[f32; 8]) -> f32 {
        let (_nearest_id, distance) = self.nearest_vertex(coords);
        // Confidence decreases as distance increases (inverse relationship)
        1.0 / (1.0 + distance)
    }

    /// Get all vertices belonging to a specific semantic domain.
    ///
    /// Note: Current implementation returns empty vec as domains are not yet
    /// populated in the graph construction. This is a placeholder for future
    /// domain assignment logic.
    pub fn vertices_by_domain(&self, target_domain: SemanticDomain) -> Vec<Vertex> {
        self.domains
            .iter()
            .enumerate()
            .filter_map(|(idx, domain_opt)| {
                domain_opt.and_then(|domain| {
                    if domain == target_domain {
                        Some(Vertex {
                            id: idx as VertexId,
                            kind: self.kinds[idx],
                            coords: self.coords[idx],
                            domain: Some(domain),
                            confidence: self.confidence[idx],
                        })
                    } else {
                        None
                    }
                })
            })
            .collect()
    }
}

fn normalize(v: &mut [f32; 8]) {
    let n2: f32 = v.iter().map(|x| x * x).sum();
    if n2 > 1e-9 {
        let inv = 1.0 / n2.sqrt();
        for x in v {
            *x *= inv;
        }
    }
}

pub trait SemanticSpace {
    fn nearest_vertex(&self, query: &[f32; 8]) -> (VertexId, f32);
    fn nearest_k(&self, query: &[f32; 8], k: usize) -> Vec<(VertexId, f32)>;
}

impl SemanticSpace for HexGraph {
    fn nearest_vertex(&self, query: &[f32; 8]) -> (VertexId, f32) {
        let mut best = (0u32, f32::MAX);
        for (i, v) in self.coords.iter().enumerate() {
            let d = l2(query, v);
            if d < best.1 {
                best = (i as u32, d);
            }
        }
        best
    }

    fn nearest_k(&self, query: &[f32; 8], k: usize) -> Vec<(VertexId, f32)> {
        let mut out = Vec::with_capacity(k);
        for (i, v) in self.coords.iter().enumerate() {
            let d = l2(query, v);
            if out.len() < k {
                out.push((i as u32, d));
                out.sort_by(|a, b| a.1.total_cmp(&b.1));
            } else if let Some(last) = out.last_mut() {
                if d < last.1 {
                    *last = (i as u32, d);
                    out.sort_by(|a, b| a.1.total_cmp(&b.1));
                }
            }
        }
        out
    }
}

#[inline(always)]
fn l2(a: &[f32; 8], b: &[f32; 8]) -> f32 {
    let mut sum = 0.0;
    sum += (a[0] - b[0]) * (a[0] - b[0]);
    sum += (a[1] - b[1]) * (a[1] - b[1]);
    sum += (a[2] - b[2]) * (a[2] - b[2]);
    sum += (a[3] - b[3]) * (a[3] - b[3]);
    sum += (a[4] - b[4]) * (a[4] - b[4]);
    sum += (a[5] - b[5]) * (a[5] - b[5]);
    sum += (a[6] - b[6]) * (a[6] - b[6]);
    sum += (a[7] - b[7]) * (a[7] - b[7]);
    sum
}

#[derive(Debug, Clone)]
pub struct SemanticTrajectory {
    pub vertices: Vec<VertexId>,
}

pub trait SemanticPathFinder {
    fn optimal_path(&self, start: VertexId, target: VertexId) -> SemanticTrajectory;
}

impl SemanticPathFinder for HexGraph {
    fn optimal_path(&self, start: VertexId, target: VertexId) -> SemanticTrajectory {
        // Simple Dijkstra on CSR.
        let n = self.coords.len();
        let mut dist = vec![f32::INFINITY; n];
        let mut prev = vec![None; n];
        let mut visited = vec![false; n];
        dist[start as usize] = 0.0;

        for _ in 0..n {
            // pick min unvisited
            let mut u = None;
            let mut best = f32::INFINITY;
            for i in 0..n {
                if !visited[i] && dist[i] < best {
                    best = dist[i];
                    u = Some(i);
                }
            }
            let u = match u {
                Some(x) => x,
                None => break,
            };
            visited[u] = true;
            if u as u32 == target {
                break;
            }
            let start_edge = self.edges.row_offsets[u] as usize;
            let end_edge = self.edges.row_offsets[u + 1] as usize;
            for idx in start_edge..end_edge {
                let v = self.edges.adjacency[idx] as usize;
                let w = self.edges.weights[idx];
                let alt = dist[u] + w;
                if alt < dist[v] {
                    dist[v] = alt;
                    prev[v] = Some(u);
                }
            }
        }

        let mut path = Vec::new();
        let mut cur = target as usize;
        if dist[cur].is_finite() {
            while let Some(p) = prev[cur] {
                path.push(cur as u32);
                cur = p;
            }
            path.push(start);
            path.reverse();
        }
        SemanticTrajectory { vertices: path }
    }
}

/// Simple gradient stepper: move in direction and snap to nearest vertex.
pub fn apply_semantic_gradient(
    graph: &HexGraph,
    start: VertexId,
    steps: usize,
    step_size: f32,
    direction: [f32; 8],
) -> SemanticTrajectory {
    let mut pos = graph.coords[start as usize];
    let mut traj = Vec::with_capacity(steps + 1);
    traj.push(start);
    for _ in 0..steps {
        for i in 0..8 {
            pos[i] += step_size * direction[i];
        }
        normalize(&mut pos);
        let (vid, _) = graph.nearest_vertex(&pos);
        traj.push(vid);
        pos = graph.coords[vid as usize];
    }
    SemanticTrajectory { vertices: traj }
}

/// Geometry diagnostics.
#[derive(Debug, Clone)]
pub struct GeometryReport {
    pub norms: Vec<f32>,
    pub min_pair: Option<((VertexId, VertexId), f32)>,
}

pub fn analyze_geometry(graph: &HexGraph) -> GeometryReport {
    let norms: Vec<f32> = graph
        .coords
        .iter()
        .map(|v| v.iter().map(|x| x * x).sum::<f32>().sqrt())
        .collect();
    let mut min_pair: Option<((VertexId, VertexId), f32)> = None;
    for i in 0..graph.coords.len() {
        for j in (i + 1)..graph.coords.len() {
            let d = l2(&graph.coords[i], &graph.coords[j]).sqrt();
            if let Some((_, best)) = &min_pair {
                if d < *best {
                    min_pair = Some(((i as u32, j as u32), d));
                }
            } else {
                min_pair = Some(((i as u32, j as u32), d));
            }
        }
    }
    GeometryReport { norms, min_pair }
}

/// Domain-specific proximity diagnostics drawn directly from the parsed tables.
#[derive(Debug, Clone)]
pub struct DomainReport {
    pub name: String,
    pub min_norm: f32,
    pub max_norm: f32,
    pub mean_norm: f32,
    pub closest_pair: Option<((usize, usize), f32)>,
}

pub fn analyze_domains() -> Vec<DomainReport> {
    let t = tables();
    let mut reports = Vec::new();
    for (name, vecs) in &t.coords_by_type {
        if vecs.is_empty() {
            continue;
        }
        let norms: Vec<f32> = vecs
            .iter()
            .map(|v| v.iter().map(|x| x * x).sum::<f32>().sqrt())
            .collect();
        let min_norm = norms.iter().cloned().fold(f32::INFINITY, f32::min);
        let max_norm = norms.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
        let mean_norm = norms.iter().sum::<f32>() / norms.len() as f32;
        let mut closest: Option<((usize, usize), f32)> = None;
        for i in 0..vecs.len() {
            for j in (i + 1)..vecs.len() {
                let d = l2(&vecs[i], &vecs[j]).sqrt();
                match closest {
                    Some((_, best)) if d >= best => {}
                    _ => closest = Some(((i, j), d)),
                }
            }
        }
        reports.push(DomainReport {
            name: (*name).to_string(),
            min_norm,
            max_norm,
            mean_norm,
            closest_pair: closest,
        });
    }
    reports
}

/// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
/// GeoCel trajectory generation implementation.
/// Provides dynamic navigation through the E8 semantic lattice using
/// momentum dynamics and stochastic processes.
pub mod geocel {
    use super::*;

    /// Primary GeoCel trajectory generator using intent and anima-driven navigation.
    pub fn spawn_surveyor_worm(
        intent: &str,
        frame: GSLFrame,
        anima: f32,
        graph: &HexGraph,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        // Create semantic address from intent (stub implementation)
        let address = WeylSemanticAddress::from_text_intent(intent, anima)?;

        // Apply momentum dynamics
        let evolution = apply_momentum_dynamics(&address, anima)?;

        // Quantize to E8 roots based on frame constraints
        let quantized = quantize_to_e8_roots(&evolution, frame, graph)?;

        // Generate final trajectory
        generate_trajectory(&quantized, graph)
    }

    impl WeylSemanticAddress {
        /// Create semantic address from text intent using basic keyword mapping.
        pub fn from_text_intent(intent: &str, _anima: f32) -> Result<Self, HexError> {
            let timestamp = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs_f64();

            // Basic intent parsing - map keywords to semantic heads
            let mut heads = Vec::new();
            let context = intent.to_string();

            // Extract key emotional concepts and map to coordinates
            if intent.contains("fear") {
                heads.push([-0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -0.5]); // Fear coordinates
            }
            if intent.contains("courage") {
                heads.push([1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5]); // Confidence coordinates
            }
            if intent.contains("love") {
                heads.push([1.0, 0.0, 0.5, 0.5, 0.5, 0.0, 1.0, 0.0]); // Love coordinates
            }

            if heads.is_empty() {
                // Default semantic head if no keywords found
                heads.push([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]);
            }

            Ok(WeylSemanticAddress {
                heads,
                tails: vec![], // Empty tails for initial address
                timestamp,
                context,
            })
        }

        /// Apply momentum dynamics to semantic address.
        pub fn apply_momentum_dynamics(&self, anima: f32) -> Result<Vec<[f32; 8]>, HexError> {
            let mut evolution = Vec::new();

            for head in &self.heads {
                let mut current = *head;
                evolution.push(current);

                // Apply momentum steps with noise injection
                for _ in 0..10 {
                    current = momentum_step(&current, anima);
                    current = noise_injection(&current, anima);
                    current = quantize_to_valid_root(&current);
                    evolution.push(current);
                }
            }

            Ok(evolution)
        }
    }

    /// Apply momentum step: accelerate in current direction with small random perturbation.
    pub fn momentum_step(vec: &[f32; 8], anima: f32) -> [f32; 8] {
        let mut normalized = *vec;
        normalize(&mut normalized);

        let mut result = *vec;
        for i in 0..8 {
            result[i] += anima * normalized[i] + 0.1 * random_unit_vector()[i];
        }
        normalize(&mut result);
        result
    }

    /// Add controlled noise to vector.
    pub fn noise_injection(vec: &[f32; 8], anima: f32) -> [f32; 8] {
        let mut result = *vec;
        let noise = gaussian_noise();
        for i in 0..8 {
            result[i] += anima * 0.3 * noise;
        }
        result
    }

    /// Quantize vector to nearest valid E8 root.
    pub fn quantize_to_valid_root(vec: &[f32; 8]) -> [f32; 8] {
        // Find nearest E8 root (simplified - would use graph lookup in full implementation)
        let default_graph = default_graph();
        let (nearest_idx, _) = default_graph.nearest_vertex(vec);
        default_graph.coords[nearest_idx as usize]
    }

    /// Apply momentum dynamics with specified anima (high-level interface).
    pub fn apply_momentum_dynamics(
        addr: &WeylSemanticAddress,
        anima: f32,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        addr.apply_momentum_dynamics(anima)
    }

    /// Quantize trajectory points to E8 roots with frame constraints.
    pub fn quantize_to_e8_roots(
        evolution: &[[f32; 8]],
        _frame: GSLFrame,
        graph: &HexGraph,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        let mut quantized = Vec::new();

        for point in evolution {
            let (nearest_idx, _) = graph.nearest_vertex(point);
            quantized.push(graph.coords[nearest_idx as usize]);
        }

        Ok(quantized)
    }

    /// Generate final smooth trajectory from quantized points.
    pub fn generate_trajectory(
        evolution: &[[f32; 8]],
        _graph: &HexGraph,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        let mut trajectory = Vec::new();
        trajectory.extend_from_slice(evolution);
        Ok(trajectory)
    }

    /// Generate random unit vector for perturbations.
    fn random_unit_vector() -> [f32; 8] {
        use std::f32::consts::PI;
        let mut vec = [0.0f32; 8];
        for i in 0..8 {
            vec[i] = (i as f32 * PI / 4.0).sin() * 0.1; // Deterministic pseudo-random
        }
        normalize(&mut vec);
        vec
    }

    /// Generate gaussian noise (simplified).
    fn gaussian_noise() -> f32 {
        // Simplified gaussian using Box-Muller transform approximation
        (std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_nanos() as f32
            * 0.000_000_000_1)
            .sin()
    }
}

pub fn domr_cpu(graph: &HexGraph, energy: &[f32], n_dr: usize) -> Result<DomR, HexError> {
    if energy.len() != graph.coords.len() {
        return Err(HexError::TypeMismatch(format!(
            "Energy length {} must match root count {}",
            energy.len(),
            graph.coords.len()
        )));
    }
    if n_dr == 0 || n_dr > graph.coords.len() {
        return Err(HexError::InvalidOperation(
            "N_DR must be between 1 and root count".into(),
        ));
    }
    let mut scores = vec![0.0f32; graph.coords.len()];
    for (x_idx, x) in graph.coords.iter().enumerate() {
        let mut acc = 0.0f32;
        for (o_idx, e) in energy.iter().enumerate() {
            let dot: f32 = graph.coords[o_idx]
                .iter()
                .zip(x.iter())
                .map(|(a, b)| a * b)
                .sum();
            acc += *e * dot;
        }
        scores[x_idx] = acc;
    }
    let mut pairs: Vec<(usize, f32)> = scores.iter().copied().enumerate().collect();
    pairs.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
    let take = n_dr.min(pairs.len());
    let mut roots = Vec::with_capacity(take);
    let mut out_scores = Vec::with_capacity(take);
    for (idx, score) in pairs.into_iter().take(take) {
        roots.push(idx as u8);
        out_scores.push(score);
    }
    Ok(DomR {
        roots,
        scores: out_scores,
    })
}

File: rune-hex\src\lib.rs
=========================
pub mod hex;

File: src\decode\mod.rs
=======================
//! Decoder Implementation
pub mod expansion;
pub mod parser;
pub mod scanner;
pub mod validation;

use serde_json::Value;

use crate::types::{DecodeOptions, ToonResult};

/// Decode a TOON string into any deserializable type.
///
/// This function accepts any type implementing `serde::Deserialize`, including:
/// - Custom structs with `#[derive(Deserialize)]`
/// - `serde_json::Value`
/// - Built-in types (Vec, HashMap, etc.)
///
/// # Examples
///
/// **With custom structs:**
/// ```
/// use serde::Deserialize;
/// use rune_format::{
///     decode,
///     DecodeOptions,
/// };
///
/// #[derive(Deserialize, Debug, PartialEq)]
/// struct User {
///     name: String,
///     age: u32,
/// }
///
/// let toon = "name: Alice\nage: 30";
/// let user: User = decode(toon, &DecodeOptions::default())?;
/// assert_eq!(user.name, "Alice");
/// assert_eq!(user.age, 30);
/// # Ok::<(), rune_format::ToonError>(())
/// ```
///
/// **With JSON values:**
/// ```
/// use serde_json::{
///     json,
///     Value,
/// };
/// use rune_format::{
///     decode,
///     DecodeOptions,
/// };
///
/// let input = "name: Alice\nage: 30";
/// let result: Value = decode(input, &DecodeOptions::default())?;
/// assert_eq!(result["name"], json!("Alice"));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn decode<T: serde::de::DeserializeOwned>(
    input: &str,
    options: &DecodeOptions,
) -> ToonResult<T> {
    let mut parser = parser::Parser::new(input, options.clone())?;
    let value = parser.parse()?;

    // Apply path expansion if enabled (v1.5 feature)
    use crate::types::PathExpansionMode;
    let final_value = if options.expand_paths != PathExpansionMode::Off {
        let json_value = crate::types::JsonValue::from(value);
        let expanded =
            expansion::expand_paths_recursive(json_value, options.expand_paths, options.strict)?;
        Value::from(expanded)
    } else {
        value
    };

    serde_json::from_value(final_value)
        .map_err(|e| crate::types::ToonError::DeserializationError(e.to_string()))
}

/// Decode with strict validation enabled (validates array lengths,
/// indentation).
///
/// # Examples
///
/// ```
/// use serde_json::{
///     json,
///     Value,
/// };
/// use rune_format::decode_strict;
///
/// // Valid array length
/// let result: Value = decode_strict("items[2]: a,b")?;
/// assert_eq!(result["items"], json!(["a", "b"]));
///
/// // Invalid array length (will error)
/// assert!(decode_strict::<Value>("items[3]: a,b").is_err());
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn decode_strict<T: serde::de::DeserializeOwned>(input: &str) -> ToonResult<T> {
    decode(input, &DecodeOptions::new().with_strict(true))
}

/// Decode with strict validation and additional options.
///
/// # Examples
///
/// ```
/// use serde_json::{
///     json,
///     Value,
/// };
/// use rune_format::{
///     decode_strict_with_options,
///     DecodeOptions,
/// };
///
/// let options = DecodeOptions::new()
///     .with_strict(true)
///     .with_delimiter(rune_format::Delimiter::Pipe);
/// let result: Value = decode_strict_with_options("items[2|]: a|b", &options)?;
/// assert_eq!(result["items"], json!(["a", "b"]));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn decode_strict_with_options<T: serde::de::DeserializeOwned>(
    input: &str,
    options: &DecodeOptions,
) -> ToonResult<T> {
    let opts = options.clone().with_strict(true);
    decode(input, &opts)
}

/// Decode without type coercion (strings remain strings).
///
/// # Examples
///
/// ```
/// use serde_json::{
///     json,
///     Value,
/// };
/// use rune_format::decode_no_coerce;
///
/// // Without coercion: quoted strings that look like numbers stay as strings
/// let result: Value = decode_no_coerce("value: \"123\"")?;
/// assert_eq!(result["value"], json!("123"));
///
/// // With default coercion: unquoted "true" becomes boolean
/// let result: Value = rune_format::decode_default("value: true")?;
/// assert_eq!(result["value"], json!(true));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn decode_no_coerce<T: serde::de::DeserializeOwned>(input: &str) -> ToonResult<T> {
    decode(input, &DecodeOptions::new().with_coerce_types(false))
}

/// Decode without type coercion and with additional options.
///
/// # Examples
///
/// ```
/// use serde_json::{
///     json,
///     Value,
/// };
/// use rune_format::{
///     decode_no_coerce_with_options,
///     DecodeOptions,
/// };
///
/// let options = DecodeOptions::new()
///     .with_coerce_types(false)
///     .with_strict(false);
/// let result: Value = decode_no_coerce_with_options("value: \"123\"", &options)?;
/// assert_eq!(result["value"], json!("123"));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn decode_no_coerce_with_options<T: serde::de::DeserializeOwned>(
    input: &str,
    options: &DecodeOptions,
) -> ToonResult<T> {
    let opts = options.clone().with_coerce_types(false);
    decode(input, &opts)
}

/// Decode with default options (strict mode, type coercion enabled).
///
/// Works with any type implementing `serde::Deserialize`.
///
/// # Examples
///
/// **With structs:**
/// ```
/// use serde::Deserialize;
/// use rune_format::decode_default;
///
/// #[derive(Deserialize)]
/// struct Person {
///     name: String,
///     age: u32,
/// }
///
/// let input = "name: Alice\nage: 30";
/// let person: Person = decode_default(input)?;
/// assert_eq!(person.name, "Alice");
/// # Ok::<(), rune_format::ToonError>(())
/// ```
///
/// **With JSON values:**
/// ```
/// use serde_json::{
///     json,
///     Value,
/// };
/// use rune_format::decode_default;
///
/// let input = "tags[3]: reading,gaming,coding";
/// let result: Value = decode_default(input)?;
/// assert_eq!(result["tags"], json!(["reading", "gaming", "coding"]));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn decode_default<T: serde::de::DeserializeOwned>(input: &str) -> ToonResult<T> {
    decode(input, &DecodeOptions::default())
}

#[cfg(test)]
mod tests {
    use core::f64;

    use serde_json::json;

    use super::*;

    #[test]
    fn test_decode_null() {
        assert_eq!(decode_default::<Value>("null").unwrap(), json!(null));
    }

    #[test]
    fn test_decode_bool() {
        assert_eq!(decode_default::<Value>("true").unwrap(), json!(true));
        assert_eq!(decode_default::<Value>("false").unwrap(), json!(false));
    }

    #[test]
    fn test_decode_number() {
        assert_eq!(decode_default::<Value>("42").unwrap(), json!(42));
        assert_eq!(
            decode_default::<Value>("3.141592653589793").unwrap(),
            json!(f64::consts::PI)
        );
        assert_eq!(decode_default::<Value>("-5").unwrap(), json!(-5));
    }

    #[test]
    fn test_decode_string() {
        assert_eq!(decode_default::<Value>("hello").unwrap(), json!("hello"));
        assert_eq!(
            decode_default::<Value>("\"hello world\"").unwrap(),
            json!("hello world")
        );
    }

    #[test]
    fn test_decode_simple_object() {
        let input = "name: Alice\nage: 30";
        let result: Value = decode_default(input).unwrap();
        assert_eq!(result["name"], json!("Alice"));
        assert_eq!(result["age"], json!(30));
    }

    #[test]
    fn test_decode_primitive_array() {
        let input = "tags[3]: reading,gaming,coding";
        let result: Value = decode_default(input).unwrap();
        assert_eq!(result["tags"], json!(["reading", "gaming", "coding"]));
    }

    #[test]
    fn test_decode_tabular_array() {
        let input = "users[2]{id,name,role}:\n  1,Alice,admin\n  2,Bob,user";
        let result: Value = decode_default(input).unwrap();
        assert_eq!(
            result["users"],
            json!([
                {"id": 1, "name": "Alice", "role": "admin"},
                {"id": 2, "name": "Bob", "role": "user"}
            ])
        );
    }

    #[test]
    fn test_decode_empty_array() {
        let input = "items[0]:";
        let result: Value = decode_default(input).unwrap();
        assert_eq!(result["items"], json!([]));
    }

    #[test]
    fn test_decode_quoted_strings() {
        let input = "tags[3]: \"true\",\"42\",\"-3.14\"";
        let result: Value = decode_default(input).unwrap();
        assert_eq!(result["tags"], json!(["true", "42", "-3.14"]));
    }
}

File: src\decode\expansion.rs
=============================
use indexmap::IndexMap;

use crate::{
    constants::QUOTED_KEY_MARKER,
    types::{JsonValue as Value, PathExpansionMode, ToonError, ToonResult, is_identifier_segment},
};

pub fn should_expand_key(key: &str, mode: PathExpansionMode) -> Option<Vec<String>> {
    match mode {
        PathExpansionMode::Off => None,
        PathExpansionMode::Safe => {
            // Quoted keys with dots shouldn't be expanded (they were explicitly quoted)
            if key.starts_with(QUOTED_KEY_MARKER) {
                return None;
            }

            if !key.contains('.') {
                return None;
            }

            let segments: Vec<String> = key.split('.').map(String::from).collect();

            if segments.len() < 2 {
                return None;
            }

            // Only expand if all segments are valid identifiers (safety requirement)
            if segments.iter().all(|s| is_identifier_segment(s)) {
                Some(segments)
            } else {
                None
            }
        }
    }
}

pub fn deep_merge_value(
    target: &mut IndexMap<String, Value>,
    segments: &[String],
    value: Value,
    strict: bool,
) -> ToonResult<()> {
    if segments.is_empty() {
        return Ok(());
    }

    if segments.len() == 1 {
        let key = &segments[0];

        // Check for conflicts at leaf level
        if let (Some(existing), true) = (target.get(key), strict) {
            return Err(ToonError::DeserializationError(format!(
                "Path expansion conflict: key '{key}' already exists with value: {existing:?}",
            )));
        }

        target.insert(key.clone(), value);
        return Ok(());
    }

    let first_key = &segments[0];
    let remaining_segments = &segments[1..];

    // Get or create nested object, handling type conflicts
    let nested_obj = if let Some(existing_value) = target.get_mut(first_key) {
        match existing_value {
            Value::Object(obj) => obj,
            _ => {
                if strict {
                    return Err(ToonError::DeserializationError(format!(
                        "Path expansion conflict: key '{first_key}' exists as non-object: \
                         {existing_value:?}",
                    )));
                }
                // Replace non-object with empty object in non-strict mode
                *existing_value = Value::Object(IndexMap::new());
                match existing_value {
                    Value::Object(obj) => obj,
                    _ => unreachable!(),
                }
            }
        }
    } else {
        target.insert(first_key.clone(), Value::Object(IndexMap::new()));
        match target.get_mut(first_key).unwrap() {
            Value::Object(obj) => obj,
            _ => unreachable!(),
        }
    };

    // Recurse into nested object
    deep_merge_value(nested_obj, remaining_segments, value, strict)
}

pub fn expand_paths_in_object(
    obj: IndexMap<String, Value>,
    mode: PathExpansionMode,
    strict: bool,
) -> ToonResult<IndexMap<String, Value>> {
    let mut result = IndexMap::new();

    for (key, mut value) in obj {
        // Expand nested objects first (depth-first)
        if let Value::Object(nested_obj) = value {
            value = Value::Object(expand_paths_in_object(nested_obj, mode, strict)?);
        }

        // Strip marker from quoted keys
        let clean_key = if key.starts_with(QUOTED_KEY_MARKER) {
            key.strip_prefix(QUOTED_KEY_MARKER).unwrap().to_string()
        } else {
            key.clone()
        };

        if let Some(segments) = should_expand_key(&key, mode) {
            deep_merge_value(&mut result, &segments, value, strict)?;
        } else {
            // Check for conflicts with expanded keys
            if let (Some(existing), true) = (result.get(&clean_key), strict) {
                return Err(ToonError::DeserializationError(format!(
                    "Key '{clean_key}' conflicts with existing value: {existing:?}",
                )));
            }
            result.insert(clean_key, value);
        }
    }

    Ok(result)
}

pub fn expand_paths_recursive(
    value: Value,
    mode: PathExpansionMode,
    strict: bool,
) -> ToonResult<Value> {
    match value {
        Value::Object(obj) => {
            let expanded = expand_paths_in_object(obj, mode, strict)?;
            Ok(Value::Object(expanded))
        }
        Value::Array(arr) => {
            let expanded: Result<Vec<_>, _> = arr
                .into_iter()
                .map(|v| expand_paths_recursive(v, mode, strict))
                .collect();
            Ok(Value::Array(expanded?))
        }
        _ => Ok(value),
    }
}

#[cfg(test)]
mod tests {
    use serde_json::json;

    use super::*;

    #[test]
    fn test_should_expand_key_off_mode() {
        assert!(should_expand_key("a.b.c", PathExpansionMode::Off).is_none());
    }

    #[test]
    fn test_should_expand_key_safe_mode() {
        // Valid expansions
        assert_eq!(
            should_expand_key("a.b", PathExpansionMode::Safe),
            Some(vec!["a".to_string(), "b".to_string()])
        );
        assert_eq!(
            should_expand_key("a.b.c", PathExpansionMode::Safe),
            Some(vec!["a".to_string(), "b".to_string(), "c".to_string()])
        );

        // No dots
        assert!(should_expand_key("simple", PathExpansionMode::Safe).is_none());

        // Invalid segments (not IdentifierSegments)
        assert!(should_expand_key("a.bad-key", PathExpansionMode::Safe).is_none());
        assert!(should_expand_key("123.key", PathExpansionMode::Safe).is_none());
    }

    #[test]
    fn test_deep_merge_simple() {
        let mut target = IndexMap::new();
        deep_merge_value(
            &mut target,
            &["a".to_string(), "b".to_string()],
            Value::from(json!(1)),
            true,
        )
        .unwrap();

        let expected = json!({"a": {"b": 1}});
        assert_eq!(Value::Object(target), Value::from(expected));
    }

    #[test]
    fn test_deep_merge_multiple_paths() {
        let mut target = IndexMap::new();

        deep_merge_value(
            &mut target,
            &["a".to_string(), "b".to_string()],
            Value::from(json!(1)),
            true,
        )
        .unwrap();

        deep_merge_value(
            &mut target,
            &["a".to_string(), "c".to_string()],
            Value::from(json!(2)),
            true,
        )
        .unwrap();

        let expected = json!({"a": {"b": 1, "c": 2}});
        assert_eq!(Value::Object(target), Value::from(expected));
    }

    #[test]
    fn test_deep_merge_conflict_strict() {
        let mut target = IndexMap::new();
        target.insert("a".to_string(), Value::from(json!({"b": 1})));

        let result = deep_merge_value(
            &mut target,
            &["a".to_string(), "b".to_string()],
            Value::from(json!(2)),
            true,
        );

        assert!(result.is_err());
    }

    #[test]
    fn test_deep_merge_conflict_non_strict() {
        let mut target = IndexMap::new();
        target.insert("a".to_string(), Value::from(json!({"b": 1})));

        deep_merge_value(
            &mut target,
            &["a".to_string(), "b".to_string()],
            Value::from(json!(2)),
            false,
        )
        .unwrap();

        let expected = json!({"a": {"b": 2}});
        assert_eq!(Value::Object(target), Value::from(expected));
    }

    #[test]
    fn test_expand_paths_in_object() {
        let mut obj = IndexMap::new();
        obj.insert("a.b.c".to_string(), Value::from(json!(1)));
        obj.insert("simple".to_string(), Value::from(json!(2)));

        let result = expand_paths_in_object(obj, PathExpansionMode::Safe, true).unwrap();

        let expected = json!({"a": {"b": {"c": 1}}, "simple": 2});
        assert_eq!(Value::Object(result), Value::from(expected));
    }

    #[test]
    fn test_expand_paths_with_merge() {
        let mut obj = IndexMap::new();
        obj.insert("a.b".to_string(), Value::from(json!(1)));
        obj.insert("a.c".to_string(), Value::from(json!(2)));

        let result = expand_paths_in_object(obj, PathExpansionMode::Safe, true).unwrap();

        let expected = json!({"a": {"b": 1, "c": 2}});
        assert_eq!(Value::Object(result), Value::from(expected));
    }
}

File: src\cli\main.rs
=====================
use std::{
    fs,
    io::{self, Read, Write},
    path::{Path, PathBuf},
};

use anyhow::{Context, Result, bail};
use clap::Parser;
use comfy_table::Table;
use rune_format::{
    decode, encode,
    types::{DecodeOptions, Delimiter, EncodeOptions, Indent, KeyFoldingMode, PathExpansionMode},
};
use serde::Serialize;
use tiktoken_rs::cl100k_base;

#[derive(Parser, Debug)]
#[command(
    name = "toon",
    version = env!("CARGO_PKG_VERSION"),
    author = env!("CARGO_PKG_AUTHORS"),
    about = "Encode JSON to TOON or decode TOON to JSON",
    long_about = "TOON Format CLI - Token-efficient JSON alternative for LLMs

EXAMPLES:
  toon --interactive                       # Launch interactive TUI
  toon -i                                  # Short flag for interactive mode

  toon input.json -o output.toon
  toon input.toon --json-indent 2
  cat data.json | toon -e --stats
  toon input.json --delimiter pipe
  toon input.toon -d --no-coerce

  toon input.json --fold-keys              # Collapse {a:{b:1}} to a.b: 1
  toon input.json --fold-keys --flatten-depth 2
  toon input.toon --expand-paths           # Expand a.b:1 to {\"a\":{\"b\":1}}",
    disable_help_subcommand = true
)]
struct Cli {
    input: Option<String>,

    #[arg(short, long, help = "Launch interactive TUI mode")]
    interactive: bool,

    #[arg(short, long, help = "Output file path")]
    output: Option<PathBuf>,

    #[arg(short, long, help = "Force encode mode (JSON → TOON)")]
    encode: bool,

    #[arg(short, long, help = "Force decode mode (TOON → JSON)")]
    decode: bool,

    #[arg(long, help = "Show token count and savings")]
    stats: bool,

    #[arg(long, value_parser = parse_delimiter, help = "Delimiter: comma, tab, or pipe")]
    delimiter: Option<Delimiter>,

    #[arg(long, value_parser = parse_indent, help = "Indentation spaces")]
    indent: Option<usize>,

    #[arg(long, help = "Disable strict validation (decode)")]
    no_strict: bool,

    #[arg(long, help = "Disable type coercion (decode)")]
    no_coerce: bool,

    #[arg(long, help = "Indent output JSON with N spaces")]
    json_indent: Option<usize>,

    #[arg(
        long,
        help = "Enable key folding (encode): collapse {a:{b:1}} → a.b: 1"
    )]
    fold_keys: bool,

    #[arg(long, help = "Max depth for key folding (default: unlimited)")]
    flatten_depth: Option<usize>,

    #[arg(
        long,
        help = "Enable path expansion (decode): expand a.b:1 → {\"a\":{\"b\":1}}"
    )]
    expand_paths: bool,

    #[arg(long, help = "Execute .rune file for geometric computation")]
    rune: bool,
}

#[derive(Debug, PartialEq)]
enum Operation {
    Encode,
    Decode,
    Rune,
}

fn parse_indent(s: &str) -> Result<usize, String> {
    s.parse::<usize>()
        .map_err(|_| format!("'{s}' is not a valid number"))
}

fn parse_delimiter(s: &str) -> Result<Delimiter, String> {
    match s.to_lowercase().as_str() {
        "comma" | "," => Ok(Delimiter::Comma),
        "tab" | "\t" => Ok(Delimiter::Tab),
        "pipe" | "|" => Ok(Delimiter::Pipe),
        _ => Err(format!(
            "'{s}' is not a valid delimiter. Use 'comma', 'tab', or 'pipe'",
        )),
    }
}

fn get_input(file_arg: Option<&str>) -> Result<String> {
    let mut input_str = String::new();
    let mut reader: Box<dyn Read> = match file_arg {
        Some(path_str) if path_str != "-" => {
            let path = Path::new(path_str);
            Box::new(
                fs::File::open(path)
                    .with_context(|| format!("Failed to open: {}", path.display()))?,
            )
        }
        _ => Box::new(io::stdin()),
    };
    reader
        .read_to_string(&mut input_str)
        .context("Failed to read input")?;
    Ok(input_str)
}

fn write_output(output_path: Option<PathBuf>, content: &str) -> Result<()> {
    let mut writer: Box<dyn Write> = match output_path {
        Some(path) => Box::new(
            fs::File::create(&path)
                .with_context(|| format!("Failed to create: {}", path.display()))?,
        ),
        None => Box::new(io::stdout()),
    };
    writer
        .write_all(content.as_bytes())
        .context("Failed to write output")?;
    Ok(())
}

fn run_encode(cli: &Cli, input: &str) -> Result<()> {
    if input.trim().is_empty() {
        bail!("Input is empty. Provide JSON data via file or stdin");
    }

    let json_value: serde_json::Value =
        serde_json::from_str(input).context("Failed to parse input as JSON")?;

    let mut opts = EncodeOptions::new();
    if let Some(d) = cli.delimiter {
        opts = opts.with_delimiter(d);
    }
    if let Some(i) = cli.indent {
        opts = opts.with_indent(Indent::Spaces(i));
    }

    if cli.fold_keys {
        opts = opts.with_key_folding(KeyFoldingMode::Safe);
        if let Some(depth) = cli.flatten_depth {
            opts = opts.with_flatten_depth(depth);
        }
    }

    let toon_str = encode(&json_value, &opts).context("Failed to encode to TOON")?;

    write_output(cli.output.clone(), &toon_str)?;

    if cli.output.is_none() && !toon_str.ends_with('\n') {
        io::stdout().write_all(b"\n")?;
    }

    if cli.stats {
        let json_bytes = input.len();
        let toon_bytes = toon_str.len();
        let size_savings = 100.0 * (1.0 - (toon_bytes as f64 / json_bytes as f64));

        let bpe = cl100k_base().context("Failed to load tokenizer")?;
        let json_tokens = bpe.encode_with_special_tokens(input).len();
        let toon_tokens = bpe.encode_with_special_tokens(&toon_str).len();
        let token_savings = 100.0 * (1.0 - (toon_tokens as f64 / json_tokens as f64));

        eprintln!("\nStats:");
        let mut table = Table::new();
        table.set_header(vec!["Metric", "JSON", "TOON", "Savings"]);

        table.add_row(vec![
            "Tokens",
            &json_tokens.to_string(),
            &toon_tokens.to_string(),
            &format!("{token_savings:.2}%"),
        ]);

        table.add_row(vec![
            "Size (bytes)",
            &json_bytes.to_string(),
            &toon_bytes.to_string(),
            &format!("{size_savings:.2}%"),
        ]);

        eprintln!("\n{table}\n");
    }

    Ok(())
}

fn run_decode(cli: &Cli, input: &str) -> Result<()> {
    if input.trim().is_empty() {
        write_output(cli.output.clone(), "{}\n")?;
        return Ok(());
    }

    let mut opts = DecodeOptions::new();
    if cli.no_strict {
        opts = opts.with_strict(false);
    }
    if cli.no_coerce {
        opts = opts.with_coerce_types(false);
    }

    if cli.expand_paths {
        opts = opts.with_expand_paths(PathExpansionMode::Safe);
    }

    let json_value: serde_json::Value = decode(input, &opts).context("Failed to decode TOON")?;

    let output_json = match cli.json_indent {
        Some(n) if n > 0 => {
            let mut buf = Vec::new();
            let indent_str = " ".repeat(n);
            let formatter = serde_json::ser::PrettyFormatter::with_indent(indent_str.as_bytes());
            let mut ser = serde_json::Serializer::with_formatter(&mut buf, formatter);
            json_value
                .serialize(&mut ser)
                .context("Failed to serialize JSON")?;
            String::from_utf8(buf).context("Invalid UTF-8 in JSON output")?
        }
        _ => serde_json::to_string(&json_value).context("Failed to serialize JSON")?,
    };

    write_output(cli.output.clone(), &output_json)?;
    if cli.output.is_none() && !output_json.ends_with('\n') {
        io::stdout().write_all(b"\n")?;
    }
    Ok(())
}

fn run_rune(input: &str) -> Result<()> {
    if input.trim().is_empty() {
        bail!("Input .rune file is empty");
    }

    #[cfg(feature = "hydron")]
    {
        use rune_format::rune::hydron::eval::Evaluator;
        use rune_format::rune::parse;

        // Parse the RUNE file
        let statements = parse(input).map_err(|e| anyhow::anyhow!("Parse error: {}", e))?;

        // Create evaluator and execute
        let mut evaluator = Evaluator::new();

        eprintln!("\n=== RUNE Geometric Computation ===\n");

        for (idx, stmt) in statements.iter().enumerate() {
            match evaluator.eval_stmt(stmt) {
                Ok(result) => {
                    eprintln!("[{}] Result: {}", idx + 1, result);
                }
                Err(e) => {
                    eprintln!("Error at statement {}: {}", idx + 1, e);
                }
            }
        }

        eprintln!("\n=== Computation Complete ===\n");

        return Ok(());
    }

    #[cfg(not(feature = "hydron"))]
    bail!("RUNE evaluation requires the 'hydron' feature. Enable it in Cargo.toml");
}

fn determine_operation(cli: &Cli) -> Result<(Operation, bool)> {
    let mut from_stdin = false;
    let mut operation: Option<Operation> = None;

    if cli.interactive {
        bail!("Interactive mode cannot be combined with other operations");
    }

    if cli.encode && cli.decode {
        bail!("Cannot use --encode and --decode simultaneously");
    }

    if cli.encode {
        operation = Some(Operation::Encode);
    } else if cli.decode {
        operation = Some(Operation::Decode);
    }

    let file_arg = cli.input.as_deref();

    match file_arg {
        None | Some("-") => {
            from_stdin = true;
            if operation.is_none() {
                operation = Some(Operation::Encode);
            }
        }
        Some(path_str) => {
            if operation.is_none() {
                let path = Path::new(path_str);
                let ext = path.extension().and_then(|s| s.to_str()).unwrap_or("");
                match ext {
                    "json" => operation = Some(Operation::Encode),
                    "toon" => operation = Some(Operation::Decode),
                    "rune" => operation = Some(Operation::Rune),
                    _ => bail!(
                        "Cannot auto-detect operation for file: {}\nUse -e to encode, -d to decode, or --rune for RUNE files",
                        path.display()
                    ),
                }
            }
        }
    }

    Ok((operation.unwrap(), from_stdin))
}

fn validate_flags(cli: &Cli, operation: &Operation) -> Result<()> {
    match operation {
        Operation::Encode => {
            if cli.no_strict {
                bail!("--no-strict is only valid for decode mode");
            }
            if cli.no_coerce {
                bail!("--no-coerce is only valid for decode mode");
            }
            if cli.json_indent.is_some() {
                bail!("--json-indent is only valid for decode mode");
            }
            if cli.expand_paths {
                bail!("--expand-paths is only valid for decode mode");
            }
        }
        Operation::Decode => {
            if cli.delimiter.is_some() {
                bail!("--delimiter is only valid for encode mode");
            }
            if cli.stats {
                bail!("--stats is only valid for encode mode");
            }
            if cli.indent.is_some() {
                bail!("--indent is only valid for encode mode");
            }
            if cli.fold_keys {
                bail!("--fold-keys is only valid for encode mode");
            }
            if cli.flatten_depth.is_some() {
                bail!("--flatten-depth is only valid for encode mode (use with --fold-keys)");
            }
        }
        Operation::Rune => {
            // RUNE mode has no restrictions on flags
        }
    }

    // Additional validation: flatten-depth requires fold-keys
    if cli.flatten_depth.is_some() && !cli.fold_keys {
        bail!("--flatten-depth requires --fold-keys to be enabled");
    }

    Ok(())
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    // Check if interactive mode is requested
    if cli.interactive {
        return run_interactive();
    }

    let (operation, from_stdin) = determine_operation(&cli)?;
    validate_flags(&cli, &operation)?;

    let input = get_input(cli.input.as_deref()).with_context(|| {
        if from_stdin {
            "Failed to read from stdin"
        } else {
            "Failed to read input file"
        }
    })?;

    match operation {
        Operation::Encode => run_encode(&cli, &input)?,
        Operation::Decode => run_decode(&cli, &input)?,
        Operation::Rune => run_rune(&input)?,
    }

    Ok(())
}

fn run_interactive() -> Result<()> {
    rune_format::tui::run().context("Failed to run interactive TUI")?;
    Ok(())
}

File: src\decode\parser.rs
==========================
use serde_json::{Map, Number, Value};

use crate::{
    constants::{KEYWORDS, MAX_DEPTH, QUOTED_KEY_MARKER},
    decode::{
        scanner::{Scanner, Token},
        validation,
    },
    types::{DecodeOptions, Delimiter, ErrorContext, ToonError, ToonResult},
    utils::validation::validate_depth,
};

/// Context for parsing arrays to determine correct indentation depth.
///
/// Arrays as the first field of list-item objects require special indentation:
/// their content (rows for tabular, items for non-uniform) appears at depth +2
/// relative to the hyphen line, while arrays in other contexts use depth +1.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum ArrayParseContext {
    /// Normal array parsing context (content at depth +1)
    Normal,

    /// Array as first field of list-item object
    /// (content at depth +2 relative to hyphen line)
    ListItemFirstField,
}

/// Parser that builds JSON values from a sequence of tokens.
#[allow(unused)]
pub struct Parser<'a> {
    scanner: Scanner,
    current_token: Token,
    options: DecodeOptions,
    delimiter: Option<Delimiter>,
    input: &'a str,
}

impl<'a> Parser<'a> {
    /// Create a new parser with the given input and options.
    pub fn new(input: &'a str, options: DecodeOptions) -> ToonResult<Self> {
        let mut scanner = Scanner::new(input);
        let chosen_delim = options.delimiter;
        scanner.set_active_delimiter(chosen_delim);
        let current_token = scanner.scan_token()?;

        Ok(Self {
            scanner,
            current_token,
            delimiter: chosen_delim,
            options,
            input,
        })
    }

    /// Parse the input into a JSON value.
    pub fn parse(&mut self) -> ToonResult<Value> {
        if self.options.strict {
            self.validate_indentation(self.scanner.get_last_line_indent())?;
        }
        let value = self.parse_value()?;

        // In strict mode, check for trailing content at root level
        if self.options.strict {
            self.skip_newlines()?;
            if !matches!(self.current_token, Token::Eof) {
                return Err(self
                    .parse_error_with_context(
                        "Multiple values at root level are not allowed in strict mode",
                    )
                    .with_suggestion("Wrap multiple values in an object or array"));
            }
        }

        Ok(value)
    }

    fn advance(&mut self) -> ToonResult<()> {
        self.current_token = self.scanner.scan_token()?;
        Ok(())
    }

    fn skip_newlines(&mut self) -> ToonResult<()> {
        while matches!(self.current_token, Token::Newline) {
            self.advance()?;
        }
        Ok(())
    }

    fn parse_value(&mut self) -> ToonResult<Value> {
        self.parse_value_with_depth(0)
    }

    fn parse_value_with_depth(&mut self, depth: usize) -> ToonResult<Value> {
        validate_depth(depth, MAX_DEPTH)?;

        let had_newline = matches!(self.current_token, Token::Newline);
        self.skip_newlines()?;

        match &self.current_token {
            Token::Null => {
                // Peek ahead to see if this is a key (followed by ':') or a value
                let next_char_is_colon = matches!(self.scanner.peek(), Some(':'));
                if next_char_is_colon {
                    let key = KEYWORDS[0].to_string();
                    self.advance()?;
                    self.parse_object_with_initial_key(key, depth)
                } else {
                    self.advance()?;
                    Ok(Value::Null)
                }
            }
            Token::Bool(b) => {
                let next_char_is_colon = matches!(self.scanner.peek(), Some(':'));
                if next_char_is_colon {
                    let key = if *b {
                        KEYWORDS[1].to_string()
                    } else {
                        KEYWORDS[2].to_string()
                    };
                    self.advance()?;
                    self.parse_object_with_initial_key(key, depth)
                } else {
                    let val = *b;
                    self.advance()?;
                    Ok(Value::Bool(val))
                }
            }
            Token::Integer(i) => {
                let next_char_is_colon = matches!(self.scanner.peek(), Some(':'));
                if next_char_is_colon {
                    let key = i.to_string();
                    self.advance()?;
                    self.parse_object_with_initial_key(key, depth)
                } else {
                    let val = *i;
                    self.advance()?;
                    Ok(serde_json::Number::from(val).into())
                }
            }
            Token::Number(n) => {
                let next_char_is_colon = matches!(self.scanner.peek(), Some(':'));
                if next_char_is_colon {
                    let key = n.to_string();
                    self.advance()?;
                    self.parse_object_with_initial_key(key, depth)
                } else {
                    let val = *n;
                    self.advance()?;
                    // Normalize floats that are actually integers
                    if val.is_finite() && val.fract() == 0.0 && val.abs() <= i64::MAX as f64 {
                        Ok(serde_json::Number::from(val as i64).into())
                    } else {
                        Ok(serde_json::Number::from_f64(val)
                            .ok_or_else(|| {
                                ToonError::InvalidInput(format!("Invalid number: {val}"))
                            })?
                            .into())
                    }
                }
            }
            Token::String(s, _) => {
                let first = s.clone();
                self.advance()?;

                match &self.current_token {
                    Token::Colon | Token::LeftBracket => {
                        self.parse_object_with_initial_key(first, depth)
                    }
                    _ => {
                        // Strings on new indented lines could be missing colons (keys) or values
                        // Only error in strict mode when we know it's a new line
                        if self.options.strict && depth > 0 && had_newline {
                            return Err(self
                                .parse_error_with_context(format!(
                                    "Expected ':' after '{first}' in object context"
                                ))
                                .with_suggestion(
                                    "Add ':' after the key, or place the value on the same line \
                                     as the parent key",
                                ));
                        }

                        // Root-level string value - join consecutive tokens
                        let mut accumulated = first;
                        while let Token::String(next, _) = &self.current_token {
                            if !accumulated.is_empty() {
                                accumulated.push(' ');
                            }
                            accumulated.push_str(next);
                            self.advance()?;
                        }
                        Ok(Value::String(accumulated))
                    }
                }
            }
            Token::LeftBracket => self.parse_root_array(depth),
            Token::Eof => Ok(Value::Object(Map::new())),
            _ => self.parse_object(depth),
        }
    }

    fn parse_object(&mut self, depth: usize) -> ToonResult<Value> {
        validate_depth(depth, MAX_DEPTH)?;

        let mut obj = Map::new();
        // Track the indentation of the first key to ensure all keys align
        let mut base_indent: Option<usize> = None;

        loop {
            while matches!(self.current_token, Token::Newline) {
                self.advance()?;
            }

            if matches!(self.current_token, Token::Eof) {
                break;
            }

            let current_indent = self.scanner.get_last_line_indent();

            if self.options.strict {
                self.validate_indentation(current_indent)?;
            }

            // Once we've seen the first key, all subsequent keys must match its indent
            if let Some(expected) = base_indent {
                if current_indent != expected {
                    break;
                }
            } else {
                base_indent = Some(current_indent);
            }

            let key = match &self.current_token {
                Token::String(s, was_quoted) => {
                    // Mark quoted keys containing dots with a special prefix
                    // so path expansion can skip them
                    if *was_quoted && s.contains('.') {
                        format!("{QUOTED_KEY_MARKER}{s}")
                    } else {
                        s.clone()
                    }
                }
                _ => {
                    return Err(self
                        .parse_error_with_context(format!(
                            "Expected key, found {:?}",
                            self.current_token
                        ))
                        .with_suggestion("Object keys must be strings"));
                }
            };
            self.advance()?;

            let value = if matches!(self.current_token, Token::LeftBracket) {
                self.parse_array(depth)?
            } else {
                if !matches!(self.current_token, Token::Colon) {
                    return Err(self
                        .parse_error_with_context(format!(
                            "Expected ':' or '[', found {:?}",
                            self.current_token
                        ))
                        .with_suggestion("Use ':' for object values or '[' for arrays"));
                }
                self.advance()?;
                self.parse_field_value(depth)?
            };

            obj.insert(key, value);
        }

        Ok(Value::Object(obj))
    }

    fn parse_object_with_initial_key(&mut self, key: String, depth: usize) -> ToonResult<Value> {
        validate_depth(depth, MAX_DEPTH)?;

        let mut obj = Map::new();
        let mut base_indent: Option<usize> = None;

        // Validate indentation for the initial key if in strict mode
        if self.options.strict {
            let current_indent = self.scanner.get_last_line_indent();
            self.validate_indentation(current_indent)?;
        }

        if matches!(self.current_token, Token::LeftBracket) {
            let value = self.parse_array(depth)?;
            obj.insert(key, value);
        } else {
            if !matches!(self.current_token, Token::Colon) {
                return Err(self.parse_error_with_context(format!(
                    "Expected ':', found {:?}",
                    self.current_token
                )));
            }
            self.advance()?;

            let value = self.parse_field_value(depth)?;
            obj.insert(key, value);
        }

        loop {
            // Skip newlines and check if the next line belongs to this object
            while matches!(self.current_token, Token::Newline) {
                self.advance()?;

                if !self.options.strict {
                    while matches!(self.current_token, Token::Newline) {
                        self.advance()?;
                    }
                }

                if matches!(self.current_token, Token::Newline) {
                    continue;
                }

                let next_indent = self.scanner.get_last_line_indent();

                // Check if the next line is at the right indentation level
                let should_continue = if let Some(expected) = base_indent {
                    next_indent == expected
                } else {
                    // First field: use depth-based expected indent
                    let current_depth_indent = self.options.indent.get_spaces() * depth;
                    next_indent == current_depth_indent
                };

                if !should_continue {
                    break;
                }
            }

            if matches!(self.current_token, Token::Eof) {
                break;
            }

            if !matches!(self.current_token, Token::String(_, _)) {
                break;
            }

            if matches!(self.current_token, Token::Eof) {
                break;
            }

            let current_indent = self.scanner.get_last_line_indent();

            if let Some(expected) = base_indent {
                if current_indent != expected {
                    break;
                }
            } else {
                // verify first additional field matches expected depth
                let expected_depth_indent = self.options.indent.get_spaces() * depth;
                if current_indent != expected_depth_indent {
                    break;
                }
            }

            if self.options.strict {
                self.validate_indentation(current_indent)?;
            }

            if base_indent.is_none() {
                base_indent = Some(current_indent);
            }

            let key = match &self.current_token {
                Token::String(s, was_quoted) => {
                    // Mark quoted keys containing dots with a special prefix
                    // so path expansion can skip them
                    if *was_quoted && s.contains('.') {
                        format!("{QUOTED_KEY_MARKER}{s}")
                    } else {
                        s.clone()
                    }
                }
                _ => break,
            };
            self.advance()?;

            let value = if matches!(self.current_token, Token::LeftBracket) {
                self.parse_array(depth)?
            } else {
                if !matches!(self.current_token, Token::Colon) {
                    break;
                }
                self.advance()?;
                self.parse_field_value(depth)?
            };

            obj.insert(key, value);
        }

        Ok(Value::Object(obj))
    }

    fn parse_field_value(&mut self, depth: usize) -> ToonResult<Value> {
        validate_depth(depth, MAX_DEPTH)?;

        if matches!(self.current_token, Token::Newline | Token::Eof) {
            let has_children = if matches!(self.current_token, Token::Newline) {
                let current_depth_indent = self.options.indent.get_spaces() * (depth + 1);
                let next_indent = self.scanner.count_leading_spaces();
                next_indent >= current_depth_indent
            } else {
                false
            };

            if has_children {
                self.parse_value_with_depth(depth + 1)
            } else {
                Ok(Value::Object(Map::new()))
            }
        } else if matches!(self.current_token, Token::LeftBracket) {
            self.parse_value_with_depth(depth + 1)
        } else {
            // Check if there's more content after the current token
            let (rest, had_space) = self.scanner.read_rest_of_line_with_space_info();

            let result = if rest.is_empty() {
                // Single token - convert directly to avoid redundant parsing
                match &self.current_token {
                    Token::String(s, _) => Ok(Value::String(s.clone())),
                    Token::Integer(i) => Ok(serde_json::Number::from(*i).into()),
                    Token::Number(n) => {
                        let val = *n;
                        if val.is_finite() && val.fract() == 0.0 && val.abs() <= i64::MAX as f64 {
                            Ok(serde_json::Number::from(val as i64).into())
                        } else {
                            Ok(serde_json::Number::from_f64(val)
                                .ok_or_else(|| {
                                    ToonError::InvalidInput(format!("Invalid number: {val}"))
                                })?
                                .into())
                        }
                    }
                    Token::Bool(b) => Ok(Value::Bool(*b)),
                    Token::Null => Ok(Value::Null),
                    _ => Err(self.parse_error_with_context("Unexpected token after colon")),
                }
            } else {
                // Multi-token value - reconstruct and re-parse as complete string
                let mut value_str = String::new();

                match &self.current_token {
                    Token::String(s, true) => {
                        // Quoted strings need quotes preserved for re-parsing
                        value_str.push('"');
                        value_str.push_str(&crate::utils::escape_string(s));
                        value_str.push('"');
                    }
                    Token::String(s, false) => value_str.push_str(s),
                    Token::Integer(i) => value_str.push_str(&i.to_string()),
                    Token::Number(n) => value_str.push_str(&n.to_string()),
                    Token::Bool(b) => value_str.push_str(if *b { "true" } else { "false" }),
                    Token::Null => value_str.push_str("null"),
                    _ => {
                        return Err(self.parse_error_with_context("Unexpected token after colon"));
                    }
                }

                // Only add space if there was whitespace in the original input
                if had_space {
                    value_str.push(' ');
                }
                value_str.push_str(&rest);

                let token = self.scanner.parse_value_string(&value_str)?;
                match token {
                    Token::String(s, _) => Ok(Value::String(s)),
                    Token::Integer(i) => Ok(serde_json::Number::from(i).into()),
                    Token::Number(n) => {
                        if n.is_finite() && n.fract() == 0.0 && n.abs() <= i64::MAX as f64 {
                            Ok(serde_json::Number::from(n as i64).into())
                        } else {
                            Ok(serde_json::Number::from_f64(n)
                                .ok_or_else(|| {
                                    ToonError::InvalidInput(format!("Invalid number: {n}"))
                                })?
                                .into())
                        }
                    }
                    Token::Bool(b) => Ok(Value::Bool(b)),
                    Token::Null => Ok(Value::Null),
                    _ => Err(ToonError::InvalidInput("Unexpected token type".to_string())),
                }
            }?;

            self.current_token = self.scanner.scan_token()?;
            Ok(result)
        }
    }

    fn parse_root_array(&mut self, depth: usize) -> ToonResult<Value> {
        validate_depth(depth, MAX_DEPTH)?;

        if !matches!(self.current_token, Token::LeftBracket) {
            return Err(self.parse_error_with_context("Expected '[' at the start of root array"));
        }

        self.parse_array(depth)
    }

    fn parse_array_header(
        &mut self,
    ) -> ToonResult<(usize, Option<Delimiter>, Option<Vec<String>>)> {
        if !matches!(self.current_token, Token::LeftBracket) {
            return Err(self.parse_error_with_context("Expected '['"));
        }
        self.advance()?;

        // Parse array length (plain integer only)
        // Supports formats: [N], [N|], [N\t] (no # marker)
        let length = if let Token::Integer(n) = &self.current_token {
            *n as usize
        } else if let Token::String(s, _) = &self.current_token {
            // Check if string starts with # - this marker is not supported
            if s.starts_with('#') {
                return Err(self
                    .parse_error_with_context(
                        "Length marker '#' is not supported. Use [N] format instead of [#N]",
                    )
                    .with_suggestion("Remove the '#' prefix from the array length"));
            }

            // Plain string that's a number: "3"
            s.parse::<usize>().map_err(|_| {
                self.parse_error_with_context(format!("Expected array length, found: {s}"))
            })?
        } else {
            return Err(self.parse_error_with_context(format!(
                "Expected array length, found {:?}",
                self.current_token
            )));
        };

        self.advance()?;

        // Check for optional delimiter after length
        let detected_delim = match &self.current_token {
            Token::Delimiter(d) => {
                let delim = *d;
                self.advance()?;
                Some(delim)
            }
            Token::String(s, _) if s == "," => {
                self.advance()?;
                Some(Delimiter::Comma)
            }
            Token::String(s, _) if s == "|" => {
                self.advance()?;
                Some(Delimiter::Pipe)
            }
            Token::String(s, _) if s == "\t" => {
                self.advance()?;
                Some(Delimiter::Tab)
            }
            _ => None,
        };

        // Default to comma if no delimiter specified
        let active_delim = detected_delim.or(Some(Delimiter::Comma));

        self.scanner.set_active_delimiter(active_delim);

        if !matches!(self.current_token, Token::RightBracket) {
            return Err(self.parse_error_with_context(format!(
                "Expected ']', found {:?}",
                self.current_token
            )));
        }
        self.advance()?;

        let fields = if matches!(self.current_token, Token::LeftBrace) {
            self.advance()?;
            let mut fields = Vec::new();

            loop {
                match &self.current_token {
                    Token::String(s, _) => {
                        fields.push(s.clone());
                        self.advance()?;

                        if matches!(self.current_token, Token::RightBrace) {
                            break;
                        }

                        if matches!(self.current_token, Token::Delimiter(_)) {
                            self.advance()?;
                        } else {
                            return Err(self.parse_error_with_context(format!(
                                "Expected delimiter or '}}', found {:?}",
                                self.current_token
                            )));
                        }
                    }
                    Token::RightBrace => break,
                    _ => {
                        return Err(self.parse_error_with_context(format!(
                            "Expected field name, found {:?}",
                            self.current_token
                        )));
                    }
                }
            }

            self.advance()?;
            Some(fields)
        } else {
            None
        };

        if !matches!(self.current_token, Token::Colon) {
            return Err(self.parse_error_with_context("Expected ':' after array header"));
        }
        self.advance()?;

        Ok((length, detected_delim, fields))
    }

    fn parse_array(&mut self, depth: usize) -> ToonResult<Value> {
        self.parse_array_with_context(depth, ArrayParseContext::Normal)
    }

    fn parse_array_with_context(
        &mut self,
        depth: usize,
        context: ArrayParseContext,
    ) -> ToonResult<Value> {
        validate_depth(depth, MAX_DEPTH)?;

        let (length, _detected_delim, fields) = self.parse_array_header()?;

        if let Some(fields) = fields {
            validation::validate_field_list(&fields)?;
            self.parse_tabular_array(length, fields, depth, context)
        } else {
            // Non-tabular arrays as first field of list items require depth adjustment
            // (items at depth +2 relative to hyphen, not the usual +1)
            let adjusted_depth = match context {
                ArrayParseContext::Normal => depth,
                ArrayParseContext::ListItemFirstField => depth + 1,
            };
            self.parse_regular_array(length, adjusted_depth)
        }
    }

    fn parse_tabular_array(
        &mut self,
        length: usize,
        fields: Vec<String>,
        depth: usize,
        context: ArrayParseContext,
    ) -> ToonResult<Value> {
        let mut rows = Vec::new();

        if !matches!(self.current_token, Token::Newline) {
            return Err(self
                .parse_error_with_context("Expected newline after tabular array header")
                .with_suggestion("Tabular arrays must have rows on separate lines"));
        }
        self.skip_newlines()?;

        for row_index in 0..length {
            if matches!(self.current_token, Token::Eof) {
                if self.options.strict {
                    return Err(self.parse_error_with_context(format!(
                        "Expected {} rows, but got {} before EOF",
                        length,
                        rows.len()
                    )));
                }
                break;
            }

            let current_indent = self.scanner.get_last_line_indent();

            // Tabular arrays as first field of list-item objects require rows at depth +2
            // (relative to hyphen), while normal tabular arrays use depth +1
            let row_depth_offset = match context {
                ArrayParseContext::Normal => 1,
                ArrayParseContext::ListItemFirstField => 2,
            };
            let expected_indent = self.options.indent.get_spaces() * (depth + row_depth_offset);

            if self.options.strict {
                self.validate_indentation(current_indent)?;

                if current_indent != expected_indent {
                    return Err(self.parse_error_with_context(format!(
                        "Invalid indentation for tabular row: expected {expected_indent} spaces, \
                         found {current_indent}"
                    )));
                }
            }

            let mut row = Map::new();

            for (field_index, field) in fields.iter().enumerate() {
                // Skip delimiter before each field except the first
                if field_index > 0 {
                    if matches!(self.current_token, Token::Delimiter(_)) {
                        self.advance()?;
                    } else {
                        return Err(self
                            .parse_error_with_context(format!(
                                "Expected delimiter, found {:?}",
                                self.current_token
                            ))
                            .with_suggestion(format!(
                                "Tabular row {} field {} needs a delimiter",
                                row_index + 1,
                                field_index + 1
                            )));
                    }
                }

                // Empty values show up as delimiters or newlines
                let value = if matches!(self.current_token, Token::Delimiter(_))
                    || matches!(self.current_token, Token::Newline | Token::Eof)
                {
                    Value::String(String::new())
                } else {
                    self.parse_tabular_field_value()?
                };

                row.insert(field.clone(), value);

                // Validate row completeness
                if field_index < fields.len() - 1 {
                    // Not the last field - shouldn't hit newline yet
                    if matches!(self.current_token, Token::Newline | Token::Eof) {
                        if self.options.strict {
                            return Err(self
                                .parse_error_with_context(format!(
                                    "Tabular row {}: expected {} values, but found only {}",
                                    row_index + 1,
                                    fields.len(),
                                    field_index + 1
                                ))
                                .with_suggestion(format!(
                                    "Row {} should have exactly {} values",
                                    row_index + 1,
                                    fields.len()
                                )));
                        } else {
                            // Fill remaining fields with null in non-strict mode
                            for field in fields.iter().skip(field_index + 1) {
                                row.insert(field.clone(), Value::Null);
                            }
                            break;
                        }
                    }
                } else if !matches!(self.current_token, Token::Newline | Token::Eof)
                    && matches!(self.current_token, Token::Delimiter(_))
                {
                    // Last field but there's another delimiter - too many values
                    return Err(self
                        .parse_error_with_context(format!(
                            "Tabular row {}: expected {} values, but found extra values",
                            row_index + 1,
                            fields.len()
                        ))
                        .with_suggestion(format!(
                            "Row {} should have exactly {} values",
                            row_index + 1,
                            fields.len()
                        )));
                }
            }

            if !self.options.strict && row.len() < fields.len() {
                for field in fields.iter().skip(row.len()) {
                    row.insert(field.clone(), Value::Null);
                }
            }

            rows.push(Value::Object(row));

            if matches!(self.current_token, Token::Eof) {
                break;
            }

            if !matches!(self.current_token, Token::Newline) {
                if !self.options.strict {
                    while !matches!(self.current_token, Token::Newline | Token::Eof) {
                        self.advance()?;
                    }
                    if matches!(self.current_token, Token::Eof) {
                        break;
                    }
                } else {
                    return Err(self.parse_error_with_context(format!(
                        "Expected newline after tabular row {}",
                        row_index + 1
                    )));
                }
            }

            if row_index + 1 < length {
                self.advance()?;
                if self.options.strict && matches!(self.current_token, Token::Newline) {
                    return Err(self.parse_error_with_context(
                        "Blank lines are not allowed inside tabular arrays in strict mode",
                    ));
                }

                self.skip_newlines()?;
            } else if matches!(self.current_token, Token::Newline) {
                // After the last row, check if there are extra rows
                self.advance()?;
                self.skip_newlines()?;

                let expected_indent = self.options.indent.get_spaces() * (depth + 1);
                let actual_indent = self.scanner.get_last_line_indent();

                // If something at the same indent level, it might be a new row (error)
                // unless it's a key-value pair (which belongs to parent)
                if actual_indent == expected_indent && !matches!(self.current_token, Token::Eof) {
                    let is_key_value = matches!(self.current_token, Token::String(_, _))
                        && matches!(self.scanner.peek(), Some(':'));

                    if !is_key_value {
                        return Err(self.parse_error_with_context(format!(
                            "Array length mismatch: expected {length} rows, but more rows found",
                        )));
                    }
                }
            }
        }

        validation::validate_array_length(length, rows.len())?;

        Ok(Value::Array(rows))
    }

    fn parse_regular_array(&mut self, length: usize, depth: usize) -> ToonResult<Value> {
        let mut items = Vec::new();

        match &self.current_token {
            Token::Newline => {
                self.skip_newlines()?;

                let expected_indent = self.options.indent.get_spaces() * (depth + 1);

                for i in 0..length {
                    let current_indent = self.scanner.get_last_line_indent();
                    if self.options.strict {
                        self.validate_indentation(current_indent)?;

                        if current_indent != expected_indent {
                            return Err(self.parse_error_with_context(format!(
                                "Invalid indentation for list item: expected {expected_indent} \
                                 spaces, found {current_indent}"
                            )));
                        }
                    }
                    if !matches!(self.current_token, Token::Dash) {
                        return Err(self
                            .parse_error_with_context(format!(
                                "Expected '-' for list item, found {:?}",
                                self.current_token
                            ))
                            .with_suggestion(format!(
                                "List arrays need '-' prefix for each item (item {} of {})",
                                i + 1,
                                length
                            )));
                    }
                    self.advance()?;

                    let value = if matches!(self.current_token, Token::Newline | Token::Eof) {
                        Value::Object(Map::new())
                    } else if matches!(self.current_token, Token::LeftBracket) {
                        self.parse_array(depth + 1)?
                    } else if let Token::String(s, _) = &self.current_token {
                        let key = s.clone();
                        self.advance()?;

                        if matches!(self.current_token, Token::Colon | Token::LeftBracket) {
                            // This is an object: key followed by colon or array bracket
                            // First field of list-item object may be an array requiring special
                            // indentation
                            let first_value = if matches!(self.current_token, Token::LeftBracket) {
                                // Array directly after key (e.g., "- key[N]:")
                                // Use ListItemFirstField context to apply correct indentation
                                self.parse_array_with_context(
                                    depth + 1,
                                    ArrayParseContext::ListItemFirstField,
                                )?
                            } else {
                                self.advance()?;
                                // Handle nested arrays: "key: [2]: ..."
                                if matches!(self.current_token, Token::LeftBracket) {
                                    // Array after colon - not directly on hyphen line, use normal
                                    // context
                                    self.parse_array(depth + 2)?
                                } else {
                                    self.parse_field_value(depth + 2)?
                                }
                            };

                            let mut obj = Map::new();
                            obj.insert(key, first_value);

                            let field_indent = self.options.indent.get_spaces() * (depth + 2);

                            // Check if there are more fields at the same indentation level
                            let should_parse_more_fields =
                                if matches!(self.current_token, Token::Newline) {
                                    let next_indent = self.scanner.count_leading_spaces();

                                    if next_indent < field_indent {
                                        false
                                    } else {
                                        self.advance()?;

                                        if !self.options.strict {
                                            self.skip_newlines()?;
                                        }
                                        true
                                    }
                                } else if matches!(self.current_token, Token::String(_, _)) {
                                    // When already positioned at a field key, check its indent
                                    let current_indent = self.scanner.get_last_line_indent();
                                    current_indent == field_indent
                                } else {
                                    false
                                };

                            // Parse additional fields if they're at the right indentation
                            if should_parse_more_fields {
                                while !matches!(self.current_token, Token::Eof) {
                                    let current_indent = self.scanner.get_last_line_indent();

                                    if current_indent < field_indent {
                                        break;
                                    }

                                    if current_indent != field_indent && self.options.strict {
                                        break;
                                    }

                                    // Stop if we hit the next list item
                                    if matches!(self.current_token, Token::Dash) {
                                        break;
                                    }

                                    let field_key = match &self.current_token {
                                        Token::String(s, _) => s.clone(),
                                        _ => break,
                                    };
                                    self.advance()?;

                                    let field_value =
                                        if matches!(self.current_token, Token::LeftBracket) {
                                            self.parse_array(depth + 2)?
                                        } else if matches!(self.current_token, Token::Colon) {
                                            self.advance()?;
                                            if matches!(self.current_token, Token::LeftBracket) {
                                                self.parse_array(depth + 2)?
                                            } else {
                                                self.parse_field_value(depth + 2)?
                                            }
                                        } else {
                                            break;
                                        };

                                    obj.insert(field_key, field_value);

                                    if matches!(self.current_token, Token::Newline) {
                                        let next_indent = self.scanner.count_leading_spaces();
                                        if next_indent < field_indent {
                                            break;
                                        }
                                        self.advance()?;
                                        if !self.options.strict {
                                            self.skip_newlines()?;
                                        }
                                    } else {
                                        break;
                                    }
                                }
                            }

                            Value::Object(obj)
                        } else if matches!(self.current_token, Token::LeftBracket) {
                            // Array as object value: "key[2]: ..."
                            let array_value = self.parse_array(depth + 1)?;
                            let mut obj = Map::new();
                            obj.insert(key, array_value);
                            Value::Object(obj)
                        } else {
                            // Plain string value
                            Value::String(key)
                        }
                    } else {
                        self.parse_primitive()?
                    };

                    items.push(value);

                    if items.len() < length {
                        if matches!(self.current_token, Token::Newline) {
                            self.advance()?;

                            if self.options.strict && matches!(self.current_token, Token::Newline) {
                                return Err(self.parse_error_with_context(
                                    "Blank lines are not allowed inside list arrays in strict mode",
                                ));
                            }

                            self.skip_newlines()?;
                        } else if !matches!(self.current_token, Token::Dash) {
                            return Err(self.parse_error_with_context(format!(
                                "Expected newline or next list item after list item {}",
                                i + 1
                            )));
                        }
                    } else if matches!(self.current_token, Token::Newline) {
                        // After the last item, check for extra items
                        self.advance()?;
                        self.skip_newlines()?;

                        let list_indent = self.options.indent.get_spaces() * (depth + 1);
                        let actual_indent = self.scanner.get_last_line_indent();
                        // If we see another dash at the same indent, there are too many items
                        if actual_indent == list_indent && matches!(self.current_token, Token::Dash)
                        {
                            return Err(self.parse_error_with_context(format!(
                                "Array length mismatch: expected {length} items, but more items \
                                 found",
                            )));
                        }
                    }
                }
            }
            _ => {
                for i in 0..length {
                    if i > 0 {
                        if matches!(self.current_token, Token::Delimiter(_)) {
                            self.advance()?;
                        } else {
                            return Err(self
                                .parse_error_with_context(format!(
                                    "Expected delimiter, found {:?}",
                                    self.current_token
                                ))
                                .with_suggestion(format!(
                                    "Expected delimiter between items (item {} of {})",
                                    i + 1,
                                    length
                                )));
                        }
                    }

                    let value = if matches!(self.current_token, Token::Delimiter(_))
                        || (matches!(self.current_token, Token::Eof | Token::Newline) && i < length)
                    {
                        Value::String(String::new())
                    } else if matches!(self.current_token, Token::LeftBracket) {
                        self.parse_array(depth + 1)?
                    } else {
                        self.parse_primitive()?
                    };

                    items.push(value);
                }
            }
        }

        validation::validate_array_length(length, items.len())?;

        if self.options.strict && matches!(self.current_token, Token::Delimiter(_)) {
            return Err(self.parse_error_with_context(format!(
                "Array length mismatch: expected {length} items, but more items found",
            )));
        }

        Ok(Value::Array(items))
    }

    fn parse_tabular_field_value(&mut self) -> ToonResult<Value> {
        match &self.current_token {
            Token::Null => {
                self.advance()?;
                Ok(Value::Null)
            }
            Token::Bool(b) => {
                let val = *b;
                self.advance()?;
                Ok(Value::Bool(val))
            }
            Token::Integer(i) => {
                let val = *i;
                self.advance()?;
                Ok(Number::from(val).into())
            }
            Token::Number(n) => {
                let val = *n;
                self.advance()?;
                // If the float is actually an integer, represent it as such
                if val.is_finite() && val.fract() == 0.0 && val.abs() <= i64::MAX as f64 {
                    Ok(Number::from(val as i64).into())
                } else {
                    Ok(Number::from_f64(val)
                        .ok_or_else(|| ToonError::InvalidInput(format!("Invalid number: {val}")))?
                        .into())
                }
            }
            Token::String(s, _) => {
                // Tabular fields can have multiple string tokens joined with spaces
                let mut accumulated = s.clone();
                self.advance()?;

                while let Token::String(next, _) = &self.current_token {
                    if !accumulated.is_empty() {
                        accumulated.push(' ');
                    }
                    accumulated.push_str(next);
                    self.advance()?;
                }

                Ok(Value::String(accumulated))
            }
            _ => Err(self.parse_error_with_context(format!(
                "Expected primitive value, found {:?}",
                self.current_token
            ))),
        }
    }

    fn parse_primitive(&mut self) -> ToonResult<Value> {
        match &self.current_token {
            Token::Null => {
                self.advance()?;
                Ok(Value::Null)
            }
            Token::Bool(b) => {
                let val = *b;
                self.advance()?;
                Ok(Value::Bool(val))
            }
            Token::Integer(i) => {
                let val = *i;
                self.advance()?;
                Ok(Number::from(val).into())
            }
            Token::Number(n) => {
                let val = *n;
                self.advance()?;

                if val.is_finite() && val.fract() == 0.0 && val.abs() <= i64::MAX as f64 {
                    Ok(Number::from(val as i64).into())
                } else {
                    Ok(Number::from_f64(val)
                        .ok_or_else(|| ToonError::InvalidInput(format!("Invalid number: {val}")))?
                        .into())
                }
            }
            Token::String(s, _) => {
                let val = s.clone();
                self.advance()?;
                Ok(Value::String(val))
            }
            _ => Err(self.parse_error_with_context(format!(
                "Expected primitive value, found {:?}",
                self.current_token
            ))),
        }
    }

    fn parse_error_with_context(&self, message: impl Into<String>) -> ToonError {
        let (line, column) = self.scanner.current_position();
        let message = message.into();

        let context = self.get_error_context(line, column);

        ToonError::ParseError {
            line,
            column,
            message,
            context: Some(Box::new(context)),
        }
    }

    fn get_error_context(&self, line: usize, column: usize) -> ErrorContext {
        let lines: Vec<&str> = self.input.lines().collect();

        let source_line = if line > 0 && line <= lines.len() {
            lines[line - 1].to_string()
        } else {
            String::new()
        };

        let preceding_lines: Vec<String> = if line > 1 {
            lines[line.saturating_sub(3)..line - 1]
                .iter()
                .map(|s| s.to_string())
                .collect()
        } else {
            Vec::new()
        };

        let following_lines: Vec<String> = if line < lines.len() {
            lines[line..line.saturating_add(2).min(lines.len())]
                .iter()
                .map(|s| s.to_string())
                .collect()
        } else {
            Vec::new()
        };

        let indicator = if column > 0 {
            Some(format!("{:width$}^", "", width = column - 1))
        } else {
            None
        };

        ErrorContext {
            source_line,
            preceding_lines,
            following_lines,
            suggestion: None,
            indicator,
        }
    }

    fn validate_indentation(&self, indent_amount: usize) -> ToonResult<()> {
        if !self.options.strict {
            return Ok(());
        }

        let indent_size = self.options.indent.get_spaces();
        // In strict mode, indentation must be a multiple of the configured indent size
        if indent_size > 0 && indent_amount > 0 && !indent_amount.is_multiple_of(indent_size) {
            Err(self.parse_error_with_context(format!(
                "Invalid indentation: found {indent_amount} spaces, but must be a multiple of \
                 {indent_size}"
            )))
        } else {
            Ok(())
        }
    }
}

#[cfg(test)]
mod tests {
    use std::f64;

    use serde_json::json;

    use super::*;

    fn parse(input: &str) -> ToonResult<Value> {
        let mut parser = Parser::new(input, DecodeOptions::default())?;
        parser.parse()
    }

    #[test]
    fn test_parse_primitives() {
        assert_eq!(parse("null").unwrap(), json!(null));
        assert_eq!(parse("true").unwrap(), json!(true));
        assert_eq!(parse("false").unwrap(), json!(false));
        assert_eq!(parse("42").unwrap(), json!(42));
        assert_eq!(parse("3.141592653589793").unwrap(), json!(f64::consts::PI));
        assert_eq!(parse("hello").unwrap(), json!("hello"));
    }

    #[test]
    fn test_parse_simple_object() {
        let result = parse("name: Alice\nage: 30").unwrap();
        assert_eq!(result["name"], json!("Alice"));
        assert_eq!(result["age"], json!(30));
    }

    #[test]
    fn test_parse_primitive_array() {
        let result = parse("tags[3]: a,b,c").unwrap();
        assert_eq!(result["tags"], json!(["a", "b", "c"]));
    }

    #[test]
    fn test_parse_empty_array() {
        let result = parse("items[0]:").unwrap();
        assert_eq!(result["items"], json!([]));
    }

    #[test]
    fn test_parse_tabular_array() {
        let result = parse("users[2]{id,name}:\n  1,Alice\n  2,Bob").unwrap();
        assert_eq!(
            result["users"],
            json!([
                {"id": 1, "name": "Alice"},
                {"id": 2, "name": "Bob"}
            ])
        );
    }

    #[test]
    fn test_empty_tokens() {
        let result = parse("items[3]: a,,c").unwrap();
        assert_eq!(result["items"], json!(["a", "", "c"]));
    }

    #[test]
    fn test_empty_nested_object() {
        let result = parse("user:").unwrap();
        assert_eq!(result, json!({"user": {}}));
    }

    #[test]
    fn test_list_item_object() {
        let result =
            parse("items[2]:\n  - id: 1\n    name: First\n  - id: 2\n    name: Second").unwrap();
        assert_eq!(
            result["items"],
            json!([
                {"id": 1, "name": "First"},
                {"id": 2, "name": "Second"}
            ])
        );
    }

    #[test]
    fn test_nested_array_in_list_item() {
        let result = parse("items[1]:\n  - tags[3]: a,b,c").unwrap();
        assert_eq!(result["items"], json!([{"tags": ["a", "b", "c"]}]));
    }

    #[test]
    fn test_two_level_siblings() {
        let input = "x:\n  y: 1\n  z: 2";
        let opts = DecodeOptions::default();
        let mut parser = Parser::new(input, opts).unwrap();
        let result = parser.parse().unwrap();

        let x = result.as_object().unwrap().get("x").unwrap();
        let x_obj = x.as_object().unwrap();

        assert_eq!(x_obj.len(), 2, "x should have 2 keys");
        assert_eq!(x_obj.get("y").unwrap(), &serde_json::json!(1));
        assert_eq!(x_obj.get("z").unwrap(), &serde_json::json!(2));
    }

    #[test]
    fn test_nested_object_with_sibling() {
        let input = "a:\n  b:\n    c: 1\n  d: 2";
        let opts = DecodeOptions::default();
        let mut parser = Parser::new(input, opts).unwrap();
        let result = parser.parse().unwrap();

        let a = result.as_object().unwrap().get("a").unwrap();
        let a_obj = a.as_object().unwrap();

        assert_eq!(a_obj.len(), 2, "a should have 2 keys (b and d)");
        assert!(a_obj.contains_key("b"), "a should have key 'b'");
        assert!(a_obj.contains_key("d"), "a should have key 'd'");

        let b = a_obj.get("b").unwrap().as_object().unwrap();
        assert_eq!(b.len(), 1, "b should have only 1 key (c)");
        assert!(b.contains_key("c"), "b should have key 'c'");
        assert!(!b.contains_key("d"), "b should NOT have key 'd'");
    }

    #[test]
    fn test_field_value_with_parentheses() {
        let result = parse("msg: Mostly Functions (3 of 3)").unwrap();
        assert_eq!(result, json!({"msg": "Mostly Functions (3 of 3)"}));

        let result = parse("val: (hello)").unwrap();
        assert_eq!(result, json!({"val": "(hello)"}));

        let result = parse("test: a (b) c (d)").unwrap();
        assert_eq!(result, json!({"test": "a (b) c (d)"}));
    }

    #[test]
    fn test_field_value_number_with_parentheses() {
        let result = parse("code: 0(f)").unwrap();
        assert_eq!(result, json!({"code": "0(f)"}));

        let result = parse("val: 5(test)").unwrap();
        assert_eq!(result, json!({"val": "5(test)"}));

        let result = parse("msg: test 123)").unwrap();
        assert_eq!(result, json!({"msg": "test 123)"}));
    }

    #[test]
    fn test_field_value_single_token_optimization() {
        let result = parse("name: hello").unwrap();
        assert_eq!(result, json!({"name": "hello"}));

        let result = parse("age: 42").unwrap();
        assert_eq!(result, json!({"age": 42}));

        let result = parse("active: true").unwrap();
        assert_eq!(result, json!({"active": true}));

        let result = parse("value: null").unwrap();
        assert_eq!(result, json!({"value": null}));
    }

    #[test]
    fn test_field_value_multi_token() {
        let result = parse("msg: hello world").unwrap();
        assert_eq!(result, json!({"msg": "hello world"}));

        let result = parse("msg: test 123 end").unwrap();
        assert_eq!(result, json!({"msg": "test 123 end"}));
    }

    #[test]
    fn test_field_value_spacing_preserved() {
        let result = parse("val: hello world").unwrap();
        assert_eq!(result, json!({"val": "hello world"}));

        let result = parse("val: 0(f)").unwrap();
        assert_eq!(result, json!({"val": "0(f)"}));
    }

    #[test]
    fn test_round_trip_parentheses() {
        use crate::{decode::decode_default, encode::encode_default};

        let original = json!({
            "message": "Mostly Functions (3 of 3)",
            "code": "0(f)",
            "simple": "(hello)",
            "mixed": "test 123)"
        });

        let encoded = encode_default(&original).unwrap();
        let decoded: Value = decode_default(&encoded).unwrap();

        assert_eq!(original, decoded);
    }

    #[test]
    fn test_multiple_fields_with_edge_cases() {
        let input = r#"message: Mostly Functions (3 of 3)
sone: (hello)
hello: 0(f)"#;

        let result = parse(input).unwrap();
        assert_eq!(
            result,
            json!({
                "message": "Mostly Functions (3 of 3)",
                "sone": "(hello)",
                "hello": "0(f)"
            })
        );
    }

    #[test]
    fn test_decode_list_item_tabular_array_v3() {
        // Tabular arrays as first field of list items
        // Rows must be at depth +2 relative to hyphen (6 spaces from root)
        let input = r#"items[1]:
  - users[2]{id,name}:
      1,Ada
      2,Bob
    status: active"#;

        let result = parse(input).unwrap();

        assert_eq!(
            result,
            json!({
                "items": [
                    {
                        "users": [
                            {"id": 1, "name": "Ada"},
                            {"id": 2, "name": "Bob"}
                        ],
                        "status": "active"
                    }
                ]
            })
        );
    }

    #[test]
    fn test_decode_list_item_tabular_array_multiple_items() {
        // Multiple list items each with tabular array as first field
        let input = r#"data[2]:
  - records[1]{id,val}:
      1,x
    count: 1
  - records[1]{id,val}:
      2,y
    count: 1"#;

        let result = parse(input).unwrap();

        assert_eq!(
            result,
            json!({
                "data": [
                    {
                        "records": [{"id": 1, "val": "x"}],
                        "count": 1
                    },
                    {
                        "records": [{"id": 2, "val": "y"}],
                        "count": 1
                    }
                ]
            })
        );
    }

    #[test]
    fn test_decode_list_item_tabular_array_with_multiple_fields() {
        // List item with tabular array first and multiple sibling fields
        let input = r#"entries[1]:
  - people[2]{name,age}:
      Alice,30
      Bob,25
    total: 2
    category: staff"#;

        let result = parse(input).unwrap();

        assert_eq!(
            result,
            json!({
                "entries": [
                    {
                        "people": [
                            {"name": "Alice", "age": 30},
                            {"name": "Bob", "age": 25}
                        ],
                        "total": 2,
                        "category": "staff"
                    }
                ]
            })
        );
    }

    #[test]
    fn test_decode_list_item_non_tabular_array_unchanged() {
        // Non-tabular arrays as first field should work normally
        let input = r#"items[1]:
  - tags[3]: a,b,c
    name: test"#;

        let result = parse(input).unwrap();

        assert_eq!(
            result,
            json!({
                "items": [
                    {
                        "tags": ["a", "b", "c"],
                        "name": "test"
                    }
                ]
            })
        );
    }

    #[test]
    fn test_decode_strict_rejects_v2_tabular_indent() {
        use crate::decode::decode_strict;

        // Old format: rows at depth +1 (4 spaces from root)
        // Strict mode should reject this incorrect indentation
        let input_v2 = r#"items[1]:
  - users[2]{id,name}:
    1,Ada
    2,Bob"#;

        let result = decode_strict::<Value>(input_v2);

        // Should error due to incorrect indentation
        assert!(
            result.is_err(),
            "Old format with incorrect indentation should be rejected in strict mode"
        );
        let err_msg = result.unwrap_err().to_string();
        assert!(
            err_msg.contains("indentation") || err_msg.contains("Invalid indentation"),
            "Error should mention indentation. Got: {}",
            err_msg
        );
    }

    #[test]
    fn test_decode_tabular_array_not_in_list_item_unchanged() {
        // Regular tabular arrays (not in list items) should still use depth +1
        let input = r#"users[2]{id,name}:
  1,Ada
  2,Bob"#;

        let result = parse(input).unwrap();

        assert_eq!(
            result,
            json!({
                "users": [
                    {"id": 1, "name": "Ada"},
                    {"id": 2, "name": "Bob"}
                ]
            })
        );
    }

    #[test]
    fn test_decode_nested_tabular_not_first_field() {
        // Tabular array as a subsequent field (not first) should use normal depth
        let input = r#"items[1]:
  - name: test
    data[2]{id,val}:
      1,x
      2,y"#;

        let result = parse(input).unwrap();

        assert_eq!(
            result,
            json!({
                "items": [
                    {
                        "name": "test",
                        "data": [
                            {"id": 1, "val": "x"},
                            {"id": 2, "val": "y"}
                        ]
                    }
                ]
            })
        );
    }
}

File: src\decode\scanner.rs
===========================
use crate::types::{Delimiter, ToonError, ToonResult};

/// Tokens produced by the scanner during lexical analysis.
#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    LeftBracket,
    RightBracket,
    LeftBrace,
    RightBrace,
    Colon,
    Dash,
    Newline,
    String(String, bool),
    Number(f64),
    Integer(i64),
    Bool(bool),
    Null,
    Delimiter(Delimiter),
    Eof,
}

/// Scanner that tokenizes TOON input into a sequence of tokens.
pub struct Scanner {
    input: Vec<char>,
    position: usize,
    line: usize,
    column: usize,
    active_delimiter: Option<Delimiter>,
    last_line_indent: usize,
}

impl Scanner {
    /// Create a new scanner for the given input string.
    pub fn new(input: &str) -> Self {
        Self {
            input: input.chars().collect(),
            position: 0,
            line: 1,
            column: 1,
            active_delimiter: None,
            last_line_indent: 0,
        }
    }

    /// Set the active delimiter for tokenizing array elements.
    pub fn set_active_delimiter(&mut self, delimiter: Option<Delimiter>) {
        self.active_delimiter = delimiter;
    }

    /// Get the current position (line, column).
    pub fn current_position(&self) -> (usize, usize) {
        (self.line, self.column)
    }

    pub fn get_line(&self) -> usize {
        self.line
    }

    pub fn get_column(&self) -> usize {
        self.column
    }

    pub fn peek(&self) -> Option<char> {
        self.input.get(self.position).copied()
    }

    pub fn count_leading_spaces(&self) -> usize {
        let mut idx = self.position;
        let mut count = 0;
        while let Some(&ch) = self.input.get(idx) {
            if ch == ' ' {
                count += 1;
                idx += 1;
            } else {
                break;
            }
        }
        count
    }

    pub fn count_spaces_after_newline(&self) -> usize {
        let mut idx = self.position;
        if self.input.get(idx) != Some(&'\n') {
            return 0;
        }
        idx += 1;
        let mut count = 0;
        while let Some(&ch) = self.input.get(idx) {
            if ch == ' ' {
                count += 1;
                idx += 1;
            } else {
                break;
            }
        }
        count
    }

    pub fn peek_ahead(&self, offset: usize) -> Option<char> {
        self.input.get(self.position + offset).copied()
    }

    pub fn advance(&mut self) -> Option<char> {
        if let Some(ch) = self.input.get(self.position) {
            self.position += 1;
            if *ch == '\n' {
                self.line += 1;
                self.column = 1;
            } else {
                self.column += 1;
            }
            Some(*ch)
        } else {
            None
        }
    }

    pub fn skip_whitespace(&mut self) {
        while let Some(ch) = self.peek() {
            if ch == ' ' {
                self.advance();
            } else {
                break;
            }
        }
    }

    /// Scan the next token from the input.
    pub fn scan_token(&mut self) -> ToonResult<Token> {
        if self.column == 1 {
            let mut count = 0;
            let mut idx = self.position;

            while let Some(&ch) = self.input.get(idx) {
                if ch == ' ' {
                    count += 1;
                    idx += 1;
                } else {
                    if ch == '\t' {
                        let (line, col) = self.current_position();
                        return Err(ToonError::parse_error(
                            line,
                            col + count,
                            "Tabs are not allowed in indentation",
                        ));
                    }
                    break;
                }
            }
            self.last_line_indent = count;
        }

        self.skip_whitespace();

        match self.peek() {
            None => Ok(Token::Eof),
            Some('\n') => {
                self.advance();
                Ok(Token::Newline)
            }
            Some('[') => {
                self.advance();
                Ok(Token::LeftBracket)
            }
            Some(']') => {
                self.advance();
                Ok(Token::RightBracket)
            }
            Some('{') => {
                self.advance();
                Ok(Token::LeftBrace)
            }
            Some('}') => {
                self.advance();
                Ok(Token::RightBrace)
            }
            Some(':') => {
                self.advance();
                Ok(Token::Colon)
            }
            Some('-') => {
                self.advance();
                if self.peek().is_some_and(|c| c.is_ascii_digit()) {
                    let num_str = self.scan_number_string(true)?;
                    return self.parse_number(&num_str);
                }
                Ok(Token::Dash)
            }
            Some(',') => {
                // Delimiter only when active, otherwise part of unquoted string
                if matches!(self.active_delimiter, Some(Delimiter::Comma)) {
                    self.advance();
                    Ok(Token::Delimiter(Delimiter::Comma))
                } else {
                    self.scan_unquoted_string()
                }
            }
            Some('|') => {
                if matches!(self.active_delimiter, Some(Delimiter::Pipe)) {
                    self.advance();
                    Ok(Token::Delimiter(Delimiter::Pipe))
                } else {
                    self.scan_unquoted_string()
                }
            }
            Some('\t') => {
                if matches!(self.active_delimiter, Some(Delimiter::Tab)) {
                    self.advance();
                    Ok(Token::Delimiter(Delimiter::Tab))
                } else {
                    self.scan_unquoted_string()
                }
            }
            Some('"') => self.scan_quoted_string(),
            Some(ch) if ch.is_ascii_digit() => {
                let num_str = self.scan_number_string(false)?;
                self.parse_number(&num_str)
            }
            Some(_) => self.scan_unquoted_string(),
        }
    }

    fn scan_quoted_string(&mut self) -> ToonResult<Token> {
        self.advance();

        let mut value = String::new();
        let mut escaped = false;

        while let Some(ch) = self.advance() {
            if escaped {
                match ch {
                    'n' => value.push('\n'),
                    'r' => value.push('\r'),
                    't' => value.push('\t'),
                    '"' => value.push('"'),
                    '\\' => value.push('\\'),
                    _ => {
                        let (line, col) = self.current_position();
                        return Err(ToonError::parse_error(
                            line,
                            col - 1,
                            format!("Invalid escape sequence: \\{ch}"),
                        ));
                    }
                }
                escaped = false;
            } else if ch == '\\' {
                escaped = true;
            } else if ch == '"' {
                return Ok(Token::String(value, true));
            } else {
                value.push(ch);
            }
        }

        Err(ToonError::UnexpectedEof)
    }

    fn scan_unquoted_string(&mut self) -> ToonResult<Token> {
        let mut value = String::new();

        while let Some(ch) = self.peek() {
            if ch == '\n'
                || ch == ' '
                || ch == ':'
                || ch == '['
                || ch == ']'
                || ch == '{'
                || ch == '}'
            {
                break;
            }

            // Active delimiters stop the string; otherwise they're part of it
            if matches!(
                (self.active_delimiter, ch),
                (Some(Delimiter::Comma), ',')
                    | (Some(Delimiter::Pipe), '|')
                    | (Some(Delimiter::Tab), '\t')
            ) {
                break;
            }
            value.push(ch);
            self.advance();
        }

        // Single-char delimiters kept as-is, others trimmed
        let value = if value.len() == 1 && (value == "," || value == "|" || value == "\t") {
            value
        } else {
            value.trim_end().to_string()
        };

        match value.as_str() {
            "null" => Ok(Token::Null),
            "true" => Ok(Token::Bool(true)),
            "false" => Ok(Token::Bool(false)),
            _ => Ok(Token::String(value, false)),
        }
    }

    pub fn get_last_line_indent(&self) -> usize {
        self.last_line_indent
    }

    fn scan_number_string(&mut self, negative: bool) -> ToonResult<String> {
        let mut num_str = if negative {
            String::from("-")
        } else {
            String::new()
        };

        while let Some(ch) = self.peek() {
            if ch.is_ascii_digit() || ch == '.' || ch == 'e' || ch == 'E' || ch == '+' || ch == '-'
            {
                num_str.push(ch);
                self.advance();
            } else {
                break;
            }
        }

        Ok(num_str)
    }

    fn parse_number(&self, s: &str) -> ToonResult<Token> {
        // Number followed immediately by other chars like "0(f)" should be a string
        if matches!(
            self.peek(),
            Some(next_ch) if next_ch != ' '
                && next_ch != '\n'
                && next_ch != ':'
                && next_ch != '['
                && next_ch != ']'
                && next_ch != '{'
                && next_ch != '}'
                && !matches!(
                    (self.active_delimiter, next_ch),
                    (Some(Delimiter::Comma), ',')
                        | (Some(Delimiter::Pipe), '|')
                        | (Some(Delimiter::Tab), '\t')
                )
        ) {
            return Ok(Token::String(s.to_string(), false));
        }

        // Leading zeros like "05" are strings, but "0", "0.5", "-0" are numbers
        if s.starts_with('0') && s.len() > 1 {
            let second_char = s.chars().nth(1).unwrap();
            if second_char.is_ascii_digit() {
                return Ok(Token::String(s.to_string(), false));
            }
        }

        if s.contains('.') || s.contains('e') || s.contains('E') {
            if let Ok(f) = s.parse::<f64>() {
                Ok(Token::Number(f))
            } else {
                Ok(Token::String(s.to_string(), false))
            }
        } else if let Ok(i) = s.parse::<i64>() {
            Ok(Token::Integer(i))
        } else {
            Ok(Token::String(s.to_string(), false))
        }
    }

    /// Read the rest of the current line (until newline or EOF).
    /// Returns the content with a flag indicating if it started with
    /// whitespace.
    pub fn read_rest_of_line_with_space_info(&mut self) -> (String, bool) {
        let had_leading_space = matches!(self.peek(), Some(' '));
        self.skip_whitespace();

        let mut result = String::new();
        while let Some(ch) = self.peek() {
            if ch == '\n' {
                break;
            }
            result.push(ch);
            self.advance();
        }

        (result.trim_end().to_string(), had_leading_space)
    }

    /// Read the rest of the current line (until newline or EOF).
    pub fn read_rest_of_line(&mut self) -> String {
        self.read_rest_of_line_with_space_info().0
    }

    /// Parse a complete value string into a token.
    pub fn parse_value_string(&self, s: &str) -> ToonResult<Token> {
        let trimmed = s.trim();

        if trimmed.is_empty() {
            return Ok(Token::String(String::new(), false));
        }

        if trimmed.starts_with('"') {
            let mut value = String::new();
            let mut escaped = false;
            let chars: Vec<char> = trimmed.chars().collect();
            let mut i = 1;

            while i < chars.len() {
                let ch = chars[i];
                if escaped {
                    match ch {
                        'n' => value.push('\n'),
                        'r' => value.push('\r'),
                        't' => value.push('\t'),
                        '"' => value.push('"'),
                        '\\' => value.push('\\'),
                        _ => {
                            return Err(ToonError::parse_error(
                                self.line,
                                self.column,
                                format!("Invalid escape sequence: \\{ch}"),
                            ));
                        }
                    }
                    escaped = false;
                } else if ch == '\\' {
                    escaped = true;
                } else if ch == '"' {
                    if i != chars.len() - 1 {
                        return Err(ToonError::parse_error(
                            self.line,
                            self.column,
                            "Unexpected characters after closing quote",
                        ));
                    }
                    return Ok(Token::String(value, true));
                } else {
                    value.push(ch);
                }
                i += 1;
            }

            return Err(ToonError::parse_error(
                self.line,
                self.column,
                "Unterminated string: missing closing quote",
            ));
        }

        match trimmed {
            "true" => return Ok(Token::Bool(true)),
            "false" => return Ok(Token::Bool(false)),
            "null" => return Ok(Token::Null),
            _ => {}
        }

        if trimmed.starts_with('-') || trimmed.chars().next().unwrap().is_ascii_digit() {
            // Leading zeros like "05" are strings
            if trimmed.starts_with('0') && trimmed.len() > 1 {
                let second_char = trimmed.chars().nth(1).unwrap();
                if second_char.is_ascii_digit() {
                    return Ok(Token::String(trimmed.to_string(), false));
                }
            }

            if trimmed.contains('.') || trimmed.contains('e') || trimmed.contains('E') {
                if let Ok(f) = trimmed.parse::<f64>() {
                    let normalized = if f == -0.0 { 0.0 } else { f };
                    return Ok(Token::Number(normalized));
                }
            } else if let Ok(i) = trimmed.parse::<i64>() {
                return Ok(Token::Integer(i));
            }
        }

        Ok(Token::String(trimmed.to_string(), false))
    }

    pub fn detect_delimiter(&mut self) -> Option<Delimiter> {
        let saved_pos = self.position;

        while let Some(ch) = self.peek() {
            match ch {
                ',' => {
                    self.position = saved_pos;
                    return Some(Delimiter::Comma);
                }
                '|' => {
                    self.position = saved_pos;
                    return Some(Delimiter::Pipe);
                }
                '\t' => {
                    self.position = saved_pos;
                    return Some(Delimiter::Tab);
                }
                '\n' | ':' | '[' | ']' | '{' | '}' => break,
                _ => {
                    self.advance();
                }
            }
        }

        self.position = saved_pos;
        None
    }
}

#[cfg(test)]
mod tests {
    use core::f64;

    use super::*;

    #[test]
    fn test_scan_structural_tokens() {
        let mut scanner = Scanner::new("[]{}:-");
        assert_eq!(scanner.scan_token().unwrap(), Token::LeftBracket);
        assert_eq!(scanner.scan_token().unwrap(), Token::RightBracket);
        assert_eq!(scanner.scan_token().unwrap(), Token::LeftBrace);
        assert_eq!(scanner.scan_token().unwrap(), Token::RightBrace);
        assert_eq!(scanner.scan_token().unwrap(), Token::Colon);
        assert_eq!(scanner.scan_token().unwrap(), Token::Dash);
    }

    #[test]
    fn test_scan_numbers() {
        let mut scanner = Scanner::new("42 3.141592653589793 -5");
        assert_eq!(scanner.scan_token().unwrap(), Token::Integer(42));
        assert_eq!(
            scanner.scan_token().unwrap(),
            Token::Number(f64::consts::PI)
        );
        assert_eq!(scanner.scan_token().unwrap(), Token::Integer(-5));
    }

    #[test]
    fn test_scan_booleans() {
        let mut scanner = Scanner::new("true false");
        assert_eq!(scanner.scan_token().unwrap(), Token::Bool(true));
        assert_eq!(scanner.scan_token().unwrap(), Token::Bool(false));
    }

    #[test]
    fn test_scan_null() {
        let mut scanner = Scanner::new("null");
        assert_eq!(scanner.scan_token().unwrap(), Token::Null);
    }

    #[test]
    fn test_scan_quoted_string() {
        let mut scanner = Scanner::new(r#""hello world""#);
        assert_eq!(
            scanner.scan_token().unwrap(),
            Token::String("hello world".to_string(), true)
        );
    }

    #[test]
    fn test_scan_escaped_string() {
        let mut scanner = Scanner::new(r#""hello\nworld""#);
        assert_eq!(
            scanner.scan_token().unwrap(),
            Token::String("hello\nworld".to_string(), true)
        );
    }

    #[test]
    fn test_scan_unquoted_string() {
        let mut scanner = Scanner::new("hello");
        assert_eq!(
            scanner.scan_token().unwrap(),
            Token::String("hello".to_string(), false)
        );
    }

    #[test]
    fn test_detect_delimiter() {
        let mut scanner = Scanner::new("a,b,c");
        assert_eq!(scanner.detect_delimiter(), Some(Delimiter::Comma));

        let mut scanner = Scanner::new("a|b|c");
        assert_eq!(scanner.detect_delimiter(), Some(Delimiter::Pipe));

        let mut scanner = Scanner::new("a\tb\tc");
        assert_eq!(scanner.detect_delimiter(), Some(Delimiter::Tab));
    }

    #[test]
    fn test_read_rest_of_line_with_space_info() {
        let mut scanner = Scanner::new(" world");
        let (content, had_space) = scanner.read_rest_of_line_with_space_info();
        assert_eq!(content, "world");
        assert!(had_space);

        let mut scanner = Scanner::new("world");
        let (content, had_space) = scanner.read_rest_of_line_with_space_info();
        assert_eq!(content, "world");
        assert!(!had_space);

        let mut scanner = Scanner::new("(hello)");
        let (content, had_space) = scanner.read_rest_of_line_with_space_info();
        assert_eq!(content, "(hello)");
        assert!(!had_space);

        let mut scanner = Scanner::new("");
        let (content, had_space) = scanner.read_rest_of_line_with_space_info();
        assert_eq!(content, "");
        assert!(!had_space);
    }

    #[test]
    fn test_parse_value_string() {
        let scanner = Scanner::new("");
        assert_eq!(
            scanner.parse_value_string("hello").unwrap(),
            Token::String("hello".to_string(), false)
        );

        assert_eq!(
            scanner.parse_value_string("(hello)").unwrap(),
            Token::String("(hello)".to_string(), false)
        );

        assert_eq!(
            scanner
                .parse_value_string("Mostly Functions (3 of 3)")
                .unwrap(),
            Token::String("Mostly Functions (3 of 3)".to_string(), false)
        );
        assert_eq!(
            scanner.parse_value_string("0(f)").unwrap(),
            Token::String("0(f)".to_string(), false)
        );

        assert_eq!(
            scanner.parse_value_string("42").unwrap(),
            Token::Integer(42)
        );

        assert_eq!(
            scanner.parse_value_string("true").unwrap(),
            Token::Bool(true)
        );
        assert_eq!(
            scanner.parse_value_string("false").unwrap(),
            Token::Bool(false)
        );
        assert_eq!(scanner.parse_value_string("null").unwrap(), Token::Null);

        assert_eq!(
            scanner.parse_value_string(r#""hello world""#).unwrap(),
            Token::String("hello world".to_string(), true)
        );
    }

    #[test]
    fn test_number_followed_by_parenthesis() {
        let mut scanner = Scanner::new("0(f)");
        let num_token = scanner.scan_number_string(false).unwrap();
        let token = scanner.parse_number(&num_token).unwrap();

        assert_eq!(token, Token::String("0".to_string(), false));
    }
}

File: src\encode\folding.rs
===========================
use crate::types::{JsonValue as Value, KeyFoldingMode, is_identifier_segment};

/// Result of chain analysis for folding.
pub struct FoldableChain {
    /// The folded key path (e.g., "a.b.c")
    pub folded_key: String,
    /// The leaf value at the end of the chain
    pub leaf_value: Value,
    /// Number of segments that were folded
    pub depth_folded: usize,
}

/// Check if a value is a single-key object suitable for folding.
fn is_single_key_object(value: &Value) -> Option<(&String, &Value)> {
    match value {
        Value::Object(obj) if obj.len() == 1 => obj.iter().next(),
        _ => None,
    }
}

/// Analyze if a key-value pair can be folded into dotted notation.
pub fn analyze_foldable_chain(
    key: &str,
    value: &Value,
    flatten_depth: usize,
    existing_keys: &[&String],
) -> Option<FoldableChain> {
    if !is_identifier_segment(key) {
        return None;
    }

    let mut segments = vec![key.to_string()];
    let mut current_value = value;

    // Follow single-key object chain until we hit a multi-key object or leaf
    while let Some((next_key, next_value)) = is_single_key_object(current_value) {
        if segments.len() >= flatten_depth {
            break;
        }

        if !is_identifier_segment(next_key) {
            break;
        }

        segments.push(next_key.clone());
        current_value = next_value;
    }

    // Must fold at least 2 segments to be worthwhile
    if segments.len() < 2 {
        return None;
    }

    let folded_key = segments.join(".");

    // Don't fold if it would collide with an existing key
    if existing_keys.contains(&&folded_key) {
        return None;
    }

    Some(FoldableChain {
        folded_key,
        leaf_value: current_value.clone(),
        depth_folded: segments.len(),
    })
}

pub fn should_fold(mode: KeyFoldingMode, chain: &Option<FoldableChain>) -> bool {
    match mode {
        KeyFoldingMode::Off => false,
        KeyFoldingMode::Safe => chain.is_some(),
    }
}

#[cfg(test)]
mod tests {
    use serde_json::json;

    use super::*;

    #[test]
    fn test_is_single_key_object() {
        let val = Value::from(json!({"a": 1}));
        assert!(is_single_key_object(&val).is_some());

        let val = Value::from(json!({"a": 1, "b": 2}));
        assert!(is_single_key_object(&val).is_none());

        let val = Value::from(json!(42));
        assert!(is_single_key_object(&val).is_none());
    }

    #[test]
    fn test_analyze_simple_chain() {
        let val = Value::from(json!({"b": {"c": 1}}));
        let existing: Vec<&String> = vec![];

        let result = analyze_foldable_chain("a", &val, usize::MAX, &existing);
        assert!(result.is_some());

        let chain = result.unwrap();
        assert_eq!(chain.folded_key, "a.b.c");
        assert_eq!(chain.depth_folded, 3);
        assert_eq!(chain.leaf_value, Value::from(json!(1)));
    }

    #[test]
    fn test_analyze_with_flatten_depth() {
        let val = Value::from(json!({"b": {"c": {"d": 1}}}));
        let existing: Vec<&String> = vec![];

        let result = analyze_foldable_chain("a", &val, 2, &existing);
        assert!(result.is_some());

        let chain = result.unwrap();
        assert_eq!(chain.folded_key, "a.b");
        assert_eq!(chain.depth_folded, 2);
    }

    #[test]
    fn test_analyze_stops_at_multi_key() {
        let val = Value::from(json!({"b": {"c": 1, "d": 2}}));
        let existing: Vec<&String> = vec![];

        let result = analyze_foldable_chain("a", &val, usize::MAX, &existing);
        assert!(result.is_some());

        let chain = result.unwrap();
        assert_eq!(chain.folded_key, "a.b");
        assert_eq!(chain.depth_folded, 2);
    }

    #[test]
    fn test_analyze_rejects_non_identifier() {
        let val = Value::from(json!({"c": 1}));
        let existing: Vec<&String> = vec![];

        let result = analyze_foldable_chain("bad-key", &val, usize::MAX, &existing);
        assert!(result.is_none());
    }

    #[test]
    fn test_analyze_detects_collision() {
        let val = Value::from(json!({"b": 1}));
        let existing_key = String::from("a.b");
        let existing: Vec<&String> = vec![&existing_key];

        let result = analyze_foldable_chain("a", &val, usize::MAX, &existing);
        assert!(result.is_none());
    }

    #[test]
    fn test_analyze_too_short_chain() {
        let val = Value::from(json!(42));
        let existing: Vec<&String> = vec![];

        let result = analyze_foldable_chain("a", &val, usize::MAX, &existing);
        assert!(result.is_none());
    }
}

File: src\decode\validation.rs
==============================
use crate::types::{ToonError, ToonResult};

/// Validate that array length matches expected value.
pub fn validate_array_length(expected: usize, actual: usize) -> ToonResult<()> {
    // Array length mismatches should always error, regardless of strict mode
    if expected != actual {
        return Err(ToonError::length_mismatch(expected, actual));
    }
    Ok(())
}

/// Validate field list for tabular arrays (no duplicates, non-empty names).
pub fn validate_field_list(fields: &[String]) -> ToonResult<()> {
    if fields.is_empty() {
        return Err(ToonError::InvalidInput(
            "Field list cannot be empty for tabular arrays".to_string(),
        ));
    }

    // Check for duplicate field names
    for i in 0..fields.len() {
        for j in (i + 1)..fields.len() {
            if fields[i] == fields[j] {
                return Err(ToonError::InvalidInput(format!(
                    "Duplicate field name: '{}'",
                    fields[i]
                )));
            }
        }
    }

    for field in fields {
        if field.is_empty() {
            return Err(ToonError::InvalidInput(
                "Field name cannot be empty".to_string(),
            ));
        }
    }

    Ok(())
}

/// Validate that a tabular row has the expected number of values.
pub fn validate_row_length(
    row_index: usize,
    expected_fields: usize,
    actual_values: usize,
) -> ToonResult<()> {
    if expected_fields != actual_values {
        return Err(ToonError::InvalidStructure(format!(
            "Row {row_index} has {actual_values} values but expected {expected_fields} fields"
        )));
    }
    Ok(())
}

/// Validate that detected and expected delimiters match.
pub fn validate_delimiter_consistency(
    detected: Option<crate::types::Delimiter>,
    expected: Option<crate::types::Delimiter>,
) -> ToonResult<()> {
    match (detected, expected) {
        (Some(d), Some(e)) if d != e => {
            return Err(ToonError::InvalidDelimiter(format!(
                "Detected delimiter {d} but expected {e}"
            )));
        }
        _ => {}
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_validate_array_length() {
        assert!(validate_array_length(5, 3).is_err());
        assert!(validate_array_length(3, 5).is_err());
        assert!(validate_array_length(5, 5).is_ok());
    }

    #[test]
    fn test_validate_field_list() {
        assert!(validate_field_list(&["id".to_string(), "name".to_string()]).is_ok());
        assert!(validate_field_list(&["field1".to_string()]).is_ok());

        assert!(validate_field_list(&[]).is_err());

        assert!(
            validate_field_list(&["id".to_string(), "name".to_string(), "id".to_string()]).is_err()
        );

        assert!(
            validate_field_list(&["id".to_string(), "".to_string(), "name".to_string()]).is_err()
        );
    }

    #[test]
    fn test_validate_row_length() {
        assert!(validate_row_length(0, 3, 3).is_ok());
        assert!(validate_row_length(1, 5, 5).is_ok());

        assert!(validate_row_length(0, 3, 2).is_err());
        assert!(validate_row_length(1, 3, 4).is_err());
    }

    #[test]
    fn test_validate_delimiter_consistency() {
        use crate::types::Delimiter;

        assert!(
            validate_delimiter_consistency(Some(Delimiter::Comma), Some(Delimiter::Comma)).is_ok()
        );

        assert!(
            validate_delimiter_consistency(Some(Delimiter::Comma), Some(Delimiter::Pipe)).is_err()
        );

        assert!(validate_delimiter_consistency(None, Some(Delimiter::Comma)).is_ok());
        assert!(validate_delimiter_consistency(Some(Delimiter::Comma), None).is_ok());
        assert!(validate_delimiter_consistency(None, None).is_ok());
    }
}

File: src\encode\mod.rs
=======================
//! Encoder Implementation
pub mod folding;
pub mod primitives;
pub mod writer;
use indexmap::IndexMap;

use crate::{
    constants::MAX_DEPTH,
    types::{
        EncodeOptions, IntoJsonValue, JsonValue as Value, KeyFoldingMode, ToonError, ToonResult,
    },
    utils::{QuotingContext, format_canonical_number, normalize, validation::validate_depth},
};

/// Encode any serializable value to TOON format.
///
/// This function accepts any type implementing `serde::Serialize`, including:
/// - Custom structs with `#[derive(Serialize)]`
/// - `serde_json::Value`
/// - Built-in types (Vec, HashMap, etc.)
///
/// # Examples
///
/// **With custom structs:**
/// ```
/// use serde::Serialize;
/// use rune_format::{
///     encode,
///     EncodeOptions,
/// };
///
/// #[derive(Serialize)]
/// struct User {
///     name: String,
///     age: u32,
/// }
///
/// let user = User {
///     name: "Alice".to_string(),
///     age: 30,
/// };
/// let toon = encode(&user, &EncodeOptions::default())?;
/// assert!(toon.contains("name: Alice"));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
///
/// **With JSON values:**
/// ```
/// use rune_format::{encode, EncodeOptions, Delimiter};
/// use serde_json::json;
///
/// let data = json!({"tags": ["a", "b", "c"]});
/// let options = EncodeOptions::new().with_delimiter(Delimiter::Pipe);
/// let toon = encode(&data, &options)?;
/// assert!(toon.contains("|"));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn encode<T: serde::Serialize>(value: &T, options: &EncodeOptions) -> ToonResult<String> {
    let json_value =
        serde_json::to_value(value).map_err(|e| ToonError::SerializationError(e.to_string()))?;
    let json_value: Value = json_value.into();
    encode_impl(&json_value, options)
}

fn encode_impl(value: &Value, options: &EncodeOptions) -> ToonResult<String> {
    let normalized: Value = normalize(value.clone());
    let mut writer = writer::Writer::new(options.clone());

    match &normalized {
        Value::Array(arr) => {
            write_array(&mut writer, None, arr, 0)?;
        }
        Value::Object(obj) => {
            write_object(&mut writer, obj, 0)?;
        }
        _ => {
            write_primitive_value(&mut writer, &normalized, QuotingContext::ObjectValue)?;
        }
    }

    Ok(writer.finish())
}

/// Encode with default options (2-space indent, comma delimiter).
///
/// Works with any type implementing `serde::Serialize`.
///
/// # Examples
///
/// **With structs:**
/// ```
/// use serde::Serialize;
/// use rune_format::encode_default;
///
/// #[derive(Serialize)]
/// struct Person {
///     name: String,
///     age: u32,
/// }
///
/// let person = Person {
///     name: "Alice".to_string(),
///     age: 30,
/// };
/// let toon = encode_default(&person)?;
/// assert!(toon.contains("name: Alice"));
/// # Ok::<(), rune_format::ToonError>(())
/// ```
///
/// **With JSON values:**
/// ```
/// use rune_format::encode_default;
/// use serde_json::json;
///
/// let data = json!({"tags": ["reading", "gaming", "coding"]});
/// let toon = encode_default(&data)?;
/// assert_eq!(toon, "tags[3]: reading,gaming,coding");
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn encode_default<T: serde::Serialize>(value: &T) -> ToonResult<String> {
    encode(value, &EncodeOptions::default())
}

/// Encode a JSON object to TOON format (errors if not an object).
///
/// This function accepts either `JsonValue` or `serde_json::Value` and converts
/// automatically.
///
/// # Examples
///
/// ```
/// use rune_format::{encode_object, EncodeOptions};
/// use serde_json::json;
///
/// let data = json!({"name": "Alice", "age": 30});
/// let toon = encode_object(&data, &EncodeOptions::default())?;
/// assert!(toon.contains("name: Alice"));
///
/// // Will error if not an object
/// assert!(encode_object(&json!(42), &EncodeOptions::default()).is_err());
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn encode_object<V: IntoJsonValue>(value: V, options: &EncodeOptions) -> ToonResult<String> {
    let json_value = value.into_json_value();
    if !json_value.is_object() {
        return Err(ToonError::TypeMismatch {
            expected: "object".to_string(),
            found: value_type_name(&json_value).to_string(),
        });
    }
    encode_impl(&json_value, options)
}

/// Encode a JSON array to TOON format (errors if not an array).
///
/// This function accepts either `JsonValue` or `serde_json::Value` and converts
/// automatically.
///
/// # Examples
///
/// ```
/// use rune_format::{encode_array, EncodeOptions};
/// use serde_json::json;
///
/// let data = json!(["a", "b", "c"]);
/// let toon = encode_array(&data, &EncodeOptions::default())?;
/// assert_eq!(toon, "[3]: a,b,c");
///
/// // Will error if not an array
/// assert!(encode_array(&json!({"key": "value"}), &EncodeOptions::default()).is_err());
/// # Ok::<(), rune_format::ToonError>(())
/// ```
pub fn encode_array<V: IntoJsonValue>(value: V, options: &EncodeOptions) -> ToonResult<String> {
    let json_value = value.into_json_value();
    if !json_value.is_array() {
        return Err(ToonError::TypeMismatch {
            expected: "array".to_string(),
            found: value_type_name(&json_value).to_string(),
        });
    }
    encode_impl(&json_value, options)
}

fn value_type_name(value: &Value) -> &'static str {
    match value {
        Value::Null => "null",
        Value::Bool(_) => "boolean",
        Value::Number(_) => "number",
        Value::String(_) => "string",
        Value::Array(_) => "array",
        Value::Object(_) => "object",
    }
}

fn write_object(
    writer: &mut writer::Writer,
    obj: &IndexMap<String, Value>,
    depth: usize,
) -> ToonResult<()> {
    write_object_impl(writer, obj, depth, false)
}

fn write_object_impl(
    writer: &mut writer::Writer,
    obj: &IndexMap<String, Value>,
    depth: usize,
    disable_folding: bool,
) -> ToonResult<()> {
    validate_depth(depth, MAX_DEPTH)?;

    let keys: Vec<&String> = obj.keys().collect();

    for (i, key) in keys.iter().enumerate() {
        if i > 0 {
            writer.write_newline()?;
        }

        let value = &obj[*key];

        // Check if this key-value pair can be folded (v1.5 feature)
        // Don't fold if any sibling key is a dotted path starting with this key
        // (e.g., don't fold inside "data" if "data.meta.items" exists as a sibling)
        let has_conflicting_sibling = keys
            .iter()
            .any(|k| k.starts_with(&format!("{key}.")) || (k.contains('.') && k == key));

        let folded = if !disable_folding
            && writer.options.key_folding == KeyFoldingMode::Safe
            && !has_conflicting_sibling
        {
            folding::analyze_foldable_chain(key, value, writer.options.flatten_depth, &keys)
        } else {
            None
        };

        if let Some(chain) = folded {
            // Write folded key-value pair
            if depth > 0 {
                writer.write_indent(depth)?;
            }

            // Write the leaf value
            match &chain.leaf_value {
                Value::Array(arr) => {
                    // For arrays, pass the folded key to write_array so it generates the header
                    // correctly
                    write_array(writer, Some(&chain.folded_key), arr, 0)?;
                }
                Value::Object(nested_obj) => {
                    // Write the folded key (e.g., "a.b.c")
                    writer.write_key(&chain.folded_key)?;
                    writer.write_char(':')?;
                    if !nested_obj.is_empty() {
                        writer.write_newline()?;
                        // After folding a chain, disable folding for the leaf object
                        // This respects flattenDepth and prevents over-folding
                        write_object_impl(writer, nested_obj, depth + 1, true)?;
                    }
                }
                _ => {
                    // Write the folded key (e.g., "a.b.c")
                    writer.write_key(&chain.folded_key)?;
                    writer.write_char(':')?;
                    writer.write_char(' ')?;
                    write_primitive_value(writer, &chain.leaf_value, QuotingContext::ObjectValue)?;
                }
            }
        } else {
            // Standard (non-folded) encoding
            match value {
                Value::Array(arr) => {
                    write_array(writer, Some(key), arr, depth)?;
                }
                Value::Object(nested_obj) => {
                    if depth > 0 {
                        writer.write_indent(depth)?;
                    }
                    writer.write_key(key)?;
                    writer.write_char(':')?;
                    if !nested_obj.is_empty() {
                        writer.write_newline()?;
                        // If this key has a conflicting sibling, disable folding for its nested
                        // objects
                        let nested_disable_folding = disable_folding || has_conflicting_sibling;
                        write_object_impl(writer, nested_obj, depth + 1, nested_disable_folding)?;
                    }
                }
                _ => {
                    if depth > 0 {
                        writer.write_indent(depth)?;
                    }
                    writer.write_key(key)?;
                    writer.write_char(':')?;
                    writer.write_char(' ')?;
                    write_primitive_value(writer, value, QuotingContext::ObjectValue)?;
                }
            }
        }
    }

    Ok(())
}

fn write_array(
    writer: &mut writer::Writer,
    key: Option<&str>,
    arr: &[Value],
    depth: usize,
) -> ToonResult<()> {
    validate_depth(depth, MAX_DEPTH)?;

    if arr.is_empty() {
        writer.write_empty_array_with_key(key, depth)?;
        return Ok(());
    }

    // Select format based on array content: tabular (uniform objects) > inline
    // primitives > nested list
    if let Some(keys) = is_tabular_array(arr) {
        encode_tabular_array(writer, key, arr, &keys, depth)?;
    } else if is_primitive_array(arr) {
        encode_primitive_array(writer, key, arr, depth)?;
    } else {
        encode_nested_array(writer, key, arr, depth)?;
    }

    Ok(())
}

/// Check if an array can be encoded as tabular format (uniform objects with
/// primitive values).
fn is_tabular_array(arr: &[Value]) -> Option<Vec<String>> {
    if arr.is_empty() {
        return None;
    }

    let first = arr.first()?;
    if !first.is_object() {
        return None;
    }

    let first_obj = first.as_object()?;
    let keys: Vec<String> = first_obj.keys().cloned().collect();

    // First object must have only primitive values
    for value in first_obj.values() {
        if !is_primitive(value) {
            return None;
        }
    }

    // All remaining objects must match: same keys and all primitive values
    for val in arr.iter().skip(1) {
        if let Some(obj) = val.as_object() {
            if obj.len() != keys.len() {
                return None;
            }
            // Verify all keys from first object exist (order doesn't matter)
            for key in &keys {
                if !obj.contains_key(key) {
                    return None;
                }
            }
            // All values must be primitives
            for value in obj.values() {
                if !is_primitive(value) {
                    return None;
                }
            }
        } else {
            return None;
        }
    }

    Some(keys)
}

/// Check if a value is a primitive (not array or object).
fn is_primitive(value: &Value) -> bool {
    matches!(
        value,
        Value::Null | Value::Bool(_) | Value::Number(_) | Value::String(_)
    )
}

/// Check if all array elements are primitives.
fn is_primitive_array(arr: &[Value]) -> bool {
    arr.iter().all(is_primitive)
}

fn encode_primitive_array(
    writer: &mut writer::Writer,
    key: Option<&str>,
    arr: &[Value],
    depth: usize,
) -> ToonResult<()> {
    writer.write_array_header(key, arr.len(), None, depth)?;
    writer.write_char(' ')?;
    // Set delimiter context for array values (affects quoting decisions)
    writer.push_active_delimiter(writer.options.delimiter);

    for (i, val) in arr.iter().enumerate() {
        if i > 0 {
            writer.write_delimiter()?;
        }
        write_primitive_value(writer, val, QuotingContext::ArrayValue)?;
    }
    writer.pop_active_delimiter();

    Ok(())
}

fn write_primitive_value(
    writer: &mut writer::Writer,
    value: &Value,
    context: QuotingContext,
) -> ToonResult<()> {
    match value {
        Value::Null => writer.write_str("null"),
        Value::Bool(b) => writer.write_str(&b.to_string()),
        Value::Number(n) => {
            // Format in canonical TOON form (no exponents, no trailing zeros)
            let num_str = format_canonical_number(n);
            writer.write_str(&num_str)
        }
        Value::String(s) => {
            if writer.needs_quoting(s, context) {
                writer.write_quoted_string(s)
            } else {
                writer.write_str(s)
            }
        }
        _ => Err(ToonError::InvalidInput(
            "Expected primitive value".to_string(),
        )),
    }
}

fn encode_tabular_array(
    writer: &mut writer::Writer,
    key: Option<&str>,
    arr: &[Value],
    keys: &[String],
    depth: usize,
) -> ToonResult<()> {
    writer.write_array_header(key, arr.len(), Some(keys), depth)?;
    writer.write_newline()?;

    writer.push_active_delimiter(writer.options.delimiter);

    // Write each row with values separated by delimiters
    for (row_index, obj_val) in arr.iter().enumerate() {
        if let Some(obj) = obj_val.as_object() {
            writer.write_indent(depth + 1)?;

            for (i, key) in keys.iter().enumerate() {
                if i > 0 {
                    writer.write_delimiter()?;
                }

                // Missing fields become null
                if let Some(val) = obj.get(key) {
                    write_primitive_value(writer, val, QuotingContext::ArrayValue)?;
                } else {
                    writer.write_str("null")?;
                }
            }

            if row_index < arr.len() - 1 {
                writer.write_newline()?;
            }
        }
    }

    Ok(())
}

/// Encode a tabular array as the first field of a list-item object.
///
/// Tabular rows appear at depth +2 relative to the hyphen line when the array
/// is the first field of a list-item object. This function handles that special
/// indentation requirement.
///
/// Note: The array header is written separately before calling this function.
fn encode_list_item_tabular_array(
    writer: &mut writer::Writer,
    arr: &[Value],
    keys: &[String],
    depth: usize,
) -> ToonResult<()> {
    // Write array header without key (key already written on hyphen line)
    writer.write_char('[')?;
    writer.write_str(&arr.len().to_string())?;

    if writer.options.delimiter != crate::types::Delimiter::Comma {
        writer.write_char(writer.options.delimiter.as_char())?;
    }

    writer.write_char(']')?;

    // Write field list for tabular arrays: {field1,field2}
    writer.write_char('{')?;
    for (i, field) in keys.iter().enumerate() {
        if i > 0 {
            writer.write_char(writer.options.delimiter.as_char())?;
        }
        writer.write_key(field)?;
    }
    writer.write_char('}')?;
    writer.write_char(':')?;
    writer.write_newline()?;

    writer.push_active_delimiter(writer.options.delimiter);

    // Write rows at depth + 2 (relative to hyphen line)
    // The hyphen line is at depth, so rows appear at depth + 2
    for (row_index, obj_val) in arr.iter().enumerate() {
        if let Some(obj) = obj_val.as_object() {
            writer.write_indent(depth + 2)?;

            for (i, key) in keys.iter().enumerate() {
                if i > 0 {
                    writer.write_delimiter()?;
                }

                // Missing fields become null
                if let Some(val) = obj.get(key) {
                    write_primitive_value(writer, val, QuotingContext::ArrayValue)?;
                } else {
                    writer.write_str("null")?;
                }
            }

            if row_index < arr.len() - 1 {
                writer.write_newline()?;
            }
        }
    }

    writer.pop_active_delimiter();

    Ok(())
}

fn encode_nested_array(
    writer: &mut writer::Writer,
    key: Option<&str>,
    arr: &[Value],
    depth: usize,
) -> ToonResult<()> {
    writer.write_array_header(key, arr.len(), None, depth)?;
    writer.write_newline()?;
    writer.push_active_delimiter(writer.options.delimiter);

    for (i, val) in arr.iter().enumerate() {
        writer.write_indent(depth + 1)?;
        writer.write_char('-')?;

        match val {
            Value::Array(inner_arr) => {
                writer.write_char(' ')?;
                write_array(writer, None, inner_arr, depth + 1)?;
            }
            Value::Object(obj) => {
                // Objects in list items: first field on same line as "- ", rest indented
                // For empty objects, write only the hyphen (no space)
                let keys: Vec<&String> = obj.keys().collect();
                if let Some(first_key) = keys.first() {
                    writer.write_char(' ')?;
                    let first_val = &obj[*first_key];

                    match first_val {
                        Value::Array(arr) => {
                            // Arrays as first field of list items require special indentation
                            // (depth +2 relative to hyphen) for their nested content
                            // (rows for tabular, items for non-uniform)
                            writer.write_key(first_key)?;

                            if let Some(keys) = is_tabular_array(arr) {
                                // Tabular array: write inline with correct indentation
                                encode_list_item_tabular_array(writer, arr, &keys, depth + 1)?;
                            } else {
                                // Non-tabular array: write with depth offset
                                // (items at depth +2 instead of depth +1)
                                write_array(writer, None, arr, depth + 2)?;
                            }
                        }
                        Value::Object(nested_obj) => {
                            writer.write_key(first_key)?;
                            writer.write_char(':')?;
                            if !nested_obj.is_empty() {
                                writer.write_newline()?;
                                write_object(writer, nested_obj, depth + 3)?;
                            }
                        }
                        _ => {
                            writer.write_key(first_key)?;
                            writer.write_char(':')?;
                            writer.write_char(' ')?;
                            write_primitive_value(writer, first_val, QuotingContext::ObjectValue)?;
                        }
                    }

                    // Remaining fields on separate lines with proper indentation
                    for key in keys.iter().skip(1) {
                        writer.write_newline()?;
                        writer.write_indent(depth + 2)?;

                        let value = &obj[*key];
                        match value {
                            Value::Array(arr) => {
                                writer.write_key(key)?;
                                write_array(writer, None, arr, depth + 1)?;
                            }
                            Value::Object(nested_obj) => {
                                writer.write_key(key)?;
                                writer.write_char(':')?;
                                if !nested_obj.is_empty() {
                                    writer.write_newline()?;
                                    write_object(writer, nested_obj, depth + 3)?;
                                }
                            }
                            _ => {
                                writer.write_key(key)?;
                                writer.write_char(':')?;
                                writer.write_char(' ')?;
                                write_primitive_value(writer, value, QuotingContext::ObjectValue)?;
                            }
                        }
                    }
                }
            }
            _ => {
                writer.write_char(' ')?;
                write_primitive_value(writer, val, QuotingContext::ArrayValue)?;
            }
        }

        if i < arr.len() - 1 {
            writer.write_newline()?;
        }
    }
    writer.pop_active_delimiter();

    Ok(())
}

#[cfg(test)]
mod tests {
    use core::f64;

    use serde_json::json;

    use super::*;

    #[test]
    fn test_encode_null() {
        let value = json!(null);
        assert_eq!(encode_default(&value).unwrap(), "null");
    }

    #[test]
    fn test_encode_bool() {
        assert_eq!(encode_default(&json!(true)).unwrap(), "true");
        assert_eq!(encode_default(&json!(false)).unwrap(), "false");
    }

    #[test]
    fn test_encode_number() {
        assert_eq!(encode_default(&json!(42)).unwrap(), "42");
        assert_eq!(
            encode_default(&json!(f64::consts::PI)).unwrap(),
            "3.141592653589793"
        );
        assert_eq!(encode_default(&json!(-5)).unwrap(), "-5");
    }

    #[test]
    fn test_encode_string() {
        assert_eq!(encode_default(&json!("hello")).unwrap(), "hello");
        assert_eq!(
            encode_default(&json!("hello world")).unwrap(),
            "hello world"
        );
    }

    #[test]
    fn test_encode_simple_object() {
        let obj = json!({"name": "Alice", "age": 30});
        let result = encode_default(&obj).unwrap();
        assert!(result.contains("name: Alice"));
        assert!(result.contains("age: 30"));
    }

    #[test]
    fn test_encode_primitive_array() {
        let obj = json!({"tags": ["reading", "gaming", "coding"]});
        let result = encode_default(&obj).unwrap();
        assert_eq!(result, "tags[3]: reading,gaming,coding");
    }

    #[test]
    fn test_encode_tabular_array() {
        let obj = json!({
            "users": [
                {"id": 1, "name": "Alice"},
                {"id": 2, "name": "Bob"}
            ]
        });
        let result = encode_default(&obj).unwrap();
        assert!(result.contains("users[2]{id,name}:"));
        assert!(result.contains("1,Alice"));
        assert!(result.contains("2,Bob"));
    }

    #[test]
    fn test_encode_empty_array() {
        let obj = json!({"items": []});
        let result = encode_default(&obj).unwrap();
        assert_eq!(result, "items[0]:");
    }

    #[test]
    fn test_encode_nested_object() {
        let obj = json!({
            "user": {
                "name": "Alice",
                "age": 30
            }
        });
        let result = encode_default(&obj).unwrap();
        assert!(result.contains("user:"));
        assert!(result.contains("name: Alice"));
        assert!(result.contains("age: 30"));
    }

    #[test]
    fn test_encode_list_item_tabular_array_v3() {
        let obj = json!({
            "items": [
                {
                    "users": [
                        {"id": 1, "name": "Ada"},
                        {"id": 2, "name": "Bob"}
                    ],
                    "status": "active"
                }
            ]
        });

        let result = encode_default(&obj).unwrap();

        assert!(
            result.contains("  - users[2]{id,name}:"),
            "Header should be on hyphen line"
        );

        assert!(
            result.contains("      1,Ada"),
            "First row should be at 6 spaces (depth +2 from hyphen). Got:\n{}",
            result
        );
        assert!(
            result.contains("      2,Bob"),
            "Second row should be at 6 spaces (depth +2 from hyphen). Got:\n{}",
            result
        );

        assert!(
            result.contains("    status: active"),
            "Sibling field should be at 4 spaces (depth +1 from hyphen). Got:\n{}",
            result
        );
    }

    #[test]
    fn test_encode_list_item_tabular_array_multiple_items() {
        let obj = json!({
            "data": [
                {
                    "records": [
                        {"id": 1, "val": "x"}
                    ],
                    "count": 1
                },
                {
                    "records": [
                        {"id": 2, "val": "y"}
                    ],
                    "count": 1
                }
            ]
        });

        let result = encode_default(&obj).unwrap();

        let lines: Vec<&str> = result.lines().collect();

        let row_lines: Vec<&str> = lines
            .iter()
            .filter(|line| line.trim().starts_with(char::is_numeric))
            .copied()
            .collect();

        for row in row_lines {
            let spaces = row.len() - row.trim_start().len();
            assert_eq!(
                spaces, 6,
                "Tabular rows should be at 6 spaces. Found {} spaces in: {}",
                spaces, row
            );
        }
    }

    #[test]
    fn test_encode_list_item_non_tabular_array_unchanged() {
        let obj = json!({
            "items": [
                {
                    "tags": ["a", "b", "c"],
                    "name": "test"
                }
            ]
        });

        let result = encode_default(&obj).unwrap();

        assert!(
            result.contains("  - tags[3]: a,b,c"),
            "Inline array should be on hyphen line. Got:\n{}",
            result
        );

        assert!(
            result.contains("    name: test"),
            "Sibling field should be at 4 spaces. Got:\n{}",
            result
        );
    }

    #[test]
    fn test_encode_list_item_tabular_array_with_nested_fields() {
        let obj = json!({
            "entries": [
                {
                    "people": [
                        {"name": "Alice", "age": 30},
                        {"name": "Bob", "age": 25}
                    ],
                    "total": 2,
                    "category": "staff"
                }
            ]
        });

        let result = encode_default(&obj).unwrap();

        assert!(result.contains("  - people[2]{name,age}:"));

        assert!(result.contains("      Alice,30"));
        assert!(result.contains("      Bob,25"));

        assert!(result.contains("    total: 2"));
        assert!(result.contains("    category: staff"));
    }
}

File: src\encode\primitives.rs
==============================
pub fn is_primitive(value: &serde_json::Value) -> bool {
    matches!(
        value,
        serde_json::Value::Null
            | serde_json::Value::Bool(_)
            | serde_json::Value::Number(_)
            | serde_json::Value::String(_)
    )
}

pub fn all_primitives(values: &[serde_json::Value]) -> bool {
    values.iter().all(is_primitive)
}

/// Recursively normalize JSON values.
pub fn normalize_value(value: serde_json::Value) -> serde_json::Value {
    match value {
        serde_json::Value::Null => serde_json::Value::Null,
        serde_json::Value::Bool(b) => serde_json::Value::Bool(b),
        serde_json::Value::Number(n) => serde_json::Value::Number(n),
        serde_json::Value::String(s) => serde_json::Value::String(s),
        serde_json::Value::Array(arr) => {
            serde_json::Value::Array(arr.into_iter().map(normalize_value).collect())
        }
        serde_json::Value::Object(obj) => serde_json::Value::Object(
            obj.into_iter()
                .map(|(k, v)| (k, normalize_value(v)))
                .collect(),
        ),
    }
}

#[cfg(test)]
mod tests {
    use serde_json::json;

    use super::*;

    #[test]
    fn test_is_primitive() {
        assert!(is_primitive(&json!(null)));
        assert!(is_primitive(&json!(true)));
        assert!(is_primitive(&json!(42)));
        assert!(is_primitive(&json!("hello")));
        assert!(!is_primitive(&json!([])));
        assert!(!is_primitive(&json!({})));
    }

    #[test]
    fn test_all_primitives() {
        assert!(all_primitives(&[json!(1), json!(2), json!(3)]));
        assert!(all_primitives(&[json!("a"), json!("b")]));
        assert!(all_primitives(&[json!(null), json!(true), json!(42)]));
        assert!(!all_primitives(&[json!(1), json!([]), json!(3)]));
        assert!(!all_primitives(&[json!({})]));
    }

    #[test]
    fn test_normalize_value() {
        assert_eq!(normalize_value(json!(null)), json!(null));
        assert_eq!(normalize_value(json!(42)), json!(42));
        assert_eq!(normalize_value(json!("hello")), json!("hello"));

        let normalized = normalize_value(json!({"a": 1, "b": [2, 3]}));
        assert_eq!(normalized, json!({"a": 1, "b": [2, 3]}));
    }
}

File: src\encode\writer.rs
==========================
use crate::{
    types::{Delimiter, EncodeOptions, ToonResult},
    utils::{
        QuotingContext,
        string::{is_valid_unquoted_key, needs_quoting, quote_string},
    },
};

/// Writer that builds TOON output string from JSON values.
pub struct Writer {
    buffer: String,
    pub(crate) options: EncodeOptions,
    active_delimiters: Vec<Delimiter>,
}

impl Writer {
    /// Create a new writer with the given options.
    pub fn new(options: EncodeOptions) -> Self {
        Self {
            buffer: String::new(),
            active_delimiters: vec![options.delimiter],
            options,
        }
    }

    /// Finish writing and return the complete TOON string.
    pub fn finish(self) -> String {
        self.buffer
    }

    pub fn write_str(&mut self, s: &str) -> ToonResult<()> {
        self.buffer.push_str(s);
        Ok(())
    }

    pub fn write_char(&mut self, ch: char) -> ToonResult<()> {
        self.buffer.push(ch);
        Ok(())
    }

    pub fn write_newline(&mut self) -> ToonResult<()> {
        self.buffer.push('\n');
        Ok(())
    }

    pub fn write_indent(&mut self, depth: usize) -> ToonResult<()> {
        let indent_string = self.options.indent.get_string(depth);
        if !indent_string.is_empty() {
            self.buffer.push_str(&indent_string);
        }
        Ok(())
    }

    pub fn write_delimiter(&mut self) -> ToonResult<()> {
        self.buffer.push(self.options.delimiter.as_char());
        Ok(())
    }

    pub fn write_key(&mut self, key: &str) -> ToonResult<()> {
        if is_valid_unquoted_key(key) {
            self.write_str(key)
        } else {
            self.write_quoted_string(key)
        }
    }

    /// Write an array header with key, length, and optional field list.
    pub fn write_array_header(
        &mut self,
        key: Option<&str>,
        length: usize,
        fields: Option<&[String]>,
        depth: usize,
    ) -> ToonResult<()> {
        if let Some(k) = key {
            if depth > 0 {
                self.write_indent(depth)?;
            }
            self.write_key(k)?;
        }

        self.write_char('[')?;
        self.write_str(&length.to_string())?;

        // Only write delimiter in header if it's not comma (comma is default/implied)
        if self.options.delimiter != Delimiter::Comma {
            self.write_delimiter()?;
        }

        self.write_char(']')?;

        // Write field list for tabular arrays: {field1,field2}
        if let Some(field_list) = fields {
            self.write_char('{')?;
            for (i, field) in field_list.iter().enumerate() {
                if i > 0 {
                    self.write_delimiter()?;
                }
                self.write_key(field)?;
            }
            self.write_char('}')?;
        }

        self.write_char(':')
    }

    /// Write an empty array header.
    pub fn write_empty_array_with_key(
        &mut self,
        key: Option<&str>,
        depth: usize,
    ) -> ToonResult<()> {
        if let Some(k) = key {
            if depth > 0 {
                self.write_indent(depth)?;
            }
            self.write_key(k)?;
        }
        self.write_char('[')?;
        self.write_str("0")?;

        if self.options.delimiter != Delimiter::Comma {
            self.write_delimiter()?;
        }

        self.write_char(']')?;
        self.write_char(':')
    }

    pub fn needs_quoting(&self, s: &str, context: QuotingContext) -> bool {
        // Use active delimiter for array values, document delimiter for object values
        let delim_char = match context {
            QuotingContext::ObjectValue => self.get_document_delimiter_char(),
            QuotingContext::ArrayValue => self.get_active_delimiter_char(),
        };
        needs_quoting(s, delim_char)
    }

    pub fn write_quoted_string(&mut self, s: &str) -> ToonResult<()> {
        self.write_str(&quote_string(s))
    }

    pub fn write_value(&mut self, s: &str, context: QuotingContext) -> ToonResult<()> {
        if self.needs_quoting(s, context) {
            self.write_quoted_string(s)
        } else {
            self.write_str(s)
        }
    }

    /// Push a new delimiter onto the stack (for nested arrays with different
    /// delimiters).
    pub fn push_active_delimiter(&mut self, delim: Delimiter) {
        self.active_delimiters.push(delim);
    }
    /// Pop the active delimiter, keeping at least one (the document default).
    pub fn pop_active_delimiter(&mut self) {
        if self.active_delimiters.len() > 1 {
            self.active_delimiters.pop();
        }
    }
    fn get_active_delimiter_char(&self) -> char {
        self.active_delimiters
            .last()
            .unwrap_or(&self.options.delimiter)
            .as_char()
    }

    fn get_document_delimiter_char(&self) -> char {
        self.options.delimiter.as_char()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_writer_basic() {
        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_str("hello").unwrap();
        writer.write_str(" ").unwrap();
        writer.write_str("world").unwrap();

        assert_eq!(writer.finish(), "hello world");
    }

    #[test]
    fn test_write_delimiter() {
        let mut opts = EncodeOptions::default();
        let mut writer = Writer::new(opts.clone());

        writer.write_str("a").unwrap();
        writer.write_delimiter().unwrap();
        writer.write_str("b").unwrap();

        assert_eq!(writer.finish(), "a,b");

        opts = opts.with_delimiter(Delimiter::Pipe);
        let mut writer = Writer::new(opts);

        writer.write_str("a").unwrap();
        writer.write_delimiter().unwrap();
        writer.write_str("b").unwrap();

        assert_eq!(writer.finish(), "a|b");
    }

    #[test]
    fn test_write_indent() {
        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_indent(0).unwrap();
        writer.write_str("a").unwrap();
        writer.write_newline().unwrap();

        writer.write_indent(1).unwrap();
        writer.write_str("b").unwrap();
        writer.write_newline().unwrap();

        writer.write_indent(2).unwrap();
        writer.write_str("c").unwrap();

        assert_eq!(writer.finish(), "a\n  b\n    c");
    }

    #[test]
    fn test_write_array_header() {
        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer
            .write_array_header(Some("items"), 3, None, 0)
            .unwrap();
        assert_eq!(writer.finish(), "items[3]:");

        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);
        let fields = vec!["id".to_string(), "name".to_string()];

        writer
            .write_array_header(Some("users"), 2, Some(&fields), 0)
            .unwrap();
        assert_eq!(writer.finish(), "users[2]{id,name}:");
    }

    #[test]
    fn test_write_array_header_with_pipe_delimiter() {
        let opts = EncodeOptions::new().with_delimiter(Delimiter::Pipe);
        let mut writer = Writer::new(opts);

        writer
            .write_array_header(Some("items"), 3, None, 0)
            .unwrap();
        assert_eq!(writer.finish(), "items[3|]:");

        let opts = EncodeOptions::new().with_delimiter(Delimiter::Pipe);
        let mut writer = Writer::new(opts);
        let fields = vec!["id".to_string(), "name".to_string()];

        writer
            .write_array_header(Some("users"), 2, Some(&fields), 0)
            .unwrap();
        assert_eq!(writer.finish(), "users[2|]{id|name}:");
    }

    #[test]
    fn test_write_key_with_special_chars() {
        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_key("normal_key").unwrap();
        assert_eq!(writer.finish(), "normal_key");

        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_key("key:with:colons").unwrap();
        assert_eq!(writer.finish(), "\"key:with:colons\"");
    }

    #[test]
    fn test_write_quoted_string() {
        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_quoted_string("hello world").unwrap();
        assert_eq!(writer.finish(), "\"hello world\"");

        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_quoted_string("say \"hi\"").unwrap();
        assert_eq!(writer.finish(), r#""say \"hi\"""#);
    }

    #[test]
    fn test_needs_quoting() {
        let opts = EncodeOptions::default();
        let writer = Writer::new(opts);
        let ctx = QuotingContext::ObjectValue;

        assert!(!writer.needs_quoting("hello", ctx));
        assert!(writer.needs_quoting("hello,world", ctx));
        assert!(writer.needs_quoting("true", ctx));
        assert!(writer.needs_quoting("false", ctx));
        assert!(writer.needs_quoting("null", ctx));
        assert!(writer.needs_quoting("123", ctx));
        assert!(writer.needs_quoting("", ctx));
        assert!(writer.needs_quoting("hello:world", ctx));
    }

    #[test]
    fn test_write_empty_array() {
        let opts = EncodeOptions::default();
        let mut writer = Writer::new(opts);

        writer.write_empty_array_with_key(Some("items"), 0).unwrap();
        assert_eq!(writer.finish(), "items[0]:");
    }
}

File: src\rune\ast.rs
=====================
/* src/rune/ast.rs */
//! RUNE Abstract Syntax Tree (AST) definitions.
//!
//! # TOON-RUNE – RUNE AST Module
//!▫~•◦---------------------------‣
//!
//! This module defines the core expression tree structures for RUNE:
//! identifiers, literals, terms, and expressions built on `RuneOp`.
//! It also includes statement-level constructs for TOON blocks and root declarations.
//!
//! The AST is intentionally minimal and expression-centric. Higher-level
//! constructs (definitions, constraints, blocks) can be layered on top
//! without changing the fundamental expression nodes.
//!
//! ### Key Types
//! - [`Literal`] – Numeric values.
//! - [`Ident`]   – Symbolic names (types, tensors, nodes, roots).
//! - [`Term`]    – Basic units: identifiers, literals, grouped expressions.
//! - [`Expr`]    – Recursive expression tree parameterized by [`RuneOp`].
//! - [`Stmt`]    – Top-level statements: root declarations, TOON blocks, expressions.
//!
//! ### Example
//! ```rust
//! use rune_format::rune::{Stmt, Expr};
//! use rune_format::rune::RuneOp;
//!
//! let root_stmt = Stmt::root("continuum");
//! let expr_stmt = Stmt::expr(
//!     Expr::binary(
//!         Expr::ident("users"),
//!         RuneOp::Descendant,
//!         Expr::ident("0"),
//!     )
//! );
//! ```
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::rune::ops::{MathOp, RuneOp};
use serde::{Deserialize, Serialize};
use std::fmt;

/// Basic type system for RUNE expressions.
/// This is intentionally small to bootstrap typed AST and inference.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum RuneType {
    Scalar,
    String,
    Gf8,
    PointCloud,
    Array,
    Bool,
    Unknown,
}

impl fmt::Display for RuneType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            RuneType::Scalar => write!(f, "Scalar"),
            RuneType::String => write!(f, "String"),
            RuneType::Gf8 => write!(f, "Gf8"),
            RuneType::PointCloud => write!(f, "PointCloud"),
            RuneType::Array => write!(f, "Array"),
            RuneType::Bool => write!(f, "Bool"),
            RuneType::Unknown => write!(f, "Unknown"),
        }
    }
}

/// A parameter in a kernel archetype declaration.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct KernelParam {
    pub name: Ident,
    pub typ: Ident,
}

/// Information about a single archetype in a kernel declaration.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct ArchetypeInfo {
    pub name: Ident,
    pub params: Vec<KernelParam>,
}

/// A kernel archetype definition with parameters.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct KernelArchetype {
    pub name: Ident,
    pub params: Vec<(Ident, Literal)>,
}

/// A symbolic identifier in RUNE.
///
/// This covers type symbols (`T`, `Gf8`, `XUID`), nodes, roots,
/// fields, and any named entities.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Ident(pub String);

impl Ident {
    pub fn new<S: Into<String>>(s: S) -> Self {
        Ident(s.into())
    }
}

impl fmt::Display for Ident {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(&self.0)
    }
}

impl From<String> for Ident {
    fn from(s: String) -> Self {
        Ident::new(s)
    }
}

impl From<&str> for Ident {
    fn from(s: &str) -> Self {
        Ident::new(s)
    }
}

impl Into<String> for Ident {
    fn into(self) -> String {
        self.0
    }
}

/// A semantic identifier with a single-letter namespace prefix.
///
/// Examples: T:Gf8, V:vector, R:continuum, Q:e32l
/// The prefix is always a single uppercase letter (A-Z).
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct SemanticIdent {
    /// The semantic prefix (A-Z)
    pub prefix: char,
    /// The identifier name
    pub name: Ident,
}

impl SemanticIdent {
    pub fn new(prefix: char, name: impl Into<String>) -> Self {
        SemanticIdent {
            prefix,
            name: Ident::new(name),
        }
    }
}

impl fmt::Display for SemanticIdent {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}:{}", self.prefix, self.name)
    }
}

/// Literal values in RUNE expressions.
///
/// Supports numeric literals, strings, arrays, and booleans.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Literal {
    /// Numeric literal (parsed as f64).
    Number(f64),
    /// String literal.
    String(String),
    /// Boolean literal: B:t (true) or B:f (false)
    Bool(bool),
    /// Array literal: [1,2,3] or [a,b,c]
    Array(Vec<Expr>),
}

impl Literal {
    pub fn number<N: Into<f64>>(n: N) -> Self {
        Literal::Number(n.into())
    }

    pub fn string<S: Into<String>>(s: S) -> Self {
        Literal::String(s.into())
    }

    pub fn bool<B: Into<bool>>(b: B) -> Self {
        Literal::Bool(b.into())
    }

    pub fn array(elements: Vec<Expr>) -> Self {
        Literal::Array(elements)
    }
}

impl fmt::Display for Literal {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Literal::Number(n) => write!(f, "{}", n),
            Literal::String(s) => write!(f, "\"{}\"", s),
            Literal::Bool(b) => write!(f, "B:{}", if *b { "t" } else { "f" }),
            Literal::Array(elements) => {
                write!(f, "[")?;
                for (i, elem) in elements.iter().enumerate() {
                    if i > 0 {
                        write!(f, ",")?;
                    }
                    write!(f, "{}", elem)?;
                }
                write!(f, "]")
            }
        }
    }
}

/// Arithmetic expressions within `[...]` value blocks.
///
/// These support traditional math with operators: `+ - * /`.
/// Isolated from glyph operators for clean separation.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum MathExpr {
    /// A single math atom (identifier, number, or grouped math).
    Atom(MathAtom),

    /// A binary math operation `lhs op rhs`.
    Binary {
        left: Box<MathExpr>,
        op: MathOp,
        right: Box<MathExpr>,
    },

    /// A unary math operation `op expr` (e.g., `-x`, `+5`).
    Unary {
        op: MathUnaryOp,
        operand: Box<MathExpr>,
    },
}

/// Unary operators in arithmetic expressions.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum MathUnaryOp {
    /// Negation `-x`.
    Negate,
    /// Positive `+x` (typically a no-op).
    Plus,
}

impl MathUnaryOp {
    pub fn as_str(self) -> &'static str {
        match self {
            MathUnaryOp::Negate => "-",
            MathUnaryOp::Plus => "+",
        }
    }
}

/// Atoms in arithmetic expressions.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum MathAtom {
    /// Numeric literal.
    Number(f64),
    /// Variable identifier.
    Ident(Ident),
    /// Grouped sub-expression `(math)` (for precedence).
    Group(Box<MathExpr>),
    /// Array literal inside math block `[expr, expr, ...]`.
    Array(Vec<MathExpr>),
}

impl MathExpr {
    /// Create a math atom expression.
    pub fn atom(atom: MathAtom) -> Self {
        MathExpr::Atom(atom)
    }

    /// Create a binary math expression.
    pub fn binary(left: MathExpr, op: MathOp, right: MathExpr) -> Self {
        MathExpr::Binary {
            left: Box::new(left),
            op,
            right: Box::new(right),
        }
    }

    /// Create a unary math expression.
    pub fn unary(op: MathUnaryOp, operand: MathExpr) -> Self {
        MathExpr::Unary {
            op,
            operand: Box::new(operand),
        }
    }
}

impl fmt::Display for MathExpr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            MathExpr::Atom(atom) => match atom {
                MathAtom::Number(n) => write!(f, "{}", n),
                MathAtom::Ident(id) => write!(f, "{}", id),
                MathAtom::Group(inner) => write!(f, "({})", inner),
                MathAtom::Array(elements) => {
                    write!(f, "[")?;
                    for (i, elem) in elements.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}", elem)?;
                    }
                    write!(f, "]")
                }
            },
            MathExpr::Binary { left, op, right } => {
                // Add parens for clarity in nested operations
                write!(f, "{} {} {}", left, op, right)
            }
            MathExpr::Unary { op, operand } => {
                write!(f, "{}{}", op.as_str(), operand)
            }
        }
    }
}

/// Atomic terms in a RUNE expression.
///
/// These are the building blocks that operators connect.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Term {
    /// A named symbol (identifier).
    Ident(Ident),
    /// A semantic identifier with namespace prefix (e.g., T:Gf8, V:vector).
    SemanticIdent(SemanticIdent),
    /// A literal value.
    Literal(Literal),
    /// A grouped sub-expression `(expr)`.
    Group(Box<Expr>),
    /// Arithmetic within `[...]` value blocks.
    Math(Box<MathExpr>),
    /// A function call: name(arg1, arg2, ...)
    FunctionCall { name: Ident, args: Vec<Expr> },
}

impl Term {
    pub fn ident<S: Into<String>>(s: S) -> Self {
        Term::Ident(Ident::new(s))
    }

    pub fn semantic_ident(prefix: char, name: impl Into<String>) -> Self {
        Term::SemanticIdent(SemanticIdent::new(prefix, name))
    }

    pub fn literal<N: Into<f64>>(n: N) -> Self {
        Term::Literal(Literal::number(n))
    }

    pub fn group(expr: Expr) -> Self {
        Term::Group(Box::new(expr))
    }

    pub fn math(math: MathExpr) -> Self {
        Term::Math(Box::new(math))
    }
}

/// A full RUNE expression.
///
/// This is the node-level representation that a Pratt parser will
/// construct from a token stream (`Term`s and `RuneOp`s).
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Expr {
    /// A single term (identifier, literal, or grouped expression).
    Term(Term),

    /// A binary expression `lhs op rhs`.
    Binary {
        left: Box<Expr>,
        op: RuneOp,
        right: Box<Expr>,
    },
}

impl Expr {
    /// Construct a term expression from an identifier.
    pub fn ident<S: Into<String>>(s: S) -> Self {
        Expr::Term(Term::ident(s))
    }

    /// Construct a term expression from a numeric literal.
    pub fn literal<N: Into<f64>>(n: N) -> Self {
        Expr::Term(Term::literal(n))
    }

    /// Construct a grouped expression `(expr)`.
    pub fn group(expr: Expr) -> Self {
        Expr::Term(Term::group(expr))
    }

    /// Construct a binary expression `left op right`.
    pub fn binary(left: Expr, op: RuneOp, right: Expr) -> Self {
        Expr::Binary {
            left: Box::new(left),
            op,
            right: Box::new(right),
        }
    }
}

/// A typed expression wrapper used for annotating an `Expr` node
/// with a best-effort type computed during parsing/type inference.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct TypedExpr {
    pub expr: Expr,
    pub r#type: RuneType,
}

impl TypedExpr {
    pub fn new(expr: Expr, r#type: RuneType) -> Self {
        Self { expr, r#type }
    }

    /// Infer a type for a given expression node using shallow heuristics.
    /// This is intentionally conservative: only literal math/strings/arrays
    /// and some semantic hints are recognized. More advanced inference is
    /// left for a future pass.
    pub fn infer(expr: &Expr) -> Self {
        // NOTE: we avoid glob-importing Expr::* to reduce ambiguity with the Term enum
        let r#type = match expr {
            Expr::Term(term) => match term {
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::Number(_)) => {
                    RuneType::Scalar
                }
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::String(_)) => {
                    RuneType::String
                }
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::Bool(_)) => {
                    RuneType::Bool
                }
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::Array(_)) => {
                    RuneType::Array
                }
                crate::rune::ast::Term::Math(_) => RuneType::Scalar,
                crate::rune::ast::Term::Ident(_) => RuneType::Unknown,
                crate::rune::ast::Term::SemanticIdent(s) => {
                    // Heuristic: common semantic prefix T:Gf8 -> Gf8 type
                    match s.prefix {
                        'T' => {
                            if s.name.0.to_lowercase().contains("gf8") {
                                RuneType::Gf8
                            } else {
                                RuneType::Unknown
                            }
                        }
                        _ => RuneType::Unknown,
                    }
                }
                crate::rune::ast::Term::Group(inner) => TypedExpr::infer(inner).r#type.clone(),
                crate::rune::ast::Term::FunctionCall { name, args: _ } => {
                    // Heuristic: function name suggests type
                    if name.0.contains("Quat")
                        || name.0.contains("quaternion")
                        || name.0.contains("Gf8")
                    {
                        RuneType::Gf8 // quaternions are 4D, represented as scalars for now
                    } else {
                        RuneType::Unknown
                    }
                }
            },
            Expr::Binary {
                left,
                op: _,
                right: _,
            } => {
                // Binary expression type inference: prefer left-side for now
                TypedExpr::infer(left).r#type.clone()
            }
        };

        TypedExpr::new(expr.clone(), r#type)
    }
}

impl fmt::Display for Expr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Expr::Term(t) => match t {
                Term::Ident(id) => write!(f, "{}", id),
                Term::SemanticIdent(sid) => write!(f, "{}", sid),
                Term::Literal(Literal::Number(n)) => write!(f, "{}", n),
                Term::Literal(Literal::String(s)) => write!(f, "\"{}\"", s),
                Term::Literal(Literal::Bool(b)) => write!(f, "B:{}", if *b { "t" } else { "f" }),
                Term::Literal(Literal::Array(elements)) => {
                    write!(f, "[")?;
                    for (i, elem) in elements.iter().enumerate() {
                        if i > 0 {
                            write!(f, ",")?;
                        }
                        write!(f, "{}", elem)?;
                    }
                    write!(f, "]")
                }
                Term::Group(inner) => write!(f, "({})", inner),
                Term::Math(math) => write!(f, "[{}]", math),
                Term::FunctionCall { name, args } => {
                    write!(f, "{}(", name)?;
                    for (i, arg) in args.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}", arg)?;
                    }
                    write!(f, ")")
                }
            },
            Expr::Binary { left, op, right } => {
                // Don't add spaces around :: (namespace operator)
                if *op == RuneOp::Namespace {
                    write!(f, "{}::{}", left, right)
                } else {
                    write!(f, "{} {} {}", left, op, right)
                }
            }
        }
    }
}

/// Top-level RUNE statements.
///
/// These are the syntactic units parsed from RUNE files:
/// root declarations anchor contexts, TOON/RUNE blocks provide raw data,
/// kernel declarations define computational archetypes,
/// and expressions allow symbolic computations over that data.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Stmt {
    /// A root declaration: `root: name`
    /// Anchors the semantic context of the document.
    RootDecl(Ident),

    /// A TOON block: `name ~TOON:\n  content`
    /// Raw TOON data preserved verbatim for later parsing by the TOON library.
    ToonBlock { name: Ident, content: String },

    /// A RUNE block: `name ~RUNE:\n  content`
    /// Preferred raw data blocks that can be interpreted/executed by Rune.
    RuneBlock { name: Ident, content: String },

    /// A kernel declaration: `Kernel:QDot := CUDA:Archetype:RowDot(D: 8)`
    /// Defines a kernel from a CUDA archetype template.
    KernelDecl {
        name: SemanticIdent,
        archetype: KernelArchetype,
    },

    /// A RUNE expression statement.
    /// Typically constraints, definitions, or relations over TOON data.
    Expr(Expr),
}

impl Stmt {
    /// Create a root declaration statement.
    pub fn root<S: Into<String>>(name: S) -> Self {
        Stmt::RootDecl(Ident::new(name))
    }

    /// Create a TOON block statement.
    pub fn toon_block<S: Into<String>>(name: S, content: String) -> Self {
        Stmt::ToonBlock {
            name: Ident::new(name),
            content,
        }
    }

    /// Create a RUNE block statement.
    pub fn rune_block<S: Into<String>>(name: S, content: String) -> Self {
        Stmt::RuneBlock {
            name: Ident::new(name),
            content,
        }
    }

    /// Create an expression statement.
    pub fn expr(expr: Expr) -> Self {
        Stmt::Expr(expr)
    }
}

impl fmt::Display for Stmt {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Stmt::RootDecl(name) => write!(f, "root: {}", name),
            Stmt::ToonBlock { name, content } => {
                writeln!(f, "{} ~TOON:", name)?;
                for line in content.lines() {
                    writeln!(f, "  {}", line)?;
                }
                Ok(())
            }
            Stmt::RuneBlock { name, content } => {
                writeln!(f, "{} ~RUNE:", name)?;
                for line in content.lines() {
                    writeln!(f, "  {}", line)?;
                }
                Ok(())
            }
            Stmt::KernelDecl { name, archetype } => {
                write!(f, "{} := {}", name, archetype.name)?;
                if !archetype.params.is_empty() {
                    write!(f, "(")?;
                    for (i, (param_name, param_value)) in archetype.params.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}: {}", param_name, param_value)?;
                    }
                    write!(f, ")")?;
                }
                Ok(())
            }
            Stmt::Expr(expr) => write!(f, "{}", expr),
        }
    }
}

/// Typed form of top-level statements.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum StmtTyped {
    RootDecl(Ident),
    ToonBlock {
        name: Ident,
        content: String,
    },
    RuneBlock {
        name: Ident,
        content: String,
    },
    KernelDecl {
        name: SemanticIdent,
        archetype: KernelArchetype,
    },
    Expr(TypedExpr),
}

impl StmtTyped {
    pub fn root<S: Into<String>>(name: S) -> Self {
        StmtTyped::RootDecl(Ident::new(name))
    }

    pub fn toon_block<S: Into<String>>(name: S, content: String) -> Self {
        StmtTyped::ToonBlock {
            name: Ident::new(name),
            content,
        }
    }

    pub fn rune_block<S: Into<String>>(name: S, content: String) -> Self {
        StmtTyped::RuneBlock {
            name: Ident::new(name),
            content,
        }
    }

    pub fn expr(expr: TypedExpr) -> Self {
        StmtTyped::Expr(expr)
    }
}

impl fmt::Display for StmtTyped {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            StmtTyped::RootDecl(name) => write!(f, "root: {}", name),
            StmtTyped::ToonBlock { name, content } => {
                writeln!(f, "{} ~TOON:", name)?;
                for line in content.lines() {
                    writeln!(f, "  {}", line)?;
                }
                Ok(())
            }
            StmtTyped::RuneBlock { name, content } => {
                writeln!(f, "{} ~RUNE:", name)?;
                for line in content.lines() {
                    writeln!(f, "  {}", line)?;
                }
                Ok(())
            }
            StmtTyped::KernelDecl { name, archetype } => {
                write!(f, "{} := {}", name, archetype.name)?;
                if !archetype.params.is_empty() {
                    write!(f, "(")?;
                    for (i, (param_name, param_value)) in archetype.params.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}: {}", param_name, param_value)?;
                    }
                    write!(f, ")")?;
                }
                Ok(())
            }
            StmtTyped::Expr(te) => write!(f, "{} :: {:?}", te.expr, te.r#type),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::rune::ops::RuneOp;

    #[test]
    fn test_expr_binary() {
        let left = Expr::ident("users");
        let right = Expr::literal(0.0);
        let expr = Expr::binary(left, RuneOp::Descendant, right);
        assert_eq!(format!("{}", expr), "users / 0");
    }

    #[test]
    fn test_stmt_root() {
        let stmt = Stmt::root("continuum");
        assert_eq!(format!("{}", stmt), "root: continuum");
    }

    #[test]
    fn test_stmt_toon_block() {
        let content = "items[2]{id,name}:\n  1,hello\n  2,world".to_string();
        let stmt = Stmt::toon_block("data", content);
        let output = format!("{}", stmt);
        assert!(output.contains("data ~TOON:"));
        assert!(output.contains("  items[2]"));
    }
}

File: src\rune\mod.rs
=====================
/* src/rune/hydron/mod.rs */
//! RUNE (Root-Unified Notation Encoding) is a semantic extension built on top of TOON.
//! Where TOON provides token-efficient data serialization, RUNE adds:
//!
//! - **Root-oriented semantics**: Everything revolves around hierarchical roots
//! - **Operator calculus**: Glyphs and tokens for describing relationships, flow, and structure
//! - **E8-awareness**: Geometric and identity-aware operators
//! - **Composability**: Mix RUNE semantics with TOON data blocks seamlessly
//!
//! ## Overview
//!
//! RUNE files can contain:
//! - **TOON blocks**: Raw TOON data (preserved verbatim)
//! - **RUNE operators**: Relations, constraints, transformations over TOON data
//! - **Root declarations**: Anchor points in your E8 ecosystem
//!
//! ## Example RUNE File
//! ```rune
//! root: continuum
//!
//! data ~TOON:
//!   users[3]{id,name,role}:
//!     1,Ada,admin
//!     2,Bob,user
//!     3,Eve,viewer
//!
//! # RUNE semantics over TOON data
//! users / 0 -> role := admin
//! users / * -> name ~ ValidString()
//! ```
//!
//! This crate leverages the TOON format as foundational data representation
//! while adding symbolic operator layers for E8 ecosystems.
//!
//! TOKEN_FORMAT is Copyright (c) 2025-PRESENT Shreyas S Bhat, Johann Schopplich
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

mod ast;
mod ops;
mod parser;
pub mod parts;

#[cfg(feature = "hydron")]
pub mod hydron;

pub use ast::*;
pub use ops::*;
pub use parser::*;

// Re-export common types for convenience
pub type RuneParser = parser::ParseError;

/// Parse a RUNE source string into a list of statements.
pub fn parse_rune(input: &str) -> Result<Vec<Stmt>, ParseError> {
    parser::parse(input)
}

/// Encode TOON data blocks within RUNE files as raw strings.
pub fn encode_rune(statements: &[Stmt]) -> String {
    let mut output = String::new();
    for stmt in statements {
        output.push_str(&format!("{}\n", stmt));
    }
    output
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_basic_toon_block() {
        let input = r#"
root: test_root

data ~TOON:
  items[2]{id,name}:
    1,hello
    2,world
"#;
        let stmts = parse_rune(input).unwrap();
        assert_eq!(stmts.len(), 2);
        // First statement is root declaration
        if let Stmt::RootDecl(root) = &stmts[0] {
            assert_eq!(root.0.as_str(), "test_root");
        } else {
            panic!("Expected root declaration");
        }
        // Second is TOON block
        if let Stmt::ToonBlock { name, content } = &stmts[1] {
            assert_eq!(name.0.as_str(), "data");
            assert!(content.contains("items[2]"));
        } else {
            panic!("Expected TOON block");
        }
    }

    #[test]
    fn test_operator_expression() {
        let input = r#"
items / 0 -> name := hello
"#;
        let stmts = parse_rune(input).unwrap();
        assert_eq!(stmts.len(), 1);
        if let Stmt::Expr(expr) = &stmts[0] {
            // Check it's a binary expression with -> operator (lower precedence)
            // Parses as: items / 0 -> (name := hello)
            if let Expr::Binary { op, left, right } = expr {
                assert_eq!(*op, RuneOp::FlowRight);
                assert_eq!(format!("{}", left), "items / 0");
                assert_eq!(format!("{}", right), "name := hello");
            } else {
                panic!("Expected binary expression");
            }
        }
    }
}

File: src\rune\ops.rs
=====================
//! Core Operator Registry and Definitions for RUNE.
//!
//! # e8 Notation – RUNE Operators
//!▫~•◦----------------------------‣
//!
//! This module defines the strict, closed registry of valid RUNE operators.
//! It maps the text representations (from the grammar) to strongly-typed
//! Rust enums, ensuring that no "illegal" or "fused" operators can represent
//! a valid state in the AST.
//!
//! ### Key Capabilities
//! - **Closed Registry:** `RuneOp` enum exhaustively lists every allowed operator.
//! - **Category Safety:** Distinguishes between `Glyph` (Topological), `Relation` (Directed), and `Math` (Value).
//! - **Precedence Logic:** Defines binding power for Pratt parsing (e.g., `*` binds tighter than `+`, which binds tighter than `->`).
//!
//! ### Example
//! ```rust
//! use rune_format::rune::RuneOp;
//! use std::str::FromStr;
//!
//! let op = RuneOp::from_str("->").unwrap();
//! assert_eq!(op, RuneOp::FlowRight);
//! assert_eq!(op.category(), rune_format::rune::OpCategory::Relation);
//! ```
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

#[cfg(feature = "fory")]
use fory::ForyObject;
use serde::{Deserialize, Serialize};
use std::fmt;
use std::str::FromStr;

/// Categories of operators in RUNE.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub enum OpCategory {
    /// Topological shapes (e.g., `/\`, `\|/`).
    Glyph,
    /// Structural relations (e.g., `->`, `:`, `:=`).
    Relation,
    /// Value comparisons (e.g., `<`, `>`).
    Compare,
    /// Arithmetic operations (e.g., `+`, `*`).
    Math,
}

/// The Closed Registry of all valid RUNE operators.
///
/// Any sequence of characters not matching one of these variants
/// is syntactically invalid in RUNE.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub enum RuneOp {
    // --- 1. Glyph Operators (Topology/Shape) ---
    /// `/\` : Branch then converge (Split -> Join).
    SplitJoin,
    /// `\/` : Converge then branch (Join -> Split).
    JoinSplit,
    /// `|/` : Stable lineage then branch away (Descend from Anchor).
    AnchorDescend,
    /// `/|` : Branch away then stabilize (Branch -> Stabilize).
    BranchStabilize,
    /// `\|` : Converge to root then stabilize.
    RootStabilize,
    /// `|\` : Stabilize then converge to root.
    StabilizeRoot,
    /// `\|/` : Symmetric split from a stable center.
    SymmetricSplit,
    /// `/|\` : Branch, Anchor, Branch (Composite).
    BranchAnchorBranch,

    // --- 2. Token Operators (Relations) ---
    /// `:` : Bind / Key-Value / Annotation.
    Bind,
    /// `=:` : Specializes / Instance of / Emergent from.
    Specializes,
    /// `::` : Namespace / Type Tag.
    Namespace,
    /// `:=` : Definition / Assignment.
    Define,
    /// `:=:` : Match / Pattern recognition.
    Match,
    /// `=:=` : Unify / Structural isomorphism.
    Unify,
    /// `=` : Equality / Constraint (Invariant).
    Equal,
    /// `->` : Directed Edge (Flow Right / Rootwards).
    /// Creates a forward directional flow between entities,
    /// typically representing data movement, inheritance, or sequential processing.
    FlowRight,
    /// `<-` : Reverse Edge (Flow Left).
    /// Creates a reverse directional flow, often representing
    /// backpropagation, parent flows, or inverse transformations.
    FlowLeft,
    /// `<->` : Bidirectional flow / Oscillation / Exchange.
    /// Represents oscillating or bidirectional exchange patterns,
    /// such as duality relationships, resonant couplings, or
    /// feedback loops between entities.
    FlowBidirectional,
    /// `>-<` : Convergent flow / Transformation focus.
    /// Denotes transformative convergence, such as energy compression,
    /// gradient descent, or focused transformation pathways.
    FlowConvergent,
    /// `/` : Descendant / Under (Structural Context).
    Descendant,
    /// `\` : Ancestor / Parent (Sugar for `->` in some contexts).
    Ancestor,
    /// `|` : Alias / Equivalence.
    Alias,
    /// `||` : Parallel / Siblings.
    Parallel,
    /// `~` : Transform / View.
    Transform,
    /// `|>` : Pipeline Right / Function composition (left-to-right).
    PipelineRight,
    /// `<|` : Pipeline Left / Reverse function composition (right-to-left).
    PipelineLeft,
    /// `:>` : Output / Produces / Generates (context yields output).
    Output,
    /// `<:` : Input / Requires / Accepts (context needs input).
    Input,

    // --- 4. Comparison ---
    /// `<` : Less / Precedes / Deeper.
    Less,
    /// `<=` : Less than or equal.
    LessEqual,
    /// `>` : Greater / Succeeds / Higher.
    Greater,
    /// `>=` : Greater than or equal.
    GreaterEqual,
}

impl RuneOp {
    /// Returns the semantic category of the operator.
    pub fn category(&self) -> OpCategory {
        match self {
            Self::SplitJoin
            | Self::JoinSplit
            | Self::AnchorDescend
            | Self::BranchStabilize
            | Self::RootStabilize
            | Self::StabilizeRoot
            | Self::SymmetricSplit
            | Self::BranchAnchorBranch => OpCategory::Glyph,

            Self::Bind
            | Self::Specializes
            | Self::Namespace
            | Self::Define
            | Self::Match
            | Self::Unify
            | Self::Equal
            | Self::FlowRight
            | Self::FlowLeft
            | Self::FlowBidirectional
            | Self::FlowConvergent
            | Self::Descendant
            | Self::Ancestor
            | Self::Alias
            | Self::Parallel
            | Self::Transform
            | Self::PipelineRight
            | Self::PipelineLeft
            | Self::Output
            | Self::Input => OpCategory::Relation,

            Self::Less | Self::LessEqual | Self::Greater | Self::GreaterEqual => {
                OpCategory::Compare
            }
        }
    }

    /// Returns the textual representation of the operator.
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::SplitJoin => "/\\",
            Self::JoinSplit => "\\/",
            Self::AnchorDescend => "|/",
            Self::BranchStabilize => "/|",
            Self::RootStabilize => "\\|",
            Self::StabilizeRoot => "|\\",
            Self::SymmetricSplit => "\\|/",
            Self::BranchAnchorBranch => "/|\\",

            Self::Bind => ":",
            Self::Specializes => "=:",
            Self::Namespace => "::",
            Self::Define => ":=",
            Self::Match => ":=:",
            Self::Unify => "=:=",
            Self::Equal => "=",
            Self::FlowRight => "->",
            Self::FlowLeft => "<-",
            Self::FlowBidirectional => "<->",
            Self::FlowConvergent => ">-<",
            Self::Descendant => "/",
            Self::Ancestor => "\\",
            Self::Alias => "|",
            Self::Parallel => "||",
            Self::Transform => "~",
            Self::PipelineRight => "|>",
            Self::PipelineLeft => "<|",
            Self::Output => ":>",
            Self::Input => "<:",

            Self::Less => "<",
            Self::LessEqual => "<=",
            Self::Greater => ">",
            Self::GreaterEqual => ">=",
        }
    }

    /// Binding Power for Pratt Parsing (Precedence).
    ///
    /// Higher numbers bind tighter.
    /// - Namespace/Path: Structural binding
    /// - Flow / Glyphs / Transform: mid-tier
    /// - Comparison: lower
    /// - Bind / Define: lowest (top-level)
    pub fn binding_power(&self) -> (u8, u8) {
        match self {
            // Namespace / Path / Hierarchy
            Self::Namespace => (70, 71),
            Self::Descendant | Self::Ancestor => (60, 61),

            // Flow / Graph Edges / Glyphs / Transform
            Self::FlowRight
            | Self::FlowLeft
            | Self::FlowBidirectional
            | Self::FlowConvergent
            | Self::SplitJoin
            | Self::JoinSplit
            | Self::SymmetricSplit
            | Self::BranchAnchorBranch
            | Self::Transform
            | Self::AnchorDescend
            | Self::BranchStabilize
            | Self::RootStabilize
            | Self::StabilizeRoot => (50, 51),

            // Comparison
            Self::Less | Self::LessEqual | Self::Greater | Self::GreaterEqual | Self::Equal => {
                (40, 41)
            }

            // Loose Structure
            Self::Parallel | Self::Alias => (30, 31),

            // Additional relation operators
            Self::Specializes
            | Self::Match
            | Self::Unify
            | Self::PipelineRight
            | Self::PipelineLeft
            | Self::Output
            | Self::Input => (35, 36),

            // Definition / Assignment / Bind: Lowest
            Self::Bind | Self::Define => (10, 11),
        }
    }
}

/// Parsing error for invalid operator strings.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct InvalidOpError(pub String);

impl fmt::Display for InvalidOpError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "Invalid RUNE operator literal: '{}'", self.0)
    }
}

impl std::error::Error for InvalidOpError {}

impl FromStr for RuneOp {
    type Err = InvalidOpError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            // Glyphs (3-char)
            "\\|/" => Ok(Self::SymmetricSplit),
            "/|\\" => Ok(Self::BranchAnchorBranch),

            // Glyphs (2-char)
            "/\\" => Ok(Self::SplitJoin),
            "\\/" => Ok(Self::JoinSplit),
            "|/" => Ok(Self::AnchorDescend),
            "/|" => Ok(Self::BranchStabilize),
            "\\|" => Ok(Self::RootStabilize),
            "|\\" => Ok(Self::StabilizeRoot),

            // Tokens (3-char)
            "=:=" => Ok(Self::Unify),
            ":=:" => Ok(Self::Match),

            // Tokens (3-char)
            "|>" => Ok(Self::PipelineRight),
            "<|" => Ok(Self::PipelineLeft),
            ":>" => Ok(Self::Output),
            "<:" => Ok(Self::Input),

            // Tokens (3-char) - Flow
            "<->" => Ok(Self::FlowBidirectional),
            ">-<" => Ok(Self::FlowConvergent),

            // Tokens (2-char)
            "=:" => Ok(Self::Specializes),
            "::" => Ok(Self::Namespace),
            ":=" => Ok(Self::Define),
            "->" => Ok(Self::FlowRight),
            "<-" => Ok(Self::FlowLeft),
            "<=" => Ok(Self::LessEqual),
            ">=" => Ok(Self::GreaterEqual),
            "||" => Ok(Self::Parallel),

            // Tokens (1-char)
            ":" => Ok(Self::Bind),
            "=" => Ok(Self::Equal),
            "<" => Ok(Self::Less),
            ">" => Ok(Self::Greater),
            "/" => Ok(Self::Descendant),
            "\\" => Ok(Self::Ancestor),
            "|" => Ok(Self::Alias),
            "~" => Ok(Self::Transform),

            _ => Err(InvalidOpError(s.to_string())),
        }
    }
}

/// Arithmetic operators within math blocks.
#[derive(Debug, Clone, Copy, PartialEq, Serialize, Deserialize)]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub enum MathOp {
    Add,
    Subtract,
    Multiply,
    Divide,
    Power, // ^ operator
    Modulo,
    Root, // R operator: n-th root
}

impl MathOp {
    pub fn precedence(self) -> u8 {
        match self {
            MathOp::Add | MathOp::Subtract => 1,                     // + -
            MathOp::Multiply | MathOp::Divide | MathOp::Modulo => 2, // * / %
            MathOp::Power | MathOp::Root => 3,                       // ^ R
        }
    }

    pub fn as_str(self) -> &'static str {
        match self {
            MathOp::Add => "+",
            MathOp::Subtract => "-",
            MathOp::Multiply => "*",
            MathOp::Divide => "/",
            MathOp::Power => "^",
            MathOp::Modulo => "%",
            MathOp::Root => "R",
        }
    }
}

impl fmt::Display for MathOp {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(self.as_str())
    }
}

impl fmt::Display for RuneOp {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(self.as_str())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_operator_from_str() {
        assert_eq!(RuneOp::from_str("->").unwrap(), RuneOp::FlowRight);
        assert_eq!(RuneOp::from_str("<-").unwrap(), RuneOp::FlowLeft);
        assert_eq!(RuneOp::from_str("<->").unwrap(), RuneOp::FlowBidirectional);
        assert_eq!(RuneOp::from_str(">-<").unwrap(), RuneOp::FlowConvergent);
        assert_eq!(RuneOp::from_str("/\\").unwrap(), RuneOp::SplitJoin);
        assert_eq!(RuneOp::from_str(":=").unwrap(), RuneOp::Define);
        assert_eq!(RuneOp::from_str("=:=").unwrap(), RuneOp::Unify);
        assert_eq!(RuneOp::from_str(":=:").unwrap(), RuneOp::Match);
        assert_eq!(RuneOp::from_str("=:").unwrap(), RuneOp::Specializes);
        assert_eq!(RuneOp::from_str("|>").unwrap(), RuneOp::PipelineRight);
        assert_eq!(RuneOp::from_str("<|").unwrap(), RuneOp::PipelineLeft);
        assert_eq!(RuneOp::from_str(":>").unwrap(), RuneOp::Output);
        assert_eq!(RuneOp::from_str("<:").unwrap(), RuneOp::Input);
    }

    #[test]
    fn test_invalid_operator() {
        assert!(RuneOp::from_str("=>").is_err());
        assert!(RuneOp::from_str("/->").is_err());
        assert!(RuneOp::from_str(":|").is_err());
    }

    #[test]
    fn test_binding_power() {
        assert!(RuneOp::FlowRight.binding_power() > RuneOp::Define.binding_power());
    }
}

File: src\rune\parser.rs
========================
/* src/rune/parser.rs */
//!
//! # e8 Notation – RUNE Parser
//!▫~•◦-------------------------‣
//!
//! This module provides parsing functionality for RUNE source code,
//! converting text into `Stmt` structures with proper operator precedence.
//! It uses Pest for lexical analysis and implements expression parsing
//! driven by the grammar’s precedence layering.
//!
//! The parser handles:
//! - **Operator precedence** via grammar layers:
//!   - `mul`   → `*` level
//!   - `add_sub` → `+` / `-`
//!   - `access` / `relation_expr` / `expr` → structural / relation ops
//! - **TOON blocks**: Raw content preservation for later TOON library parsing
//! - **RUNE blocks**: Preferred raw content blocks for executable Rune data
//! - **Root declarations**: Semantic anchors for E8 contexts
//! - **Expression trees**: Recursive binary structures respecting precedence
//!
//! ### Implementation Details
//! - Uses grammar-encoded precedence (`term (op term)*` per layer).
//! - Preserves TOON blocks as raw strings without internal parsing.
//! - Validates all operators against the closed `RuneOp` registry.
//!
//! ### Error Handling
//! Parser errors include:
//! - Invalid operators (not in registry)
//! - Mismatched parentheses
//! - Malformed TOON blocks
//! - Unexpected tokens
//!
//! ### Example
//! ```rust
//! use rune_format::rune::parse_rune;
//!
//! let input = r#"
//! root: continuum
//! data ~TOON:
//!   users[2]{id,name}:
//!     1,Ada
//!     2,Bob
//! users / 1 := Bob
//! "#;
//!
//! let stmts = parse_rune(input).unwrap();
//! // stmts contains RootDecl, ToonBlock, and ExprStmt
//! ```
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use pest::Parser;
use pest::iterators::Pair;
use pest_derive::Parser;
use std::str::FromStr;
use thiserror::Error;

use crate::rune::ast::*;
use crate::rune::ops::*;

// Pest grammar reference
#[derive(Parser)]
#[grammar = "rune/grammar.pest"]
pub struct RuneParser;

/// Root error type for parsing RUNE source code.
#[derive(Debug, Error)]
pub enum ParseError {
    #[error("Pest parse error: {0}")]
    Pest(Box<pest::error::Error<Rule>>),
    #[error("Invalid operator '{0}' not in registry")]
    InvalidOperator(String),
    #[error("Expected identifier, found: {0}")]
    ExpectedIdent(String),
    #[error("Expected number, found: {0}")]
    ExpectedNumber(String),
    #[error("Parse tree error: {0}")]
    ParseTree(String),
}

/// Parse RUNE source code into a list of statements.
pub fn parse(input: &str) -> Result<Vec<Stmt>, ParseError> {
    let pairs = RuneParser::parse(Rule::file, input).map_err(|e| ParseError::Pest(Box::new(e)))?;
    let mut stmts = Vec::new();

    for pair in pairs {
        if pair.as_rule() == Rule::file {
            for inner_pair in pair.into_inner() {
                match inner_pair.as_rule() {
                    Rule::WHITESPACE | Rule::COMMENT => {} // skip
                    Rule::stmt => {
                        if let Some(stmt_pair) = inner_pair.into_inner().next() {
                            stmts.push(parse_stmt(stmt_pair)?);
                        }
                    }
                    Rule::root_decl | Rule::toon_block | Rule::stmt_expr => {
                        stmts.push(parse_stmt(inner_pair)?);
                    }
                    _ => {}
                }
            }
        }
    }

    Ok(stmts)
}

/// Parse and return typed statements using a shallow type inference pass.
pub fn parse_typed(input: &str) -> Result<Vec<crate::rune::ast::StmtTyped>, ParseError> {
    let stmts = parse(input)?;
    let mut typed: Vec<crate::rune::ast::StmtTyped> = Vec::new();
    for stmt in stmts {
        match stmt {
            crate::rune::ast::Stmt::RootDecl(id) => {
                typed.push(crate::rune::ast::StmtTyped::root(id.to_string()))
            }
            crate::rune::ast::Stmt::ToonBlock { name, content } => typed.push(
                crate::rune::ast::StmtTyped::toon_block(name.to_string(), content),
            ),
            crate::rune::ast::Stmt::KernelDecl { name, archetype } => {
                typed.push(crate::rune::ast::StmtTyped::KernelDecl {
                    name: name.clone(),
                    archetype: archetype.clone(),
                });
            }
            crate::rune::ast::Stmt::RuneBlock { name, content } => typed.push(
                crate::rune::ast::StmtTyped::rune_block(name.to_string(), content),
            ),
            crate::rune::ast::Stmt::Expr(expr) => {
                let te = crate::rune::ast::TypedExpr::infer(&expr);
                typed.push(crate::rune::ast::StmtTyped::expr(te));
            }
        }
    }
    Ok(typed)
}

/// Parse a statement pair into a Stmt.
fn parse_stmt(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let rule = pair.as_rule();
    match rule {
        Rule::root_decl => parse_root_decl(pair),
        Rule::toon_block => parse_toon_block(pair),
        Rule::rune_block => parse_rune_block(pair),
        Rule::kernel_decl => parse_kernel_decl(pair),
        Rule::stmt_expr => {
            let expr_pair = pair.into_inner().next().unwrap();
            Ok(Stmt::expr(parse_expr(expr_pair)?))
        }
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected statement rule: {:?}",
            rule
        ))),
    }
}

/// Parse root declaration: `root: name` or `root: e8::continuum`
fn parse_root_decl(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let inner = pair.into_inner();

    let mut segments = Vec::new();

    // Collect all identifier segments (with :: separators)
    for pair in inner {
        if pair.as_rule() == Rule::ident {
            segments.push(pair.as_str());
        }
    }

    if segments.is_empty() {
        return Err(ParseError::ParseTree(
            "root declaration missing identifier".to_string(),
        ));
    }

    // Join segments with :: to create the full name
    let name = segments.join("::");
    Ok(Stmt::root(&name))
}

/// Parse TOON block: `name ~TOON:\n  content\n  content`
fn parse_toon_block(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let mut inner = pair.into_inner();
    let ident_pair = inner.next().unwrap();
    let name = ident_pair.as_str();

    // The next pair is toon_content (atomic capture of all lines)
    let content_pair = inner.next().unwrap();
    let content = content_pair.as_str();

    // Split into lines and dedent (remove common leading whitespace)
    let lines: Vec<&str> = content.lines().collect();

    if lines.is_empty() {
        return Ok(Stmt::toon_block(name, String::new()));
    }

    // Find minimum indentation (excluding empty lines)
    let min_indent = lines
        .iter()
        .filter(|line| !line.trim().is_empty())
        .map(|line| line.len() - line.trim_start().len())
        .min()
        .unwrap_or(0);

    // Remove the common indentation from all lines
    let dedented: Vec<String> = lines
        .iter()
        .map(|line| {
            if line.trim().is_empty() {
                String::new()
            } else {
                line[min_indent..].to_string()
            }
        })
        .collect();

    let final_content = dedented.join("\n");

    Ok(Stmt::toon_block(name, final_content))
}

/// Parse RUNE block: `name ~RUNE:\n  content\n  content`
fn parse_rune_block(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let mut inner = pair.into_inner();
    let ident_pair = inner.next().unwrap();
    let name = ident_pair.as_str();

    let content_pair = inner.next().unwrap();
    let content = content_pair.as_str();

    let lines: Vec<&str> = content.lines().collect();

    if lines.is_empty() {
        return Ok(Stmt::rune_block(name, String::new()));
    }

    let min_indent = lines
        .iter()
        .filter(|line| !line.trim().is_empty())
        .map(|line| line.len() - line.trim_start().len())
        .min()
        .unwrap_or(0);

    let dedented: Vec<String> = lines
        .iter()
        .map(|line| {
            if line.trim().is_empty() {
                "".to_string()
            } else {
                line.chars().skip(min_indent).collect()
            }
        })
        .collect();

    Ok(Stmt::rune_block(name, dedented.join("\n")))
}

/// Parse kernel parameter: ident : (number | ident | string)
fn parse_kernel_param(pair: Pair<Rule>) -> Result<(Ident, Literal), ParseError> {
    let mut inner = pair.into_inner();
    let name_pair = inner.next().unwrap();
    let name = Ident::new(name_pair.as_str());

    inner.next(); // :
    inner.next(); // WHITESPACE*

    let value_pair = inner.next().unwrap();
    let value = match value_pair.as_rule() {
        Rule::number => {
            let num = value_pair
                .as_str()
                .parse()
                .map_err(|_| ParseError::ExpectedNumber(value_pair.as_str().to_string()))?;
            Literal::Number(num)
        }
        Rule::string => {
            let raw = value_pair.as_str();
            let content = &raw[1..raw.len() - 1];
            let unescaped = content
                .replace("\\\"", "\"")
                .replace("\\\\", "\\")
                .replace("\\n", "\n")
                .replace("\\r", "\r")
                .replace("\\t", "\t");
            Literal::String(unescaped)
        }
        Rule::ident => Literal::String(value_pair.as_str().to_string()),
        _ => {
            return Err(ParseError::ParseTree(format!(
                "Unexpected value type in kernel param: {:?}",
                value_pair.as_rule()
            )));
        }
    };

    Ok((name, value))
}

/// Parse kernel archetype: CUDA:Archetype:ident(params...)
fn parse_kernel_archetype(pair: Pair<Rule>) -> Result<KernelArchetype, ParseError> {
    let mut inner = pair.into_inner();
    inner.next(); // "CUDA:Archetype:"
    let name_pair = inner.next().unwrap();
    let name = Ident::new(name_pair.as_str());
    inner.next(); // "("

    let mut params = Vec::new();
    while let Some(pair) = inner.next() {
        if pair.as_rule() == Rule::kernel_param {
            params.push(parse_kernel_param(pair)?);
            // Next should be , or )
            let next = inner.next();
            if let Some(sep) = next {
                if sep.as_str() == "," {
                    // Skip WHITESPACE*
                    let ws = inner.next();
                    if let Some(ws_pair) = ws {
                        if ws_pair.as_rule() != Rule::WHITESPACE {
                            return Err(ParseError::ParseTree(
                                "Expected whitespace after comma".to_string(),
                            ));
                        }
                    }
                } else if sep.as_str() == ")" {
                    break;
                } else {
                    return Err(ParseError::ParseTree(format!(
                        "Expected , or ), got {}",
                        sep.as_str()
                    )));
                }
            }
        } else if pair.as_str() == ")" {
            break;
        } else {
            return Err(ParseError::ParseTree(format!(
                "Unexpected in kernel archetype: {:?}",
                pair.as_rule()
            )));
        }
    }

    Ok(KernelArchetype { name, params })
}

/// Parse kernel declaration: semantic_ident := kernel_archetype
fn parse_kernel_decl(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let mut inner = pair.into_inner();
    let semantic_ident_pair = inner.next().unwrap();
    let semantic_ident = {
        let mut si_inner = semantic_ident_pair.into_inner();
        let prefix_pair = si_inner.next().unwrap();
        let name_pair = si_inner.next().unwrap();
        let prefix = prefix_pair.as_str().chars().next().unwrap();
        let name = Ident::new(name_pair.as_str());
        SemanticIdent::new(prefix, name)
    };

    inner.next(); // :=
    inner.next(); // WHITESPACE*
    let kernel_archetype_pair = inner.next().unwrap();
    let archetype = parse_kernel_archetype(kernel_archetype_pair)?;

    Ok(Stmt::KernelDecl {
        name: semantic_ident,
        archetype,
    })
}

/// Parse expression using grammar-driven precedence.
///
/// We rely on the Pest grammar to encode precedence via nested rules:
/// - `flow_expr` wraps `struct_expr` (lower precedence)
/// - `struct_expr` wraps `access` (higher precedence)
/// - `access` wraps `term`
///
/// Each non-terminal is parsed as:
///   sub_expr (op sub_expr)*
fn parse_expr(pair: Pair<Rule>) -> Result<Expr, ParseError> {
    match pair.as_rule() {
        // Expression layers for structural operators
        Rule::relation_expr | Rule::flow_expr | Rule::struct_expr | Rule::access => {
            let mut inner = pair.into_inner();

            // First element is always a sub-expression or term.
            let first = inner
                .next()
                .ok_or_else(|| ParseError::ParseTree("Empty expression".to_string()))?;

            let mut left = match first.as_rule() {
                Rule::relation_expr | Rule::flow_expr | Rule::struct_expr | Rule::access => {
                    parse_expr(first)?
                }
                Rule::term => parse_term(first)?,
                _ => parse_term(first)?,
            };

            // Then we expect zero or more (op, rhs) pairs.
            while let Some(op_pair) = inner.next() {
                // Determine what kind of pair this is
                let (op, right) = match op_pair.as_rule() {
                    // If it's one of the named operator rules, parse it
                    Rule::relation_op | Rule::flow_op | Rule::struct_op | Rule::path_op => {
                        let op = parse_operator(op_pair)?;
                        let rhs_pair = inner.next().ok_or_else(|| {
                            ParseError::ParseTree("Missing right operand".to_string())
                        })?;
                        let right = match rhs_pair.as_rule() {
                            Rule::relation_expr
                            | Rule::flow_expr
                            | Rule::struct_expr
                            | Rule::access => parse_expr(rhs_pair)?,
                            Rule::term => parse_term(rhs_pair)?,
                            _ => parse_term(rhs_pair)?,
                        };
                        (op, right)
                    }
                    // If it's another expression layer, something is wrong
                    Rule::access | Rule::struct_expr | Rule::flow_expr | Rule::relation_expr => {
                        return Err(ParseError::ParseTree(format!(
                            "Unexpected expression node where operator expected: {:?}",
                            op_pair.as_rule()
                        )));
                    }
                    _ => {
                        // Fallback: treat as operator by text
                        let op = parse_operator(op_pair)?;
                        let rhs_pair = inner.next().ok_or_else(|| {
                            ParseError::ParseTree("Missing right operand".to_string())
                        })?;
                        let right = match rhs_pair.as_rule() {
                            Rule::relation_expr
                            | Rule::flow_expr
                            | Rule::struct_expr
                            | Rule::access => parse_expr(rhs_pair)?,
                            Rule::term => parse_term(rhs_pair)?,
                            _ => parse_term(rhs_pair)?,
                        };
                        (op, right)
                    }
                };

                left = Expr::binary(left, op, right);
            }

            Ok(left)
        }
        // Direct term -> literal / ident / grouped expr
        Rule::term => parse_term(pair),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected expression rule: {:?}",
            pair.as_rule()
        ))),
    }
}

/// Parse a term: identifier, number, string, array, grouped expression, or math block.
fn parse_term(pair: Pair<Rule>) -> Result<Expr, ParseError> {
    match pair.as_rule() {
        Rule::term => {
            // Term is a composite rule, get its inner content
            let inner = pair
                .into_inner()
                .next()
                .ok_or_else(|| ParseError::ParseTree("Empty term".to_string()))?;
            parse_term(inner) // Recursively parse the inner rule
        }
        Rule::array_literal => {
            // Parse array literal: [expr, expr, ...]
            let inner = pair.into_inner();
            let mut elements = Vec::new();

            for expr_pair in inner {
                elements.push(parse_expr(expr_pair)?);
            }

            Ok(Expr::Term(Term::Literal(Literal::Array(elements))))
        }
        Rule::semantic_ident => {
            // Parse semantic identifier: prefix:name
            let mut inner = pair.into_inner();
            let prefix_pair = inner.next().unwrap();
            let name_pair = inner.next().unwrap();

            // Extract prefix character (first char before the colon)
            let prefix_str = prefix_pair.as_str();
            let prefix = prefix_str.chars().next().unwrap();

            let name = name_pair.as_str();
            Ok(Expr::Term(Term::semantic_ident(prefix, name)))
        }
        Rule::ident => Ok(Expr::ident(pair.as_str())),
        Rule::fn_call => {
            // Parse function call: name(arg1, arg2, ...)
            let mut inner = pair.into_inner();
            let name_pair = inner
                .next()
                .ok_or_else(|| ParseError::ParseTree("Missing function name".to_string()))?;
            let name = Ident::new(name_pair.as_str());

            let mut args = Vec::new();
            for expr_pair in inner {
                args.push(parse_expr(expr_pair)?);
            }

            Ok(Expr::Term(Term::FunctionCall { name, args }))
        }
        Rule::number => {
            let num: f64 = pair
                .as_str()
                .parse()
                .map_err(|_| ParseError::ExpectedNumber(pair.as_str().to_string()))?;
            Ok(Expr::literal(num))
        }
        Rule::boolean_literal => {
            // Parse boolean literal: B:t (true) or B:f (false)
            let text = pair.as_str();
            match text {
                "B:t" => Ok(Expr::Term(Term::Literal(Literal::bool(true)))),
                "B:f" => Ok(Expr::Term(Term::Literal(Literal::bool(false)))),
                _ => Err(ParseError::ParseTree(format!(
                    "Invalid boolean literal: {}",
                    text
                ))),
            }
        }
        Rule::string => {
            // Parse string, handling escape sequences
            let raw = pair.as_str();
            // Remove surrounding quotes
            let content = &raw[1..raw.len() - 1];
            // Unescape common sequences
            let unescaped = content
                .replace("\\\"", "\"")
                .replace("\\\\", "\\")
                .replace("\\n", "\n")
                .replace("\\r", "\r")
                .replace("\\t", "\t");
            Ok(Expr::Term(Term::Literal(Literal::String(unescaped))))
        }
        Rule::relation_expr | Rule::flow_expr | Rule::struct_expr | Rule::access => {
            // These are expression nodes that can appear as terms (e.g., in parentheses)
            parse_expr(pair)
        }
        Rule::math_block => {
            // Math blocks are at the term level, parse content as math expression
            let math_expr = parse_math_expr(pair)?;
            Ok(Expr::Term(Term::Math(Box::new(math_expr))))
        }
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected term rule: {:?}",
            pair.as_rule()
        ))),
    }
}

/// Parse math expression from a math block `[...]`.
/// Handles arithmetic operators with proper precedence.
fn parse_math_expr(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    // The pair is a math_block, we need the inner math_expr
    let math_expr_pair = pair
        .into_inner()
        .next()
        .ok_or_else(|| ParseError::ParseTree("Empty math block".to_string()))?;

    parse_math_expr_inner(math_expr_pair)
}

/// Internal math expression parser.
fn parse_math_expr_inner(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    match pair.as_rule() {
        Rule::math_expr | Rule::math_add | Rule::math_mul | Rule::math_exp => {
            let mut inner = pair.into_inner();

            let first = inner
                .next()
                .ok_or_else(|| ParseError::ParseTree("Empty math expression".to_string()))?;

            let mut left = match first.as_rule() {
                Rule::math_expr | Rule::math_add | Rule::math_mul | Rule::math_exp => {
                    parse_math_expr_inner(first)?
                }
                Rule::math_unary => parse_math_unary(first)?,
                Rule::math_atom => parse_math_atom(first)?,
                _ => parse_math_expr_inner(first)?,
            };

            while let Some(op_pair) = inner.next() {
                let op = parse_math_operator(op_pair)?;

                let rhs_pair = inner.next().ok_or_else(|| {
                    ParseError::ParseTree("Missing right operand in math".to_string())
                })?;

                let right = match rhs_pair.as_rule() {
                    Rule::math_expr | Rule::math_add | Rule::math_mul | Rule::math_exp => {
                        parse_math_expr_inner(rhs_pair)?
                    }
                    Rule::math_unary => parse_math_unary(rhs_pair)?,
                    Rule::math_atom => parse_math_atom(rhs_pair)?,
                    _ => parse_math_atom(rhs_pair)?,
                };

                left = MathExpr::binary(left, op, right);
            }

            Ok(left)
        }
        Rule::math_unary => parse_math_unary(pair),
        Rule::math_atom => parse_math_atom(pair),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected math expression rule: {:?}",
            pair.as_rule()
        ))),
    }
}

/// Parse a math atom: number, identifier, or grouped expression.
fn parse_math_atom(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    let inner = pair
        .into_inner()
        .next()
        .ok_or_else(|| ParseError::ParseTree("Empty math atom".to_string()))?;

    match inner.as_rule() {
        Rule::number => {
            let num: f64 = inner
                .as_str()
                .parse()
                .map_err(|_| ParseError::ExpectedNumber(inner.as_str().to_string()))?;
            Ok(MathExpr::atom(MathAtom::Number(num)))
        }
        Rule::ident => Ok(MathExpr::atom(MathAtom::Ident(Ident::new(inner.as_str())))),
        Rule::semantic_ident => {
            // Parse semantic identifier inside math blocks - treat as regular identifier for now
            Ok(MathExpr::atom(MathAtom::Ident(Ident::new(inner.as_str()))))
        }
        Rule::math_array_literal => {
            // Parse array literal inside math blocks
            let elements: Result<Vec<MathExpr>, ParseError> =
                inner.into_inner().map(parse_math_expr_inner).collect();
            Ok(MathExpr::atom(MathAtom::Array(elements?)))
        }
        Rule::math_expr => Ok(MathExpr::atom(MathAtom::Group(Box::new(
            parse_math_expr_inner(inner)?,
        )))),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected math atom rule: {:?}",
            inner.as_rule()
        ))),
    }
}

/// Parse unary expression: optional prefix operator followed by atom.
fn parse_math_unary(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    let mut inner = pair.into_inner();

    let first = inner
        .next()
        .ok_or_else(|| ParseError::ParseTree("Empty unary expression".to_string()))?;

    // Check if first is a unary operator
    match first.as_rule() {
        Rule::math_unary_op => {
            let op = parse_math_unary_operator(first)?;
            let operand_pair = inner.next().ok_or_else(|| {
                ParseError::ParseTree("Missing operand after unary operator".to_string())
            })?;

            let operand = match operand_pair.as_rule() {
                Rule::math_atom => parse_math_atom(operand_pair)?,
                Rule::math_unary => parse_math_unary(operand_pair)?,
                _ => {
                    return Err(ParseError::ParseTree(format!(
                        "Unexpected unary operand rule: {:?}",
                        operand_pair.as_rule()
                    )));
                }
            };

            Ok(MathExpr::unary(op, operand))
        }
        Rule::math_atom => parse_math_atom(first),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected unary rule: {:?}",
            first.as_rule()
        ))),
    }
}

/// Parse math operator into MathOp.
fn parse_math_operator(pair: Pair<Rule>) -> Result<MathOp, ParseError> {
    match pair.as_str().trim() {
        "+" => Ok(MathOp::Add),
        "-" => Ok(MathOp::Subtract),
        "*" => Ok(MathOp::Multiply),
        "/" => Ok(MathOp::Divide),
        "%" => Ok(MathOp::Modulo),
        "^" => Ok(MathOp::Power),
        "R" => Ok(MathOp::Root),
        op => Err(ParseError::InvalidOperator(format!(
            "Unknown math operator: {}",
            op
        ))),
    }
}

/// Parse unary operator into MathUnaryOp.
fn parse_math_unary_operator(pair: Pair<Rule>) -> Result<MathUnaryOp, ParseError> {
    match pair.as_str().trim() {
        "-" => Ok(MathUnaryOp::Negate),
        "+" => Ok(MathUnaryOp::Plus),
        op => Err(ParseError::InvalidOperator(format!(
            "Unknown unary operator: {}",
            op
        ))),
    }
}

/// Parse operator token into RuneOp.
///
/// We defensively trim whitespace so that rules which
/// include incidental spaces around operators do not
/// accidentally produce `"+"`, `"1 "` or `"b * c"` as a
/// single operator token.
fn parse_operator(pair: Pair<Rule>) -> Result<RuneOp, ParseError> {
    let text = pair.as_str().trim();
    RuneOp::from_str(text).map_err(|_| ParseError::InvalidOperator(text.to_string()))
}

File: src\tui\keybindings.rs
============================
//! Keyboard shortcuts and action mapping.

use ratatui::crossterm::event::{KeyCode, KeyEvent, KeyModifiers};

/// Actions that can be triggered by keyboard shortcuts.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Action {
    Quit,
    ToggleMode,
    SwitchPanel,
    OpenFile,
    SaveFile,
    Refresh,
    ToggleSettings,
    ToggleHelp,
    ToggleFileBrowser,
    ToggleHistory,
    ToggleDiff,
    ToggleTheme,
    CopyOutput,
    CopySelection,
    PasteInput,
    ClearInput,
    NewFile,
    RoundTrip,
    OpenRepl,
    None,
}

pub struct KeyBindings;

impl KeyBindings {
    /// Map key event to action.
    pub fn handle(key: KeyEvent) -> Action {
        match (key.code, key.modifiers) {
            (KeyCode::Char('c'), KeyModifiers::CONTROL) => Action::Quit,
            (KeyCode::Char('q'), KeyModifiers::CONTROL) => Action::Quit,
            (KeyCode::Char('e'), KeyModifiers::CONTROL) => Action::ToggleMode,
            (KeyCode::Char('m'), KeyModifiers::CONTROL) => Action::ToggleMode,
            (KeyCode::Tab, KeyModifiers::NONE) => Action::SwitchPanel,
            (KeyCode::Char('o'), KeyModifiers::CONTROL) => Action::OpenFile,
            (KeyCode::Char('s'), KeyModifiers::CONTROL) => Action::SaveFile,
            (KeyCode::Char('n'), KeyModifiers::CONTROL) => Action::NewFile,
            (KeyCode::Char('p'), KeyModifiers::CONTROL) => Action::ToggleSettings,
            (KeyCode::F(1), KeyModifiers::NONE) => Action::ToggleHelp,
            (KeyCode::Char('f'), KeyModifiers::CONTROL) => Action::ToggleFileBrowser,
            (KeyCode::Char('h'), KeyModifiers::CONTROL) => Action::ToggleHistory,
            (KeyCode::Char('d'), KeyModifiers::CONTROL) => Action::ToggleDiff,
            (KeyCode::Char('t'), KeyModifiers::CONTROL) => Action::ToggleTheme,
            (KeyCode::Char('y'), KeyModifiers::CONTROL) => Action::CopyOutput,
            (KeyCode::Char('k'), KeyModifiers::CONTROL) => Action::CopySelection,
            (KeyCode::Char('v'), KeyModifiers::CONTROL) => Action::PasteInput,
            (KeyCode::Char('b'), KeyModifiers::CONTROL) => Action::RoundTrip,
            (KeyCode::Char('r'), KeyModifiers::CONTROL) => Action::OpenRepl,
            (KeyCode::Char('l'), KeyModifiers::CONTROL) => Action::ClearInput,

            _ => Action::None,
        }
    }

    /// Get list of shortcuts for help display.
    pub fn shortcuts() -> Vec<(&'static str, &'static str)> {
        vec![
            ("Ctrl+C/Q", "Quit"),
            ("Ctrl+E/M", "Toggle Mode"),
            ("Tab", "Switch Panel"),
            ("Ctrl+R", "Open REPL"),
            ("Ctrl+O", "Open File"),
            ("Ctrl+S", "Save File"),
            ("Ctrl+N", "New File"),
            ("Ctrl+P", "Settings"),
            ("F1", "Help"),
            ("Ctrl+F", "File Browser"),
            ("Ctrl+H", "History"),
            ("Ctrl+D", "Diff View"),
            ("Ctrl+T", "Toggle Theme"),
            ("Ctrl+Y", "Copy All Output"),
            ("Ctrl+K", "Copy Selection"),
            ("Ctrl+V", "Paste Input"),
            ("Ctrl+B", "Round Trip Test"),
            ("Ctrl+L", "Clear Input"),
        ]
    }
}

File: src\tui\app.rs
====================
use std::{fs, path::PathBuf, time::Duration};

use anyhow::{Context, Result};
use chrono::Local;
use ratatui::crossterm::event::{KeyCode, KeyEvent};
use tiktoken_rs::cl100k_base;

#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;

use crate::{
    decode, encode,
    tui::{
        components::FileBrowser,
        events::{Event, EventHandler},
        keybindings::{Action, KeyBindings},
        repl_command::ReplCommand,
        state::{AppState, ConversionHistory, app_state::ConversionStats},
        ui,
    },
};

/// Main TUI application managing state, events, and rendering.
pub struct TuiApp<'a> {
    pub app_state: AppState<'a>,
    pub file_browser: FileBrowser,
}

impl<'a> TuiApp<'a> {
    pub fn new() -> Self {
        Self {
            app_state: AppState::new(),
            file_browser: FileBrowser::new(),
        }
    }

    pub fn run<B: ratatui::backend::Backend>(
        &mut self,
        terminal: &mut ratatui::Terminal<B>,
    ) -> Result<()> {
        loop {
            terminal.draw(|f| ui::render(f, &mut self.app_state, &mut self.file_browser))?;

            if let Some(event) = EventHandler::poll(Duration::from_millis(100))? {
                self.handle_event(event)?;
            }

            if self.app_state.should_quit {
                break;
            }
        }
        Ok(())
    }

    fn handle_event(&mut self, event: Event) -> Result<()> {
        match event {
            Event::Key(key) => self.handle_key_event(key)?,
            Event::Resize => {}
            Event::Tick => {}
        }
        Ok(())
    }

    fn handle_key_event(&mut self, key: KeyEvent) -> Result<()> {
        // Confirmation dialog takes highest priority
        if self.app_state.show_confirmation {
            return self.handle_confirmation_key(key);
        }

        // REPL takes priority when active
        if self.app_state.repl.active {
            return self.handle_repl_key(key);
        }

        // Handle overlay panels (help, file browser, settings, etc.)
        if self.app_state.show_help
            || self.app_state.show_file_browser
            || self.app_state.show_history
            || self.app_state.show_diff
            || self.app_state.show_settings
        {
            match key.code {
                KeyCode::Esc => {
                    self.app_state.show_help = false;
                    self.app_state.show_file_browser = false;
                    self.app_state.show_history = false;
                    self.app_state.show_diff = false;
                    self.app_state.show_settings = false;
                    return Ok(());
                }
                KeyCode::F(1) if self.app_state.show_help => {
                    self.app_state.show_help = false;
                    return Ok(());
                }
                _ => {}
            }

            if self.app_state.show_file_browser {
                match key.code {
                    KeyCode::Up => {
                        self.file_browser.move_up();
                        return Ok(());
                    }
                    KeyCode::Down => {
                        let count = self
                            .file_browser
                            .get_entry_count(&self.app_state.file_state.current_dir);
                        self.file_browser.move_down(count);
                        return Ok(());
                    }
                    KeyCode::Enter => {
                        self.handle_file_selection()?;
                        return Ok(());
                    }
                    KeyCode::Char(' ') => {
                        self.handle_file_toggle_selection()?;
                        return Ok(());
                    }
                    _ => {}
                }
            }

            if self.app_state.show_settings {
                match key.code {
                    KeyCode::Esc => {
                        self.app_state.show_settings = false;
                        return Ok(());
                    }
                    KeyCode::Char('d') => {
                        self.app_state.cycle_delimiter();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('+') | KeyCode::Char('=') => {
                        self.app_state.increase_indent();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('-') | KeyCode::Char('_') => {
                        self.app_state.decrease_indent();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('f') => {
                        self.app_state.toggle_fold_keys();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('p') => {
                        self.app_state.toggle_expand_paths();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('s') => {
                        self.app_state.toggle_strict();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('c') => {
                        self.app_state.toggle_coerce_types();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('[') | KeyCode::Char('{') => {
                        self.app_state.decrease_flatten_depth();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char(']') | KeyCode::Char('}') => {
                        self.app_state.increase_flatten_depth();
                        self.perform_conversion();
                        return Ok(());
                    }
                    KeyCode::Char('u') => {
                        self.app_state.toggle_flatten_depth();
                        self.perform_conversion();
                        return Ok(());
                    }
                    _ => {}
                }
            }
        }

        let action = KeyBindings::handle(key);
        match action {
            Action::Quit => {
                self.app_state.update(crate::tui::message::Msg::Quit);
            }
            Action::ToggleMode => {
                self.app_state.update(crate::tui::message::Msg::ToggleMode);
                self.perform_conversion();
            }
            Action::SwitchPanel => {
                self.app_state.editor.toggle_active();
            }
            Action::OpenFile => {
                self.open_file_dialog()?;
            }
            Action::SaveFile => {
                self.save_output()?;
            }
            Action::NewFile => {
                self.new_file();
            }
            Action::Refresh => {
                self.perform_conversion();
            }
            Action::ToggleSettings => {
                self.app_state
                    .update(crate::tui::message::Msg::ToggleSettings);
            }
            Action::ToggleHelp => {
                self.app_state.update(crate::tui::message::Msg::ToggleHelp);
            }
            Action::ToggleFileBrowser => {
                self.app_state
                    .update(crate::tui::message::Msg::ToggleFileBrowser);
            }
            Action::ToggleHistory => {
                self.app_state
                    .update(crate::tui::message::Msg::ToggleHistory);
            }
            Action::ToggleDiff => {
                self.app_state.update(crate::tui::message::Msg::ToggleDiff);
            }
            Action::ToggleTheme => {
                self.app_state.update(crate::tui::message::Msg::ToggleTheme);
            }
            Action::CopyOutput => {
                self.copy_to_clipboard()?;
            }
            Action::OpenRepl => {
                self.app_state.repl.activate();
            }
            Action::CopySelection => {
                self.copy_selection_to_clipboard()?;
            }
            Action::PasteInput => {
                self.paste_from_clipboard()?;
            }
            Action::RoundTrip => {
                self.perform_round_trip()?;
            }
            Action::ClearInput => {
                self.app_state.editor.clear_input();
                self.app_state.editor.clear_output();
                self.app_state.stats = None;
            }
            Action::None => {
                if self.app_state.editor.is_input_active() {
                    self.app_state.editor.input.input(key);
                    self.app_state.file_state.mark_modified();
                    self.perform_conversion();
                } else if self.app_state.editor.is_output_active() {
                    // Output is read-only, only allow navigation
                    match key.code {
                        KeyCode::Up
                        | KeyCode::Down
                        | KeyCode::Left
                        | KeyCode::Right
                        | KeyCode::PageUp
                        | KeyCode::PageDown
                        | KeyCode::Home
                        | KeyCode::End => {
                            self.app_state.editor.output.input(key);
                        }
                        _ => {}
                    }
                }
            }
        }

        Ok(())
    }

    /// Convert input based on current mode (encode/decode).
    fn perform_conversion(&mut self) {
        let input = self.app_state.editor.get_input();
        if input.trim().is_empty() {
            self.app_state.editor.clear_output();
            self.app_state.stats = None;
            self.app_state.clear_error();
            return;
        }

        self.app_state.clear_error();

        match self.app_state.mode {
            crate::tui::state::app_state::Mode::Encode => {
                self.encode_input(&input);
            }
            crate::tui::state::app_state::Mode::Decode => {
                self.decode_input(&input);
            }
            crate::tui::state::app_state::Mode::Rune => {
                self.parse_rune_input(&input);
            }
        }
    }

    fn encode_input(&mut self, input: &str) {
        self.app_state.editor.clear_output();

        match serde_json::from_str::<serde_json::Value>(input) {
            Ok(json_value) => match encode(&json_value, &self.app_state.encode_options) {
                Ok(toon_str) => {
                    self.app_state.editor.set_output(toon_str.clone());
                    self.app_state.clear_error();

                    if let Ok(bpe) = cl100k_base() {
                        let json_tokens = bpe.encode_with_special_tokens(input).len();
                        let toon_tokens = bpe.encode_with_special_tokens(&toon_str).len();
                        let json_bytes = input.len();
                        let toon_bytes = toon_str.len();

                        let token_savings =
                            100.0 * (1.0 - (toon_tokens as f64 / json_tokens as f64));
                        let byte_savings = 100.0 * (1.0 - (toon_bytes as f64 / json_bytes as f64));

                        self.app_state.stats = Some(ConversionStats {
                            json_tokens,
                            toon_tokens,
                            json_bytes,
                            toon_bytes,
                            token_savings,
                            byte_savings,
                        });

                        self.app_state.file_state.add_to_history(ConversionHistory {
                            timestamp: Local::now(),
                            mode: "Encode".to_string(),
                            input_file: self.app_state.file_state.current_file.clone(),
                            output_file: None,
                            token_savings,
                            byte_savings,
                        });
                    }
                }
                Err(e) => {
                    self.app_state.set_error(format!("Encode error: {e}"));
                }
            },
            Err(e) => {
                self.app_state.set_error(format!("Invalid JSON: {e}"));
            }
        }
    }

    fn decode_input(&mut self, input: &str) {
        self.app_state.editor.clear_output();

        match decode::<serde_json::Value>(input, &self.app_state.decode_options) {
            Ok(json_value) => match serde_json::to_string_pretty(&json_value) {
                Ok(json_str) => {
                    self.app_state.editor.set_output(json_str.clone());
                    self.app_state.clear_error();

                    if let Ok(bpe) = cl100k_base() {
                        let toon_tokens = bpe.encode_with_special_tokens(input).len();
                        let json_tokens = bpe.encode_with_special_tokens(&json_str).len();
                        let toon_bytes = input.len();
                        let json_bytes = json_str.len();

                        let token_savings =
                            100.0 * (1.0 - (toon_tokens as f64 / json_tokens as f64));
                        let byte_savings = 100.0 * (1.0 - (toon_bytes as f64 / json_bytes as f64));

                        self.app_state.stats = Some(ConversionStats {
                            json_tokens,
                            toon_tokens,
                            json_bytes,
                            toon_bytes,
                            token_savings,
                            byte_savings,
                        });

                        self.app_state.file_state.add_to_history(ConversionHistory {
                            timestamp: Local::now(),
                            mode: "Decode".to_string(),
                            input_file: self.app_state.file_state.current_file.clone(),
                            output_file: None,
                            token_savings,
                            byte_savings,
                        });
                    }
                }
                Err(e) => {
                    self.app_state
                        .set_error(format!("JSON serialization error: {e}"));
                }
            },
            Err(e) => {
                self.app_state.set_error(format!("Decode error: {e}"));
            }
        }
    }

    fn open_file_dialog(&mut self) -> Result<()> {
        self.app_state
            .update(crate::tui::message::Msg::ToggleFileBrowser);
        Ok(())
    }

    fn parse_rune_input(&mut self, input: &str) {
        self.app_state.editor.clear_output();

        match crate::rune::parse_rune(input) {
            Ok(statements) => {
                let mut output = String::new();

                for stmt in &statements {
                    match stmt {
                        crate::rune::Stmt::RootDecl(root) => {
                            output.push_str(&format!("Root: {}\n", root));
                        }
                        crate::rune::Stmt::ToonBlock { name, content } => {
                            output.push_str(&format!("TOON Block '{}':\n", name));
                            // Try to decode as TOON and show JSON
                            match crate::decode::decode::<serde_json::Value>(
                                content,
                                &self.app_state.decode_options,
                            ) {
                                Ok(json) => {
                                    if let Ok(pretty) = serde_json::to_string_pretty(&json) {
                                        output.push_str(&format!("Decoded JSON:\n{}\n", pretty));
                                    }
                                }
                                Err(_) => {
                                    output.push_str(&format!("Raw TOON:\n{}\n", content));
                                }
                            }
                        }
                        crate::rune::Stmt::RuneBlock { name, content } => {
                            output.push_str(&format!("RUNE Block '{}':\n{}\n", name, content));
                        }
                        crate::rune::Stmt::KernelDecl { name, archetype } => {
                            output.push_str(&format!("Kernel: {} := {}\n", name, archetype.name));
                        }
                        crate::rune::Stmt::Expr(expr) => {
                            output.push_str(&format!("Expression: {}\n", expr));
                        }
                    }
                }

                self.app_state.editor.set_output(output);
                self.app_state.clear_error();

                // Count statements as "complexity"
                self.app_state.stats = Some(ConversionStats {
                    json_tokens: statements.len(),
                    toon_tokens: 0,
                    json_bytes: input.len(),
                    toon_bytes: 0,
                    token_savings: 0.0,
                    byte_savings: 0.0,
                });
            }
            Err(e) => {
                self.app_state.set_error(format!("RUNE parse error: {e}"));
            }
        }
    }

    fn save_output(&mut self) -> Result<()> {
        let output = self.app_state.editor.get_output();
        if output.trim().is_empty() {
            self.app_state.set_error("Nothing to save".to_string());
            return Ok(());
        }

        let extension = match self.app_state.mode {
            crate::tui::state::app_state::Mode::Encode => "toon",
            crate::tui::state::app_state::Mode::Decode => "json",
            crate::tui::state::app_state::Mode::Rune => "rune",
        };

        let path = if let Some(current) = &self.app_state.file_state.current_file {
            current.with_extension(extension)
        } else {
            PathBuf::from(format!("output.{extension}"))
        };

        fs::write(&path, output).context("Failed to save file")?;
        self.app_state
            .set_status(format!("Saved to {}", path.display()));
        self.app_state.file_state.is_modified = false;

        Ok(())
    }

    fn new_file(&mut self) {
        if self.app_state.file_state.is_modified {
            self.app_state.show_confirmation = true;
            self.app_state.confirmation_action =
                crate::tui::state::app_state::ConfirmationAction::NewFile;
            return;
        }
        self.app_state.editor.clear_input();
        self.app_state.editor.clear_output();
        self.app_state.file_state.clear_current_file();
        self.app_state.stats = None;
        self.app_state.set_status("New file created".to_string());
    }

    fn copy_to_clipboard(&mut self) -> Result<()> {
        let output = self.app_state.editor.get_output();
        if output.trim().is_empty() {
            self.app_state.set_error("Nothing to copy".to_string());
            return Ok(());
        }

        #[cfg(not(target_os = "unknown"))]
        {
            use arboard::Clipboard;
            let mut clipboard = Clipboard::new()?;
            clipboard.set_text(output)?;
            self.app_state.set_status("Copied to clipboard".to_string());
        }

        #[cfg(target_os = "unknown")]
        {
            self.app_state
                .set_error("Clipboard not supported on this platform".to_string());
        }

        Ok(())
    }

    fn paste_from_clipboard(&mut self) -> Result<()> {
        #[cfg(not(target_os = "unknown"))]
        {
            use arboard::Clipboard;
            let mut clipboard = Clipboard::new()?;
            let text = clipboard.get_text()?;
            self.app_state.editor.set_input(text);
            self.app_state.file_state.mark_modified();
            self.perform_conversion();
            self.app_state
                .set_status("Pasted from clipboard".to_string());
        }

        #[cfg(target_os = "unknown")]
        {
            self.app_state
                .set_error("Clipboard not supported on this platform".to_string());
        }

        Ok(())
    }

    fn handle_confirmation_key(&mut self, key: KeyEvent) -> Result<()> {
        use crate::tui::state::app_state::ConfirmationAction;

        match key.code {
            KeyCode::Char('y') | KeyCode::Char('Y') => {
                // User confirmed - perform action
                match self.app_state.confirmation_action {
                    ConfirmationAction::NewFile => {
                        self.app_state.editor.clear_input();
                        self.app_state.editor.clear_output();
                        self.app_state.file_state.clear_current_file();
                        self.app_state.set_status("New file created".to_string());
                    }
                    ConfirmationAction::Quit => {
                        self.app_state.should_quit = true;
                    }
                    ConfirmationAction::DeleteFile => {
                        if let Some(current_file) = &self.app_state.file_state.current_file {
                            if let Err(e) = std::fs::remove_file(current_file) {
                                self.app_state.set_error(format!("Delete failed: {e}"));
                            } else {
                                self.app_state.set_status("File deleted".to_string());
                            }
                        }
                    }
                    ConfirmationAction::None => {}
                }
                self.app_state.show_confirmation = false;
                self.app_state.confirmation_action = ConfirmationAction::None;
            }
            KeyCode::Char('n') | KeyCode::Char('N') | KeyCode::Esc => {
                // User cancelled
                self.app_state.show_confirmation = false;
                self.app_state.confirmation_action = ConfirmationAction::None;
            }
            _ => {}
        }
        Ok(())
    }

    fn handle_file_selection(&mut self) -> Result<()> {
        let current_dir = self.app_state.file_state.current_dir.clone();
        if let Some(selected_path) = self.file_browser.get_selected_entry(&current_dir) {
            if selected_path.is_dir() {
                // Navigate into directory
                self.app_state.file_state.current_dir = selected_path;
                self.file_browser.selected_index = 0;
                self.app_state.set_status(format!(
                    "Navigated to {}",
                    self.app_state.file_state.current_dir.display()
                ));
            } else if selected_path.is_file() {
                // Open file
                match fs::read_to_string(&selected_path) {
                    Ok(content) => {
                        self.app_state.editor.set_input(content);
                        self.app_state
                            .file_state
                            .set_current_file(selected_path.clone());

                        // Auto-detect mode based on extension
                        if let Some(ext) = selected_path.extension().and_then(|e| e.to_str()) {
                            match ext {
                                "json" => {
                                    self.app_state.mode =
                                        crate::tui::state::app_state::Mode::Encode;
                                }
                                "toon" => {
                                    self.app_state.mode =
                                        crate::tui::state::app_state::Mode::Decode;
                                }
                                "rune" => {
                                    self.app_state.mode = crate::tui::state::app_state::Mode::Rune;
                                }
                                _ => {}
                            }
                        }

                        self.perform_conversion();
                        self.app_state.show_file_browser = false;
                        self.app_state
                            .set_status(format!("Opened {}", selected_path.display()));
                    }
                    Err(e) => {
                        self.app_state
                            .set_error(format!("Failed to read file: {e}"));
                    }
                }
            }
        }
        Ok(())
    }

    fn handle_file_toggle_selection(&mut self) -> Result<()> {
        let current_dir = self.app_state.file_state.current_dir.clone();
        if let Some(selected_path) = self
            .file_browser
            .get_selected_entry(&current_dir)
            .filter(|p| p.is_file())
        {
            self.app_state
                .file_state
                .toggle_file_selection(selected_path.clone());
            let is_selected = self.app_state.file_state.is_selected(&selected_path);
            let action = if is_selected {
                "Selected"
            } else {
                "Deselected"
            };
            self.app_state
                .set_status(format!("{} {}", action, selected_path.display()));
        }
        Ok(())
    }

    fn copy_selection_to_clipboard(&mut self) -> Result<()> {
        let text = if self.app_state.editor.is_input_active() {
            self.app_state.editor.input.yank_text()
        } else {
            self.app_state.editor.output.yank_text()
        };

        if text.is_empty() {
            self.app_state.set_error("Nothing to copy".to_string());
            return Ok(());
        }

        #[cfg(not(target_os = "unknown"))]
        {
            use arboard::Clipboard;
            let mut clipboard = Clipboard::new()?;
            clipboard.set_text(text)?;
            self.app_state
                .set_status("Copied selection to clipboard".to_string());
        }

        #[cfg(target_os = "unknown")]
        {
            self.app_state
                .set_error("Clipboard not supported on this platform".to_string());
        }

        Ok(())
    }

    /// Round-trip test: convert output back to input and verify.
    fn perform_round_trip(&mut self) -> Result<()> {
        let output = self.app_state.editor.get_output();
        if output.trim().is_empty() {
            self.app_state
                .set_error("No output to round-trip test. Convert something first!".to_string());
            return Ok(());
        }

        let original_input = self.app_state.editor.get_input();
        self.app_state.editor.set_input(output.clone());
        self.app_state.toggle_mode();
        self.perform_conversion();

        let roundtrip_output = self.app_state.editor.get_output();

        if roundtrip_output.trim().is_empty() {
            self.app_state.set_error(
                "Round-trip failed! Conversion produced no output. Check for errors.".to_string(),
            );
            return Ok(());
        }

        let matches = self.compare_data(&original_input, &roundtrip_output);

        if matches {
            self.app_state
                .set_status("✓ Round-trip successful! Output matches original.".to_string());
        } else {
            self.app_state.set_error(format!(
                "⚠ Round-trip mismatch! Original had {} chars, round-trip has {} chars.",
                original_input.len(),
                roundtrip_output.len()
            ));
        }

        Ok(())
    }

    /// Compare data semantically, trying JSON parse first.
    fn compare_data(&self, original: &str, roundtrip: &str) -> bool {
        // Try JSON comparison for accuracy
        if let (Ok(orig_json), Ok(rt_json)) = (
            serde_json::from_str::<serde_json::Value>(original),
            serde_json::from_str::<serde_json::Value>(roundtrip),
        ) {
            return orig_json == rt_json;
        }

        let original_normalized: String = original.split_whitespace().collect();
        let roundtrip_normalized: String = roundtrip.split_whitespace().collect();
        original_normalized == roundtrip_normalized
    }

    /// Handle keyboard input when REPL is active.
    fn handle_repl_key(&mut self, key: KeyEvent) -> Result<()> {
        match key.code {
            KeyCode::Esc => {
                self.app_state.repl.deactivate();
            }
            KeyCode::Char('r')
                if key
                    .modifiers
                    .contains(ratatui::crossterm::event::KeyModifiers::CONTROL) =>
            {
                self.app_state.repl.deactivate();
            }
            KeyCode::Enter => {
                let cmd_input = self.app_state.repl.input.clone();
                if !cmd_input.trim().is_empty() {
                    self.app_state.repl.add_prompt(&cmd_input);
                    self.app_state.repl.add_to_history(cmd_input.clone());

                    if let Err(e) = self.execute_repl_command(&cmd_input) {
                        self.app_state.repl.add_error(format!("{e}"));
                    }

                    self.app_state.repl.input.clear();
                    self.app_state.repl.scroll_to_bottom();
                }
            }
            KeyCode::Up => {
                self.app_state.repl.history_up();
            }
            KeyCode::Down => {
                self.app_state.repl.history_down();
            }
            KeyCode::PageUp => {
                self.app_state.repl.scroll_up();
            }
            KeyCode::PageDown => {
                self.app_state.repl.scroll_down(20);
            }
            KeyCode::Char(c) => {
                self.app_state.repl.input.push(c);
            }
            KeyCode::Backspace => {
                self.app_state.repl.input.pop();
            }
            _ => {}
        }
        Ok(())
    }

    /// Execute parsed REPL command and update state.
    fn execute_repl_command(&mut self, input: &str) -> Result<()> {
        let cmd = ReplCommand::parse(input)?;

        match cmd.name.as_str() {
            "encode" | "e" => {
                let mut data = cmd
                    .inline_data
                    .as_ref()
                    .map(|s| s.to_string())
                    .unwrap_or_else(String::new);

                data = self.substitute_variables(&data);

                if data.is_empty() {
                    self.app_state
                        .repl
                        .add_error("Usage: encode {\"data\": true} or encode $var".to_string());
                    return Ok(());
                }

                match serde_json::from_str::<serde_json::Value>(&data) {
                    Ok(json_value) => match encode(&json_value, &self.app_state.encode_options) {
                        Ok(toon_str) => {
                            self.app_state.repl.add_success(toon_str.clone());
                            self.app_state.repl.last_result = Some(toon_str);
                        }
                        Err(e) => {
                            self.app_state.repl.add_error(format!("Encode error: {e}"));
                        }
                    },
                    Err(e) => {
                        self.app_state.repl.add_error(format!("Invalid JSON: {e}"));
                    }
                }
            }
            "decode" | "d" => {
                let mut data = cmd
                    .inline_data
                    .as_ref()
                    .map(|s| s.to_string())
                    .unwrap_or_else(String::new);

                data = self.substitute_variables(&data);

                if data.is_empty() {
                    self.app_state
                        .repl
                        .add_error("Usage: decode name: Alice or decode $var".to_string());
                    return Ok(());
                }

                match decode::<serde_json::Value>(&data, &self.app_state.decode_options) {
                    Ok(json_value) => match serde_json::to_string_pretty(&json_value) {
                        Ok(json_str) => {
                            self.app_state.repl.add_success(json_str.clone());
                            self.app_state.repl.last_result = Some(json_str);
                        }
                        Err(e) => {
                            self.app_state.repl.add_error(format!("JSON error: {e}"));
                        }
                    },
                    Err(e) => {
                        self.app_state.repl.add_error(format!("Decode error: {e}"));
                    }
                }
            }
            "rune" | "r" => {
                let mut data = cmd
                    .inline_data
                    .as_ref()
                    .map(|s| s.to_string())
                    .unwrap_or_else(String::new);

                data = self.substitute_variables(&data);

                if data.is_empty() {
                    self.app_state.repl.add_error(
                        "Usage: rune root: example\ndata ~TOON:\n  items: value\n\nor rune $var"
                            .to_string(),
                    );
                    return Ok(());
                }

                match crate::rune::parse_rune(&data) {
                    Ok(statements) => {
                        #[cfg(feature = "hydron")]
                        {
                            let mut output = String::new();
                            for stmt in &statements {
                                match self.app_state.rune_eval.eval_stmt(stmt) {
                                    Ok(val) => {
                                        let rendered = self.format_rune_value(&val);
                                        output.push_str(&format!("✓ {rendered}\n"));
                                        self.app_state.repl.last_result = Some(rendered);
                                    }
                                    Err(e) => {
                                        self.app_state
                                            .repl
                                            .add_error(format!("RUNE eval error: {e}"));
                                    }
                                }
                            }
                            if !output.is_empty() {
                                self.app_state
                                    .repl
                                    .add_success(output.trim_end().to_string());
                            }
                        }

                        #[cfg(not(feature = "hydron"))]
                        {
                            let mut output = String::new();

                            for stmt in &statements {
                                match stmt {
                                    crate::rune::Stmt::RootDecl(root) => {
                                        output.push_str(&format!("✓ Root: {}\n", root));
                                    }
                                    crate::rune::Stmt::ToonBlock { name, content } => {
                                        output.push_str(&format!(
                                            "✓ TOON Block '{}': {} chars\n",
                                            name,
                                            content.len()
                                        ));
                                        if let Ok(json) = crate::decode::decode::<serde_json::Value>(
                                            content,
                                            &self.app_state.decode_options,
                                        ) {
                                            if let Ok(json_str) = serde_json::to_string(&json) {
                                                if json_str.len() < 200 {
                                                    output.push_str(&format!("  {}", json_str));
                                                } else {
                                                    output.push_str(&format!(
                                                        "  ({} items)",
                                                        if json.is_array() {
                                                            json.as_array().unwrap().len()
                                                        } else if json.is_object() {
                                                            json.as_object().unwrap().len()
                                                        } else {
                                                            1
                                                        }
                                                    ));
                                                }
                                                output.push('\n');
                                            }
                                        }
                                    }
                                    crate::rune::Stmt::RuneBlock { name, content } => {
                                        output.push_str(&format!(
                                            "✓ RUNE Block '{}': {} chars\n",
                                            name,
                                            content.len()
                                        ));
                                    }
                                    crate::rune::Stmt::KernelDecl { name, archetype } => {
                                        output.push_str(&format!(
                                            "✓ Kernel: {} := {}\n",
                                            name, archetype.name
                                        ));
                                    }
                                    crate::rune::Stmt::Expr(expr) => {
                                        output.push_str(&format!("✓ Expression: {}\n", expr));
                                    }
                                }
                            }
                            self.app_state.repl.add_success(output);
                            self.app_state.repl.last_result = Some(statements.len().to_string());
                            self.app_state.repl.add_info(
                                "Enable the 'hydron' feature for full RUNE execution".to_string(),
                            );
                        }
                    }
                    Err(e) => {
                        self.app_state
                            .repl
                            .add_error(format!("RUNE parse error: {e}"));
                    }
                }
            }
            "let" => {
                let parts: Vec<&str> = input.splitn(2, '=').collect();
                if parts.len() == 2 {
                    let var_part = parts[0].trim().trim_start_matches("let").trim();
                    let data_part = parts[1].trim();

                    if !var_part.is_empty() && !data_part.is_empty() {
                        let var_name = var_part.trim_start_matches('$');
                        self.app_state
                            .repl
                            .variables
                            .insert(var_name.to_string(), data_part.to_string());
                        self.app_state
                            .repl
                            .add_info(format!("Stored in ${var_name}"));
                        self.app_state.repl.last_result = Some(data_part.to_string());
                    } else {
                        self.app_state
                            .repl
                            .add_error("Usage: let $var = {\"data\": true}".to_string());
                    }
                } else {
                    self.app_state
                        .repl
                        .add_error("Usage: let $var = {\"data\": true}".to_string());
                }
            }
            "vars" => {
                if self.app_state.repl.variables.is_empty() {
                    self.app_state
                        .repl
                        .add_info("No variables defined".to_string());
                } else {
                    let vars: Vec<String> = self
                        .app_state
                        .repl
                        .variables
                        .keys()
                        .map(|k| format!("${k}"))
                        .collect();
                    for var in vars {
                        self.app_state.repl.add_info(var);
                    }
                }
            }
            "clear" => {
                self.app_state.repl.output.clear();
                self.app_state
                    .repl
                    .output
                    .push(crate::tui::state::ReplLine {
                        kind: crate::tui::state::ReplLineKind::Info,
                        content: "Cleared".to_string(),
                    });
            }
            "help" | "h" => {
                self.app_state
                    .repl
                    .add_info("📖 REPL Commands:".to_string());
                self.app_state.repl.add_info("".to_string());
                self.app_state
                    .repl
                    .add_info("  encode {\"data\": true}  - Encode JSON to TOON".to_string());
                self.app_state
                    .repl
                    .add_info("  decode name: Alice      - Decode TOON to JSON".to_string());
                self.app_state
                    .repl
                    .add_info("  rune root: continuum   - Parse and evaluate RUNE".to_string());
                self.app_state
                    .repl
                    .add_info("  let $var = {...}        - Store data in variable".to_string());
                self.app_state
                    .repl
                    .add_info("  vars                    - List all variables".to_string());
                self.app_state
                    .repl
                    .add_info("  clear                   - Clear session".to_string());
                self.app_state
                    .repl
                    .add_info("  help                    - Show this help".to_string());
                self.app_state
                    .repl
                    .add_info("  exit                    - Close REPL".to_string());
                self.app_state.repl.add_info("".to_string());
                self.app_state
                    .repl
                    .add_info("Press ↑/↓ for history, Esc to close".to_string());
            }
            "exit" | "quit" | "q" => {
                self.app_state.repl.add_info("Closing REPL...".to_string());
                self.app_state.repl.deactivate();
            }
            _ => {
                self.app_state
                    .repl
                    .add_error(format!("Unknown command: {}. Type 'help'", cmd.name));
            }
        }

        Ok(())
    }

    /// Replace $var and $_ with their stored values.
    fn substitute_variables(&self, text: &str) -> String {
        let mut result = text.to_string();

        // $_ is the last result
        if let Some(last) = &self.app_state.repl.last_result {
            result = result.replace("$_", last);
        }

        // Variables are stored without $, add it for matching
        for (var_name, var_value) in &self.app_state.repl.variables {
            let pattern = format!("${var_name}");
            result = result.replace(&pattern, var_value);
        }

        result
    }

    #[cfg(feature = "hydron")]
    fn format_rune_value(&self, value: &Value) -> String {
        match value {
            Value::Bool(b) => b.to_string(),
            Value::Scalar(s) => format!("{s}"),
            Value::Float(f) => format!("{f}"),
            Value::String(s) => s.clone(),
            Value::Vec8(v) => {
                let parts: Vec<String> = v.iter().map(|x| format!("{:.4}", x)).collect();
                format!("Vec8({})", parts.join(", "))
            }
            Value::Vec16(v) => {
                let parts: Vec<String> = v.iter().map(|x| format!("{:.4}", x)).collect();
                format!("Vec16({})", parts.join(", "))
            }
            Value::Array(items) | Value::Tuple(items) => {
                let inner: Vec<String> = items.iter().map(|v| self.format_rune_value(v)).collect();
                format!("[{}]", inner.join(", "))
            }
            Value::Struct(name, items) => {
                let inner: Vec<String> = items.iter().map(|v| self.format_rune_value(v)).collect();
                format!("{name}({})", inner.join(", "))
            }
            Value::Map(map) => {
                let mut parts: Vec<String> = map
                    .iter()
                    .map(|(k, v)| format!("{k}: {}", self.format_rune_value(v)))
                    .collect();
                parts.sort();
                format!("{{{}}}", parts.join(", "))
            }
            _ => format!("{:?}", value),
        }
    }
}

impl<'a> Default for TuiApp<'a> {
    fn default() -> Self {
        Self::new()
    }
}

File: src\tui\message.rs
========================
//! Application messages (Elm-style) for TUI
//!
// This module defines the central `Msg` enum which represents all
// user actions and events that can modify application state.

use std::path::PathBuf;

#[derive(Debug, Clone, PartialEq)]
pub enum Msg {
    Quit,
    ToggleMode,
    ToggleSettings,
    ToggleHelp,
    ToggleFileBrowser,
    ToggleHistory,
    ToggleDiff,
    ToggleTheme,
    OpenFile(PathBuf),
    SaveFile,
    NewFile,
    Refresh,
    ExecuteRepl(String),
    CopyOutput,
    CopySelection,
    PasteInput,
    RoundTrip,
    ClearInput,
    SetError(String),
    SetStatus(String),
    ClearError,
    ClearStatus,
    // Add more messages as needed for components
}

File: src\tui\events.rs
=======================
//! Event handling for terminal input.

use std::time::Duration;

use ratatui::crossterm::event::{self, Event as CrosstermEvent, KeyEvent};

/// TUI events.
pub enum Event {
    Key(KeyEvent),
    Tick,
    Resize,
}

pub struct EventHandler;

impl EventHandler {
    /// Poll for next event with timeout.
    pub fn poll(timeout: Duration) -> std::io::Result<Option<Event>> {
        if event::poll(timeout)? {
            match event::read()? {
                CrosstermEvent::Key(key) => Ok(Some(Event::Key(key))),
                CrosstermEvent::Resize(_, _) => Ok(Some(Event::Resize)),
                _ => Ok(None),
            }
        } else {
            Ok(Some(Event::Tick))
        }
    }
}

File: src\tui\mod.rs
====================
//! Terminal User Interface for TOON format conversion.
//!
//! Provides an interactive TUI with real-time conversion, REPL, and settings
//! panels.

pub mod app;
pub mod components;
pub mod events;
pub mod keybindings;
pub mod message;
pub mod repl_command;
pub mod state;
pub mod theme;
pub mod ui;

use std::io;

use anyhow::Result;
pub use app::TuiApp;
use crossterm::{
    execute,
    terminal::{EnterAlternateScreen, LeaveAlternateScreen, disable_raw_mode, enable_raw_mode},
};
use ratatui::{Terminal, backend::CrosstermBackend};

/// Initialize and run the TUI application.
///
/// Sets up terminal in raw mode, runs the app, then restores terminal state.
pub fn run() -> Result<()> {
    enable_raw_mode()?;
    let mut stdout = io::stdout();
    execute!(stdout, EnterAlternateScreen)?;
    let backend = CrosstermBackend::new(stdout);
    let mut terminal = Terminal::new(backend)?;

    let mut app = TuiApp::new();
    let res = app.run(&mut terminal);

    // Always restore terminal, even on error
    disable_raw_mode()?;
    execute!(terminal.backend_mut(), LeaveAlternateScreen)?;
    terminal.show_cursor()?;

    res
}

File: src\tui\repl_command.rs
=============================
//! REPL command parser with inline data support

use anyhow::{Result, bail};

/// Parsed REPL command with inline data
#[derive(Debug, Clone)]
pub struct ReplCommand {
    pub name: String,
    pub inline_data: Option<String>,
    pub args: Vec<String>,
}

impl ReplCommand {
    /// Parse command input, extracting inline data if present.
    ///
    /// Handles patterns like:
    /// - `encode {"data": true}` - JSON inline
    /// - `decode name: Alice` - TOON inline
    /// - `encode $var` - Variable reference
    pub fn parse(input: &str) -> Result<Self> {
        let input = input.trim();
        if input.is_empty() {
            bail!("Empty command");
        }

        let parts: Vec<&str> = input.splitn(2, ' ').collect();
        let cmd_name = parts[0].to_string();

        let (inline_data, remaining_args) = if parts.len() > 1 {
            let rest = parts[1].trim();

            // Check if input looks like data rather than flags/args
            if rest.starts_with('{')
                || rest.starts_with('"')
                || rest.starts_with('$')
                || rest.contains(':')
            {
                let data_end = if rest.starts_with('{') {
                    find_matching_brace(rest) // Handle nested braces
                } else if rest.starts_with('$') {
                    rest.find(' ').unwrap_or(rest.len()) // Variable name
                } else {
                    rest.find(" --").unwrap_or(rest.len()) // Until flag or end
                };

                let data = rest[..data_end].trim().to_string();
                let remaining = rest[data_end..].trim();

                (
                    Some(data),
                    if remaining.is_empty() {
                        vec![]
                    } else {
                        remaining
                            .split_whitespace()
                            .map(|s| s.to_string())
                            .collect()
                    },
                )
            } else {
                (
                    None,
                    rest.split_whitespace().map(|s| s.to_string()).collect(),
                )
            }
        } else {
            (None, vec![])
        };

        Ok(ReplCommand {
            name: cmd_name,
            inline_data,
            args: remaining_args,
        })
    }

    pub fn has_flag(&self, flag: &str) -> bool {
        self.args.iter().any(|a| a == flag)
    }

    pub fn get_option(&self, option: &str) -> Option<&str> {
        self.args
            .iter()
            .position(|a| a == option)
            .and_then(|i| self.args.get(i + 1))
            .map(|s| s.as_str())
    }
}

fn find_matching_brace(s: &str) -> usize {
    let mut depth = 0;
    for (i, ch) in s.chars().enumerate() {
        match ch {
            '{' => depth += 1,
            '}' => {
                depth -= 1;
                if depth == 0 {
                    return i + 1;
                }
            }
            _ => {}
        }
    }
    s.len()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_inline_json() {
        let cmd = ReplCommand::parse(r#"encode {"test": true}"#).unwrap();
        assert_eq!(cmd.name, "encode");
        assert_eq!(cmd.inline_data, Some(r#"{"test": true}"#.to_string()));
    }

    #[test]
    fn test_inline_toon() {
        let cmd = ReplCommand::parse("decode name: Alice").unwrap();
        assert_eq!(cmd.name, "decode");
        assert_eq!(cmd.inline_data, Some("name: Alice".to_string()));
    }

    #[test]
    fn test_with_flags() {
        let cmd = ReplCommand::parse(r#"encode {"test": true} --fold-keys"#).unwrap();
        assert_eq!(cmd.name, "encode");
        assert!(cmd.inline_data.is_some());
        assert!(cmd.has_flag("--fold-keys"));
    }
}

File: src\types\delimeter.rs
============================
use std::fmt;

use serde::{Deserialize, Serialize};

/// Delimiter character used to separate array elements.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]
pub enum Delimiter {
    #[default]
    Comma,
    Tab,
    Pipe,
}

impl Delimiter {
    /// Get the character representation of this delimiter.
    pub fn as_char(&self) -> char {
        match self {
            Delimiter::Comma => ',',
            Delimiter::Tab => '\t',
            Delimiter::Pipe => '|',
        }
    }

    /// Get the string representation for metadata (empty for comma, char for
    /// others).
    pub fn as_metadata_str(&self) -> &'static str {
        match self {
            Delimiter::Comma => "",
            Delimiter::Tab => "\t",
            Delimiter::Pipe => "|",
        }
    }

    /// Parse a delimiter from a character.
    pub fn from_char(c: char) -> Option<Self> {
        match c {
            ',' => Some(Delimiter::Comma),
            '\t' => Some(Delimiter::Tab),
            '|' => Some(Delimiter::Pipe),
            _ => None,
        }
    }

    /// Check if the delimiter character appears in the string.
    pub fn contains_in(&self, s: &str) -> bool {
        s.contains(self.as_char())
    }
}

impl fmt::Display for Delimiter {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.as_char())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_delimiter_conversion() {
        assert_eq!(Delimiter::Comma.as_char(), ',');
        assert_eq!(Delimiter::Tab.as_char(), '\t');
        assert_eq!(Delimiter::Pipe.as_char(), '|');
    }

    #[test]
    fn test_delimiter_from_char() {
        assert_eq!(Delimiter::from_char(','), Some(Delimiter::Comma));
        assert_eq!(Delimiter::from_char('\t'), Some(Delimiter::Tab));
        assert_eq!(Delimiter::from_char('|'), Some(Delimiter::Pipe));
        assert_eq!(Delimiter::from_char('x'), None);
    }

    #[test]
    fn test_delimiter_contains() {
        assert!(Delimiter::Comma.contains_in("a,b,c"));
        assert!(Delimiter::Tab.contains_in("a\tb\tc"));
        assert!(Delimiter::Pipe.contains_in("a|b|c"));
        assert!(!Delimiter::Comma.contains_in("abc"));
    }
}

File: src\types\mod.rs
======================
mod delimeter;
mod errors;
mod folding;
mod options;
mod value;

pub use delimeter::Delimiter;
pub use errors::{ErrorContext, ToonError, ToonResult};
pub use folding::{KeyFoldingMode, PathExpansionMode, is_identifier_segment};
pub use options::{DecodeOptions, EncodeOptions, Indent};
pub use value::{IntoJsonValue, JsonValue, Number};

File: src\tui\theme.rs
======================
//! Color themes for the TUI.

use ratatui::style::{Color, Modifier, Style};

/// Available color themes.
#[derive(Debug, Clone, Copy, PartialEq, Default)]
pub enum Theme {
    #[default]
    Dark,
    Light,
}

impl Theme {
    /// Switch between dark and light themes.
    pub fn toggle(&self) -> Self {
        match self {
            Theme::Dark => Theme::Light,
            Theme::Light => Theme::Dark,
        }
    }

    pub fn background(&self) -> Color {
        match self {
            Theme::Dark => Color::Black,
            Theme::Light => Color::White,
        }
    }

    pub fn foreground(&self) -> Color {
        match self {
            Theme::Dark => Color::White,
            Theme::Light => Color::Black,
        }
    }

    pub fn border(&self) -> Color {
        match self {
            Theme::Dark => Color::Cyan,
            Theme::Light => Color::Blue,
        }
    }

    pub fn border_active(&self) -> Color {
        match self {
            Theme::Dark => Color::Green,
            Theme::Light => Color::Green,
        }
    }

    pub fn title(&self) -> Color {
        match self {
            Theme::Dark => Color::Yellow,
            Theme::Light => Color::Blue,
        }
    }

    pub fn success(&self) -> Color {
        Color::Green
    }

    pub fn error(&self) -> Color {
        Color::Red
    }

    pub fn warning(&self) -> Color {
        Color::Yellow
    }

    pub fn info(&self) -> Color {
        Color::Cyan
    }

    pub fn highlight(&self) -> Color {
        match self {
            Theme::Dark => Color::Blue,
            Theme::Light => Color::LightBlue,
        }
    }

    pub fn selection(&self) -> Color {
        match self {
            Theme::Dark => Color::DarkGray,
            Theme::Light => Color::LightYellow,
        }
    }

    pub fn line_number(&self) -> Color {
        match self {
            Theme::Dark => Color::DarkGray,
            Theme::Light => Color::Gray,
        }
    }

    pub fn normal_style(&self) -> Style {
        Style::default().fg(self.foreground()).bg(self.background())
    }

    /// Get border style, highlighted if active.
    pub fn border_style(&self, active: bool) -> Style {
        Style::default().fg(if active {
            self.border_active()
        } else {
            self.border()
        })
    }

    pub fn title_style(&self) -> Style {
        Style::default()
            .fg(self.title())
            .add_modifier(Modifier::BOLD)
    }

    pub fn highlight_style(&self) -> Style {
        Style::default().fg(self.foreground()).bg(self.highlight())
    }

    pub fn selection_style(&self) -> Style {
        Style::default()
            .fg(self.foreground())
            .bg(self.selection())
            .add_modifier(Modifier::BOLD)
    }

    pub fn error_style(&self) -> Style {
        Style::default()
            .fg(self.error())
            .add_modifier(Modifier::BOLD)
    }

    pub fn success_style(&self) -> Style {
        Style::default()
            .fg(self.success())
            .add_modifier(Modifier::BOLD)
    }

    pub fn warning_style(&self) -> Style {
        Style::default()
            .fg(self.warning())
            .add_modifier(Modifier::BOLD)
    }

    pub fn info_style(&self) -> Style {
        Style::default().fg(self.info())
    }

    pub fn line_number_style(&self) -> Style {
        Style::default().fg(self.line_number())
    }
}

File: src\tui\ui.rs
===================
use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, Paragraph},
};

use super::{
    components::{
        ConfirmationDialog, DiffViewer, EditorComponent, FileBrowser, HelpScreen, HistoryPanel,
        ReplPanel, SettingsPanel, StatsBar, StatusBar,
    },
    state::AppState,
    theme::Theme,
};
use crate::types::{KeyFoldingMode, PathExpansionMode};

/// Main render function - orchestrates all UI components.
pub fn render(f: &mut Frame, app: &mut AppState, file_browser: &mut FileBrowser) {
    let theme = app.theme;

    let chunks = Layout::default()
        .direction(Direction::Vertical)
        .constraints([
            Constraint::Length(3),
            Constraint::Min(10),
            Constraint::Length(4),
            Constraint::Length(3),
        ])
        .split(f.area());

    render_header(f, chunks[0], app);

    // REPL takes full screen (except header)
    if app.repl.active {
        let repl_area = Layout::default()
            .direction(Direction::Vertical)
            .constraints([Constraint::Length(3), Constraint::Min(10)])
            .split(f.area())[1];

        ReplPanel::render(f, repl_area, app);
        return;
    } else if app.show_help {
        HelpScreen::render(f, chunks[1], &theme);
    } else if app.show_file_browser {
        file_browser.render(f, chunks[1], app, &theme);
    } else if app.show_history {
        HistoryPanel::render(f, chunks[1], app, &theme);
    } else if app.show_diff {
        DiffViewer::render(f, chunks[1], app, &theme);
    } else if app.show_settings {
        SettingsPanel::render(f, chunks[1], app, &theme);
    } else {
        let editor_chunks = Layout::default()
            .direction(Direction::Horizontal)
            .constraints([
                Constraint::Percentage(48),
                Constraint::Percentage(4),
                Constraint::Percentage(48),
            ])
            .split(chunks[1]);

        EditorComponent::render(f, editor_chunks[0], editor_chunks[2], app, &theme);
        render_arrow(f, editor_chunks[1], app, &theme);
    }

    StatsBar::render(f, chunks[2], app, &theme);
    StatusBar::render(f, chunks[3], app, &theme);

    // Render confirmation dialog on top if active
    if app.show_confirmation {
        ConfirmationDialog::render(f, f.area(), app.confirmation_action);
    }
}

/// Render conversion arrow and round-trip button between panels.
fn render_arrow(f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
    let arrow_symbol = match app.mode {
        crate::tui::state::app_state::Mode::Encode => "→",
        crate::tui::state::app_state::Mode::Decode => "←",
        crate::tui::state::app_state::Mode::Rune => "🪄",
    };

    let arrow_text = vec![
        Line::from(""),
        Line::from(""),
        Line::from(Span::styled(arrow_symbol, theme.info_style())),
        Line::from(""),
        Line::from(Span::styled("Ctrl+B", theme.line_number_style())),
        Line::from(Span::styled("Round", theme.line_number_style())),
        Line::from(Span::styled("Trip", theme.line_number_style())),
    ];

    let arrow_para = Paragraph::new(arrow_text).alignment(Alignment::Center);

    f.render_widget(arrow_para, area);
}

/// Render header with title, mode, and current settings.
fn render_header(f: &mut Frame, area: Rect, app: &AppState) {
    let theme = app.theme;

    let chunks = Layout::default()
        .direction(Direction::Horizontal)
        .constraints([
            Constraint::Percentage(33),
            Constraint::Percentage(34),
            Constraint::Percentage(33),
        ])
        .split(area);

    let title = Paragraph::new(Line::from(vec![
        Span::styled("📋 ", theme.normal_style()),
        Span::styled("TOON", theme.title_style()),
        Span::styled(" Format", theme.info_style()),
    ]))
    .block(Block::default().borders(Borders::ALL));
    f.render_widget(title, chunks[0]);

    let mode_text = Paragraph::new(Line::from(vec![Span::styled(
        app.mode.as_str(),
        theme.highlight_style(),
    )]))
    .alignment(Alignment::Center)
    .block(Block::default().borders(Borders::ALL));
    f.render_widget(mode_text, chunks[1]);

    // Show relevant settings based on current mode
    let settings_line = match app.mode {
        crate::tui::state::app_state::Mode::Encode => {
            let delimiter = match app.encode_options.delimiter {
                crate::Delimiter::Comma => "comma",
                crate::Delimiter::Tab => "tab",
                crate::Delimiter::Pipe => "pipe",
            };

            let indent = match app.encode_options.indent {
                crate::Indent::Spaces(n) => format!("{n}sp"),
            };

            let mut spans = vec![
                Span::styled("Delim:", theme.line_number_style()),
                Span::styled(format!(" {delimiter}"), theme.info_style()),
                Span::styled(" | Indent:", theme.line_number_style()),
                Span::styled(format!(" {indent}"), theme.info_style()),
            ];

            // Show folding depth only when folding is enabled
            match app.encode_options.key_folding {
                KeyFoldingMode::Off => {}
                KeyFoldingMode::Safe => {
                    spans.push(Span::styled(" | fold:", theme.line_number_style()));
                    spans.push(Span::styled("on", theme.info_style()));

                    // ∞ for unlimited, number for specific depth
                    let depth_str = if app.encode_options.flatten_depth == usize::MAX {
                        "∞".to_string()
                    } else {
                        format!("{}", app.encode_options.flatten_depth)
                    };
                    spans.push(Span::styled(" (", theme.line_number_style()));
                    spans.push(Span::styled(depth_str, theme.info_style()));
                    spans.push(Span::styled(")", theme.line_number_style()));
                }
            }

            spans
        }
        crate::tui::state::app_state::Mode::Decode => {
            let strict = if app.decode_options.strict {
                "on"
            } else {
                "off"
            };
            let coerce = if app.decode_options.coerce_types {
                "on"
            } else {
                "off"
            };
            let expand = match app.decode_options.expand_paths {
                PathExpansionMode::Off => "",
                PathExpansionMode::Safe => " | expand:on",
            };

            vec![
                Span::styled("Strict:", theme.line_number_style()),
                Span::styled(format!(" {strict}"), theme.info_style()),
                Span::styled(" | Coerce:", theme.line_number_style()),
                Span::styled(format!(" {coerce}"), theme.info_style()),
                Span::styled(expand, theme.line_number_style()),
            ]
        }
        crate::tui::state::app_state::Mode::Rune => {
            vec![
                Span::styled("RUNE:", theme.line_number_style()),
                Span::styled(" Geometric", theme.info_style()),
                Span::styled(" | Operators:", theme.line_number_style()),
                Span::styled(" 21", theme.info_style()),
            ]
        }
    };

    let settings = Paragraph::new(Line::from(settings_line))
        .alignment(Alignment::Right)
        .block(Block::default().borders(Borders::ALL));
    f.render_widget(settings, chunks[2]);
}

File: src\types\folding.rs
==========================
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum KeyFoldingMode {
    /// No folding performed. All objects use standard nesting.
    #[default]
    Off,
    /// Fold eligible chains according to safety rules.
    Safe,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum PathExpansionMode {
    /// Dotted keys are treated as literal keys. No expansion.
    #[default]
    Off,
    /// Expand eligible dotted keys according to safety rules.
    Safe,
}

/// Check if a key segment is a valid IdentifierSegment (stricter than unquoted
/// keys).
pub fn is_identifier_segment(s: &str) -> bool {
    if s.is_empty() {
        return false;
    }

    let mut chars = s.chars();

    // First character must be letter or underscore
    let first = match chars.next() {
        Some(c) => c,
        None => return false,
    };

    if !first.is_alphabetic() && first != '_' {
        return false;
    }

    // Remaining characters: letters, digits, or underscore (NO dots)
    chars.all(|c| c.is_alphanumeric() || c == '_')
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_key_folding_mode_default() {
        assert_eq!(KeyFoldingMode::default(), KeyFoldingMode::Off);
    }

    #[test]
    fn test_path_expansion_mode_default() {
        assert_eq!(PathExpansionMode::default(), PathExpansionMode::Off);
    }

    #[test]
    fn test_is_identifier_segment() {
        // Valid segments
        assert!(is_identifier_segment("a"));
        assert!(is_identifier_segment("_private"));
        assert!(is_identifier_segment("userName"));
        assert!(is_identifier_segment("user_name"));
        assert!(is_identifier_segment("user123"));
        assert!(is_identifier_segment("_123"));

        // Invalid segments
        assert!(!is_identifier_segment(""));
        assert!(!is_identifier_segment("123"));
        assert!(!is_identifier_segment("user-name"));
        assert!(!is_identifier_segment("user.name")); // Contains dot
        assert!(!is_identifier_segment("user name")); // Contains space
        assert!(!is_identifier_segment("user:name")); // Contains colon
        assert!(!is_identifier_segment(".name")); // Starts with dot
    }

    #[test]
    fn test_identifier_segment_vs_general_key() {
        // These are valid unquoted keys but NOT IdentifierSegments
        assert!(!is_identifier_segment("a.b")); // Contains dot
        assert!(!is_identifier_segment("a.b.c")); // Contains dots

        // These are valid for both
        assert!(is_identifier_segment("abc"));
        assert!(is_identifier_segment("_private"));
        assert!(is_identifier_segment("key123"));
    }
}

File: src\types\errors.rs
=========================
use thiserror::Error;

/// Result type alias for TOON operations.
pub type ToonResult<T> = std::result::Result<T, ToonError>;

/// Errors that can occur during TOON encoding or decoding.
#[derive(Error, Debug, Clone, PartialEq)]
pub enum ToonError {
    #[error("Invalid input: {0}")]
    InvalidInput(String),

    #[error("Parse error at line {line}, column {column}: {message}")]
    ParseError {
        line: usize,
        column: usize,
        message: String,
        #[source]
        context: Option<Box<ErrorContext>>,
    },

    #[error("Invalid character '{char}' at position {position}")]
    InvalidCharacter { char: char, position: usize },

    #[error("Unexpected end of input")]
    UnexpectedEof,

    #[error("Type mismatch: expected {expected}, found {found}")]
    TypeMismatch { expected: String, found: String },

    #[error("Invalid delimiter: {0}")]
    InvalidDelimiter(String),

    #[error("Array length mismatch: expected {expected}, found {found}")]
    LengthMismatch {
        expected: usize,
        found: usize,
        #[source]
        context: Option<Box<ErrorContext>>,
    },

    #[error("Invalid structure: {0}")]
    InvalidStructure(String),

    #[error("Serialization error: {0}")]
    SerializationError(String),

    #[error("Deserialization error: {0}")]
    DeserializationError(String),
}

/// Contextual information for error reporting, including source location
/// and suggestions.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct ErrorContext {
    pub source_line: String,
    pub preceding_lines: Vec<String>,
    pub following_lines: Vec<String>,
    pub suggestion: Option<String>,
    pub indicator: Option<String>,
}

impl std::fmt::Display for ErrorContext {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        writeln!(f, "\nContext:")?;

        for line in &self.preceding_lines {
            writeln!(f, "  {line}")?;
        }

        writeln!(f, "> {}", self.source_line)?;

        if let Some(indicator) = &self.indicator {
            writeln!(f, "  {indicator}")?;
        }

        for line in &self.following_lines {
            writeln!(f, "  {line}")?;
        }

        if let Some(suggestion) = &self.suggestion {
            writeln!(f, "\nSuggestion: {suggestion}")?;
        }

        Ok(())
    }
}

impl std::error::Error for ErrorContext {}

impl ErrorContext {
    /// Create a new error context with a source line.
    pub fn new(source_line: impl Into<String>) -> Self {
        Self {
            source_line: source_line.into(),
            preceding_lines: Vec::new(),
            following_lines: Vec::new(),
            suggestion: None,
            indicator: None,
        }
    }

    /// Add preceding context lines.
    pub fn with_preceding_lines(mut self, lines: Vec<String>) -> Self {
        self.preceding_lines = lines;
        self
    }

    /// Add following context lines.
    pub fn with_following_lines(mut self, lines: Vec<String>) -> Self {
        self.following_lines = lines;
        self
    }

    /// Add a suggestion message to help fix the error.
    pub fn with_suggestion(mut self, suggestion: impl Into<String>) -> Self {
        self.suggestion = Some(suggestion.into());
        self
    }

    /// Add a column indicator (caret) pointing to the error position.
    pub fn with_indicator(mut self, column: usize) -> Self {
        let indicator = format!("{}^", " ".repeat(column));
        self.indicator = Some(indicator);
        self
    }

    /// Create error context from input string with automatic context
    /// extraction.
    pub fn from_input(
        input: &str,
        line: usize,
        column: usize,
        context_lines: usize,
    ) -> Option<Self> {
        let lines: Vec<&str> = input.lines().collect();

        if line == 0 || line > lines.len() {
            return None;
        }

        let line_idx = line - 1;
        let source_line = lines.get(line_idx)?.to_string();

        let start_line = line_idx.saturating_sub(context_lines);
        let end_line = (line_idx + context_lines + 1).min(lines.len());

        let preceding_lines = lines[start_line..line_idx]
            .iter()
            .map(|s| s.to_string())
            .collect();

        let following_lines = lines[(line_idx + 1)..end_line]
            .iter()
            .map(|s| s.to_string())
            .collect();

        Some(Self {
            source_line,
            preceding_lines,
            following_lines,
            suggestion: None,
            indicator: Some(format!("{}^", " ".repeat(column.saturating_sub(1)))),
        })
    }
}

impl ToonError {
    /// Create a parse error at the given position.
    pub fn parse_error(line: usize, column: usize, message: impl Into<String>) -> Self {
        ToonError::ParseError {
            line,
            column,
            message: message.into(),
            context: None,
        }
    }

    /// Create a parse error with additional context information.
    pub fn parse_error_with_context(
        line: usize,
        column: usize,
        message: impl Into<String>,
        context: ErrorContext,
    ) -> Self {
        ToonError::ParseError {
            line,
            column,
            message: message.into(),
            context: Some(Box::new(context)),
        }
    }

    /// Create an error for an invalid character.
    pub fn invalid_char(char: char, position: usize) -> Self {
        ToonError::InvalidCharacter { char, position }
    }

    /// Create an error for a type mismatch.
    pub fn type_mismatch(expected: impl Into<String>, found: impl Into<String>) -> Self {
        ToonError::TypeMismatch {
            expected: expected.into(),
            found: found.into(),
        }
    }

    /// Create an error for array length mismatch.
    pub fn length_mismatch(expected: usize, found: usize) -> Self {
        ToonError::LengthMismatch {
            expected,
            found,
            context: None,
        }
    }

    /// Create an array length mismatch error with context.
    pub fn length_mismatch_with_context(
        expected: usize,
        found: usize,
        context: ErrorContext,
    ) -> Self {
        ToonError::LengthMismatch {
            expected,
            found,
            context: Some(Box::new(context)),
        }
    }

    /// Add context to an error if it supports it.
    pub fn with_context(self, context: ErrorContext) -> Self {
        match self {
            ToonError::ParseError {
                line,
                column,
                message,
                ..
            } => ToonError::ParseError {
                line,
                column,
                message,
                context: Some(Box::new(context)),
            },
            ToonError::LengthMismatch {
                expected, found, ..
            } => ToonError::LengthMismatch {
                expected,
                found,
                context: Some(Box::new(context)),
            },
            other => other,
        }
    }

    /// Add a suggestion to help fix the error.
    pub fn with_suggestion(self, suggestion: impl Into<String>) -> Self {
        let suggestion = suggestion.into();
        match self {
            ToonError::ParseError {
                line,
                column,
                message,
                context,
            } => {
                let new_context = context
                    .map(|c| Box::new(c.with_suggestion(suggestion.clone())))
                    .or_else(|| Some(Box::new(ErrorContext::new("").with_suggestion(suggestion))));
                ToonError::ParseError {
                    line,
                    column,
                    message,
                    context: new_context,
                }
            }
            other => other,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_error_context_creation() {
        let ctx = ErrorContext::new("test line")
            .with_suggestion("Try using quotes")
            .with_indicator(5);

        assert_eq!(ctx.source_line, "test line");
        assert_eq!(ctx.suggestion, Some("Try using quotes".to_string()));
        assert!(ctx.indicator.is_some());
    }

    #[test]
    fn test_error_context_from_input() {
        let input = "line 1\nline 2 with error\nline 3";
        let ctx = ErrorContext::from_input(input, 2, 6, 1);

        assert!(ctx.is_some());
        let ctx = ctx.unwrap();
        assert_eq!(ctx.source_line, "line 2 with error");
        assert_eq!(ctx.preceding_lines, vec!["line 1"]);
        assert_eq!(ctx.following_lines, vec!["line 3"]);
    }

    #[test]
    fn test_parse_error_with_context() {
        let ctx =
            ErrorContext::new("invalid: value").with_suggestion("Did you mean 'value: invalid'?");

        let err = ToonError::parse_error_with_context(1, 8, "Unexpected token", ctx);

        match err {
            ToonError::ParseError {
                line,
                column,
                message,
                context,
            } => {
                assert_eq!(line, 1);
                assert_eq!(column, 8);
                assert_eq!(message, "Unexpected token");
                assert!(context.is_some());
            }
            _ => panic!("Wrong error type"),
        }
    }

    #[test]
    fn test_error_with_suggestion() {
        let err = ToonError::parse_error(1, 5, "Invalid syntax")
            .with_suggestion("Use quotes around string values");

        match err {
            ToonError::ParseError { context, .. } => {
                assert!(context.is_some());
                let ctx = context.unwrap();
                assert_eq!(
                    ctx.suggestion,
                    Some("Use quotes around string values".to_string())
                );
            }
            _ => panic!("Wrong error type"),
        }
    }

    #[test]
    fn test_length_mismatch_with_context() {
        let ctx = ErrorContext::new("items[3]: a,b").with_suggestion(
            "Expected 3 items but found 2. Add another item or fix the length marker.",
        );

        let err = ToonError::length_mismatch_with_context(3, 2, ctx);

        match err {
            ToonError::LengthMismatch {
                expected,
                found,
                context,
            } => {
                assert_eq!(expected, 3);
                assert_eq!(found, 2);
                assert!(context.is_some());
            }
            _ => panic!("Wrong error type"),
        }
    }
}

File: src\utils\literal.rs
==========================
use crate::constants;

/// Check if a string looks like a keyword or number (needs quoting).
pub fn is_literal_like(s: &str) -> bool {
    is_keyword(s) || is_numeric_like(s)
}

#[inline]
pub fn is_keyword(s: &str) -> bool {
    constants::is_keyword(s)
}

#[inline]
pub fn is_structural_char(ch: char) -> bool {
    constants::is_structural_char(ch)
}

/// Check if a string looks like a number (starts with digit, no leading zeros).
pub fn is_numeric_like(s: &str) -> bool {
    if s.is_empty() {
        return false;
    }

    let chars: Vec<char> = s.chars().collect();
    let mut i = 0;

    if chars[i] == '-' {
        i += 1;
    }

    if i >= chars.len() {
        return false;
    }

    if !chars[i].is_ascii_digit() {
        return false;
    }

    if chars[i] == '0' && i + 1 < chars.len() && chars[i + 1].is_ascii_digit() {
        return false;
    }

    chars[i..].iter().all(|c| {
        c.is_ascii_digit() || *c == '.' || *c == 'e' || *c == 'E' || *c == '+' || *c == '-'
    })
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_is_literal_like() {
        assert!(is_literal_like("null"));
        assert!(is_literal_like("true"));
        assert!(is_literal_like("false"));
        assert!(is_literal_like("123"));
        assert!(is_literal_like("-456"));
        assert!(is_literal_like("3.14"));
        assert!(!is_literal_like("hello"));
        assert!(!is_literal_like(""));
    }

    #[test]
    fn test_is_keyword() {
        assert!(is_keyword("null"));
        assert!(is_keyword("true"));
        assert!(is_keyword("false"));
        assert!(!is_keyword("TRUE"));
        assert!(!is_keyword("hello"));
    }

    #[test]
    fn test_is_structural_char() {
        assert!(is_structural_char('['));
        assert!(is_structural_char('{'));
        assert!(is_structural_char(':'));
        assert!(!is_structural_char('a'));
    }

    #[test]
    fn test_is_numeric_like() {
        assert!(is_numeric_like("123"));
        assert!(is_numeric_like("-456"));
        assert!(is_numeric_like("0"));
        assert!(is_numeric_like("3.14"));
        assert!(is_numeric_like("1e10"));
        assert!(is_numeric_like("1.5e-3"));

        assert!(!is_numeric_like(""));
        assert!(!is_numeric_like("-"));
        assert!(!is_numeric_like("abc"));
        assert!(!is_numeric_like("01"));
        assert!(!is_numeric_like("00"));
    }
}

File: src\types\options.rs
==========================
use crate::{
    constants::DEFAULT_INDENT,
    types::{Delimiter, KeyFoldingMode, PathExpansionMode},
};

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Indent {
    Spaces(usize),
}

impl Default for Indent {
    fn default() -> Self {
        Indent::Spaces(DEFAULT_INDENT)
    }
}

impl Indent {
    pub fn get_string(&self, depth: usize) -> String {
        if depth == 0 {
            return String::new();
        }

        match self {
            Indent::Spaces(count) => {
                if *count > 0 {
                    " ".repeat(*count * depth)
                } else {
                    String::new()
                }
            }
        }
    }

    pub fn get_spaces(&self) -> usize {
        match self {
            Indent::Spaces(count) => *count,
        }
    }
}

/// Options for encoding JSON values to TOON format.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct EncodeOptions {
    pub delimiter: Delimiter,
    pub indent: Indent,
    pub key_folding: KeyFoldingMode,
    pub flatten_depth: usize,
}

impl Default for EncodeOptions {
    fn default() -> Self {
        Self {
            delimiter: Delimiter::Comma,
            indent: Indent::default(),
            key_folding: KeyFoldingMode::Off,
            flatten_depth: usize::MAX,
        }
    }
}

impl EncodeOptions {
    /// Create new encoding options with defaults.
    pub fn new() -> Self {
        Self::default()
    }

    /// Set the delimiter for array elements.
    pub fn with_delimiter(mut self, delimiter: Delimiter) -> Self {
        self.delimiter = delimiter;
        self
    }

    /// Set the indentation string for nested structures.
    pub fn with_indent(mut self, style: Indent) -> Self {
        self.indent = style;
        self
    }

    /// Set indentation to a specific number of spaces.
    pub fn with_spaces(mut self, count: usize) -> Self {
        self.indent = Indent::Spaces(count);
        self
    }

    /// Enable key folding (v1.5 feature).
    ///
    /// When set to `Safe`, single-key object chains will be folded into
    /// dotted-path notation if all safety requirements are met.
    ///
    /// Default: `Off`
    pub fn with_key_folding(mut self, mode: KeyFoldingMode) -> Self {
        self.key_folding = mode;
        self
    }

    /// Set maximum depth for key folding.
    ///
    /// Controls how many segments will be folded. A value of 2 folds
    /// only two-segment chains: `{a: {b: val}}` → `a.b: val`.
    ///
    /// Default: `usize::MAX` (fold entire eligible chains)
    pub fn with_flatten_depth(mut self, depth: usize) -> Self {
        self.flatten_depth = depth;
        self
    }
}

/// Options for decoding TOON format to JSON values.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct DecodeOptions {
    pub delimiter: Option<Delimiter>,
    pub strict: bool,
    pub coerce_types: bool,
    pub indent: Indent,
    pub expand_paths: PathExpansionMode,
}

impl Default for DecodeOptions {
    fn default() -> Self {
        Self {
            delimiter: None,
            strict: true,
            coerce_types: true,
            indent: Indent::default(),
            expand_paths: PathExpansionMode::Off,
        }
    }
}

impl DecodeOptions {
    /// Create new decoding options with defaults (strict mode enabled).
    pub fn new() -> Self {
        Self::default()
    }

    /// Enable or disable strict mode (validates array lengths, indentation,
    /// etc.).
    pub fn with_strict(mut self, strict: bool) -> Self {
        self.strict = strict;
        self
    }

    /// Set the expected delimiter (auto-detected if None).
    pub fn with_delimiter(mut self, delimiter: Delimiter) -> Self {
        self.delimiter = Some(delimiter);
        self
    }

    /// Enable or disable type coercion (strings like "123" -> numbers).
    pub fn with_coerce_types(mut self, coerce: bool) -> Self {
        self.coerce_types = coerce;
        self
    }

    pub fn with_indent(mut self, style: Indent) -> Self {
        self.indent = style;
        self
    }

    /// Enable path expansion (v1.5 feature).
    ///
    /// When set to `Safe`, dotted keys will be expanded into nested objects
    /// if all segments are IdentifierSegments.
    ///
    /// Conflict handling:
    /// - `strict=true`: Errors on conflicts
    /// - `strict=false`: Last-write-wins
    ///
    /// Default: `Off`
    pub fn with_expand_paths(mut self, mode: PathExpansionMode) -> Self {
        self.expand_paths = mode;
        self
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_encode_options_indent() {
        let opts = EncodeOptions::new().with_spaces(4);
        assert_eq!(opts.indent, Indent::Spaces(4));

        let opts = EncodeOptions::new().with_indent(Indent::Spaces(2));
        assert_eq!(opts.indent, Indent::Spaces(2));
    }

    #[test]
    fn test_decode_options_coerce_types() {
        let opts = DecodeOptions::new();
        assert!(opts.coerce_types);

        let opts = DecodeOptions::new().with_coerce_types(false);
        assert!(!opts.coerce_types);

        let opts = DecodeOptions::new().with_coerce_types(true);
        assert!(opts.coerce_types);
    }
}

File: src\types\value.rs
========================
use std::{
    fmt,
    ops::{Index, IndexMut},
};

use indexmap::IndexMap;

#[derive(Clone, Debug, PartialEq)]
pub enum Number {
    PosInt(u64),
    NegInt(i64),
    Float(f64),
}

impl Number {
    pub fn from_f64(f: f64) -> Option<Self> {
        if f.is_finite() {
            Some(Number::Float(f))
        } else {
            None
        }
    }

    pub fn is_i64(&self) -> bool {
        match self {
            Number::NegInt(_) => true,
            Number::PosInt(u) => *u <= i64::MAX as u64,
            Number::Float(f) => {
                let i = *f as i64;
                i as f64 == *f && i != i64::MAX
            }
        }
    }

    pub fn is_u64(&self) -> bool {
        match self {
            Number::PosInt(_) => true,
            Number::NegInt(_) => false,
            Number::Float(f) => {
                let u = *f as u64;
                u as f64 == *f
            }
        }
    }

    pub fn is_f64(&self) -> bool {
        matches!(self, Number::Float(_))
    }

    pub fn as_i64(&self) -> Option<i64> {
        match self {
            Number::PosInt(u) => {
                if *u <= i64::MAX as u64 {
                    Some(*u as i64)
                } else {
                    None
                }
            }
            Number::NegInt(i) => Some(*i),
            Number::Float(f) => {
                let i = *f as i64;
                if i as f64 == *f { Some(i) } else { None }
            }
        }
    }

    pub fn as_u64(&self) -> Option<u64> {
        match self {
            Number::PosInt(u) => Some(*u),
            Number::NegInt(_) => None,
            Number::Float(f) => {
                if *f >= 0.0 {
                    let u = *f as u64;
                    if u as f64 == *f { Some(u) } else { None }
                } else {
                    None
                }
            }
        }
    }

    pub fn as_f64(&self) -> Option<f64> {
        match self {
            Number::PosInt(u) => Some(*u as f64),
            Number::NegInt(i) => Some(*i as f64),
            Number::Float(f) => Some(*f),
        }
    }

    pub fn is_integer(&self) -> bool {
        match self {
            Number::PosInt(_) | Number::NegInt(_) => true,
            Number::Float(f) => f.fract() == 0.0,
        }
    }
}

impl fmt::Display for Number {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let s_json_num = match self {
            Number::PosInt(u) => serde_json::Number::from(*u),
            Number::NegInt(i) => serde_json::Number::from(*i),
            Number::Float(fl) => {
                serde_json::Number::from_f64(*fl).unwrap_or_else(|| serde_json::Number::from(0))
            }
        };
        write!(f, "{s_json_num}")
    }
}

impl From<i8> for Number {
    fn from(n: i8) -> Self {
        Number::NegInt(n as i64)
    }
}

impl From<i16> for Number {
    fn from(n: i16) -> Self {
        Number::NegInt(n as i64)
    }
}

impl From<i32> for Number {
    fn from(n: i32) -> Self {
        Number::NegInt(n as i64)
    }
}

impl From<i64> for Number {
    fn from(n: i64) -> Self {
        if n >= 0 {
            Number::PosInt(n as u64)
        } else {
            Number::NegInt(n)
        }
    }
}

impl From<isize> for Number {
    fn from(n: isize) -> Self {
        Number::from(n as i64)
    }
}

impl From<u8> for Number {
    fn from(n: u8) -> Self {
        Number::PosInt(n as u64)
    }
}

impl From<u16> for Number {
    fn from(n: u16) -> Self {
        Number::PosInt(n as u64)
    }
}

impl From<u32> for Number {
    fn from(n: u32) -> Self {
        Number::PosInt(n as u64)
    }
}

impl From<u64> for Number {
    fn from(n: u64) -> Self {
        Number::PosInt(n)
    }
}

impl From<usize> for Number {
    fn from(n: usize) -> Self {
        Number::PosInt(n as u64)
    }
}

impl From<f32> for Number {
    fn from(n: f32) -> Self {
        Number::Float(n as f64)
    }
}

impl From<f64> for Number {
    fn from(n: f64) -> Self {
        Number::Float(n)
    }
}

pub type Object = IndexMap<String, JsonValue>;

#[derive(Clone, Debug, PartialEq, Default)]
pub enum JsonValue {
    #[default]
    Null,
    Bool(bool),
    Number(Number),
    String(String),
    Array(Vec<JsonValue>),
    Object(Object),
}

impl JsonValue {
    pub const fn is_null(&self) -> bool {
        matches!(self, JsonValue::Null)
    }

    pub const fn is_bool(&self) -> bool {
        matches!(self, JsonValue::Bool(_))
    }

    pub const fn is_number(&self) -> bool {
        matches!(self, JsonValue::Number(_))
    }

    pub const fn is_string(&self) -> bool {
        matches!(self, JsonValue::String(_))
    }

    pub const fn is_array(&self) -> bool {
        matches!(self, JsonValue::Array(_))
    }

    pub const fn is_object(&self) -> bool {
        matches!(self, JsonValue::Object(_))
    }

    /// Returns true if the value is a number that can be represented as i64
    pub fn is_i64(&self) -> bool {
        match self {
            JsonValue::Number(n) => n.is_i64(),
            _ => false,
        }
    }

    /// Returns true if the value is a number that can be represented as u64
    pub fn is_u64(&self) -> bool {
        match self {
            JsonValue::Number(n) => n.is_u64(),
            _ => false,
        }
    }

    pub fn is_f64(&self) -> bool {
        match self {
            JsonValue::Number(n) => n.is_f64(),
            _ => false,
        }
    }

    /// If the value is a Bool, returns the associated bool. Returns None
    /// otherwise.
    pub fn as_bool(&self) -> Option<bool> {
        match self {
            JsonValue::Bool(b) => Some(*b),
            _ => None,
        }
    }

    /// If the value is a number, represent it as i64 if possible. Returns None
    /// otherwise.
    pub fn as_i64(&self) -> Option<i64> {
        match self {
            JsonValue::Number(n) => n.as_i64(),
            _ => None,
        }
    }

    /// If the value is a number, represent it as u64 if possible. Returns None
    /// otherwise.
    pub fn as_u64(&self) -> Option<u64> {
        match self {
            JsonValue::Number(n) => n.as_u64(),
            _ => None,
        }
    }

    /// If the value is a number, represent it as f64 if possible. Returns None
    /// otherwise.
    pub fn as_f64(&self) -> Option<f64> {
        match self {
            JsonValue::Number(n) => n.as_f64(),
            _ => None,
        }
    }

    pub fn as_str(&self) -> Option<&str> {
        match self {
            JsonValue::String(s) => Some(s),
            _ => None,
        }
    }

    pub fn as_array(&self) -> Option<&Vec<JsonValue>> {
        match self {
            JsonValue::Array(arr) => Some(arr),
            _ => None,
        }
    }

    pub fn as_array_mut(&mut self) -> Option<&mut Vec<JsonValue>> {
        match self {
            JsonValue::Array(arr) => Some(arr),
            _ => None,
        }
    }

    pub fn as_object(&self) -> Option<&Object> {
        match self {
            JsonValue::Object(obj) => Some(obj),
            _ => None,
        }
    }

    pub fn as_object_mut(&mut self) -> Option<&mut Object> {
        match self {
            JsonValue::Object(obj) => Some(obj),
            _ => None,
        }
    }

    /// Takes the value, leaving Null in its place.
    pub fn take(&mut self) -> JsonValue {
        std::mem::replace(self, JsonValue::Null)
    }

    pub fn type_name(&self) -> &'static str {
        match self {
            JsonValue::Null => "null",
            JsonValue::Bool(_) => "boolean",
            JsonValue::Number(_) => "number",
            JsonValue::String(_) => "string",
            JsonValue::Array(_) => "array",
            JsonValue::Object(_) => "object",
        }
    }
}

impl fmt::Display for JsonValue {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            JsonValue::Null => write!(f, "null"),
            JsonValue::Bool(b) => write!(f, "{b}"),
            JsonValue::Number(n) => write!(f, "{n}"),
            JsonValue::String(s) => write!(f, "\"{s}\""),
            JsonValue::Array(arr) => {
                write!(f, "[")?;
                for (i, v) in arr.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    write!(f, "{v}")?;
                }
                write!(f, "]")
            }
            JsonValue::Object(obj) => {
                write!(f, "{{")?;
                for (i, (k, v)) in obj.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    write!(f, "\"{k}\": {v}")?;
                }
                write!(f, "}}")
            }
        }
    }
}

impl Index<usize> for JsonValue {
    type Output = JsonValue;

    fn index(&self, index: usize) -> &Self::Output {
        match self {
            JsonValue::Array(arr) => &arr[index],
            _ => panic!("cannot index into non-array value with usize"),
        }
    }
}

impl IndexMut<usize> for JsonValue {
    fn index_mut(&mut self, index: usize) -> &mut Self::Output {
        match self {
            JsonValue::Array(arr) => &mut arr[index],
            _ => panic!("cannot index into non-array value with usize"),
        }
    }
}

impl Index<&str> for JsonValue {
    type Output = JsonValue;

    fn index(&self, key: &str) -> &Self::Output {
        match self {
            JsonValue::Object(obj) => obj
                .get(key)
                .unwrap_or_else(|| panic!("key '{key}' not found in object")),
            _ => panic!("cannot index into non-object value with &str"),
        }
    }
}

impl IndexMut<&str> for JsonValue {
    fn index_mut(&mut self, key: &str) -> &mut Self::Output {
        match self {
            JsonValue::Object(obj) => obj
                .get_mut(key)
                .unwrap_or_else(|| panic!("key '{key}' not found in object")),
            _ => panic!("cannot index into non-object value with &str"),
        }
    }
}

impl Index<String> for JsonValue {
    type Output = JsonValue;

    fn index(&self, key: String) -> &Self::Output {
        self.index(key.as_str())
    }
}

impl IndexMut<String> for JsonValue {
    fn index_mut(&mut self, key: String) -> &mut Self::Output {
        self.index_mut(key.as_str())
    }
}

impl From<serde_json::Value> for JsonValue {
    fn from(value: serde_json::Value) -> Self {
        match value {
            serde_json::Value::Null => JsonValue::Null,
            serde_json::Value::Bool(b) => JsonValue::Bool(b),
            serde_json::Value::Number(n) => {
                if let Some(i) = n.as_i64() {
                    JsonValue::Number(Number::from(i))
                } else if let Some(u) = n.as_u64() {
                    JsonValue::Number(Number::from(u))
                } else if let Some(f) = n.as_f64() {
                    JsonValue::Number(Number::from(f))
                } else {
                    JsonValue::Null
                }
            }
            serde_json::Value::String(s) => JsonValue::String(s),
            serde_json::Value::Array(arr) => {
                JsonValue::Array(arr.into_iter().map(JsonValue::from).collect())
            }
            serde_json::Value::Object(obj) => {
                let mut new_obj = Object::new();
                for (k, v) in obj {
                    new_obj.insert(k, JsonValue::from(v));
                }
                JsonValue::Object(new_obj)
            }
        }
    }
}

impl From<&serde_json::Value> for JsonValue {
    fn from(value: &serde_json::Value) -> Self {
        value.clone().into()
    }
}

impl From<JsonValue> for serde_json::Value {
    fn from(value: JsonValue) -> Self {
        match value {
            JsonValue::Null => serde_json::Value::Null,
            JsonValue::Bool(b) => serde_json::Value::Bool(b),
            JsonValue::Number(n) => {
                if let Some(i) = n.as_i64() {
                    serde_json::Value::Number(i.into())
                } else if let Some(u) = n.as_u64() {
                    serde_json::Value::Number(u.into())
                } else if let Some(f) = n.as_f64() {
                    serde_json::Number::from_f64(f)
                        .map(serde_json::Value::Number)
                        .unwrap_or(serde_json::Value::Null)
                } else {
                    serde_json::Value::Null
                }
            }
            JsonValue::String(s) => serde_json::Value::String(s),
            JsonValue::Array(arr) => {
                serde_json::Value::Array(arr.into_iter().map(Into::into).collect())
            }
            JsonValue::Object(obj) => {
                let mut new_obj = serde_json::Map::new();
                for (k, v) in obj {
                    new_obj.insert(k, v.into());
                }
                serde_json::Value::Object(new_obj)
            }
        }
    }
}

impl From<&JsonValue> for serde_json::Value {
    fn from(value: &JsonValue) -> Self {
        value.clone().into()
    }
}

pub trait IntoJsonValue {
    fn into_json_value(self) -> JsonValue;
}

impl IntoJsonValue for &JsonValue {
    fn into_json_value(self) -> JsonValue {
        self.clone()
    }
}

impl IntoJsonValue for JsonValue {
    fn into_json_value(self) -> JsonValue {
        self
    }
}

impl IntoJsonValue for &serde_json::Value {
    fn into_json_value(self) -> JsonValue {
        self.into()
    }
}

impl IntoJsonValue for serde_json::Value {
    fn into_json_value(self) -> JsonValue {
        (&self).into()
    }
}

File: src\utils\mod.rs
======================
pub mod literal;
pub mod number;
pub mod string;
pub mod validation;

use indexmap::IndexMap;
pub use literal::{is_keyword, is_literal_like, is_numeric_like, is_structural_char};
pub use number::format_canonical_number;
pub use string::{
    escape_string, is_valid_unquoted_key, needs_quoting, quote_string, unescape_string,
};

use crate::types::{JsonValue as Value, Number};

/// Context for determining when quoting is needed.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QuotingContext {
    ObjectValue,
    ArrayValue,
}

/// Normalize a JSON value (converts NaN/Infinity to null, -0 to 0).
pub fn normalize(value: Value) -> Value {
    match value {
        Value::Number(n) => {
            // Handle NegInt(0) case - convert to PosInt(0)
            if let Number::NegInt(0) = n {
                Value::Number(Number::from(0u64))
            } else if let Some(f) = n.as_f64() {
                if f.is_nan() || f.is_infinite() {
                    Value::Null
                } else if f == 0.0 && f.is_sign_negative() {
                    Value::Number(Number::from(0u64))
                } else {
                    Value::Number(n)
                }
            } else {
                Value::Number(n)
            }
        }
        Value::Object(obj) => {
            let normalized: IndexMap<String, Value> =
                obj.into_iter().map(|(k, v)| (k, normalize(v))).collect();
            Value::Object(normalized)
        }
        Value::Array(arr) => {
            let normalized: Vec<Value> = arr.into_iter().map(normalize).collect();
            Value::Array(normalized)
        }
        _ => value,
    }
}

#[cfg(test)]
mod tests {
    use core::f64;

    use serde_json::json;

    use super::*;

    #[test]
    fn test_normalize_nan() {
        let value = Value::from(json!(f64::NAN));
        let normalized = normalize(value);
        assert_eq!(normalized, Value::from(json!(null)));
    }

    #[test]
    fn test_normalize_infinity() {
        let value = Value::from(json!(f64::INFINITY));
        let normalized = normalize(value);
        assert_eq!(normalized, Value::from(json!(null)));

        let value = Value::from(json!(f64::NEG_INFINITY));
        let normalized = normalize(value);
        assert_eq!(normalized, Value::from(json!(null)));
    }

    #[test]
    fn test_normalize_negative_zero() {
        let value = Value::from(json!(-0.0));
        let normalized = normalize(value);
        assert_eq!(normalized, Value::from(json!(0)));
    }

    #[test]
    fn test_normalize_nested() {
        let value = Value::from(json!({
            "a": f64::NAN,
            "b": {
                "c": f64::INFINITY
            },
            "d": [1, f64::NAN, 3]
        }));

        let normalized = normalize(value);
        assert_eq!(
            normalized,
            Value::from(json!({
                "a": null,
                "b": {
                    "c": null
                },
                "d": [1, null, 3]
            }))
        );
    }

    #[test]
    fn test_normalize_normal_values() {
        let value = Value::from(json!({
            "name": "Alice",
            "age": 30,
            "score": f64::consts::PI
        }));

        let normalized = normalize(value.clone());
        assert_eq!(normalized, value);
    }
}

File: src\utils\number.rs
=========================
use crate::types::Number;

/// Format a number in TOON canonical form (no exponents, no trailing zeros).
pub fn format_canonical_number(n: &Number) -> String {
    if let Some(i) = n.as_i64() {
        return i.to_string();
    }

    if let Some(u) = n.as_u64() {
        return u.to_string();
    }

    if let Some(f) = n.as_f64() {
        return format_f64_canonical(f);
    }

    n.to_string()
}

fn format_f64_canonical(f: f64) -> String {
    // Normalize integer-valued floats to integers
    if f.is_finite() && f.fract() == 0.0 && f.abs() <= i64::MAX as f64 {
        return format!("{}", f as i64);
    }

    let default_format = format!("{f}");

    // Handle cases where Rust would use exponential notation
    if default_format.contains('e') || default_format.contains('E') {
        format_without_exponent(f)
    } else {
        remove_trailing_zeros(&default_format)
    }
}

fn format_without_exponent(f: f64) -> String {
    if !f.is_finite() {
        return "0".to_string();
    }

    if f.abs() >= 1.0 {
        let abs_f = f.abs();
        let int_part = abs_f.trunc();
        let frac_part = abs_f.fract();

        if frac_part == 0.0 {
            format!("{}{}", if f < 0.0 { "-" } else { "" }, int_part as i64)
        } else {
            // High precision to avoid exponent, then trim trailing zeros
            let result = format!("{f:.17}");
            remove_trailing_zeros(&result)
        }
    } else if f == 0.0 {
        "0".to_string()
    } else {
        // Small numbers: use high precision to avoid exponent
        let result = format!("{f:.17}",);
        remove_trailing_zeros(&result)
    }
}

fn remove_trailing_zeros(s: &str) -> String {
    if !s.contains('.') {
        // No decimal point, return as-is
        return s.to_string();
    }

    let parts: Vec<&str> = s.split('.').collect();
    if parts.len() != 2 {
        return s.to_string();
    }

    let int_part = parts[0];
    let mut frac_part = parts[1].to_string();

    frac_part = frac_part.trim_end_matches('0').to_string();

    if frac_part.is_empty() {
        // All zeros removed, return as integer
        int_part.to_string()
    } else {
        format!("{int_part}.{frac_part}")
    }
}

#[cfg(test)]
mod tests {
    use std::f64;

    use serde_json::json;

    use super::*;

    #[test]
    fn test_format_canonical_integers() {
        let n = Number::from(42i64);
        assert_eq!(format_canonical_number(&n), "42");

        let n = Number::from(-123i64);
        assert_eq!(format_canonical_number(&n), "-123");

        let n = Number::from(0i64);
        assert_eq!(format_canonical_number(&n), "0");
    }

    #[test]
    fn test_format_canonical_floats() {
        // Integer-valued floats
        let n = Number::from_f64(1.0).unwrap();
        assert_eq!(format_canonical_number(&n), "1");

        let n = Number::from_f64(42.0).unwrap();
        assert_eq!(format_canonical_number(&n), "42");

        // Non-integer floats
        let n = Number::from_f64(1.5).unwrap();
        assert_eq!(format_canonical_number(&n), "1.5");

        let n = Number::from_f64(f64::consts::PI).unwrap();
        let result = format_canonical_number(&n);
        assert!(result.starts_with("3.141592653589793"));
        assert!(!result.contains('e'));
        assert!(!result.contains('E'));
    }

    #[test]
    fn test_remove_trailing_zeros() {
        assert_eq!(remove_trailing_zeros("1.5000"), "1.5");
        assert_eq!(remove_trailing_zeros("1.0"), "1");
        assert_eq!(remove_trailing_zeros("1.500"), "1.5");
        assert_eq!(remove_trailing_zeros("42"), "42");
        assert_eq!(remove_trailing_zeros("0.0"), "0");
        assert_eq!(remove_trailing_zeros("1.23"), "1.23");
    }

    #[test]
    fn test_large_numbers_no_exponent() {
        // 1e6 should become 1000000
        let n = Number::from_f64(1_000_000.0).unwrap();
        let result = format_canonical_number(&n);
        assert_eq!(result, "1000000");
        assert!(!result.contains('e'));

        // 1e9
        let n = Number::from_f64(1_000_000_000.0).unwrap();
        let result = format_canonical_number(&n);
        assert_eq!(result, "1000000000");
        assert!(!result.contains('e'));
    }

    #[test]
    fn test_small_numbers_no_exponent() {
        // 1e-6 should become 0.000001
        let n = Number::from_f64(0.000001).unwrap();
        let result = format_canonical_number(&n);
        assert!(result.starts_with("0.000001"));
        assert!(!result.contains('e'));
        assert!(!result.contains('E'));

        // 1e-3
        let n = Number::from_f64(0.001).unwrap();
        let result = format_canonical_number(&n);
        assert_eq!(result, "0.001");
    }

    #[test]
    fn test_pi_formatting() {
        let n = Number::from_f64(std::f64::consts::PI).unwrap();
        let result = format_canonical_number(&n);

        // Should not have exponent
        assert!(!result.contains('e'));
        assert!(!result.contains('E'));

        // Should start with 3.14159...
        assert!(result.starts_with("3.14159"));
    }

    #[test]
    fn test_from_json_values() {
        // Test with actual JSON values
        let val = json!(1000000);
        if let Some(n) = val.as_i64() {
            let num = Number::from(n);
            assert_eq!(format_canonical_number(&num), "1000000");
        }

        let val = json!(1.5000);
        if let Some(f) = val.as_f64() {
            let num = Number::from_f64(f).unwrap();
            assert_eq!(format_canonical_number(&num), "1.5");
        }
    }

    #[test]
    fn test_negative_numbers() {
        let n = Number::from_f64(-1.5).unwrap();
        assert_eq!(format_canonical_number(&n), "-1.5");

        let n = Number::from(-42i64);
        assert_eq!(format_canonical_number(&n), "-42");

        let n = Number::from_f64(-1000000.0).unwrap();
        assert_eq!(format_canonical_number(&n), "-1000000");
    }
}

File: src\utils\string.rs
=========================
use crate::{types::Delimiter, utils::literal};

/// Escape special characters in a string for quoted output.
pub fn escape_string(s: &str) -> String {
    let mut result = String::with_capacity(s.len());

    for ch in s.chars() {
        match ch {
            '\n' => result.push_str("\\n"),
            '\r' => result.push_str("\\r"),
            '\t' => result.push_str("\\t"),
            '"' => result.push_str("\\\""),
            '\\' => result.push_str("\\\\"),
            _ => result.push(ch),
        }
    }

    result
}

/// Unescape special characters in a quoted string.
///
/// Per TOON spec §7.1, only these escape sequences are valid:
/// - `\\` → `\`
/// - `\"` → `"`
/// - `\n` → newline
/// - `\r` → carriage return
/// - `\t` → tab
///
/// Any other escape sequence MUST cause an error.
///
/// # Errors
///
/// Returns an error if the string contains an invalid escape sequence
/// or if a backslash appears at the end of the string.
pub fn unescape_string(s: &str) -> Result<String, String> {
    let mut result = String::with_capacity(s.len());
    let mut chars = s.chars().peekable();
    let mut position = 0;

    while let Some(ch) = chars.next() {
        position += 1;

        if ch == '\\' {
            if let Some(&next) = chars.peek() {
                match next {
                    'n' => {
                        result.push('\n');
                        chars.next(); // consume the 'n'
                        position += 1;
                    }
                    'r' => {
                        result.push('\r');
                        chars.next();
                        position += 1;
                    }
                    't' => {
                        result.push('\t');
                        chars.next();
                        position += 1;
                    }
                    '"' => {
                        result.push('"');
                        chars.next();
                        position += 1;
                    }
                    '\\' => {
                        result.push('\\');
                        chars.next();
                        position += 1;
                    }
                    _ => {
                        return Err(format!(
                            "Invalid escape sequence '\\{next}' at position {position}. Only \
                             \\\\, \\\", \\n, \\r, \\t are valid",
                        ));
                    }
                }
            } else {
                return Err(format!(
                    "Unterminated escape sequence at end of string (position {position})",
                ));
            }
        } else {
            result.push(ch);
        }
    }

    Ok(result)
}

/// Check if a key can be written without quotes (alphanumeric, underscore,
/// dot).
pub fn is_valid_unquoted_key(key: &str) -> bool {
    if key.is_empty() {
        return false;
    }

    let mut chars = key.chars();
    let first = match chars.next() {
        Some(c) => c,
        None => return false,
    };

    if !first.is_alphabetic() && first != '_' {
        return false;
    }

    chars.all(|c| c.is_alphanumeric() || c == '_' || c == '.')
}

/// Determine if a string needs quoting based on content and delimiter.
pub fn needs_quoting(s: &str, delimiter: char) -> bool {
    if s.is_empty() {
        return true;
    }

    if literal::is_literal_like(s) {
        return true;
    }

    if s.chars().any(literal::is_structural_char) {
        return true;
    }

    if s.contains('\\') || s.contains('"') {
        return true;
    }

    if s.contains(delimiter) {
        return true;
    }

    if s.contains('\n') || s.contains('\r') || s.contains('\t') {
        return true;
    }

    if s.starts_with(char::is_whitespace) || s.ends_with(char::is_whitespace) {
        return true;
    }

    if s.starts_with("-") {
        return true;
    }

    // Check for leading zeros (e.g., "05", "007", "0123")
    // Numbers with leading zeros must be quoted
    if s.starts_with('0') && s.len() > 1 && s.chars().nth(1).is_some_and(|c| c.is_ascii_digit()) {
        return true;
    }

    false
}

/// Quote and escape a string.
pub fn quote_string(s: &str) -> String {
    format!("\"{}\"", escape_string(s))
}

pub fn split_by_delimiter(s: &str, delimiter: Delimiter) -> Vec<String> {
    let mut result = Vec::new();
    let mut current = String::new();
    let mut in_quotes = false;
    let chars = s.chars().peekable();
    let delim_char = delimiter.as_char();

    for ch in chars {
        if ch == '"' && (current.is_empty() || !current.ends_with('\\')) {
            in_quotes = !in_quotes;
            current.push(ch);
        } else if ch == delim_char && !in_quotes {
            result.push(current.trim().to_string());
            current.clear();
        } else {
            current.push(ch);
        }
    }

    if !current.is_empty() {
        result.push(current.trim().to_string());
    }

    result
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_escape_string() {
        assert_eq!(escape_string("hello"), "hello");
        assert_eq!(escape_string("hello\nworld"), "hello\\nworld");
        assert_eq!(escape_string("say \"hi\""), "say \\\"hi\\\"");
        assert_eq!(escape_string("back\\slash"), "back\\\\slash");
    }

    #[test]
    fn test_unescape_string() {
        // Valid escapes
        assert_eq!(unescape_string("hello").unwrap(), "hello");
        assert_eq!(unescape_string("hello\\nworld").unwrap(), "hello\nworld");
        assert_eq!(unescape_string("say \\\"hi\\\"").unwrap(), "say \"hi\"");
        assert_eq!(unescape_string("back\\\\slash").unwrap(), "back\\slash");
        assert_eq!(unescape_string("tab\\there").unwrap(), "tab\there");
        assert_eq!(unescape_string("return\\rhere").unwrap(), "return\rhere");
    }

    #[test]
    fn test_unescape_string_invalid_escapes() {
        // Invalid escape sequences should error
        assert!(unescape_string("bad\\xescape").is_err());
        assert!(unescape_string("bad\\uescape").is_err());
        assert!(unescape_string("bad\\0escape").is_err());
        assert!(unescape_string("bad\\aescape").is_err());

        // Unterminated escape at end
        assert!(unescape_string("ends\\").is_err());
    }

    #[test]
    fn test_unescape_string_error_messages() {
        let result = unescape_string("bad\\x");
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert!(err.contains("Invalid escape sequence"));
        assert!(err.contains("\\x"));
    }

    #[test]
    fn test_needs_quoting() {
        let comma = Delimiter::Comma.as_char();

        assert!(needs_quoting("", comma));

        assert!(needs_quoting("true", comma));
        assert!(needs_quoting("false", comma));
        assert!(needs_quoting("null", comma));
        assert!(needs_quoting("123", comma));

        assert!(needs_quoting("hello[world]", comma));
        assert!(needs_quoting("key:value", comma));

        assert!(needs_quoting("a,b", comma));
        assert!(!needs_quoting("a,b", Delimiter::Pipe.as_char()));

        assert!(!needs_quoting("hello world", comma));
        assert!(needs_quoting(" hello", comma));
        assert!(needs_quoting("hello ", comma));

        assert!(!needs_quoting("hello", comma));
        assert!(!needs_quoting("world", comma));
        assert!(!needs_quoting("helloworld", comma));
    }

    #[test]
    fn test_quote_string() {
        assert_eq!(quote_string("hello"), "\"hello\"");
        assert_eq!(quote_string("hello\nworld"), "\"hello\\nworld\"");
    }

    #[test]
    fn test_split_by_delimiter() {
        let comma = Delimiter::Comma;

        assert_eq!(split_by_delimiter("a,b,c", comma), vec!["a", "b", "c"]);

        assert_eq!(split_by_delimiter("a, b, c", comma), vec!["a", "b", "c"]);

        assert_eq!(split_by_delimiter("\"a,b\",c", comma), vec!["\"a,b\"", "c"]);
    }

    #[test]
    fn test_is_valid_unquoted_key() {
        // Valid keys (should return true)
        assert!(is_valid_unquoted_key("normal_key"));
        assert!(is_valid_unquoted_key("key123"));
        assert!(is_valid_unquoted_key("key.value"));
        assert!(is_valid_unquoted_key("_private"));
        assert!(is_valid_unquoted_key("KeyName"));
        assert!(is_valid_unquoted_key("key_name"));
        assert!(is_valid_unquoted_key("key.name.sub"));
        assert!(is_valid_unquoted_key("a"));
        assert!(is_valid_unquoted_key("_"));
        assert!(is_valid_unquoted_key("key_123.value"));

        assert!(!is_valid_unquoted_key(""));
        assert!(!is_valid_unquoted_key("123"));
        assert!(!is_valid_unquoted_key("key:value"));
        assert!(!is_valid_unquoted_key("key-value"));
        assert!(!is_valid_unquoted_key("key value"));
        assert!(!is_valid_unquoted_key(".key"));
        assert!(is_valid_unquoted_key("key.value.sub."));
        assert!(is_valid_unquoted_key("key."));
        assert!(!is_valid_unquoted_key("key[value]"));
        assert!(!is_valid_unquoted_key("key{value}"));
    }
}

File: tools\rune-vscode-theme\CHANGELOG.md
==========================================
# Unreleased

- Remove UI color overrides so the RUNE theme only applies token colors; it no longer forces an editor background/foreground.

File: tools\rune-vscode-theme\language-configuration.json
=========================================================
{
  "comments": {
    "lineComment": "#"
  },
  "brackets": [
    ["(", ")"],
    ["[", "]"],
    ["{", "}"]
  ],
  "autoClosingPairs": [
    {"open": "(", "close": ")"},
    {"open": "[", "close": "]"},
    {"open": "{", "close": "}"},
    {"open": "\"", "close": "\""}
  ],
  "surroundingPairs": [
    ["(", ")"],
    ["[", "]"],
    ["{", "}"],
    ["\"", "\""]
  ]
}

File: src\utils\validation.rs
=============================
use serde_json::Value;

use crate::types::{ToonError, ToonResult};

/// Validate that nesting depth doesn't exceed the maximum.
pub fn validate_depth(depth: usize, max_depth: usize) -> ToonResult<()> {
    if depth > max_depth {
        return Err(ToonError::InvalidStructure(
            "Maximum nesting depth of {max_depth} exceeded".to_string(),
        ));
    }
    Ok(())
}

/// Validate that a field name is not empty.
pub fn validate_field_name(name: &str) -> ToonResult<()> {
    if name.is_empty() {
        return Err(ToonError::InvalidInput(
            "Field name cannot be empty".to_string(),
        ));
    }
    Ok(())
}

/// Recursively validate a JSON value and all nested fields.
pub fn validate_value(value: &Value) -> ToonResult<()> {
    match value {
        Value::Object(obj) => {
            for (key, val) in obj.iter() {
                validate_field_name(key)?;
                validate_value(val)?;
            }
        }
        Value::Array(arr) => {
            for val in arr.iter() {
                validate_value(val)?;
            }
        }
        _ => {}
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use serde_json::json;

    use super::*;

    #[test]
    fn test_validate_depth() {
        assert!(validate_depth(0, 10).is_ok());
        assert!(validate_depth(5, 10).is_ok());
        assert!(validate_depth(10, 10).is_ok());
        assert!(validate_depth(11, 10).is_err());
    }

    #[test]
    fn test_validate_field_name() {
        assert!(validate_field_name("name").is_ok());
        assert!(validate_field_name("user_id").is_ok());
        assert!(validate_field_name("").is_err());
    }

    #[test]
    fn test_validate_value() {
        assert!(validate_value(&json!(null)).is_ok());
        assert!(validate_value(&json!(123)).is_ok());
        assert!(validate_value(&json!("hello")).is_ok());
        assert!(validate_value(&json!({"name": "Alice"})).is_ok());
        assert!(validate_value(&json!([1, 2, 3])).is_ok());

        let bad_obj = json!({"": "value"});
        assert!(validate_value(&bad_obj).is_err());
    }
}

File: tools\rune-vscode-theme\README.md
=======================================
# RUNE Syntax + Theme (local)

A small VS Code extension that adds syntax highlighting and a themed palette for RUNE/TOON glyphs.

## Install (unpacked)

1. In VS Code, run `Developer: Install Extension from Location...` and choose this folder (`tools/rune-vscode-theme`).
2. Set the color theme to **RUNE Theme**.

## Notes

- Registered for `*.rune` with scope `source.rune`.
- Color choices: flow (water blues), splits/merges (lilac/purple), stability (icy blues), bind/energy (deep purple/amber), types (gold), functions (aqua).
- TextMate grammar lives in `syntaxes/rune.tmLanguage.json`; theme in `themes/rune-color-theme.json`.

File: tools\rune-vscode-theme\package.json
==========================================
{
  "name": "rune-syntax-theme",
  "displayName": "RUNE Syntax + Theme",
  "description": "Syntax highlighting and thematic colors for RUNE glyphs.",
  "version": "0.0.1",
  "publisher": "local",
  "repository": {
    "type": "git",
    "url": "https://github.com/arcmoonstudios/toon-rune"
  },
  "engines": {
    "vscode": "^1.80.0"
  },
  "categories": ["Programming Languages", "Themes"],
  "contributes": {
    "languages": [
      {
        "id": "rune",
        "aliases": ["RUNE", "rune"],
        "extensions": [".rune"],
        "configuration": "./language-configuration.json"
      }
    ],
    "grammars": [
      {
        "language": "rune",
        "scopeName": "source.rune",
        "path": "./syntaxes/rune.tmLanguage.json"
      }
    ],
    "themes": [
      {
        "label": "RUNE Theme",
        "uiTheme": "vs-dark",
        "path": "./themes/rune-color-theme.json"
      }
    ]
  }
}

File: rune-curs\src\kernels\mod.rs
==================================
pub mod cuda;
pub mod dom_r;

File: rune-curs\src\kernels\cuda.rs
===================================
/* curs/src/kernels/cuda.rs */
//! Embedded PTX kernel strings for the `rune-curs` crate.
//!
//! This module centralizes all pre-compiled CUDA kernels, ensuring a single
//! source of truth for GPU code and separating it from the Rust orchestration logic.

/// PTX for the `DomR` kernel.
///
/// This kernel computes scores for each of the `n` E8 roots based on an input
/// energy vector and the geometric dot product relationships between all roots.
///
/// - **Function Signature:** `domr_kernel(energy, coords, scores, n)`
/// - **`energy`:** `const float*` - Input energy vector of length `n`.
/// - **`coords`:** `const float*` - Flattened `AoS` coordinates array (`n * 8` floats).
/// - **`scores`:** `float*` - Output scores vector of length `n`.
/// - **`n`:** `int` - The number of roots (e.g., 240).
pub const DOMR_PTX: &str = r"
.version 6.0
.target sm_89
.address_size 64

.visible .entry domr_kernel(
    .param .u64 energy,
    .param .u64 coords,
    .param .u64 scores,
    .param .u32 n
) {
    .reg .pred p;
    .reg .f32 acc, dot, cx0,cx1,cx2,cx3,cx4,cx5,cx6,cx7, co;
    .reg .s32 idx, nval, o;
    .reg .u64 eptr, cptr, sptr, base;

    ld.param.u64 eptr, [energy];
    ld.param.u64 cptr, [coords];
    ld.param.u64 sptr, [scores];
    ld.param.u32 nval, [n];
    mov.u32 idx, %tid.x;
    mad.lo.s32 idx, %ctaid.x, %ntid.x, idx;
    setp.ge.s32 p, idx, nval;
    @p ret;

    // load coords[idx]
    mul.wide.s32 base, idx, 32;
    add.s64 base, cptr, base;
    ld.global.f32 cx0, [base+0];
    ld.global.f32 cx1, [base+4];
    ld.global.f32 cx2, [base+8];
    ld.global.f32 cx3, [base+12];
    ld.global.f32 cx4, [base+16];
    ld.global.f32 cx5, [base+20];
    ld.global.f32 cx6, [base+24];
    ld.global.f32 cx7, [base+28];

    mov.f32 acc, 0f00000000;
    mov.s32 o, 0;
L_loop:
    setp.ge.s32 p, o, nval;
    @p bra L_end;
    mul.wide.s32 base, o, 32;
    add.s64 base, cptr, base;
    ld.global.f32 dot, [base+0];
    mul.f32 dot, dot, cx0;
    ld.global.f32 co, [base+4];
    fma.rn.f32 dot, co, cx1, dot;
    ld.global.f32 co, [base+8];
    fma.rn.f32 dot, co, cx2, dot;
    ld.global.f32 co, [base+12];
    fma.rn.f32 dot, co, cx3, dot;
    ld.global.f32 co, [base+16];
    fma.rn.f32 dot, co, cx4, dot;
    ld.global.f32 co, [base+20];
    fma.rn.f32 dot, co, cx5, dot;
    ld.global.f32 co, [base+24];
    fma.rn.f32 dot, co, cx6, dot;
    ld.global.f32 co, [base+28];
    fma.rn.f32 dot, co, cx7, dot;

    ld.global.f32 co, [eptr + o*4];
    fma.rn.f32 acc, co, dot, acc;
    add.s32 o, o, 1;
    bra L_loop;
L_end:
    mul.wide.s32 base, idx, 4;
    add.s64 base, sptr, base;
    st.global.f32 [base], acc;
    ret;
}
";

File: rune-curs\src\kernels\dom_r.rs
====================================
//! Embedded PTX for `DomR` kernel.

pub const DOMR_PTX: &str = r"
.version 6.0
.target sm_89
.address_size 64

.visible .entry domr_kernel(
    .param .u64 energy,
    .param .u64 coords,
    .param .u64 scores,
    .param .u32 n
) {
    .reg .pred p;
    .reg .f32 acc, dot, cx0,cx1,cx2,cx3,cx4,cx5,cx6,cx7, co;
    .reg .s32 idx, nval, o;
    .reg .u64 eptr, cptr, sptr, base;

    ld.param.u64 eptr, [energy];
    ld.param.u64 cptr, [coords];
    ld.param.u64 sptr, [scores];
    ld.param.u32 nval, [n];
    mov.u32 idx, %tid.x;
    mad.lo.s32 idx, %ctaid.x, %ntid.x, idx;
    setp.ge.s32 p, idx, nval;
    @p ret;

    // load coords[idx]
    mul.wide.s32 base, idx, 32;
    add.s64 base, cptr, base;
    ld.global.f32 cx0, [base+0];
    ld.global.f32 cx1, [base+4];
    ld.global.f32 cx2, [base+8];
    ld.global.f32 cx3, [base+12];
    ld.global.f32 cx4, [base+16];
    ld.global.f32 cx5, [base+20];
    ld.global.f32 cx6, [base+24];
    ld.global.f32 cx7, [base+28];

    mov.f32 acc, 0f00000000;
    mov.s32 o, 0;
L_loop:
    setp.ge.s32 p, o, nval;
    @p bra L_end;
    mul.wide.s32 base, o, 32;
    add.s64 base, cptr, base;
    ld.global.f32 dot, [base+0];
    mul.f32 dot, dot, cx0;
    ld.global.f32 co, [base+4];
    fma.rn.f32 dot, co, cx1, dot;
    ld.global.f32 co, [base+8];
    fma.rn.f32 dot, co, cx2, dot;
    ld.global.f32 co, [base+12];
    fma.rn.f32 dot, co, cx3, dot;
    ld.global.f32 co, [base+16];
    fma.rn.f32 dot, co, cx4, dot;
    ld.global.f32 co, [base+20];
    fma.rn.f32 dot, co, cx5, dot;
    ld.global.f32 co, [base+24];
    fma.rn.f32 dot, co, cx6, dot;
    ld.global.f32 co, [base+28];
    fma.rn.f32 dot, co, cx7, dot;

    ld.global.f32 co, [eptr + o*4];
    fma.rn.f32 acc, co, dot, acc;
    add.s32 o, o, 1;
    bra L_loop;
L_end:
    mul.wide.s32 base, idx, 4;
    add.s64 base, sptr, base;
    st.global.f32 [base], acc;
    ret;
}
";

File: src\rune\hydron\mod.rs
============================
//! Hydron - E8 Geometric Mathematics Engine
//!
//! Pure mathematical implementations of E8 lattice geometry with multi-geometric layers:
//! - Fisher information geometry (statistical manifolds)
//! - Symplectic T*E8 geometry (Hamiltonian dynamics)
//! - Hyperbolic H8 geometry (Poincaré ball model)
//! - Topological analysis (persistent homology)
//! - Lorentzian geometry (spacetime metrics)
//! - Quaternion algebra (rotations, SLERP)
//! - Spherical S7 geometry (unit sphere)
//!
//! All modules provide pure geometric operations. Application-specific extensions
//! (e.g., causal DAGs, event systems) are clearly separated.
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

#[cfg(feature = "cuda")]
pub mod cuda;
pub mod eval;
pub mod perception;
pub mod topology;
pub mod values;

// Re-export the hydron-core crate's math modules when the feature is enabled.
// This keeps the Rune crate's public API stable while the actual math is
// implemented in the `hydron-core` crate.
#[cfg(feature = "hydron")]
pub use hydron_core::{
    FisherLayer, Gf8, Gf8Tensor, HyperbolicLayer, LorentzianCausalLayer, LorentzianLayer,
    PersistencePair, QuaternionOps, SpacetimePoint, SphericalLayer, SymplecticLayer,
    TopologicalLayer, intrinsics_for_f32_width,
};

// When hydron feature is disabled, keep local types for the evaluator and values as-is.
// Re-export the runtime value types so code can always import `crate::rune::hydron::Value`.
pub use crate::rune::hydron::values::{EvalContext, EvalError, Octonion, Value};

File: src\rune\hydron\cuda.rs
=============================
//! CUDA-specific evaluation bridge for Hydron operations.
//!
//! Provides GPU-accelerated implementations for DomR computations using the rune-curs
//! CUDA acceleration layer.

#[cfg(feature = "cuda")]
use rune_curs as curs;
use rune_hex::hex;

/// CUDA accelerator for Hydron operations
#[derive(Debug, Clone)]
pub struct CudaAccelerator {
    /// Whether CUDA is available on this system
    cuda_available: bool,
}

impl CudaAccelerator {
    /// Create a new CUDA accelerator and check availability
    pub fn new() -> Self {
        #[cfg(feature = "cuda")]
        let cuda_available = true; // Assume available if compiled with feature

        #[cfg(not(feature = "cuda"))]
        let cuda_available = false;

        Self { cuda_available }
    }

    /// Check if CUDA acceleration is available
    pub fn is_available(&self) -> bool {
        self.cuda_available
    }

    /// Execute CUDA-accelerated DomR computation if available
    pub fn execute_domr(
        &self,
        operation: &str,
        energy_args: &[crate::rune::hydron::values::Value],
    ) -> Result<crate::rune::hydron::values::Value, crate::rune::hydron::values::EvalError> {
        use crate::rune::hydron::values::{EvalError, Value};

        if !self.cuda_available {
            return Err(EvalError::UnsupportedOperation(
                "CUDA not available on this system".to_string(),
            ));
        }

        match operation {
            "CudaDomR" | "CudaArchetypeDomR" => {
                // Extract energy array from first argument
                let energy_vec = extract_energy_array(&energy_args[0])?;
                let n_dr = energy_args.get(1)
                    .map(|v| extract_usize(v))
                    .transpose()?
                    .unwrap_or(8);

                #[cfg(feature = "cuda")]
                {
                    // Get the default hex graph
                    let graph = hex::default_graph();

                    // Compute scores using CUDA
                    let scores = curs::domr_scores_gpu(&energy_vec, graph.coords())
                        .map_err(|e| EvalError::InvalidOperation(format!("CUDA DomR failed: {}", e)))?;

                    if scores.len() != graph.coords().len() {
                        return Err(EvalError::InvalidOperation(
                            "CUDA returned mismatched score length".to_string(),
                        ));
                    }

                    // Sort by score descending and take top n_dr
                    let mut pairs: Vec<(usize, f32)> = scores.into_iter().enumerate().collect();
                    pairs.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

                    let take = n_dr.min(pairs.len());
                    let mut roots = Vec::with_capacity(take);
                    let mut out_scores = Vec::with_capacity(take);

                    for (idx, score) in pairs.into_iter().take(take) {
                        roots.push(idx as u8);
                        out_scores.push(score);
                    }

                    Ok(Value::DomR(hex::DomR {
                        roots,
                        scores: out_scores,
                    }))
                }

                #[cfg(not(feature = "cuda"))]
                {
                    Err(EvalError::UnsupportedOperation(
                        "CUDA feature not enabled".to_string(),
                    ))
                }
            }

            _ => Err(EvalError::UnsupportedOperation(format!(
                "Unknown CUDA operation: {} (only DomR operations supported)",
                operation
            ))),
        }
    }
}

impl Default for CudaAccelerator {
    fn default() -> Self {
        Self::new()
    }
}

/// Global CUDA accelerator instance
static CUDA_ACCELERATOR: std::sync::OnceLock<CudaAccelerator> = std::sync::OnceLock::new();

/// Get or initialize the global CUDA accelerator
pub fn get_cuda_accelerator() -> &'static CudaAccelerator {
    CUDA_ACCELERATOR.get_or_init(|| CudaAccelerator::new())
}

// Helper functions for extracting values from Value enum

fn extract_energy_array(val: &crate::rune::hydron::values::Value) -> Result<Vec<f32>, crate::rune::hydron::values::EvalError> {
    use crate::rune::hydron::values::{EvalError, Value};

    match val {
        Value::Array(arr) => {
            if arr.len() != 240 {
                return Err(EvalError::TypeMismatch(format!(
                    "Energy array must have length 240, got {}",
                    arr.len()
                )));
            }
            arr.iter()
                .map(|v| extract_f32(v))
                .collect()
        }
        _ => Err(EvalError::TypeMismatch(
            "Energy argument must be an Array of 240 floats".to_string(),
        )),
    }
}

fn extract_f32(val: &crate::rune::hydron::values::Value) -> Result<f32, crate::rune::hydron::values::EvalError> {
    use crate::rune::hydron::values::{EvalError, Value};

    match val {
        Value::Scalar(f) => Ok(*f),
        Value::Float(f) => Ok(*f as f32),
        Value::Integer(i) => Ok(*i as f32),
        _ => Err(EvalError::TypeMismatch(
            "Value must be numeric (Scalar, Float, or Integer)".to_string(),
        )),
    }
}

fn extract_usize(val: &crate::rune::hydron::values::Value) -> Result<usize, crate::rune::hydron::values::EvalError> {
    use crate::rune::hydron::values::{EvalError, Value};

    match val {
        Value::Scalar(f) => Ok(*f as usize),
        Value::Float(f) => Ok(*f as usize),
        Value::Integer(i) => Ok(*i as usize),
        _ => Err(EvalError::TypeMismatch(
            "Index must be numeric".to_string(),
        )),
    }
}

File: src\rune\hydron\eval.rs
=============================
//! RUNE Expression Evaluator
//!
//! Evaluates RUNE expressions with semantic prefixes, array literals, and operators.
//! Supports mathematical operations, semantic type checking, and E8 geometry primitives.
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use super::values::{EvalContext, EvalError, Value};
use crate::rune::ops::MathOp;
use crate::rune::{
    Expr, Ident, Literal, MathAtom, MathExpr, MathUnaryOp, RuneOp, SemanticIdent, Stmt, Term,
};
use std::collections::HashMap;

/// RUNE expression evaluator with semantic type support
pub struct Evaluator {
    /// Variable bindings (name -> value)
    variables: HashMap<String, Value>,
    /// Semantic namespace bindings (T:name -> value)
    semantic_vars: HashMap<String, Value>,
}

impl Evaluator {
    /// Create a new evaluator with empty context
    pub fn new() -> Self {
        Self {
            variables: HashMap::new(),
            semantic_vars: HashMap::new(),
        }
    }

    /// Create evaluator with pre-populated context
    pub fn with_context(ctx: EvalContext) -> Self {
        Self {
            variables: ctx.variables,
            semantic_vars: ctx.semantic_vars,
        }
    }

    /// Set a variable value
    pub fn set_var(&mut self, name: impl Into<String>, value: Value) {
        self.variables.insert(name.into(), value);
    }

    /// Set a semantic variable value (e.g., T:Gf8)
    pub fn set_semantic(&mut self, prefix: char, name: impl Into<String>, value: Value) {
        let key = format!("{}:{}", prefix, name.into());
        self.semantic_vars.insert(key, value);
    }

    /// Print SIMD capabilities (diagnostic)
    #[cfg(feature = "simd")]
    pub fn print_simd_info(&self) {
        use super::values::{get_available_f32_256_intrinsics, print_simd_capabilities};
        print_simd_capabilities();
        let intrinsics = get_available_f32_256_intrinsics();
        println!("Available f32x256 intrinsics: {:?}", intrinsics);
    }

    /// Get a variable value
    pub fn get_var(&self, name: &str) -> Option<&Value> {
        self.variables.get(name)
    }

    /// Get a semantic variable value
    pub fn get_semantic(&self, prefix: char, name: &str) -> Option<&Value> {
        let key = format!("{}:{}", prefix, name);
        self.semantic_vars.get(&key)
    }

    /// Evaluate a statement
    pub fn eval_stmt(&mut self, stmt: &Stmt) -> Result<Value, EvalError> {
        match stmt {
            Stmt::RootDecl(root) => {
                // Root declarations don't produce values, but we can store them as context
                Ok(Value::String(root.to_string()))
            }
            Stmt::ToonBlock { name, content } => {
                // TOON blocks are data, not computation - return the raw content
                Ok(Value::String(format!(
                    "TOON block '{}': {} chars",
                    name,
                    content.len()
                )))
            }
            Stmt::RuneBlock { name, content } => {
                // RUNE blocks are preferred executable data blobs; return size summary for now
                Ok(Value::String(format!(
                    "RUNE block '{}': {} chars",
                    name,
                    content.len()
                )))
            }
            Stmt::KernelDecl { name, archetype: _ } => {
                // Kernel declarations are declarations, not computations - return description
                Ok(Value::String(format!("Kernel '{}' declared", name.name.0)))
            }
            Stmt::Expr(expr) => self.eval_expr(expr),
        }
    }

    /// Evaluate a typed statement (StmtTyped), respecting the type annotations
    /// provided by the parser's inference pass.
    pub fn eval_typed_stmt(&mut self, stmt: &crate::rune::ast::StmtTyped) -> Result<Value, EvalError> {
        match stmt {
            crate::rune::ast::StmtTyped::RootDecl(root) => Ok(Value::String(root.to_string())),
            crate::rune::ast::StmtTyped::ToonBlock { name, content } => Ok(Value::String(format!(
                "TOON block '{}': {} chars",
                name,
                content.len()
            ))),
            crate::rune::ast::StmtTyped::RuneBlock { name, content } => Ok(Value::String(format!(
                "RUNE block '{}': {} chars",
                name,
                content.len()
            ))),
            crate::rune::ast::StmtTyped::KernelDecl { name, archetype: _ } => Ok(Value::String(format!("Kernel '{}' declared", name.name.0))),
            crate::rune::ast::StmtTyped::Expr(te) => {
                // For now, just evaluate the inner expression as before, type info is advisory.
                self.eval_expr(&te.expr)
            }
        }
    }

    /// Evaluate an expression
    pub fn eval_expr(&mut self, expr: &Expr) -> Result<Value, EvalError> {
        match expr {
            Expr::Term(term) => self.eval_term(term),
            Expr::Binary { left, op, right } => {
                // Special-case: transform operator `~` used as builtin invocation
                // e.g., `S7Slerp ~ [a, b, t]` where left is builtin name
                if *op == RuneOp::Transform {
                    // If left is a direct identifier, treat as builtin name
                    if let Expr::Term(Term::Ident(id)) = &**left {
                        // Evaluate the right expression to a value
                        let right_val = self.eval_expr(right)?;
                        // If right_val is an Array, use elements as args; otherwise a single arg
                        let args: Vec<Value> = match right_val {
                            Value::Array(arr) => arr,
                            v => vec![v],
                        };

                        // Dispatch to builtin
                        let ctx = self.context();
                        return ctx.apply_builtin_by_name(&id.0, &args);
                    }
                }

                let left_val = self.eval_expr(left)?;
                let right_val = self.eval_expr(right)?;
                self.eval_binary_op(&left_val, op, &right_val)
            }
        }
    }

    /// Evaluate a term
    fn eval_term(&self, term: &Term) -> Result<Value, EvalError> {
        match term {
            Term::Literal(lit) => self.eval_literal(lit),
            Term::Ident(ident) => self.eval_ident(ident),
            Term::SemanticIdent(sem) => self.eval_semantic_ident(sem),
            Term::Group(expr) => {
                // Group expressions are used for math blocks [expr]
                // For now, just evaluate the inner expression
                let mut temp_eval = Self {
                    variables: self.variables.clone(),
                    semantic_vars: self.semantic_vars.clone(),
                };
                temp_eval.eval_expr(expr)
            }
            Term::Math(math_expr) => {
                // Math blocks contain MathExpr which needs evaluation
                self.eval_math_expr(math_expr)
            }
            Term::FunctionCall { name, args } => {
                // Evaluate function call by dispatching to builtin
                let mut temp_eval = Self {
                    variables: self.variables.clone(),
                    semantic_vars: self.semantic_vars.clone(),
                };
                let args: Vec<Value> = args.iter().map(|arg| temp_eval.eval_expr(arg)).collect::<Result<_, _>>()?;
                let ctx = self.context();
                ctx.apply_builtin_by_name(&name.0, &args)
            }
        }
    }

    /// Evaluate a math expression
    fn eval_math_expr(&self, math: &MathExpr) -> Result<Value, EvalError> {
        match math {
            MathExpr::Atom(atom) => self.eval_math_atom(atom),
            MathExpr::Binary { left, op, right } => {
                let left_val = self.eval_math_expr(left)?;
                let right_val = self.eval_math_expr(right)?;
                self.eval_math_op(&left_val, op, &right_val)
            }
            MathExpr::Unary { op, operand } => {
                let val = self.eval_math_expr(operand)?;
                self.eval_math_unary_op(op, &val)
            }
        }
    }

    /// Evaluate a math atom
    fn eval_math_atom(&self, atom: &MathAtom) -> Result<Value, EvalError> {
        match atom {
            MathAtom::Number(n) => Ok(Value::Float(*n)),
            MathAtom::Ident(ident) => {
                // Check if it's a semantic identifier (contains ':')
                if ident.0.contains(':') {
                    let parts: Vec<&str> = ident.0.split(':').collect();
                    if parts.len() == 2 && parts[0].len() == 1 {
                        let prefix = parts[0].chars().next().unwrap();
                        self.get_semantic(prefix, parts[1])
                            .cloned()
                            .ok_or_else(|| EvalError::UndefinedVariable(ident.0.clone()))
                    } else {
                        self.eval_ident(ident)
                    }
                } else {
                    self.eval_ident(ident)
                }
            }
            MathAtom::Group(math) => self.eval_math_expr(math),
            MathAtom::Array(elements) => {
                // Evaluate array literal inside math block
                let mut values = Vec::new();
                for elem in elements {
                    values.push(self.eval_math_expr(elem)?);
                }
                Ok(Value::Array(values))
            }
        }
    }

    /// Evaluate a math binary operation
    fn eval_math_op(&self, left: &Value, op: &MathOp, right: &Value) -> Result<Value, EvalError> {
        match op {
            MathOp::Add => left.add(right),
            MathOp::Subtract => left.sub(right),
            MathOp::Multiply => left.mul(right),
            MathOp::Divide => left.div(right),
            MathOp::Power => left.pow(right),
            MathOp::Modulo => left.modulo(right),
            MathOp::Root => Err(EvalError::UnsupportedOperation(
                "Root operator not yet implemented".into(),
            )),
        }
    }

    /// Evaluate a math unary operation
    fn eval_math_unary_op(&self, op: &MathUnaryOp, val: &Value) -> Result<Value, EvalError> {
        match op {
            MathUnaryOp::Negate => val.negate(),
            MathUnaryOp::Plus => Ok(val.clone()),
        }
    }

    /// Evaluate a literal value
    fn eval_literal(&self, lit: &Literal) -> Result<Value, EvalError> {
        match lit {
            Literal::Number(n) => Ok(Value::Float(*n)),
            Literal::String(s) => Ok(Value::String(s.clone())),
            Literal::Bool(b) => Ok(Value::Scalar(if *b { 1.0 } else { 0.0 })),
            Literal::Array(exprs) => {
                let mut values = Vec::new();
                let mut temp_eval = Self {
                    variables: self.variables.clone(),
                    semantic_vars: self.semantic_vars.clone(),
                };
                for expr in exprs {
                    values.push(temp_eval.eval_expr(expr)?);
                }
                Ok(Value::Array(values))
            }
        }
    }

    /// Evaluate an identifier (variable lookup)
    fn eval_ident(&self, ident: &Ident) -> Result<Value, EvalError> {
        self.variables
            .get(&ident.0)
            .cloned()
            .ok_or_else(|| EvalError::UndefinedVariable(ident.0.clone()))
    }

    /// Evaluate a semantic identifier (T:name, V:velocity, etc.)
    fn eval_semantic_ident(&self, sem: &SemanticIdent) -> Result<Value, EvalError> {
        let key = format!("{}:{}", sem.prefix, sem.name.0);
        self.semantic_vars
            .get(&key)
            .cloned()
            .ok_or_else(|| EvalError::UndefinedVariable(key))
    }

    /// Evaluate a binary operation using RuneOp (structural operations only)
    /// Arithmetic operations are handled by MathOp within math blocks `[]`
    fn eval_binary_op(&self, left: &Value, op: &RuneOp, right: &Value) -> Result<Value, EvalError> {
        use RuneOp::*;

        match op {
            // Comparison operators
            Less => left.lt(right),
            LessEqual => left.le(right),
            Greater => left.gt(right),
            GreaterEqual => left.ge(right),
            Equal => Ok(Value::Bool(left == right)),

            // Glyph operators -> geometric primitives
            SplitJoin | BranchStabilize => left.geometric_midpoint(right),
            JoinSplit => left.geometric_antipode_midpoint(right),
            StabilizeRoot => left.geometric_project(right),
            RootStabilize => left.geometric_reject(right),
            AnchorDescend => left.geometric_distance(right),
            SymmetricSplit => {
                let proj = left.geometric_project(right)?;
                let rej = left.geometric_reject(right)?;
                Ok(Value::Tuple(vec![proj, rej]))
            }
            BranchAnchorBranch => {
                let mid = left.geometric_midpoint(right)?;
                let dist = left.geometric_distance(right)?;
                Ok(Value::Tuple(vec![mid, dist]))
            }

            // Structural operators (not for computation) - arithmetic handled by MathOp
            Descendant | Ancestor | Define | FlowRight | FlowLeft | Bind | Namespace | Alias
            | Parallel | Transform | Specializes | Match | Unify | FlowBidirectional | FlowConvergent
            | PipelineRight | PipelineLeft | Output | Input => {
                Err(EvalError::UnsupportedOperation(format!(
                    "Structural operator {:?} not implemented for computation. Use math blocks `[]` for arithmetic.",
                    op
                )))
            }
        }
    }

    /// Export current context
    pub fn context(&self) -> EvalContext {
        let mut ctx = EvalContext::new();
        for (name, value) in &self.variables {
            ctx.bind(name.clone(), value.clone());
        }
        // Add semantic variables from the evaluator into the context so builtins
        // can resolve semantic identifiers.
        for (k, v) in &self.semantic_vars {
            ctx.semantic_vars.insert(k.clone(), v.clone());
        }
        ctx
    }

    /// Evaluate a builtin by its textual name using the current context
    pub fn eval_builtin_by_name(
        &self,
        name: &str,
        args: &[Value],
    ) -> Result<Value, EvalError> {
        let ctx = self.context();
        ctx.apply_builtin_by_name(name, args)
    }
}

impl Default for Evaluator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::rune::parse;

    #[test]
    fn test_eval_literal_number() {
        let mut eval = Evaluator::new();
        let stmts = parse("42").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(42.0));
    }

    #[test]
    fn test_eval_arithmetic() {
        let mut eval = Evaluator::new();

        // Simple addition in math block
        let stmts = parse("[2 + 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(5.0));

        // Multiplication in math block
        let stmts = parse("[4 * 5]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(20.0));

        // Complex expression with precedence
        let stmts = parse("[2 + 3 * 4]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(14.0)); // Respects precedence

        // Division in math block
        let stmts = parse("[10 / 2]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(5.0));

        // Power in math block
        let stmts = parse("[2 ^ 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(8.0));

        // Modulo in math block
        let stmts = parse("[10 % 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(1.0));
    }

    #[test]
    fn test_eval_array_literal() {
        let mut eval = Evaluator::new();
        let stmts = parse("[1, 2, 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();

        match result {
            Value::Array(arr) => {
                assert_eq!(arr.len(), 3);
                assert_eq!(arr[0], Value::Float(1.0));
                assert_eq!(arr[1], Value::Float(2.0));
                assert_eq!(arr[2], Value::Float(3.0));
            }
            _ => panic!("Expected array value"),
        }
    }

    #[test]
    fn test_eval_array_operations() {
        let mut eval = Evaluator::new();

        // Array addition (element-wise) in math block
        let stmts = parse("[[1, 2, 3] + [4, 5, 6]]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();

        match result {
            Value::Array(arr) => {
                assert_eq!(arr.len(), 3);
                assert_eq!(arr[0], Value::Float(5.0));
                assert_eq!(arr[1], Value::Float(7.0));
                assert_eq!(arr[2], Value::Float(9.0));
            }
            _ => panic!("Expected array value"),
        }
    }

    #[test]
    fn test_eval_semantic_prefix() {
        let mut eval = Evaluator::new();

        // Set semantic variable
        eval.set_semantic('T', "Gf8", Value::Float(2.5));

        // Evaluate semantic expression in math block
        let stmts = parse("[T:Gf8 * 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(7.5));
    }

    #[test]
    fn test_eval_variables() {
        let mut eval = Evaluator::new();

        // Set variable
        eval.set_var("x", Value::Float(10.0));

        // Use in expression within math block
        let stmts = parse("[x + 5]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(15.0));
    }

    #[test]
    fn test_eval_nested_math() {
        let mut eval = Evaluator::new();

        // Math block with nested operations
        let stmts = parse("[[3, 3, 3] * [2, 2, 2]]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();

        match result {
            Value::Array(arr) => {
                assert_eq!(arr.len(), 3);
                assert_eq!(arr[0], Value::Float(6.0));
                assert_eq!(arr[1], Value::Float(6.0));
                assert_eq!(arr[2], Value::Float(6.0));
            }
            _ => panic!("Expected array value"),
        }
    }

    #[test]
    fn test_eval_comparison() {
        let mut eval = Evaluator::new();

        // Comparisons work with RuneOp outside math blocks
        let stmts = parse("5 > 3").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("2 = 2").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));
    }

    #[test]
    fn test_eval_unary_minus() {
        let mut eval = Evaluator::new();

        // Unary minus in math block
        let stmts = parse("[-5]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(-5.0));
    }

    #[test]
    fn test_eval_comparison_operators() {
        let mut eval = Evaluator::new();

        // Test less than or equal
        let stmts = parse("3 <= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("5 <= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("7 <= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(false));

        // Test greater than or equal
        let stmts = parse("5 >= 3").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("5 >= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("3 >= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(false));
    }

    #[test]
    fn test_eval_builtin_by_name() {
        let eval = Evaluator::new();
        let a = crate::rune::hydron::values::Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let b = crate::rune::hydron::values::Value::Vec8([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use static method eval_builtin_by_name to invoke S7Distance
        let result = eval.eval_builtin_by_name("S7Distance", &[a.clone(), b.clone()]).unwrap();
        assert!(matches!(result, crate::rune::hydron::values::Value::Scalar(_)));

        // Slerp interception
        let t = crate::rune::hydron::values::Value::Scalar(0.5);
        let interp = eval
            .eval_builtin_by_name("S7Slerp", &[a.clone(), b.clone(), t])
            .unwrap();
        assert!(matches!(interp, crate::rune::hydron::values::Value::Vec8(_)));
    }

    #[test]
    fn test_parse_typed_and_eval() {
        let mut eval = Evaluator::new();
        // parse typed statement
        let typed = crate::rune::parse_typed("[2 + 3]").unwrap();
        assert_eq!(typed.len(), 1);
        if let crate::rune::ast::StmtTyped::Expr(te) = &typed[0] {
            // Type should be Scalar
            assert_eq!(te.r#type, crate::rune::ast::RuneType::Scalar);
            let result = eval.eval_typed_stmt(&typed[0]).unwrap();
            assert_eq!(result, crate::rune::hydron::values::Value::Float(5.0));
        } else {
            panic!("Expected typed expr");
        }
    }

    #[test]
    fn test_eval_transform_builtin_slerp() {
        let mut eval = Evaluator::new();
        let script = "S7Slerp ~ [[1,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0], 0.5]";
        let stmts = crate::rune::parse(script).unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        // Expect Vec8 result
        assert!(matches!(result, crate::rune::hydron::values::Value::Vec8(_)));
    }
}

File: rune-hex\.rune-hexFiles\rune-hex.txt
==========================================
File: Cargo.toml
================
[package]
name = "rune-hex"
version = "0.0.1"
edition = "2024"
publish = false

[lib]
path = "src/lib.rs"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
thiserror = "2.0"

File: src\lib.rs
================
pub mod hex;

File: src\hex.rs
================
//! Human Experience Semantic Schema and Geometry Bridge.
//!
//! This module materializes the declarative `examples/hex.rune` asset
//! into strongly-typed Rust structures that are laid out for SIMD- and
//! GPU-friendly traversal (tight coordinate buffers + CSR adjacency).
//! It also exposes fast lookup of the semantic coordinate tables and baseline
//! search/path routines.
//!
//! Design notes:
//! - Types mirror the RUNE schema (RootKind, SemanticDomain, HumanExperience, etc.)
//! - Coordinates are parsed once from the `.rune` asset into contiguous arrays and
//!   then accessed by enum index (no string lookups on the hot path).
//! - Graph storage is AoS for coordinates plus CSR for adjacency to ease future
//!   CUDA mirroring.

use std::collections::HashMap;
use std::fs;
use std::path::Path;
use std::sync::OnceLock;

use serde::{Deserialize, Serialize};
use thiserror::Error;

#[derive(Debug, Error)]
pub enum HexError {
    #[error("Invalid operation: {0}")]
    InvalidOperation(String),
    #[error("Type mismatch: {0}")]
    TypeMismatch(String),
}

pub type VertexId = u32;

/// ErsRootKind – Rust enum projection of `T:RootKind` from hex.rune.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RootKind {
    TypeI,
    TypeII,
}

/// ErsSemanticDomain – Rust enum projection of `T:SemanticDomain`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SemanticDomain {
    Psychology,
    Relationships,
    Economics,
    Creativity,
    Spirituality,
    Physical,
    Existential,
    Ethics,
    Education,
    Health,
}

/// ErsEmotionType – projection of `T:EmotionType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EmotionType {
    Joy,
    Sorrow,
    Anger,
    Fear,
    Surprise,
    Disgust,
    Love,
    Hate,
    Hope,
    Despair,
    Pride,
    Shame,
    Awe,
    Envy,
    Guilt,
    Gratitude,
    Nostalgia,
    Serenity,
    Empathy,
    Compassion,
    Jealousy,
    Loneliness,
    Belonging,
    Confidence,
    Insecurity,
    Embarrassment,
    Humility,
    Frustration,
    Calm,
    Anxiety,
}

/// ErsCognitiveType – projection of `T:CognitiveType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CognitiveType {
    Attention,
    Memory,
    Learning,
    Perception,
    Reasoning,
    ProblemSolving,
    DecisionMaking,
    Planning,
    Creativity,
    SelfAwareness,
    Reflection,
    Introspection,
    Insight,
    Understanding,
    Confusion,
    Clarity,
    Realization,
    ConfirmationBias,
    Anchoring,
    Availability,
    Overconfidence,
}

/// ErsSocialType – projection of `T:SocialType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SocialType {
    Friendship,
    Romance,
    Family,
    Professional,
    Cooperation,
    Competition,
    Conflict,
    Collaboration,
    Acceptance,
    Rejection,
    Inclusion,
    Exclusion,
    Listening,
    Speaking,
    Arguing,
    Negotiating,
    Leader,
    Follower,
    Mentor,
    Student,
}

/// ErsExistentialType – projection of `T:ExistentialType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ExistentialType {
    Meaning,
    Purpose,
    Identity,
    Freedom,
    Responsibility,
    Mortality,
    Authenticity,
    Absurdity,
    Alienation,
    Transcendence,
}

/// ErsPhysicalType – projection of `T:PhysicalType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PhysicalType {
    Pain,
    Pleasure,
    Hunger,
    Thirst,
    Fatigue,
    Energy,
    Touch,
    Temperature,
    Movement,
    Balance,
    Health,
    Illness,
}

/// ErsEthicalType – projection of `T:EthicalType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EthicalType {
    Righteousness,
    Compassion,
    Justice,
    Fairness,
    Integrity,
    Honesty,
    Empathy,
    Responsibility,
    Duty,
    Virtue,
    Temptation,
    Guilt,
}

/// ErsCreativeType – projection of `T:CreativeType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CreativeType {
    Inspiration,
    Imagination,
    Innovation,
    Expression,
    Design,
    Artistry,
    Invention,
    Discovery,
    Revelation,
    Synthesis,
    Originality,
    Vision,
}

/// ErsSpiritualType – projection of `T:SpiritualType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SpiritualType {
    Meditation,
    Prayer,
    Contemplation,
    Transcendence,
    Enlightenment,
    Devotion,
    Surrender,
    Grace,
    Sacredness,
    Mysticism,
    Presence,
    Unity,
}

/// ErsEconomicType – projection of `T:EconomicType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EconomicType {
    Wealth,
    Poverty,
    Value,
    Exchange,
    Trade,
    Investment,
    Production,
    Consumption,
    Scarcity,
    Abundance,
    Profit,
    Loss,
}

/// ErsHealthType – projection of `T:HealthType`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HealthType {
    Wellness,
    Illness,
    Healing,
    Recovery,
    Vitality,
    Fatigue,
    Balance,
    Imbalance,
    Strength,
    Weakness,
    Resilience,
    Fragility,
}

/// ErsGSLFrame – projection of `T:GSLFrame`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum GSLFrame {
    Unrestricted,
    Restricted,
    Constrained,
}

/// ErsWeylSemanticAddress – projection of `T:WeylSemanticAddress`.
#[derive(Debug, Clone)]
pub struct WeylSemanticAddress {
    pub heads: Vec<[f32; 8]>,
    pub tails: Vec<[f32; 8]>,
    pub timestamp: f64,
    pub context: String,
}

/// ErsHumanExperience – projection of `T:HumanExperience`.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HumanExperience {
    Emotional(EmotionType),
    Cognitive(CognitiveType),
    Social(SocialType),
    Existential(ExistentialType),
    Physical(PhysicalType),
    Ethical(EthicalType),
    Creative(CreativeType),
    Spiritual(SpiritualType),
    Economic(EconomicType),
    Health(HealthType),
}

#[derive(Debug, Clone)]
pub struct Axis {
    pub id: String,
    pub index: u8,
    pub plus: String,
    pub minus: String,
    pub weight: f32,
}

#[derive(Debug, Clone)]
pub struct Vertex {
    pub id: VertexId,
    pub kind: RootKind,
    pub coords: [f32; 8],
    pub domain: Option<SemanticDomain>,
    pub confidence: f32,
}

impl Vertex {
    /// Get the primary human experience associated with this vertex.
    ///
    /// This is a heuristic mapping based on the vertex's coordinates and domain.
    /// Returns None if no clear primary experience can be determined.
    pub fn primary_experience(&self) -> Option<HumanExperience> {
        // Map domain to a representative experience
        // This is a simplified heuristic - in practice, would use coordinate analysis
        self.domain.and_then(|domain| match domain {
            SemanticDomain::Psychology => Some(HumanExperience::Emotional(EmotionType::Joy)),
            SemanticDomain::Relationships => Some(HumanExperience::Social(SocialType::Friendship)),
            SemanticDomain::Economics => Some(HumanExperience::Economic(EconomicType::Wealth)),
            SemanticDomain::Creativity => Some(HumanExperience::Creative(CreativeType::Innovation)),
            SemanticDomain::Spirituality => Some(HumanExperience::Spiritual(SpiritualType::Meditation)),
            SemanticDomain::Physical => Some(HumanExperience::Physical(PhysicalType::Touch)),
            SemanticDomain::Existential => Some(HumanExperience::Existential(ExistentialType::Meaning)),
            SemanticDomain::Ethics => Some(HumanExperience::Ethical(EthicalType::Justice)),
            SemanticDomain::Education => Some(HumanExperience::Cognitive(CognitiveType::Learning)),
            SemanticDomain::Health => Some(HumanExperience::Health(HealthType::Wellness)),
        })
    }
}

#[derive(Debug, Clone)]
pub struct Edge {
    pub u: VertexId,
    pub v: VertexId,
    pub strength: f32,
}

/// ErsDomR – Rust projection of `T:DomR` from RUNE.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct DomR {
    pub roots: Vec<u8>,   // dominant root indices (0..240)
    pub scores: Vec<f32>, // corresponding scores
}

/// CSR adjacency for fast traversal.
#[derive(Debug, Clone)]
pub struct CsrGraph {
    pub row_offsets: Vec<u32>,
    pub adjacency: Vec<u32>,
    pub weights: Vec<f32>,
}

#[derive(Debug, Clone)]
pub struct HexGraph {
    pub axes: Vec<Axis>,
    pub coords: Vec<[f32; 8]>,
    pub kinds: Vec<RootKind>,
    pub domains: Vec<Option<SemanticDomain>>,
    pub confidence: Vec<f32>,
    pub edges: CsrGraph,
}

/// Parsed, normalized tables from the `.rune` asset.
struct ParsedTables {
    axes: Vec<Axis>,
    coords_by_type: HashMap<&'static str, Vec<[f32; 8]>>,
}

static TABLES: OnceLock<ParsedTables> = OnceLock::new();
static HOLO_GRAPH: OnceLock<HexGraph> = OnceLock::new();

fn parse_hex() -> Result<ParsedTables, HexError> {
    let path = Path::new("examples/hex.rune");
    let content = fs::read_to_string(path)
        .map_err(|e| HexError::InvalidOperation(format!("Failed to read hex.rune: {e}")))?;

    let mut axes = Vec::new();
    let mut coords_by_type: HashMap<&'static str, Vec<[f32; 8]>> = HashMap::new();

    let mut in_axes = false;
    let mut in_coords = false;
    let mut current_type: Option<String> = None;

    for line in content.lines() {
        let trimmed = line.trim();
        if trimmed.starts_with('#') || trimmed.is_empty() {
            continue;
        }
        if trimmed.starts_with("Axes:") {
            in_axes = true;
            in_coords = false;
            continue;
        }
        if trimmed.starts_with("Coordinates:") {
            in_coords = true;
            in_axes = false;
            continue;
        }
        if in_axes && trimmed.starts_with('-') {
            // Example: - { id: "A", index: 0, plus: "...", minus: "...", weight: 1.0 }
            let mut id = String::new();
            let mut plus = String::new();
            let mut minus = String::new();
            let mut index = 0u8;
            let mut weight = 1.0f32;
            let inner = trimmed.trim_start_matches('-').trim();
            let inner = inner.trim_start_matches('{').trim_end_matches('}');
            for part in inner.split(',') {
                let kv: Vec<_> = part.trim().splitn(2, ':').collect();
                if kv.len() != 2 {
                    continue;
                }
                let key = kv[0].trim();
                let val = kv[1].trim().trim_matches('"');
                match key {
                    "id" => id = val.to_string(),
                    "plus" => plus = val.to_string(),
                    "minus" => minus = val.to_string(),
                    "index" => index = val.parse::<u8>().unwrap_or(0),
                    "weight" => weight = val.parse::<f32>().unwrap_or(1.0),
                    _ => {}
                }
            }
            axes.push(Axis {
                id,
                index,
                plus,
                minus,
                weight,
            });
            continue;
        }
        if in_coords {
            if trimmed.starts_with("T:") && trimmed.ends_with(':') {
                let name = trimmed
                    .trim_end_matches(':')
                    .trim_start_matches("T:")
                    .to_string();
                current_type = Some(name);
                continue;
            }
            if let Some(ref ty) = current_type {
                if trimmed.starts_with(char::is_alphanumeric) {
                    if let Some((_label, vec_part)) = trimmed.split_once(':') {
                        let vec_part = vec_part.trim();
                        if vec_part.starts_with('[') && vec_part.ends_with(']') {
                            let inner = vec_part.trim_start_matches('[').trim_end_matches(']');
                            let nums: Vec<f32> = inner
                                .split(',')
                                .filter_map(|s| s.trim().parse::<f32>().ok())
                                .collect();
                            if nums.len() == 8 {
                                let mut arr = [0.0f32; 8];
                                arr.copy_from_slice(&nums[..]);
                                coords_by_type
                                    .entry(Box::leak(ty.clone().into_boxed_str()))
                                    .or_default()
                                    .push(arr);
                            }
                        }
                    }
                }
            }
        }
    }

    Ok(ParsedTables {
        axes,
        coords_by_type,
    })
}

fn tables() -> &'static ParsedTables {
    TABLES.get_or_init(|| parse_hex().expect("hex parse"))
}

/// Default HexGraph built from the canonical hex.rune asset.
pub fn default_graph() -> &'static HexGraph {
    HOLO_GRAPH.get_or_init(|| {
        HexGraph::from_rune("examples/hex.rune").expect("failed to build default hex graph")
    })
}

/// Lookup coordinates for a human experience using the parsed tables.
pub fn to_e8_coordinates(exp: &HumanExperience) -> [f32; 8] {
    let t = tables();
    match exp {
        HumanExperience::Emotional(e) => pick(&t.coords_by_type, "EmotionType", *e as usize),
        HumanExperience::Cognitive(c) => pick(&t.coords_by_type, "CognitiveType", *c as usize),
        HumanExperience::Social(s) => pick(&t.coords_by_type, "SocialType", *s as usize),
        HumanExperience::Existential(x) => pick(&t.coords_by_type, "ExistentialType", *x as usize),
        HumanExperience::Physical(p) => pick(&t.coords_by_type, "PhysicalType", *p as usize),
        HumanExperience::Ethical(e) => pick(&t.coords_by_type, "EthicalType", *e as usize),
        HumanExperience::Creative(c) => pick(&t.coords_by_type, "CreativeType", *c as usize),
        HumanExperience::Spiritual(s) => pick(&t.coords_by_type, "SpiritualType", *s as usize),
        HumanExperience::Economic(e) => pick(&t.coords_by_type, "EconomicType", *e as usize),
        HumanExperience::Health(h) => pick(&t.coords_by_type, "HealthType", *h as usize),
    }
}

fn pick(map: &HashMap<&'static str, Vec<[f32; 8]>>, key: &'static str, idx: usize) -> [f32; 8] {
    map.get(key)
        .and_then(|v| v.get(idx))
        .copied()
        .unwrap_or([0.0; 8])
}

impl HexGraph {
    /// Build the graph from the canonical `.rune` asset.
    pub fn from_rune<P: AsRef<Path>>(path: P) -> Result<Self, HexError> {
        let _ = path; // path is currently advisory; we rely on the canonical asset.
        let t = tables();
        let axes = t.axes.clone();

        // Generate Type-I vertices (axis pairs with sign permutations).
        let mut coords = Vec::new();
        let mut kinds = Vec::new();
        let mut domains = Vec::new();
        let mut confidence = Vec::new();

        for a in 0..axes.len() {
            for b in (a + 1)..axes.len() {
                let (idx_a, w_a) = (axes[a].index as usize, axes[a].weight);
                let (idx_b, w_b) = (axes[b].index as usize, axes[b].weight);
                let signs = [(1.0, 1.0), (1.0, -1.0), (-1.0, 1.0), (-1.0, -1.0)];
                for (sa, sb) in signs {
                    let mut v = [0.0f32; 8];
                    v[idx_a] = sa * w_a;
                    v[idx_b] = sb * w_b;
                    normalize(&mut v);
                    coords.push(v);
                    kinds.push(RootKind::TypeI);
                    domains.push(None);
                    confidence.push(1.0);
                }
            }
        }

        // Type-II spinors (even parity).
        for mask in 0u16..256 {
            if mask.count_ones() % 2 != 0 {
                continue;
            }
            let mut v = [0.0f32; 8];
            for (i, axis) in axes.iter().enumerate() {
                let sign = if (mask & (1 << i)) != 0 { -0.5 } else { 0.5 };
                v[axis.index as usize] = sign * axis.weight;
            }
            normalize(&mut v);
            coords.push(v);
            kinds.push(RootKind::TypeII);
            domains.push(None);
            confidence.push(1.0);
        }

        // Build edges by inner product threshold 0.5.
        let n = coords.len();
        let mut row_offsets = Vec::with_capacity(n + 1);
        let mut adjacency = Vec::new();
        let mut weights = Vec::new();
        row_offsets.push(0);
        for i in 0..n {
            for j in (i + 1)..n {
                let dot: f32 = coords[i]
                    .iter()
                    .zip(coords[j].iter())
                    .map(|(a, b)| a * b)
                    .sum();
                if (dot - 0.5).abs() <= 1e-4 {
                    adjacency.push(j as u32);
                    weights.push(dot);
                }
            }
            row_offsets.push(adjacency.len() as u32);
        }

        Ok(Self {
            axes,
            coords,
            kinds,
            domains,
            confidence,
            edges: CsrGraph {
                row_offsets,
                adjacency,
                weights,
            },
        })
    }

    /// Borrow packed coordinates (AoS) for SIMD/GPU export.
    pub fn coords(&self) -> &[[f32; 8]] {
        &self.coords
    }

    /// Borrow CSR adjacency (row_offsets, adjacency, weights).
    pub fn csr(&self) -> (&[u32], &[u32], &[f32]) {
        (
            &self.edges.row_offsets,
            &self.edges.adjacency,
            &self.edges.weights,
        )
    }

    /// Find k-nearest vertices to given coordinates in semantic space.
    ///
    /// Returns vector of cloned Vertex structs sorted by distance.
    pub fn find_nearest_vertices(&self, coords: &[f32; 8], k: usize) -> Vec<Vertex> {
        let mut candidates: Vec<(usize, f32)> = self
            .coords
            .iter()
            .enumerate()
            .map(|(idx, vertex_coords)| (idx, l2(coords, vertex_coords)))
            .collect();

        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));

        candidates
            .into_iter()
            .take(k)
            .map(|(idx, _dist)| Vertex {
                id: idx as VertexId,
                kind: self.kinds[idx],
                coords: self.coords[idx],
                domain: self.domains[idx],
                confidence: self.confidence[idx],
            })
            .collect()
    }

    /// Calculate semantic confidence score for given coordinates.
    ///
    /// Confidence decreases as distance from nearest vertex increases.
    /// Returns value between 0.0 and 1.0.
    pub fn calculate_semantic_confidence(&self, coords: &[f32; 8]) -> f32 {
        let (_nearest_id, distance) = self.nearest_vertex(coords);
        // Confidence decreases as distance increases (inverse relationship)
        1.0 / (1.0 + distance)
    }

    /// Get all vertices belonging to a specific semantic domain.
    ///
    /// Note: Current implementation returns empty vec as domains are not yet
    /// populated in the graph construction. This is a placeholder for future
    /// domain assignment logic.
    pub fn vertices_by_domain(&self, target_domain: SemanticDomain) -> Vec<Vertex> {
        self.domains
            .iter()
            .enumerate()
            .filter_map(|(idx, domain_opt)| {
                domain_opt.and_then(|domain| {
                    if domain == target_domain {
                        Some(Vertex {
                            id: idx as VertexId,
                            kind: self.kinds[idx],
                            coords: self.coords[idx],
                            domain: Some(domain),
                            confidence: self.confidence[idx],
                        })
                    } else {
                        None
                    }
                })
            })
            .collect()
    }
}

fn normalize(v: &mut [f32; 8]) {
    let n2: f32 = v.iter().map(|x| x * x).sum();
    if n2 > 1e-9 {
        let inv = 1.0 / n2.sqrt();
        for x in v {
            *x *= inv;
        }
    }
}

pub trait SemanticSpace {
    fn nearest_vertex(&self, query: &[f32; 8]) -> (VertexId, f32);
    fn nearest_k(&self, query: &[f32; 8], k: usize) -> Vec<(VertexId, f32)>;
}

impl SemanticSpace for HexGraph {
    fn nearest_vertex(&self, query: &[f32; 8]) -> (VertexId, f32) {
        let mut best = (0u32, f32::MAX);
        for (i, v) in self.coords.iter().enumerate() {
            let d = l2(query, v);
            if d < best.1 {
                best = (i as u32, d);
            }
        }
        best
    }

    fn nearest_k(&self, query: &[f32; 8], k: usize) -> Vec<(VertexId, f32)> {
        let mut out = Vec::with_capacity(k);
        for (i, v) in self.coords.iter().enumerate() {
            let d = l2(query, v);
            if out.len() < k {
                out.push((i as u32, d));
                out.sort_by(|a, b| a.1.total_cmp(&b.1));
            } else if let Some(last) = out.last_mut() {
                if d < last.1 {
                    *last = (i as u32, d);
                    out.sort_by(|a, b| a.1.total_cmp(&b.1));
                }
            }
        }
        out
    }
}

#[inline(always)]
fn l2(a: &[f32; 8], b: &[f32; 8]) -> f32 {
    let mut sum = 0.0;
    sum += (a[0] - b[0]) * (a[0] - b[0]);
    sum += (a[1] - b[1]) * (a[1] - b[1]);
    sum += (a[2] - b[2]) * (a[2] - b[2]);
    sum += (a[3] - b[3]) * (a[3] - b[3]);
    sum += (a[4] - b[4]) * (a[4] - b[4]);
    sum += (a[5] - b[5]) * (a[5] - b[5]);
    sum += (a[6] - b[6]) * (a[6] - b[6]);
    sum += (a[7] - b[7]) * (a[7] - b[7]);
    sum
}

#[derive(Debug, Clone)]
pub struct SemanticTrajectory {
    pub vertices: Vec<VertexId>,
}

pub trait SemanticPathFinder {
    fn optimal_path(&self, start: VertexId, target: VertexId) -> SemanticTrajectory;
}

impl SemanticPathFinder for HexGraph {
    fn optimal_path(&self, start: VertexId, target: VertexId) -> SemanticTrajectory {
        // Simple Dijkstra on CSR.
        let n = self.coords.len();
        let mut dist = vec![f32::INFINITY; n];
        let mut prev = vec![None; n];
        let mut visited = vec![false; n];
        dist[start as usize] = 0.0;

        for _ in 0..n {
            // pick min unvisited
            let mut u = None;
            let mut best = f32::INFINITY;
            for i in 0..n {
                if !visited[i] && dist[i] < best {
                    best = dist[i];
                    u = Some(i);
                }
            }
            let u = match u {
                Some(x) => x,
                None => break,
            };
            visited[u] = true;
            if u as u32 == target {
                break;
            }
            let start_edge = self.edges.row_offsets[u] as usize;
            let end_edge = self.edges.row_offsets[u + 1] as usize;
            for idx in start_edge..end_edge {
                let v = self.edges.adjacency[idx] as usize;
                let w = self.edges.weights[idx];
                let alt = dist[u] + w;
                if alt < dist[v] {
                    dist[v] = alt;
                    prev[v] = Some(u);
                }
            }
        }

        let mut path = Vec::new();
        let mut cur = target as usize;
        if dist[cur].is_finite() {
            while let Some(p) = prev[cur] {
                path.push(cur as u32);
                cur = p;
            }
            path.push(start);
            path.reverse();
        }
        SemanticTrajectory { vertices: path }
    }
}

/// Simple gradient stepper: move in direction and snap to nearest vertex.
pub fn apply_semantic_gradient(
    graph: &HexGraph,
    start: VertexId,
    steps: usize,
    step_size: f32,
    direction: [f32; 8],
) -> SemanticTrajectory {
    let mut pos = graph.coords[start as usize];
    let mut traj = Vec::with_capacity(steps + 1);
    traj.push(start);
    for _ in 0..steps {
        for i in 0..8 {
            pos[i] += step_size * direction[i];
        }
        normalize(&mut pos);
        let (vid, _) = graph.nearest_vertex(&pos);
        traj.push(vid);
        pos = graph.coords[vid as usize];
    }
    SemanticTrajectory { vertices: traj }
}

/// Geometry diagnostics.
#[derive(Debug, Clone)]
pub struct GeometryReport {
    pub norms: Vec<f32>,
    pub min_pair: Option<((VertexId, VertexId), f32)>,
}

pub fn analyze_geometry(graph: &HexGraph) -> GeometryReport {
    let norms: Vec<f32> = graph
        .coords
        .iter()
        .map(|v| v.iter().map(|x| x * x).sum::<f32>().sqrt())
        .collect();
    let mut min_pair: Option<((VertexId, VertexId), f32)> = None;
    for i in 0..graph.coords.len() {
        for j in (i + 1)..graph.coords.len() {
            let d = l2(&graph.coords[i], &graph.coords[j]).sqrt();
            if let Some((_, best)) = &min_pair {
                if d < *best {
                    min_pair = Some(((i as u32, j as u32), d));
                }
            } else {
                min_pair = Some(((i as u32, j as u32), d));
            }
        }
    }
    GeometryReport { norms, min_pair }
}

/// Domain-specific proximity diagnostics drawn directly from the parsed tables.
#[derive(Debug, Clone)]
pub struct DomainReport {
    pub name: String,
    pub min_norm: f32,
    pub max_norm: f32,
    pub mean_norm: f32,
    pub closest_pair: Option<((usize, usize), f32)>,
}

pub fn analyze_domains() -> Vec<DomainReport> {
    let t = tables();
    let mut reports = Vec::new();
    for (name, vecs) in &t.coords_by_type {
        if vecs.is_empty() {
            continue;
        }
        let norms: Vec<f32> = vecs
            .iter()
            .map(|v| v.iter().map(|x| x * x).sum::<f32>().sqrt())
            .collect();
        let min_norm = norms.iter().cloned().fold(f32::INFINITY, f32::min);
        let max_norm = norms.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
        let mean_norm = norms.iter().sum::<f32>() / norms.len() as f32;
        let mut closest: Option<((usize, usize), f32)> = None;
        for i in 0..vecs.len() {
            for j in (i + 1)..vecs.len() {
                let d = l2(&vecs[i], &vecs[j]).sqrt();
                match closest {
                    Some((_, best)) if d >= best => {}
                    _ => closest = Some(((i, j), d)),
                }
            }
        }
        reports.push(DomainReport {
            name: (*name).to_string(),
            min_norm,
            max_norm,
            mean_norm,
            closest_pair: closest,
        });
    }
    reports
}

/// Reference CPU DomR computation: score[x] = Σ_o e[o] * dot(root_o, root_x), top N.
/// GeoCel trajectory generation implementation.
/// Provides dynamic navigation through the E8 semantic lattice using
/// momentum dynamics and stochastic processes.
pub mod geocel {
    use super::*;

    /// Primary GeoCel trajectory generator using intent and anima-driven navigation.
    pub fn spawn_surveyor_worm(
        intent: &str,
        frame: GSLFrame,
        anima: f32,
        graph: &HexGraph,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        // Create semantic address from intent (stub implementation)
        let address = WeylSemanticAddress::from_text_intent(intent, anima)?;

        // Apply momentum dynamics
        let evolution = apply_momentum_dynamics(&address, anima)?;

        // Quantize to E8 roots based on frame constraints
        let quantized = quantize_to_e8_roots(&evolution, frame, graph)?;

        // Generate final trajectory
        generate_trajectory(&quantized, graph)
    }

    impl WeylSemanticAddress {
        /// Create semantic address from text intent using basic keyword mapping.
        pub fn from_text_intent(intent: &str, _anima: f32) -> Result<Self, HexError> {
            let timestamp = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs_f64();

            // Basic intent parsing - map keywords to semantic heads
            let mut heads = Vec::new();
            let context = intent.to_string();

            // Extract key emotional concepts and map to coordinates
            if intent.contains("fear") {
                heads.push([-0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -0.5]); // Fear coordinates
            }
            if intent.contains("courage") {
                heads.push([1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5]); // Confidence coordinates
            }
            if intent.contains("love") {
                heads.push([1.0, 0.0, 0.5, 0.5, 0.5, 0.0, 1.0, 0.0]); // Love coordinates
            }

            if heads.is_empty() {
                // Default semantic head if no keywords found
                heads.push([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]);
            }

            Ok(WeylSemanticAddress {
                heads,
                tails: vec![], // Empty tails for initial address
                timestamp,
                context,
            })
        }

        /// Apply momentum dynamics to semantic address.
        pub fn apply_momentum_dynamics(&self, anima: f32) -> Result<Vec<[f32; 8]>, HexError> {
            let mut evolution = Vec::new();

            for head in &self.heads {
                let mut current = *head;
                evolution.push(current);

                // Apply momentum steps with noise injection
                for _ in 0..10 {
                    current = momentum_step(&current, anima);
                    current = noise_injection(&current, anima);
                    current = quantize_to_valid_root(&current);
                    evolution.push(current);
                }
            }

            Ok(evolution)
        }
    }

    /// Apply momentum step: accelerate in current direction with small random perturbation.
    pub fn momentum_step(vec: &[f32; 8], anima: f32) -> [f32; 8] {
        let mut normalized = *vec;
        normalize(&mut normalized);

        let mut result = *vec;
        for i in 0..8 {
            result[i] += anima * normalized[i] + 0.1 * random_unit_vector()[i];
        }
        normalize(&mut result);
        result
    }

    /// Add controlled noise to vector.
    pub fn noise_injection(vec: &[f32; 8], anima: f32) -> [f32; 8] {
        let mut result = *vec;
        let noise = gaussian_noise();
        for i in 0..8 {
            result[i] += anima * 0.3 * noise;
        }
        result
    }

    /// Quantize vector to nearest valid E8 root.
    pub fn quantize_to_valid_root(vec: &[f32; 8]) -> [f32; 8] {
        // Find nearest E8 root (simplified - would use graph lookup in full implementation)
        let default_graph = default_graph();
        let (nearest_idx, _) = default_graph.nearest_vertex(vec);
        default_graph.coords[nearest_idx as usize]
    }

    /// Apply momentum dynamics with specified anima (high-level interface).
    pub fn apply_momentum_dynamics(
        addr: &WeylSemanticAddress,
        anima: f32,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        addr.apply_momentum_dynamics(anima)
    }

    /// Quantize trajectory points to E8 roots with frame constraints.
    pub fn quantize_to_e8_roots(
        evolution: &[[f32; 8]],
        _frame: GSLFrame,
        graph: &HexGraph,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        let mut quantized = Vec::new();

        for point in evolution {
            let (nearest_idx, _) = graph.nearest_vertex(point);
            quantized.push(graph.coords[nearest_idx as usize]);
        }

        Ok(quantized)
    }

    /// Generate final smooth trajectory from quantized points.
    pub fn generate_trajectory(
        evolution: &[[f32; 8]],
        _graph: &HexGraph,
    ) -> Result<Vec<[f32; 8]>, HexError> {
        let mut trajectory = Vec::new();
        trajectory.extend_from_slice(evolution);
        Ok(trajectory)
    }

    /// Generate random unit vector for perturbations.
    fn random_unit_vector() -> [f32; 8] {
        use std::f32::consts::PI;
        let mut vec = [0.0f32; 8];
        for i in 0..8 {
            vec[i] = (i as f32 * PI / 4.0).sin() * 0.1; // Deterministic pseudo-random
        }
        normalize(&mut vec);
        vec
    }

    /// Generate gaussian noise (simplified).
    fn gaussian_noise() -> f32 {
        // Simplified gaussian using Box-Muller transform approximation
        (std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_nanos() as f32
            * 0.000_000_000_1)
            .sin()
    }
}

pub fn domr_cpu(graph: &HexGraph, energy: &[f32], n_dr: usize) -> Result<DomR, HexError> {
    if energy.len() != graph.coords.len() {
        return Err(HexError::TypeMismatch(format!(
            "Energy length {} must match root count {}",
            energy.len(),
            graph.coords.len()
        )));
    }
    if n_dr == 0 || n_dr > graph.coords.len() {
        return Err(HexError::InvalidOperation(
            "N_DR must be between 1 and root count".into(),
        ));
    }
    let mut scores = vec![0.0f32; graph.coords.len()];
    for (x_idx, x) in graph.coords.iter().enumerate() {
        let mut acc = 0.0f32;
        for (o_idx, e) in energy.iter().enumerate() {
            let dot: f32 = graph.coords[o_idx]
                .iter()
                .zip(x.iter())
                .map(|(a, b)| a * b)
                .sum();
            acc += *e * dot;
        }
        scores[x_idx] = acc;
    }
    let mut pairs: Vec<(usize, f32)> = scores.iter().copied().enumerate().collect();
    pairs.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
    let take = n_dr.min(pairs.len());
    let mut roots = Vec::with_capacity(take);
    let mut out_scores = Vec::with_capacity(take);
    for (idx, score) in pairs.into_iter().take(take) {
        roots.push(idx as u8);
        out_scores.push(score);
    }
    Ok(DomR {
        roots,
        scores: out_scores,
    })
}

File: src\rune\.runeFiles\rune.txt
==================================
File: grammar.pest
==================
WHITESPACE = _{ " " | "\t" }
NEWLINE = _{ "\r\n" | "\n" }

COMMENT = _{ "#" ~ (!NEWLINE ~ ANY)* }

// --- LEXICAL PRIMITIVES ---
ident = @{ (ASCII_ALPHA | "_") ~ (ASCII_ALPHANUMERIC | "_" )* }

// Semantic prefix: single uppercase letter followed by colon (A:, T:, V:, R:, etc.)
semantic_prefix = @{ ASCII_ALPHA_UPPER ~ ":" }

// Semantic identifier: prefix + name (e.g., T:Gf8, V:vector, R:continuum)
semantic_ident = { semantic_prefix ~ ident }

number = @{
    "-"? ~ ASCII_DIGIT+ ~ ("." ~ ASCII_DIGIT+)?   // simple int/float
}

string = @{
    "\"" ~ string_inner ~ "\""
}

string_inner = @{
    (
        !("\"" | "\\") ~ ANY
        | "\\" ~ ("\"" | "\\" | "/" | "b" | "f" | "n" | "r" | "t")
    )*
}

// Boolean literals: B:t (true) or B:f (false)
boolean_literal = { "B:" ~ ("t" | "f") }

// --- OPERATORS (matched in order of length) ---

// 1. Glyph operators (must be ordered longest-first, now included in relation_op for chaining)
// Note: glyph_op removed from grammar, integrated into relation_op for better parsing of chains

// 2. Flow operators (lower precedence - flow between things)
flow_op = {
      "<->"    // FlowBidirectional
    | ">-<"    // FlowConvergent
    | "->"     // FlowRight
    | "<-"     // FlowLeft
}

// 3. Structural / binding operators (higher precedence - create associations)
struct_op = {
      "\\|/"   // SymmetricSplit
    | "/|\\"   // BranchAnchorBranch
    | "/\\"    // SplitJoin
    | "\\/"    // JoinSplit
    | "|/"     // AnchorDescend
    | "/|"     // BranchStabilize
    | "\\|"    // RootStabilize
    | "|\\"    // StabilizeRoot
    | "::"     // Namespace
    | ":="     // Define
    | ":>"     // Output
    | "<:"     // Input
    | "|>"     // PipelineRight
    | "<|"     // PipelineLeft
    | "<="     // LessEqual
    | ">="     // GreaterEqual
    | "||"     // Parallel
    | ":"      // Bind
    | "="      // Equal
    | "<"      // Less
    | ">"      // Greater
    | "\\"     // Ancestor
    | "|"      // Alias
    | "~"      // Transform
}

// All relation operators combined (for fallback parsing)
relation_op = { flow_op | struct_op }

// Path operators used for hierarchical access (distinct from math)
path_op = { "/" | "\\" }

// Unified operator token (arithmetic operators only within math blocks `[]`)
op = { relation_op }

// --- EXPRESSIONS ---
// Domains: Structural (outside []) vs Arithmetic (inside [])

// Function call: name(arg1, arg2, ...)
fn_call = { ident ~ "(" ~ relation_expr ~ ("," ~ relation_expr)* ~ ")" }

// Array literal: [1,2,3] or [a,b,c] (comma-separated)
// Distinct from math blocks which use operators without commas
array_literal = { "[" ~ relation_expr ~ ("," ~ relation_expr)+ ~ "]" }

term = {
      string
    | number
    | boolean_literal // Boolean literals: B:t, B:f
    | math_block      // Try math block first (has operators/unary)
    | fn_call         // Try function call (has parens)
    | array_literal   // Then try array (has commas)
    | semantic_ident
    | ident
    | "(" ~ relation_expr ~ ")"
}

// Arithmetic within [ ... ] value blocks ---
// Math precedence: PEMDAS (Parentheses, Exponents, Multiply/Divide, Add/Subtract)
math_block  = { "[" ~ math_expr ~ "]" }

math_expr   = { math_add }

math_add    = { math_mul ~ (WHITESPACE* ~ math_add_op ~ WHITESPACE* ~ math_mul)* }
math_add_op = { "+" | "-" }

math_mul    = { math_exp ~ (WHITESPACE* ~ math_mul_op ~ WHITESPACE* ~ math_exp)* }
math_mul_op = { "*" | "/" | "%" }

math_exp    = { math_unary ~ (WHITESPACE* ~ math_exp_op ~ WHITESPACE* ~ math_unary)* }
math_exp_op = { "^" | "√" | "R" }

math_unary  = { math_unary_op? ~ math_atom }
math_unary_op = { "-" | "+" }

// Math atom now supports arrays and semantic identifiers inside math blocks
math_array_literal = { "[" ~ math_expr ~ ("," ~ math_expr)+ ~ "]" }
math_atom   = { number | semantic_ident | math_array_literal | ident | "(" ~ math_expr ~ ")" }

// Structural expressions ---
// Precedence layers: flow_expr < struct_expr < access < term
// Lower precedence (parsed first) = looser binding

// Access (hierarchical navigation - using binary operators below)
access = { term ~ (WHITESPACE* ~ path_op ~ WHITESPACE* ~ term)* }

// Structural operators (tighter binding - associations, definitions)
struct_expr = { access ~ (WHITESPACE* ~ struct_op ~ WHITESPACE* ~ access)* }

// Flow operators (looser binding - data flow between structures)
flow_expr = { struct_expr ~ (WHITESPACE* ~ flow_op ~ WHITESPACE* ~ struct_expr)* }

// Relations: top-level expression (kept for backward compatibility)
relation_expr = { flow_expr }

// Expression: structural operations only (no arithmetic)
expr = { relation_expr }

// --- STATEMENTS ---

// Root declaration (supports namespaces like e8::continuum)
root_decl = { "root:" ~ WHITESPACE* ~ ident ~ ("::" ~ ident)* }

// TOON block (indentation-based)
// Use $ to disable implicit whitespace, @ for atomic capture
toon_content = @{
    (
        // Match any line that isn't empty and doesn't start a new top-level statement
        (!NEWLINE ~ ANY)+ ~ NEWLINE
    )+
}

toon_block = ${
    ident ~ " "* ~ "~TOON:" ~ NEWLINE ~
    toon_content
}

// Kernel archetype declarations
kernel_param = { ident ~ ":" ~ WHITESPACE* ~ (number | ident | string) }
kernel_archetype = { "CUDA:Archetype:" ~ ident ~ "(" ~ (kernel_param ~ ("," ~ WHITESPACE* ~ kernel_param)*)? ~ ")" }
kernel_decl = { semantic_ident ~ WHITESPACE* ~ ":=" ~ WHITESPACE* ~ kernel_archetype }

// Expression statement (catch-all for operator expressions)
stmt_expr = { relation_expr }

// Top-level statement
stmt = _{ root_decl | toon_block | kernel_decl | stmt_expr }

// File: sequence of statements
// Note: No WHITESPACE* before stmt to preserve TOON block indentation
file = { SOI ~ (NEWLINE* ~ stmt ~ WHITESPACE* ~ NEWLINE*)* ~ EOI }

File: mod.rs
============
/* src/rune/hydron/mod.rs */
//! RUNE (Root-Unified Notation Encoding) is a semantic extension built on top of TOON.
//! Where TOON provides token-efficient data serialization, RUNE adds:
//!
//! - **Root-oriented semantics**: Everything revolves around hierarchical roots
//! - **Operator calculus**: Glyphs and tokens for describing relationships, flow, and structure
//! - **E8-awareness**: Geometric and identity-aware operators
//! - **Composability**: Mix RUNE semantics with TOON data blocks seamlessly
//!
//! ## Overview
//!
//! RUNE files can contain:
//! - **TOON blocks**: Raw TOON data (preserved verbatim)
//! - **RUNE operators**: Relations, constraints, transformations over TOON data
//! - **Root declarations**: Anchor points in your E8 ecosystem
//!
//! ## Example RUNE File
//! ```rune
//! root: continuum
//!
//! data ~TOON:
//!   users[3]{id,name,role}:
//!     1,Ada,admin
//!     2,Bob,user
//!     3,Eve,viewer
//!
//! # RUNE semantics over TOON data
//! users / 0 -> role := admin
//! users / * -> name ~ ValidString()
//! ```
//!
//! This crate leverages the TOON format as foundational data representation
//! while adding symbolic operator layers for E8 ecosystems.
//!
//! TOKEN_FORMAT is Copyright (c) 2025-PRESENT Shreyas S Bhat, Johann Schopplich
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

mod ast;
mod ops;
mod parser;
pub mod parts;

#[cfg(feature = "hydron")]
pub mod hydron;

pub use ast::*;
pub use ops::*;
pub use parser::*;

// Re-export common types for convenience
pub type RuneParser = parser::ParseError;

/// Parse a RUNE source string into a list of statements.
pub fn parse_rune(input: &str) -> Result<Vec<Stmt>, ParseError> {
    parser::parse(input)
}

/// Encode TOON data blocks within RUNE files as raw strings.
pub fn encode_rune(statements: &[Stmt]) -> String {
    let mut output = String::new();
    for stmt in statements {
        output.push_str(&format!("{}\n", stmt));
    }
    output
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_basic_toon_block() {
        let input = r#"
root: test_root

data ~TOON:
  items[2]{id,name}:
    1,hello
    2,world
"#;
        let stmts = parse_rune(input).unwrap();
        assert_eq!(stmts.len(), 2);
        // First statement is root declaration
        if let Stmt::RootDecl(root) = &stmts[0] {
            assert_eq!(root.0.as_str(), "test_root");
        } else {
            panic!("Expected root declaration");
        }
        // Second is TOON block
        if let Stmt::ToonBlock { name, content } = &stmts[1] {
            assert_eq!(name.0.as_str(), "data");
            assert!(content.contains("items[2]"));
        } else {
            panic!("Expected TOON block");
        }
    }

    #[test]
    fn test_operator_expression() {
        let input = r#"
items / 0 -> name := hello
"#;
        let stmts = parse_rune(input).unwrap();
        assert_eq!(stmts.len(), 1);
        if let Stmt::Expr(expr) = &stmts[0] {
            // Check it's a binary expression with -> operator (lower precedence)
            // Parses as: items / 0 -> (name := hello)
            if let Expr::Binary { op, left, right } = expr {
                assert_eq!(*op, RuneOp::FlowRight);
                assert_eq!(format!("{}", left), "items / 0");
                assert_eq!(format!("{}", right), "name := hello");
            } else {
                panic!("Expected binary expression");
            }
        }
    }
}

File: parser.rs
===============
/* src/rune/parser.rs */
//!
//! # e8 Notation – RUNE Parser
//!▫~•◦-------------------------‣
//!
//! This module provides parsing functionality for RUNE source code,
//! converting text into `Stmt` structures with proper operator precedence.
//! It uses Pest for lexical analysis and implements expression parsing
//! driven by the grammar’s precedence layering.
//!
//! The parser handles:
//! - **Operator precedence** via grammar layers:
//!   - `mul`   → `*` level
//!   - `add_sub` → `+` / `-`
//!   - `access` / `relation_expr` / `expr` → structural / relation ops
//! - **TOON blocks**: Raw content preservation for later TOON library parsing
//! - **Root declarations**: Semantic anchors for E8 contexts
//! - **Expression trees**: Recursive binary structures respecting precedence
//!
//! ### Implementation Details
//! - Uses grammar-encoded precedence (`term (op term)*` per layer).
//! - Preserves TOON blocks as raw strings without internal parsing.
//! - Validates all operators against the closed `RuneOp` registry.
//!
//! ### Error Handling
//! Parser errors include:
//! - Invalid operators (not in registry)
//! - Mismatched parentheses
//! - Malformed TOON blocks
//! - Unexpected tokens
//!
//! ### Example
//! ```rust
//! use rune_format::rune::parse_rune;
//!
//! let input = r#"
//! root: continuum
//! data ~TOON:
//!   users[2]{id,name}:
//!     1,Ada
//!     2,Bob
//! users / 1 := Bob
//! "#;
//!
//! let stmts = parse_rune(input).unwrap();
//! // stmts contains RootDecl, ToonBlock, and ExprStmt
//! ```
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use pest::Parser;
use pest::iterators::Pair;
use pest_derive::Parser;
use std::str::FromStr;
use thiserror::Error;

use crate::rune::ast::*;
use crate::rune::ops::*;

// Pest grammar reference
#[derive(Parser)]
#[grammar = "rune/grammar.pest"]
pub struct RuneParser;

/// Root error type for parsing RUNE source code.
#[derive(Debug, Error)]
pub enum ParseError {
    #[error("Pest parse error: {0}")]
    Pest(Box<pest::error::Error<Rule>>),
    #[error("Invalid operator '{0}' not in registry")]
    InvalidOperator(String),
    #[error("Expected identifier, found: {0}")]
    ExpectedIdent(String),
    #[error("Expected number, found: {0}")]
    ExpectedNumber(String),
    #[error("Parse tree error: {0}")]
    ParseTree(String),
}

/// Parse RUNE source code into a list of statements.
pub fn parse(input: &str) -> Result<Vec<Stmt>, ParseError> {
    let pairs = RuneParser::parse(Rule::file, input).map_err(|e| ParseError::Pest(Box::new(e)))?;
    let mut stmts = Vec::new();

    for pair in pairs {
        if pair.as_rule() == Rule::file {
            for inner_pair in pair.into_inner() {
                match inner_pair.as_rule() {
                    Rule::WHITESPACE | Rule::COMMENT => {} // skip
                    Rule::stmt => {
                        if let Some(stmt_pair) = inner_pair.into_inner().next() {
                            stmts.push(parse_stmt(stmt_pair)?);
                        }
                    }
                    Rule::root_decl | Rule::toon_block | Rule::stmt_expr => {
                        stmts.push(parse_stmt(inner_pair)?);
                    }
                    _ => {}
                }
            }
        }
    }

    Ok(stmts)
}

/// Parse and return typed statements using a shallow type inference pass.
pub fn parse_typed(input: &str) -> Result<Vec<crate::rune::ast::StmtTyped>, ParseError> {
    let stmts = parse(input)?;
    let mut typed: Vec<crate::rune::ast::StmtTyped> = Vec::new();
    for stmt in stmts {
        match stmt {
            crate::rune::ast::Stmt::RootDecl(id) => {
                typed.push(crate::rune::ast::StmtTyped::root(id.to_string()))
            }
            crate::rune::ast::Stmt::ToonBlock { name, content } => typed.push(
                crate::rune::ast::StmtTyped::toon_block(name.to_string(), content),
            ),
            crate::rune::ast::Stmt::KernelDecl { name, archetype } => {
                typed.push(crate::rune::ast::StmtTyped::KernelDecl {
                    name: name.clone(),
                    archetype: archetype.clone(),
                });
            }
            crate::rune::ast::Stmt::Expr(expr) => {
                let te = crate::rune::ast::TypedExpr::infer(&expr);
                typed.push(crate::rune::ast::StmtTyped::expr(te));
            }
        }
    }
    Ok(typed)
}

/// Parse a statement pair into a Stmt.
fn parse_stmt(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let rule = pair.as_rule();
    match rule {
        Rule::root_decl => parse_root_decl(pair),
        Rule::toon_block => parse_toon_block(pair),
        Rule::kernel_decl => parse_kernel_decl(pair),
        Rule::stmt_expr => {
            let expr_pair = pair.into_inner().next().unwrap();
            Ok(Stmt::expr(parse_expr(expr_pair)?))
        }
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected statement rule: {:?}",
            rule
        ))),
    }
}

/// Parse root declaration: `root: name` or `root: e8::continuum`
fn parse_root_decl(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let inner = pair.into_inner();

    let mut segments = Vec::new();

    // Collect all identifier segments (with :: separators)
    for pair in inner {
        if pair.as_rule() == Rule::ident {
            segments.push(pair.as_str());
        }
    }

    if segments.is_empty() {
        return Err(ParseError::ParseTree(
            "root declaration missing identifier".to_string(),
        ));
    }

    // Join segments with :: to create the full name
    let name = segments.join("::");
    Ok(Stmt::root(&name))
}

/// Parse TOON block: `name ~TOON:\n  content\n  content`
fn parse_toon_block(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let mut inner = pair.into_inner();
    let ident_pair = inner.next().unwrap();
    let name = ident_pair.as_str();

    // The next pair is toon_content (atomic capture of all lines)
    let content_pair = inner.next().unwrap();
    let content = content_pair.as_str();

    // Split into lines and dedent (remove common leading whitespace)
    let lines: Vec<&str> = content.lines().collect();

    if lines.is_empty() {
        return Ok(Stmt::toon_block(name, String::new()));
    }

    // Find minimum indentation (excluding empty lines)
    let min_indent = lines
        .iter()
        .filter(|line| !line.trim().is_empty())
        .map(|line| line.len() - line.trim_start().len())
        .min()
        .unwrap_or(0);

    // Remove the common indentation from all lines
    let dedented: Vec<String> = lines
        .iter()
        .map(|line| {
            if line.trim().is_empty() {
                String::new()
            } else {
                line[min_indent..].to_string()
            }
        })
        .collect();

    let final_content = dedented.join("\n");

    Ok(Stmt::toon_block(name, final_content))
}

/// Parse kernel parameter: ident : (number | ident | string)
fn parse_kernel_param(pair: Pair<Rule>) -> Result<(Ident, Literal), ParseError> {
    let mut inner = pair.into_inner();
    let name_pair = inner.next().unwrap();
    let name = Ident::new(name_pair.as_str());

    inner.next(); // :
    inner.next(); // WHITESPACE*

    let value_pair = inner.next().unwrap();
    let value = match value_pair.as_rule() {
        Rule::number => {
            let num = value_pair
                .as_str()
                .parse()
                .map_err(|_| ParseError::ExpectedNumber(value_pair.as_str().to_string()))?;
            Literal::Number(num)
        }
        Rule::string => {
            let raw = value_pair.as_str();
            let content = &raw[1..raw.len() - 1];
            let unescaped = content
                .replace("\\\"", "\"")
                .replace("\\\\", "\\")
                .replace("\\n", "\n")
                .replace("\\r", "\r")
                .replace("\\t", "\t");
            Literal::String(unescaped)
        }
        Rule::ident => Literal::String(value_pair.as_str().to_string()),
        _ => {
            return Err(ParseError::ParseTree(format!(
                "Unexpected value type in kernel param: {:?}",
                value_pair.as_rule()
            )));
        }
    };

    Ok((name, value))
}

/// Parse kernel archetype: CUDA:Archetype:ident(params...)
fn parse_kernel_archetype(pair: Pair<Rule>) -> Result<KernelArchetype, ParseError> {
    let mut inner = pair.into_inner();
    inner.next(); // "CUDA:Archetype:"
    let name_pair = inner.next().unwrap();
    let name = Ident::new(name_pair.as_str());
    inner.next(); // "("

    let mut params = Vec::new();
    while let Some(pair) = inner.next() {
        if pair.as_rule() == Rule::kernel_param {
            params.push(parse_kernel_param(pair)?);
            // Next should be , or )
            let next = inner.next();
            if let Some(sep) = next {
                if sep.as_str() == "," {
                    // Skip WHITESPACE*
                    let ws = inner.next();
                    if let Some(ws_pair) = ws {
                        if ws_pair.as_rule() != Rule::WHITESPACE {
                            return Err(ParseError::ParseTree(
                                "Expected whitespace after comma".to_string(),
                            ));
                        }
                    }
                } else if sep.as_str() == ")" {
                    break;
                } else {
                    return Err(ParseError::ParseTree(format!(
                        "Expected , or ), got {}",
                        sep.as_str()
                    )));
                }
            }
        } else if pair.as_str() == ")" {
            break;
        } else {
            return Err(ParseError::ParseTree(format!(
                "Unexpected in kernel archetype: {:?}",
                pair.as_rule()
            )));
        }
    }

    Ok(KernelArchetype { name, params })
}

/// Parse kernel declaration: semantic_ident := kernel_archetype
fn parse_kernel_decl(pair: Pair<Rule>) -> Result<Stmt, ParseError> {
    let mut inner = pair.into_inner();
    let semantic_ident_pair = inner.next().unwrap();
    let semantic_ident = {
        let mut si_inner = semantic_ident_pair.into_inner();
        let prefix_pair = si_inner.next().unwrap();
        let name_pair = si_inner.next().unwrap();
        let prefix = prefix_pair.as_str().chars().next().unwrap();
        let name = Ident::new(name_pair.as_str());
        SemanticIdent::new(prefix, name)
    };

    inner.next(); // :=
    inner.next(); // WHITESPACE*
    let kernel_archetype_pair = inner.next().unwrap();
    let archetype = parse_kernel_archetype(kernel_archetype_pair)?;

    Ok(Stmt::KernelDecl {
        name: semantic_ident,
        archetype,
    })
}

/// Parse expression using grammar-driven precedence.
///
/// We rely on the Pest grammar to encode precedence via nested rules:
/// - `flow_expr` wraps `struct_expr` (lower precedence)
/// - `struct_expr` wraps `access` (higher precedence)
/// - `access` wraps `term`
///
/// Each non-terminal is parsed as:
///   sub_expr (op sub_expr)*
fn parse_expr(pair: Pair<Rule>) -> Result<Expr, ParseError> {
    match pair.as_rule() {
        // Expression layers for structural operators
        Rule::relation_expr | Rule::flow_expr | Rule::struct_expr | Rule::access => {
            let mut inner = pair.into_inner();

            // First element is always a sub-expression or term.
            let first = inner
                .next()
                .ok_or_else(|| ParseError::ParseTree("Empty expression".to_string()))?;

            let mut left = match first.as_rule() {
                Rule::relation_expr | Rule::flow_expr | Rule::struct_expr | Rule::access => {
                    parse_expr(first)?
                }
                Rule::term => parse_term(first)?,
                _ => parse_term(first)?,
            };

            // Then we expect zero or more (op, rhs) pairs.
            while let Some(op_pair) = inner.next() {
                // Determine what kind of pair this is
                let (op, right) = match op_pair.as_rule() {
                    // If it's one of the named operator rules, parse it
                    Rule::relation_op | Rule::flow_op | Rule::struct_op | Rule::path_op => {
                        let op = parse_operator(op_pair)?;
                        let rhs_pair = inner.next().ok_or_else(|| {
                            ParseError::ParseTree("Missing right operand".to_string())
                        })?;
                        let right = match rhs_pair.as_rule() {
                            Rule::relation_expr
                            | Rule::flow_expr
                            | Rule::struct_expr
                            | Rule::access => parse_expr(rhs_pair)?,
                            Rule::term => parse_term(rhs_pair)?,
                            _ => parse_term(rhs_pair)?,
                        };
                        (op, right)
                    }
                    // If it's another expression layer, something is wrong
                    Rule::access | Rule::struct_expr | Rule::flow_expr | Rule::relation_expr => {
                        return Err(ParseError::ParseTree(format!(
                            "Unexpected expression node where operator expected: {:?}",
                            op_pair.as_rule()
                        )));
                    }
                    _ => {
                        // Fallback: treat as operator by text
                        let op = parse_operator(op_pair)?;
                        let rhs_pair = inner.next().ok_or_else(|| {
                            ParseError::ParseTree("Missing right operand".to_string())
                        })?;
                        let right = match rhs_pair.as_rule() {
                            Rule::relation_expr
                            | Rule::flow_expr
                            | Rule::struct_expr
                            | Rule::access => parse_expr(rhs_pair)?,
                            Rule::term => parse_term(rhs_pair)?,
                            _ => parse_term(rhs_pair)?,
                        };
                        (op, right)
                    }
                };

                left = Expr::binary(left, op, right);
            }

            Ok(left)
        }
        // Direct term -> literal / ident / grouped expr
        Rule::term => parse_term(pair),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected expression rule: {:?}",
            pair.as_rule()
        ))),
    }
}

/// Parse a term: identifier, number, string, array, grouped expression, or math block.
fn parse_term(pair: Pair<Rule>) -> Result<Expr, ParseError> {
    match pair.as_rule() {
        Rule::term => {
            // Term is a composite rule, get its inner content
            let inner = pair
                .into_inner()
                .next()
                .ok_or_else(|| ParseError::ParseTree("Empty term".to_string()))?;
            parse_term(inner) // Recursively parse the inner rule
        }
        Rule::array_literal => {
            // Parse array literal: [expr, expr, ...]
            let inner = pair.into_inner();
            let mut elements = Vec::new();

            for expr_pair in inner {
                elements.push(parse_expr(expr_pair)?);
            }

            Ok(Expr::Term(Term::Literal(Literal::Array(elements))))
        }
        Rule::semantic_ident => {
            // Parse semantic identifier: prefix:name
            let mut inner = pair.into_inner();
            let prefix_pair = inner.next().unwrap();
            let name_pair = inner.next().unwrap();

            // Extract prefix character (first char before the colon)
            let prefix_str = prefix_pair.as_str();
            let prefix = prefix_str.chars().next().unwrap();

            let name = name_pair.as_str();
            Ok(Expr::Term(Term::semantic_ident(prefix, name)))
        }
        Rule::ident => Ok(Expr::ident(pair.as_str())),
        Rule::fn_call => {
            // Parse function call: name(arg1, arg2, ...)
            let mut inner = pair.into_inner();
            let name_pair = inner
                .next()
                .ok_or_else(|| ParseError::ParseTree("Missing function name".to_string()))?;
            let name = Ident::new(name_pair.as_str());

            let mut args = Vec::new();
            for expr_pair in inner {
                args.push(parse_expr(expr_pair)?);
            }

            Ok(Expr::Term(Term::FunctionCall { name, args }))
        }
        Rule::number => {
            let num: f64 = pair
                .as_str()
                .parse()
                .map_err(|_| ParseError::ExpectedNumber(pair.as_str().to_string()))?;
            Ok(Expr::literal(num))
        }
        Rule::boolean_literal => {
            // Parse boolean literal: B:t (true) or B:f (false)
            let text = pair.as_str();
            match text {
                "B:t" => Ok(Expr::Term(Term::Literal(Literal::bool(true)))),
                "B:f" => Ok(Expr::Term(Term::Literal(Literal::bool(false)))),
                _ => Err(ParseError::ParseTree(format!(
                    "Invalid boolean literal: {}",
                    text
                ))),
            }
        }
        Rule::string => {
            // Parse string, handling escape sequences
            let raw = pair.as_str();
            // Remove surrounding quotes
            let content = &raw[1..raw.len() - 1];
            // Unescape common sequences
            let unescaped = content
                .replace("\\\"", "\"")
                .replace("\\\\", "\\")
                .replace("\\n", "\n")
                .replace("\\r", "\r")
                .replace("\\t", "\t");
            Ok(Expr::Term(Term::Literal(Literal::String(unescaped))))
        }
        Rule::relation_expr | Rule::flow_expr | Rule::struct_expr | Rule::access => {
            // These are expression nodes that can appear as terms (e.g., in parentheses)
            parse_expr(pair)
        }
        Rule::math_block => {
            // Math blocks are at the term level, parse content as math expression
            let math_expr = parse_math_expr(pair)?;
            Ok(Expr::Term(Term::Math(Box::new(math_expr))))
        }
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected term rule: {:?}",
            pair.as_rule()
        ))),
    }
}

/// Parse math expression from a math block `[...]`.
/// Handles arithmetic operators with proper precedence.
fn parse_math_expr(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    // The pair is a math_block, we need the inner math_expr
    let math_expr_pair = pair
        .into_inner()
        .next()
        .ok_or_else(|| ParseError::ParseTree("Empty math block".to_string()))?;

    parse_math_expr_inner(math_expr_pair)
}

/// Internal math expression parser.
fn parse_math_expr_inner(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    match pair.as_rule() {
        Rule::math_expr | Rule::math_add | Rule::math_mul | Rule::math_exp => {
            let mut inner = pair.into_inner();

            let first = inner
                .next()
                .ok_or_else(|| ParseError::ParseTree("Empty math expression".to_string()))?;

            let mut left = match first.as_rule() {
                Rule::math_expr | Rule::math_add | Rule::math_mul | Rule::math_exp => {
                    parse_math_expr_inner(first)?
                }
                Rule::math_unary => parse_math_unary(first)?,
                Rule::math_atom => parse_math_atom(first)?,
                _ => parse_math_expr_inner(first)?,
            };

            while let Some(op_pair) = inner.next() {
                let op = parse_math_operator(op_pair)?;

                let rhs_pair = inner.next().ok_or_else(|| {
                    ParseError::ParseTree("Missing right operand in math".to_string())
                })?;

                let right = match rhs_pair.as_rule() {
                    Rule::math_expr | Rule::math_add | Rule::math_mul | Rule::math_exp => {
                        parse_math_expr_inner(rhs_pair)?
                    }
                    Rule::math_unary => parse_math_unary(rhs_pair)?,
                    Rule::math_atom => parse_math_atom(rhs_pair)?,
                    _ => parse_math_atom(rhs_pair)?,
                };

                left = MathExpr::binary(left, op, right);
            }

            Ok(left)
        }
        Rule::math_unary => parse_math_unary(pair),
        Rule::math_atom => parse_math_atom(pair),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected math expression rule: {:?}",
            pair.as_rule()
        ))),
    }
}

/// Parse a math atom: number, identifier, or grouped expression.
fn parse_math_atom(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    let inner = pair
        .into_inner()
        .next()
        .ok_or_else(|| ParseError::ParseTree("Empty math atom".to_string()))?;

    match inner.as_rule() {
        Rule::number => {
            let num: f64 = inner
                .as_str()
                .parse()
                .map_err(|_| ParseError::ExpectedNumber(inner.as_str().to_string()))?;
            Ok(MathExpr::atom(MathAtom::Number(num)))
        }
        Rule::ident => Ok(MathExpr::atom(MathAtom::Ident(Ident::new(inner.as_str())))),
        Rule::semantic_ident => {
            // Parse semantic identifier inside math blocks - treat as regular identifier for now
            Ok(MathExpr::atom(MathAtom::Ident(Ident::new(inner.as_str()))))
        }
        Rule::math_array_literal => {
            // Parse array literal inside math blocks
            let elements: Result<Vec<MathExpr>, ParseError> =
                inner.into_inner().map(parse_math_expr_inner).collect();
            Ok(MathExpr::atom(MathAtom::Array(elements?)))
        }
        Rule::math_expr => Ok(MathExpr::atom(MathAtom::Group(Box::new(
            parse_math_expr_inner(inner)?,
        )))),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected math atom rule: {:?}",
            inner.as_rule()
        ))),
    }
}

/// Parse unary expression: optional prefix operator followed by atom.
fn parse_math_unary(pair: Pair<Rule>) -> Result<MathExpr, ParseError> {
    let mut inner = pair.into_inner();

    let first = inner
        .next()
        .ok_or_else(|| ParseError::ParseTree("Empty unary expression".to_string()))?;

    // Check if first is a unary operator
    match first.as_rule() {
        Rule::math_unary_op => {
            let op = parse_math_unary_operator(first)?;
            let operand_pair = inner.next().ok_or_else(|| {
                ParseError::ParseTree("Missing operand after unary operator".to_string())
            })?;

            let operand = match operand_pair.as_rule() {
                Rule::math_atom => parse_math_atom(operand_pair)?,
                Rule::math_unary => parse_math_unary(operand_pair)?,
                _ => {
                    return Err(ParseError::ParseTree(format!(
                        "Unexpected unary operand rule: {:?}",
                        operand_pair.as_rule()
                    )));
                }
            };

            Ok(MathExpr::unary(op, operand))
        }
        Rule::math_atom => parse_math_atom(first),
        _ => Err(ParseError::ParseTree(format!(
            "Unexpected unary rule: {:?}",
            first.as_rule()
        ))),
    }
}

/// Parse math operator into MathOp.
fn parse_math_operator(pair: Pair<Rule>) -> Result<MathOp, ParseError> {
    match pair.as_str().trim() {
        "+" => Ok(MathOp::Add),
        "-" => Ok(MathOp::Subtract),
        "*" => Ok(MathOp::Multiply),
        "/" => Ok(MathOp::Divide),
        "%" => Ok(MathOp::Modulo),
        "^" => Ok(MathOp::Power),
        "R" => Ok(MathOp::Root),
        op => Err(ParseError::InvalidOperator(format!(
            "Unknown math operator: {}",
            op
        ))),
    }
}

/// Parse unary operator into MathUnaryOp.
fn parse_math_unary_operator(pair: Pair<Rule>) -> Result<MathUnaryOp, ParseError> {
    match pair.as_str().trim() {
        "-" => Ok(MathUnaryOp::Negate),
        "+" => Ok(MathUnaryOp::Plus),
        op => Err(ParseError::InvalidOperator(format!(
            "Unknown unary operator: {}",
            op
        ))),
    }
}

/// Parse operator token into RuneOp.
///
/// We defensively trim whitespace so that rules which
/// include incidental spaces around operators do not
/// accidentally produce `"+"`, `"1 "` or `"b * c"` as a
/// single operator token.
fn parse_operator(pair: Pair<Rule>) -> Result<RuneOp, ParseError> {
    let text = pair.as_str().trim();
    RuneOp::from_str(text).map_err(|_| ParseError::InvalidOperator(text.to_string()))
}

File: ops.rs
============
//! Core Operator Registry and Definitions for RUNE.
//!
//! # e8 Notation – RUNE Operators
//!▫~•◦----------------------------‣
//!
//! This module defines the strict, closed registry of valid RUNE operators.
//! It maps the text representations (from the grammar) to strongly-typed
//! Rust enums, ensuring that no "illegal" or "fused" operators can represent
//! a valid state in the AST.
//!
//! ### Key Capabilities
//! - **Closed Registry:** `RuneOp` enum exhaustively lists every allowed operator.
//! - **Category Safety:** Distinguishes between `Glyph` (Topological), `Relation` (Directed), and `Math` (Value).
//! - **Precedence Logic:** Defines binding power for Pratt parsing (e.g., `*` binds tighter than `+`, which binds tighter than `->`).
//!
//! ### Example
//! ```rust
//! use rune_format::rune::RuneOp;
//! use std::str::FromStr;
//!
//! let op = RuneOp::from_str("->").unwrap();
//! assert_eq!(op, RuneOp::FlowRight);
//! assert_eq!(op.category(), rune_format::rune::OpCategory::Relation);
//! ```
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

#[cfg(feature = "fory")]
use fory::ForyObject;
use serde::{Deserialize, Serialize};
use std::fmt;
use std::str::FromStr;

/// Categories of operators in RUNE.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub enum OpCategory {
    /// Topological shapes (e.g., `/\`, `\|/`).
    Glyph,
    /// Structural relations (e.g., `->`, `:`, `:=`).
    Relation,
    /// Value comparisons (e.g., `<`, `>`).
    Compare,
    /// Arithmetic operations (e.g., `+`, `*`).
    Math,
}

/// The Closed Registry of all valid RUNE operators.
///
/// Any sequence of characters not matching one of these variants
/// is syntactically invalid in RUNE.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub enum RuneOp {
    // --- 1. Glyph Operators (Topology/Shape) ---
    /// `/\` : Branch then converge (Split -> Join).
    SplitJoin,
    /// `\/` : Converge then branch (Join -> Split).
    JoinSplit,
    /// `|/` : Stable lineage then branch away (Descend from Anchor).
    AnchorDescend,
    /// `/|` : Branch away then stabilize (Branch -> Stabilize).
    BranchStabilize,
    /// `\|` : Converge to root then stabilize.
    RootStabilize,
    /// `|\` : Stabilize then converge to root.
    StabilizeRoot,
    /// `\|/` : Symmetric split from a stable center.
    SymmetricSplit,
    /// `/|\` : Branch, Anchor, Branch (Composite).
    BranchAnchorBranch,

    // --- 2. Token Operators (Relations) ---
    /// `:` : Bind / Key-Value / Annotation.
    Bind,
    /// `=:` : Specializes / Instance of / Emergent from.
    Specializes,
    /// `::` : Namespace / Type Tag.
    Namespace,
    /// `:=` : Definition / Assignment.
    Define,
    /// `:=:` : Match / Pattern recognition.
    Match,
    /// `=:=` : Unify / Structural isomorphism.
    Unify,
    /// `=` : Equality / Constraint (Invariant).
    Equal,
    /// `->` : Directed Edge (Flow Right / Rootwards).
    /// Creates a forward directional flow between entities,
    /// typically representing data movement, inheritance, or sequential processing.
    FlowRight,
    /// `<-` : Reverse Edge (Flow Left).
    /// Creates a reverse directional flow, often representing
    /// backpropagation, parent flows, or inverse transformations.
    FlowLeft,
    /// `<->` : Bidirectional flow / Oscillation / Exchange.
    /// Represents oscillating or bidirectional exchange patterns,
    /// such as duality relationships, resonant couplings, or
    /// feedback loops between entities.
    FlowBidirectional,
    /// `>-<` : Convergent flow / Transformation focus.
    /// Denotes transformative convergence, such as energy compression,
    /// gradient descent, or focused transformation pathways.
    FlowConvergent,
    /// `/` : Descendant / Under (Structural Context).
    Descendant,
    /// `\` : Ancestor / Parent (Sugar for `->` in some contexts).
    Ancestor,
    /// `|` : Alias / Equivalence.
    Alias,
    /// `||` : Parallel / Siblings.
    Parallel,
    /// `~` : Transform / View.
    Transform,
    /// `|>` : Pipeline Right / Function composition (left-to-right).
    PipelineRight,
    /// `<|` : Pipeline Left / Reverse function composition (right-to-left).
    PipelineLeft,
    /// `:>` : Output / Produces / Generates (context yields output).
    Output,
    /// `<:` : Input / Requires / Accepts (context needs input).
    Input,

    // --- 4. Comparison ---
    /// `<` : Less / Precedes / Deeper.
    Less,
    /// `<=` : Less than or equal.
    LessEqual,
    /// `>` : Greater / Succeeds / Higher.
    Greater,
    /// `>=` : Greater than or equal.
    GreaterEqual,
}

impl RuneOp {
    /// Returns the semantic category of the operator.
    pub fn category(&self) -> OpCategory {
        match self {
            Self::SplitJoin
            | Self::JoinSplit
            | Self::AnchorDescend
            | Self::BranchStabilize
            | Self::RootStabilize
            | Self::StabilizeRoot
            | Self::SymmetricSplit
            | Self::BranchAnchorBranch => OpCategory::Glyph,

            Self::Bind
            | Self::Specializes
            | Self::Namespace
            | Self::Define
            | Self::Match
            | Self::Unify
            | Self::Equal
            | Self::FlowRight
            | Self::FlowLeft
            | Self::FlowBidirectional
            | Self::FlowConvergent
            | Self::Descendant
            | Self::Ancestor
            | Self::Alias
            | Self::Parallel
            | Self::Transform
            | Self::PipelineRight
            | Self::PipelineLeft
            | Self::Output
            | Self::Input => OpCategory::Relation,

            Self::Less | Self::LessEqual | Self::Greater | Self::GreaterEqual => {
                OpCategory::Compare
            }
        }
    }

    /// Returns the textual representation of the operator.
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::SplitJoin => "/\\",
            Self::JoinSplit => "\\/",
            Self::AnchorDescend => "|/",
            Self::BranchStabilize => "/|",
            Self::RootStabilize => "\\|",
            Self::StabilizeRoot => "|\\",
            Self::SymmetricSplit => "\\|/",
            Self::BranchAnchorBranch => "/|\\",

            Self::Bind => ":",
            Self::Specializes => "=:",
            Self::Namespace => "::",
            Self::Define => ":=",
            Self::Match => ":=:",
            Self::Unify => "=:=",
            Self::Equal => "=",
            Self::FlowRight => "->",
            Self::FlowLeft => "<-",
            Self::FlowBidirectional => "<->",
            Self::FlowConvergent => ">-<",
            Self::Descendant => "/",
            Self::Ancestor => "\\",
            Self::Alias => "|",
            Self::Parallel => "||",
            Self::Transform => "~",
            Self::PipelineRight => "|>",
            Self::PipelineLeft => "<|",
            Self::Output => ":>",
            Self::Input => "<:",

            Self::Less => "<",
            Self::LessEqual => "<=",
            Self::Greater => ">",
            Self::GreaterEqual => ">=",
        }
    }

    /// Binding Power for Pratt Parsing (Precedence).
    ///
    /// Higher numbers bind tighter.
    /// - Namespace/Path: Structural binding
    /// - Flow / Glyphs / Transform: mid-tier
    /// - Comparison: lower
    /// - Bind / Define: lowest (top-level)
    pub fn binding_power(&self) -> (u8, u8) {
        match self {
            // Namespace / Path / Hierarchy
            Self::Namespace => (70, 71),
            Self::Descendant | Self::Ancestor => (60, 61),

            // Flow / Graph Edges / Glyphs / Transform
            Self::FlowRight
            | Self::FlowLeft
            | Self::FlowBidirectional
            | Self::FlowConvergent
            | Self::SplitJoin
            | Self::JoinSplit
            | Self::SymmetricSplit
            | Self::BranchAnchorBranch
            | Self::Transform
            | Self::AnchorDescend
            | Self::BranchStabilize
            | Self::RootStabilize
            | Self::StabilizeRoot => (50, 51),

            // Comparison
            Self::Less | Self::LessEqual | Self::Greater | Self::GreaterEqual | Self::Equal => {
                (40, 41)
            }

            // Loose Structure
            Self::Parallel | Self::Alias => (30, 31),

            // Additional relation operators
            Self::Specializes
            | Self::Match
            | Self::Unify
            | Self::PipelineRight
            | Self::PipelineLeft
            | Self::Output
            | Self::Input => (35, 36),

            // Definition / Assignment / Bind: Lowest
            Self::Bind | Self::Define => (10, 11),
        }
    }
}

/// Parsing error for invalid operator strings.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct InvalidOpError(pub String);

impl fmt::Display for InvalidOpError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "Invalid RUNE operator literal: '{}'", self.0)
    }
}

impl std::error::Error for InvalidOpError {}

impl FromStr for RuneOp {
    type Err = InvalidOpError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            // Glyphs (3-char)
            "\\|/" => Ok(Self::SymmetricSplit),
            "/|\\" => Ok(Self::BranchAnchorBranch),

            // Glyphs (2-char)
            "/\\" => Ok(Self::SplitJoin),
            "\\/" => Ok(Self::JoinSplit),
            "|/" => Ok(Self::AnchorDescend),
            "/|" => Ok(Self::BranchStabilize),
            "\\|" => Ok(Self::RootStabilize),
            "|\\" => Ok(Self::StabilizeRoot),

            // Tokens (3-char)
            "=:=" => Ok(Self::Unify),
            ":=:" => Ok(Self::Match),

            // Tokens (3-char)
            "|>" => Ok(Self::PipelineRight),
            "<|" => Ok(Self::PipelineLeft),
            ":>" => Ok(Self::Output),
            "<:" => Ok(Self::Input),

            // Tokens (3-char) - Flow
            "<->" => Ok(Self::FlowBidirectional),
            ">-<" => Ok(Self::FlowConvergent),

            // Tokens (2-char)
            "=:" => Ok(Self::Specializes),
            "::" => Ok(Self::Namespace),
            ":=" => Ok(Self::Define),
            "->" => Ok(Self::FlowRight),
            "<-" => Ok(Self::FlowLeft),
            "<=" => Ok(Self::LessEqual),
            ">=" => Ok(Self::GreaterEqual),
            "||" => Ok(Self::Parallel),

            // Tokens (1-char)
            ":" => Ok(Self::Bind),
            "=" => Ok(Self::Equal),
            "<" => Ok(Self::Less),
            ">" => Ok(Self::Greater),
            "/" => Ok(Self::Descendant),
            "\\" => Ok(Self::Ancestor),
            "|" => Ok(Self::Alias),
            "~" => Ok(Self::Transform),

            _ => Err(InvalidOpError(s.to_string())),
        }
    }
}

/// Arithmetic operators within math blocks.
#[derive(Debug, Clone, Copy, PartialEq, Serialize, Deserialize)]
#[cfg_attr(feature = "fory", derive(ForyObject))]
pub enum MathOp {
    Add,
    Subtract,
    Multiply,
    Divide,
    Power, // ^ operator
    Modulo,
    Root, // R operator: n-th root
}

impl MathOp {
    pub fn precedence(self) -> u8 {
        match self {
            MathOp::Add | MathOp::Subtract => 1,                     // + -
            MathOp::Multiply | MathOp::Divide | MathOp::Modulo => 2, // * / %
            MathOp::Power | MathOp::Root => 3,                       // ^ R
        }
    }

    pub fn as_str(self) -> &'static str {
        match self {
            MathOp::Add => "+",
            MathOp::Subtract => "-",
            MathOp::Multiply => "*",
            MathOp::Divide => "/",
            MathOp::Power => "^",
            MathOp::Modulo => "%",
            MathOp::Root => "R",
        }
    }
}

impl fmt::Display for MathOp {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(self.as_str())
    }
}

impl fmt::Display for RuneOp {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(self.as_str())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_operator_from_str() {
        assert_eq!(RuneOp::from_str("->").unwrap(), RuneOp::FlowRight);
        assert_eq!(RuneOp::from_str("<-").unwrap(), RuneOp::FlowLeft);
        assert_eq!(RuneOp::from_str("<->").unwrap(), RuneOp::FlowBidirectional);
        assert_eq!(RuneOp::from_str(">-<").unwrap(), RuneOp::FlowConvergent);
        assert_eq!(RuneOp::from_str("/\\").unwrap(), RuneOp::SplitJoin);
        assert_eq!(RuneOp::from_str(":=").unwrap(), RuneOp::Define);
        assert_eq!(RuneOp::from_str("=:=").unwrap(), RuneOp::Unify);
        assert_eq!(RuneOp::from_str(":=:").unwrap(), RuneOp::Match);
        assert_eq!(RuneOp::from_str("=:").unwrap(), RuneOp::Specializes);
        assert_eq!(RuneOp::from_str("|>").unwrap(), RuneOp::PipelineRight);
        assert_eq!(RuneOp::from_str("<|").unwrap(), RuneOp::PipelineLeft);
        assert_eq!(RuneOp::from_str(":>").unwrap(), RuneOp::Output);
        assert_eq!(RuneOp::from_str("<:").unwrap(), RuneOp::Input);
    }

    #[test]
    fn test_invalid_operator() {
        assert!(RuneOp::from_str("=>").is_err());
        assert!(RuneOp::from_str("/->").is_err());
        assert!(RuneOp::from_str(":|").is_err());
    }

    #[test]
    fn test_binding_power() {
        assert!(RuneOp::FlowRight.binding_power() > RuneOp::Define.binding_power());
    }
}

File: ast.rs
============
/* src/rune/ast.rs */
//! RUNE Abstract Syntax Tree (AST) definitions.
//!
//! # TOON-RUNE – RUNE AST Module
//!▫~•◦---------------------------‣
//!
//! This module defines the core expression tree structures for RUNE:
//! identifiers, literals, terms, and expressions built on `RuneOp`.
//! It also includes statement-level constructs for TOON blocks and root declarations.
//!
//! The AST is intentionally minimal and expression-centric. Higher-level
//! constructs (definitions, constraints, blocks) can be layered on top
//! without changing the fundamental expression nodes.
//!
//! ### Key Types
//! - [`Literal`] – Numeric values.
//! - [`Ident`]   – Symbolic names (types, tensors, nodes, roots).
//! - [`Term`]    – Basic units: identifiers, literals, grouped expressions.
//! - [`Expr`]    – Recursive expression tree parameterized by [`RuneOp`].
//! - [`Stmt`]    – Top-level statements: root declarations, TOON blocks, expressions.
//!
//! ### Example
//! ```rust
//! use rune_format::rune::{Stmt, Expr};
//! use rune_format::rune::RuneOp;
//!
//! let root_stmt = Stmt::root("continuum");
//! let expr_stmt = Stmt::expr(
//!     Expr::binary(
//!         Expr::ident("users"),
//!         RuneOp::Descendant,
//!         Expr::ident("0"),
//!     )
//! );
//! ```
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use crate::rune::ops::{MathOp, RuneOp};
use serde::{Deserialize, Serialize};
use std::fmt;

/// Basic type system for RUNE expressions.
/// This is intentionally small to bootstrap typed AST and inference.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum RuneType {
    Scalar,
    String,
    Gf8,
    PointCloud,
    Array,
    Bool,
    Unknown,
}

impl fmt::Display for RuneType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            RuneType::Scalar => write!(f, "Scalar"),
            RuneType::String => write!(f, "String"),
            RuneType::Gf8 => write!(f, "Gf8"),
            RuneType::PointCloud => write!(f, "PointCloud"),
            RuneType::Array => write!(f, "Array"),
            RuneType::Bool => write!(f, "Bool"),
            RuneType::Unknown => write!(f, "Unknown"),
        }
    }
}

/// A parameter in a kernel archetype declaration.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct KernelParam {
    pub name: Ident,
    pub typ: Ident,
}

/// Information about a single archetype in a kernel declaration.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct ArchetypeInfo {
    pub name: Ident,
    pub params: Vec<KernelParam>,
}

/// A kernel archetype definition with parameters.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct KernelArchetype {
    pub name: Ident,
    pub params: Vec<(Ident, Literal)>,
}

/// A symbolic identifier in RUNE.
///
/// This covers type symbols (`T`, `Gf8`, `XUID`), nodes, roots,
/// fields, and any named entities.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Ident(pub String);

impl Ident {
    pub fn new<S: Into<String>>(s: S) -> Self {
        Ident(s.into())
    }
}

impl fmt::Display for Ident {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(&self.0)
    }
}

impl From<String> for Ident {
    fn from(s: String) -> Self {
        Ident::new(s)
    }
}

impl From<&str> for Ident {
    fn from(s: &str) -> Self {
        Ident::new(s)
    }
}

impl Into<String> for Ident {
    fn into(self) -> String {
        self.0
    }
}

/// A semantic identifier with a single-letter namespace prefix.
///
/// Examples: T:Gf8, V:vector, R:continuum, Q:e32l
/// The prefix is always a single uppercase letter (A-Z).
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct SemanticIdent {
    /// The semantic prefix (A-Z)
    pub prefix: char,
    /// The identifier name
    pub name: Ident,
}

impl SemanticIdent {
    pub fn new(prefix: char, name: impl Into<String>) -> Self {
        SemanticIdent {
            prefix,
            name: Ident::new(name),
        }
    }
}

impl fmt::Display for SemanticIdent {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}:{}", self.prefix, self.name)
    }
}

/// Literal values in RUNE expressions.
///
/// Supports numeric literals, strings, arrays, and booleans.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Literal {
    /// Numeric literal (parsed as f64).
    Number(f64),
    /// String literal.
    String(String),
    /// Boolean literal: B:t (true) or B:f (false)
    Bool(bool),
    /// Array literal: [1,2,3] or [a,b,c]
    Array(Vec<Expr>),
}

impl Literal {
    pub fn number<N: Into<f64>>(n: N) -> Self {
        Literal::Number(n.into())
    }

    pub fn string<S: Into<String>>(s: S) -> Self {
        Literal::String(s.into())
    }

    pub fn bool<B: Into<bool>>(b: B) -> Self {
        Literal::Bool(b.into())
    }

    pub fn array(elements: Vec<Expr>) -> Self {
        Literal::Array(elements)
    }
}

impl fmt::Display for Literal {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Literal::Number(n) => write!(f, "{}", n),
            Literal::String(s) => write!(f, "\"{}\"", s),
            Literal::Bool(b) => write!(f, "B:{}", if *b { "t" } else { "f" }),
            Literal::Array(elements) => {
                write!(f, "[")?;
                for (i, elem) in elements.iter().enumerate() {
                    if i > 0 {
                        write!(f, ",")?;
                    }
                    write!(f, "{}", elem)?;
                }
                write!(f, "]")
            }
        }
    }
}

/// Arithmetic expressions within `[...]` value blocks.
///
/// These support traditional math with operators: `+ - * /`.
/// Isolated from glyph operators for clean separation.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum MathExpr {
    /// A single math atom (identifier, number, or grouped math).
    Atom(MathAtom),

    /// A binary math operation `lhs op rhs`.
    Binary {
        left: Box<MathExpr>,
        op: MathOp,
        right: Box<MathExpr>,
    },

    /// A unary math operation `op expr` (e.g., `-x`, `+5`).
    Unary {
        op: MathUnaryOp,
        operand: Box<MathExpr>,
    },
}

/// Unary operators in arithmetic expressions.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum MathUnaryOp {
    /// Negation `-x`.
    Negate,
    /// Positive `+x` (typically a no-op).
    Plus,
}

impl MathUnaryOp {
    pub fn as_str(self) -> &'static str {
        match self {
            MathUnaryOp::Negate => "-",
            MathUnaryOp::Plus => "+",
        }
    }
}

/// Atoms in arithmetic expressions.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum MathAtom {
    /// Numeric literal.
    Number(f64),
    /// Variable identifier.
    Ident(Ident),
    /// Grouped sub-expression `(math)` (for precedence).
    Group(Box<MathExpr>),
    /// Array literal inside math block `[expr, expr, ...]`.
    Array(Vec<MathExpr>),
}

impl MathExpr {
    /// Create a math atom expression.
    pub fn atom(atom: MathAtom) -> Self {
        MathExpr::Atom(atom)
    }

    /// Create a binary math expression.
    pub fn binary(left: MathExpr, op: MathOp, right: MathExpr) -> Self {
        MathExpr::Binary {
            left: Box::new(left),
            op,
            right: Box::new(right),
        }
    }

    /// Create a unary math expression.
    pub fn unary(op: MathUnaryOp, operand: MathExpr) -> Self {
        MathExpr::Unary {
            op,
            operand: Box::new(operand),
        }
    }
}

impl fmt::Display for MathExpr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            MathExpr::Atom(atom) => match atom {
                MathAtom::Number(n) => write!(f, "{}", n),
                MathAtom::Ident(id) => write!(f, "{}", id),
                MathAtom::Group(inner) => write!(f, "({})", inner),
                MathAtom::Array(elements) => {
                    write!(f, "[")?;
                    for (i, elem) in elements.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}", elem)?;
                    }
                    write!(f, "]")
                }
            },
            MathExpr::Binary { left, op, right } => {
                // Add parens for clarity in nested operations
                write!(f, "{} {} {}", left, op, right)
            }
            MathExpr::Unary { op, operand } => {
                write!(f, "{}{}", op.as_str(), operand)
            }
        }
    }
}

/// Atomic terms in a RUNE expression.
///
/// These are the building blocks that operators connect.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Term {
    /// A named symbol (identifier).
    Ident(Ident),
    /// A semantic identifier with namespace prefix (e.g., T:Gf8, V:vector).
    SemanticIdent(SemanticIdent),
    /// A literal value.
    Literal(Literal),
    /// A grouped sub-expression `(expr)`.
    Group(Box<Expr>),
    /// Arithmetic within `[...]` value blocks.
    Math(Box<MathExpr>),
    /// A function call: name(arg1, arg2, ...)
    FunctionCall { name: Ident, args: Vec<Expr> },
}

impl Term {
    pub fn ident<S: Into<String>>(s: S) -> Self {
        Term::Ident(Ident::new(s))
    }

    pub fn semantic_ident(prefix: char, name: impl Into<String>) -> Self {
        Term::SemanticIdent(SemanticIdent::new(prefix, name))
    }

    pub fn literal<N: Into<f64>>(n: N) -> Self {
        Term::Literal(Literal::number(n))
    }

    pub fn group(expr: Expr) -> Self {
        Term::Group(Box::new(expr))
    }

    pub fn math(math: MathExpr) -> Self {
        Term::Math(Box::new(math))
    }
}

/// A full RUNE expression.
///
/// This is the node-level representation that a Pratt parser will
/// construct from a token stream (`Term`s and `RuneOp`s).
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Expr {
    /// A single term (identifier, literal, or grouped expression).
    Term(Term),

    /// A binary expression `lhs op rhs`.
    Binary {
        left: Box<Expr>,
        op: RuneOp,
        right: Box<Expr>,
    },
}

impl Expr {
    /// Construct a term expression from an identifier.
    pub fn ident<S: Into<String>>(s: S) -> Self {
        Expr::Term(Term::ident(s))
    }

    /// Construct a term expression from a numeric literal.
    pub fn literal<N: Into<f64>>(n: N) -> Self {
        Expr::Term(Term::literal(n))
    }

    /// Construct a grouped expression `(expr)`.
    pub fn group(expr: Expr) -> Self {
        Expr::Term(Term::group(expr))
    }

    /// Construct a binary expression `left op right`.
    pub fn binary(left: Expr, op: RuneOp, right: Expr) -> Self {
        Expr::Binary {
            left: Box::new(left),
            op,
            right: Box::new(right),
        }
    }
}

/// A typed expression wrapper used for annotating an `Expr` node
/// with a best-effort type computed during parsing/type inference.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct TypedExpr {
    pub expr: Expr,
    pub r#type: RuneType,
}

impl TypedExpr {
    pub fn new(expr: Expr, r#type: RuneType) -> Self {
        Self { expr, r#type }
    }

    /// Infer a type for a given expression node using shallow heuristics.
    /// This is intentionally conservative: only literal math/strings/arrays
    /// and some semantic hints are recognized. More advanced inference is
    /// left for a future pass.
    pub fn infer(expr: &Expr) -> Self {
        // NOTE: we avoid glob-importing Expr::* to reduce ambiguity with the Term enum
        let r#type = match expr {
            Expr::Term(term) => match term {
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::Number(_)) => {
                    RuneType::Scalar
                }
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::String(_)) => {
                    RuneType::String
                }
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::Bool(_)) => {
                    RuneType::Bool
                }
                crate::rune::ast::Term::Literal(crate::rune::ast::Literal::Array(_)) => {
                    RuneType::Array
                }
                crate::rune::ast::Term::Math(_) => RuneType::Scalar,
                crate::rune::ast::Term::Ident(_) => RuneType::Unknown,
                crate::rune::ast::Term::SemanticIdent(s) => {
                    // Heuristic: common semantic prefix T:Gf8 -> Gf8 type
                    match s.prefix {
                        'T' => {
                            if s.name.0.to_lowercase().contains("gf8") {
                                RuneType::Gf8
                            } else {
                                RuneType::Unknown
                            }
                        }
                        _ => RuneType::Unknown,
                    }
                }
                crate::rune::ast::Term::Group(inner) => TypedExpr::infer(inner).r#type.clone(),
                crate::rune::ast::Term::FunctionCall { name, args: _ } => {
                    // Heuristic: function name suggests type
                    if name.0.contains("Quat")
                        || name.0.contains("quaternion")
                        || name.0.contains("Gf8")
                    {
                        RuneType::Gf8 // quaternions are 4D, represented as scalars for now
                    } else {
                        RuneType::Unknown
                    }
                }
            },
            Expr::Binary {
                left,
                op: _,
                right: _,
            } => {
                // Binary expression type inference: prefer left-side for now
                TypedExpr::infer(left).r#type.clone()
            }
        };

        TypedExpr::new(expr.clone(), r#type)
    }
}

impl fmt::Display for Expr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Expr::Term(t) => match t {
                Term::Ident(id) => write!(f, "{}", id),
                Term::SemanticIdent(sid) => write!(f, "{}", sid),
                Term::Literal(Literal::Number(n)) => write!(f, "{}", n),
                Term::Literal(Literal::String(s)) => write!(f, "\"{}\"", s),
                Term::Literal(Literal::Bool(b)) => write!(f, "B:{}", if *b { "t" } else { "f" }),
                Term::Literal(Literal::Array(elements)) => {
                    write!(f, "[")?;
                    for (i, elem) in elements.iter().enumerate() {
                        if i > 0 {
                            write!(f, ",")?;
                        }
                        write!(f, "{}", elem)?;
                    }
                    write!(f, "]")
                }
                Term::Group(inner) => write!(f, "({})", inner),
                Term::Math(math) => write!(f, "[{}]", math),
                Term::FunctionCall { name, args } => {
                    write!(f, "{}(", name)?;
                    for (i, arg) in args.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}", arg)?;
                    }
                    write!(f, ")")
                }
            },
            Expr::Binary { left, op, right } => {
                // Don't add spaces around :: (namespace operator)
                if *op == RuneOp::Namespace {
                    write!(f, "{}::{}", left, right)
                } else {
                    write!(f, "{} {} {}", left, op, right)
                }
            }
        }
    }
}

/// Top-level RUNE statements.
///
/// These are the syntactic units parsed from RUNE files:
/// root declarations anchor contexts, TOON blocks provide raw data,
/// kernel declarations define computational archetypes,
/// and expressions allow symbolic computations over that data.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Stmt {
    /// A root declaration: `root: name`
    /// Anchors the semantic context of the document.
    RootDecl(Ident),

    /// A TOON block: `name ~TOON:\n  content`
    /// Raw TOON data preserved verbatim for later parsing by the TOON library.
    ToonBlock { name: Ident, content: String },

    /// A kernel declaration: `Kernel:QDot := CUDA:Archetype:RowDot(D: 8)`
    /// Defines a kernel from a CUDA archetype template.
    KernelDecl {
        name: SemanticIdent,
        archetype: KernelArchetype,
    },

    /// A RUNE expression statement.
    /// Typically constraints, definitions, or relations over TOON data.
    Expr(Expr),
}

impl Stmt {
    /// Create a root declaration statement.
    pub fn root<S: Into<String>>(name: S) -> Self {
        Stmt::RootDecl(Ident::new(name))
    }

    /// Create a TOON block statement.
    pub fn toon_block<S: Into<String>>(name: S, content: String) -> Self {
        Stmt::ToonBlock {
            name: Ident::new(name),
            content,
        }
    }

    /// Create an expression statement.
    pub fn expr(expr: Expr) -> Self {
        Stmt::Expr(expr)
    }
}

impl fmt::Display for Stmt {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Stmt::RootDecl(name) => write!(f, "root: {}", name),
            Stmt::ToonBlock { name, content } => {
                writeln!(f, "{} ~TOON:", name)?;
                for line in content.lines() {
                    writeln!(f, "  {}", line)?;
                }
                Ok(())
            }
            Stmt::KernelDecl { name, archetype } => {
                write!(f, "{} := {}", name, archetype.name)?;
                if !archetype.params.is_empty() {
                    write!(f, "(")?;
                    for (i, (param_name, param_value)) in archetype.params.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}: {}", param_name, param_value)?;
                    }
                    write!(f, ")")?;
                }
                Ok(())
            }
            Stmt::Expr(expr) => write!(f, "{}", expr),
        }
    }
}

/// Typed form of top-level statements.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum StmtTyped {
    RootDecl(Ident),
    ToonBlock {
        name: Ident,
        content: String,
    },
    KernelDecl {
        name: SemanticIdent,
        archetype: KernelArchetype,
    },
    Expr(TypedExpr),
}

impl StmtTyped {
    pub fn root<S: Into<String>>(name: S) -> Self {
        StmtTyped::RootDecl(Ident::new(name))
    }

    pub fn toon_block<S: Into<String>>(name: S, content: String) -> Self {
        StmtTyped::ToonBlock {
            name: Ident::new(name),
            content,
        }
    }

    pub fn expr(expr: TypedExpr) -> Self {
        StmtTyped::Expr(expr)
    }
}

impl fmt::Display for StmtTyped {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            StmtTyped::RootDecl(name) => write!(f, "root: {}", name),
            StmtTyped::ToonBlock { name, content } => {
                writeln!(f, "{} ~TOON:", name)?;
                for line in content.lines() {
                    writeln!(f, "  {}", line)?;
                }
                Ok(())
            }
            StmtTyped::KernelDecl { name, archetype } => {
                write!(f, "{} := {}", name, archetype.name)?;
                if !archetype.params.is_empty() {
                    write!(f, "(")?;
                    for (i, (param_name, param_value)) in archetype.params.iter().enumerate() {
                        if i > 0 {
                            write!(f, ", ")?;
                        }
                        write!(f, "{}: {}", param_name, param_value)?;
                    }
                    write!(f, ")")?;
                }
                Ok(())
            }
            StmtTyped::Expr(te) => write!(f, "{} :: {:?}", te.expr, te.r#type),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::rune::ops::RuneOp;

    #[test]
    fn test_expr_binary() {
        let left = Expr::ident("users");
        let right = Expr::literal(0.0);
        let expr = Expr::binary(left, RuneOp::Descendant, right);
        assert_eq!(format!("{}", expr), "users / 0");
    }

    #[test]
    fn test_stmt_root() {
        let stmt = Stmt::root("continuum");
        assert_eq!(format!("{}", stmt), "root: continuum");
    }

    #[test]
    fn test_stmt_toon_block() {
        let content = "items[2]{id,name}:\n  1,hello\n  2,world".to_string();
        let stmt = Stmt::toon_block("data", content);
        let output = format!("{}", stmt);
        assert!(output.contains("data ~TOON:"));
        assert!(output.contains("  items[2]"));
    }
}

File: hydron\cuda.rs
====================
//! CUDA-specific evaluation bridge for Hydron operations.
//!
//! Provides GPU-accelerated implementations for DomR computations using the rune-curs
//! CUDA acceleration layer.

#[cfg(feature = "cuda")]
use rune_curs as curs;
use rune_hex::hex;

/// CUDA accelerator for Hydron operations
#[derive(Debug, Clone)]
pub struct CudaAccelerator {
    /// Whether CUDA is available on this system
    cuda_available: bool,
}

impl CudaAccelerator {
    /// Create a new CUDA accelerator and check availability
    pub fn new() -> Self {
        #[cfg(feature = "cuda")]
        let cuda_available = true; // Assume available if compiled with feature

        #[cfg(not(feature = "cuda"))]
        let cuda_available = false;

        Self { cuda_available }
    }

    /// Check if CUDA acceleration is available
    pub fn is_available(&self) -> bool {
        self.cuda_available
    }

    /// Execute CUDA-accelerated DomR computation if available
    pub fn execute_domr(
        &self,
        operation: &str,
        energy_args: &[crate::rune::hydron::values::Value],
    ) -> Result<crate::rune::hydron::values::Value, crate::rune::hydron::values::EvalError> {
        use crate::rune::hydron::values::{EvalError, Value};

        if !self.cuda_available {
            return Err(EvalError::UnsupportedOperation(
                "CUDA not available on this system".to_string(),
            ));
        }

        match operation {
            "CudaDomR" | "CudaArchetypeDomR" => {
                // Extract energy array from first argument
                let energy_vec = extract_energy_array(&energy_args[0])?;
                let n_dr = energy_args.get(1)
                    .map(|v| extract_usize(v))
                    .transpose()?
                    .unwrap_or(8);

                #[cfg(feature = "cuda")]
                {
                    // Get the default hex graph
                    let graph = hex::default_graph();

                    // Compute scores using CUDA
                    let scores = curs::domr_scores_gpu(&energy_vec, graph.coords())
                        .map_err(|e| EvalError::InvalidOperation(format!("CUDA DomR failed: {}", e)))?;

                    if scores.len() != graph.coords().len() {
                        return Err(EvalError::InvalidOperation(
                            "CUDA returned mismatched score length".to_string(),
                        ));
                    }

                    // Sort by score descending and take top n_dr
                    let mut pairs: Vec<(usize, f32)> = scores.into_iter().enumerate().collect();
                    pairs.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

                    let take = n_dr.min(pairs.len());
                    let mut roots = Vec::with_capacity(take);
                    let mut out_scores = Vec::with_capacity(take);

                    for (idx, score) in pairs.into_iter().take(take) {
                        roots.push(idx as u8);
                        out_scores.push(score);
                    }

                    Ok(Value::DomR(hex::DomR {
                        roots,
                        scores: out_scores,
                    }))
                }

                #[cfg(not(feature = "cuda"))]
                {
                    Err(EvalError::UnsupportedOperation(
                        "CUDA feature not enabled".to_string(),
                    ))
                }
            }

            _ => Err(EvalError::UnsupportedOperation(format!(
                "Unknown CUDA operation: {} (only DomR operations supported)",
                operation
            ))),
        }
    }
}

impl Default for CudaAccelerator {
    fn default() -> Self {
        Self::new()
    }
}

/// Global CUDA accelerator instance
static CUDA_ACCELERATOR: std::sync::OnceLock<CudaAccelerator> = std::sync::OnceLock::new();

/// Get or initialize the global CUDA accelerator
pub fn get_cuda_accelerator() -> &'static CudaAccelerator {
    CUDA_ACCELERATOR.get_or_init(|| CudaAccelerator::new())
}

// Helper functions for extracting values from Value enum

fn extract_energy_array(val: &crate::rune::hydron::values::Value) -> Result<Vec<f32>, crate::rune::hydron::values::EvalError> {
    use crate::rune::hydron::values::{EvalError, Value};

    match val {
        Value::Array(arr) => {
            if arr.len() != 240 {
                return Err(EvalError::TypeMismatch(format!(
                    "Energy array must have length 240, got {}",
                    arr.len()
                )));
            }
            arr.iter()
                .map(|v| extract_f32(v))
                .collect()
        }
        _ => Err(EvalError::TypeMismatch(
            "Energy argument must be an Array of 240 floats".to_string(),
        )),
    }
}

fn extract_f32(val: &crate::rune::hydron::values::Value) -> Result<f32, crate::rune::hydron::values::EvalError> {
    use crate::rune::hydron::values::{EvalError, Value};

    match val {
        Value::Scalar(f) => Ok(*f),
        Value::Float(f) => Ok(*f as f32),
        Value::Integer(i) => Ok(*i as f32),
        _ => Err(EvalError::TypeMismatch(
            "Value must be numeric (Scalar, Float, or Integer)".to_string(),
        )),
    }
}

fn extract_usize(val: &crate::rune::hydron::values::Value) -> Result<usize, crate::rune::hydron::values::EvalError> {
    use crate::rune::hydron::values::{EvalError, Value};

    match val {
        Value::Scalar(f) => Ok(*f as usize),
        Value::Float(f) => Ok(*f as usize),
        Value::Integer(i) => Ok(*i as usize),
        _ => Err(EvalError::TypeMismatch(
            "Index must be numeric".to_string(),
        )),
    }
}

File: hydron\eval.rs
====================
//! RUNE Expression Evaluator
//!
//! Evaluates RUNE expressions with semantic prefixes, array literals, and operators.
//! Supports mathematical operations, semantic type checking, and E8 geometry primitives.
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use super::values::{EvalContext, EvalError, Value};
use crate::rune::ops::MathOp;
use crate::rune::{
    Expr, Ident, Literal, MathAtom, MathExpr, MathUnaryOp, RuneOp, SemanticIdent, Stmt, Term,
};
use std::collections::HashMap;

/// RUNE expression evaluator with semantic type support
pub struct Evaluator {
    /// Variable bindings (name -> value)
    variables: HashMap<String, Value>,
    /// Semantic namespace bindings (T:name -> value)
    semantic_vars: HashMap<String, Value>,
}

impl Evaluator {
    /// Create a new evaluator with empty context
    pub fn new() -> Self {
        Self {
            variables: HashMap::new(),
            semantic_vars: HashMap::new(),
        }
    }

    /// Create evaluator with pre-populated context
    pub fn with_context(ctx: EvalContext) -> Self {
        Self {
            variables: ctx.variables,
            semantic_vars: ctx.semantic_vars,
        }
    }

    /// Set a variable value
    pub fn set_var(&mut self, name: impl Into<String>, value: Value) {
        self.variables.insert(name.into(), value);
    }

    /// Set a semantic variable value (e.g., T:Gf8)
    pub fn set_semantic(&mut self, prefix: char, name: impl Into<String>, value: Value) {
        let key = format!("{}:{}", prefix, name.into());
        self.semantic_vars.insert(key, value);
    }

    /// Print SIMD capabilities (diagnostic)
    #[cfg(feature = "simd")]
    pub fn print_simd_info(&self) {
        use super::values::{get_available_f32_256_intrinsics, print_simd_capabilities};
        print_simd_capabilities();
        let intrinsics = get_available_f32_256_intrinsics();
        println!("Available f32x256 intrinsics: {:?}", intrinsics);
    }

    /// Get a variable value
    pub fn get_var(&self, name: &str) -> Option<&Value> {
        self.variables.get(name)
    }

    /// Get a semantic variable value
    pub fn get_semantic(&self, prefix: char, name: &str) -> Option<&Value> {
        let key = format!("{}:{}", prefix, name);
        self.semantic_vars.get(&key)
    }

    /// Evaluate a statement
    pub fn eval_stmt(&mut self, stmt: &Stmt) -> Result<Value, EvalError> {
        match stmt {
            Stmt::RootDecl(root) => {
                // Root declarations don't produce values, but we can store them as context
                Ok(Value::String(root.to_string()))
            }
            Stmt::ToonBlock { name, content } => {
                // TOON blocks are data, not computation - return the raw content
                Ok(Value::String(format!(
                    "TOON block '{}': {} chars",
                    name,
                    content.len()
                )))
            }
            Stmt::KernelDecl { name, archetype: _ } => {
                // Kernel declarations are declarations, not computations - return description
                Ok(Value::String(format!("Kernel '{}' declared", name.name.0)))
            }
            Stmt::Expr(expr) => self.eval_expr(expr),
        }
    }

    /// Evaluate a typed statement (StmtTyped), respecting the type annotations
    /// provided by the parser's inference pass.
    pub fn eval_typed_stmt(&mut self, stmt: &crate::rune::ast::StmtTyped) -> Result<Value, EvalError> {
        match stmt {
            crate::rune::ast::StmtTyped::RootDecl(root) => Ok(Value::String(root.to_string())),
            crate::rune::ast::StmtTyped::ToonBlock { name, content } => Ok(Value::String(format!(
                "TOON block '{}': {} chars",
                name,
                content.len()
            ))),
            crate::rune::ast::StmtTyped::KernelDecl { name, archetype: _ } => Ok(Value::String(format!("Kernel '{}' declared", name.name.0))),
            crate::rune::ast::StmtTyped::Expr(te) => {
                // For now, just evaluate the inner expression as before, type info is advisory.
                self.eval_expr(&te.expr)
            }
        }
    }

    /// Evaluate an expression
    pub fn eval_expr(&mut self, expr: &Expr) -> Result<Value, EvalError> {
        match expr {
            Expr::Term(term) => self.eval_term(term),
            Expr::Binary { left, op, right } => {
                // Special-case: transform operator `~` used as builtin invocation
                // e.g., `S7Slerp ~ [a, b, t]` where left is builtin name
                if *op == RuneOp::Transform {
                    // If left is a direct identifier, treat as builtin name
                    if let Expr::Term(Term::Ident(id)) = &**left {
                        // Evaluate the right expression to a value
                        let right_val = self.eval_expr(right)?;
                        // If right_val is an Array, use elements as args; otherwise a single arg
                        let args: Vec<Value> = match right_val {
                            Value::Array(arr) => arr,
                            v => vec![v],
                        };

                        // Dispatch to builtin
                        let ctx = self.context();
                        return ctx.apply_builtin_by_name(&id.0, &args);
                    }
                }

                let left_val = self.eval_expr(left)?;
                let right_val = self.eval_expr(right)?;
                self.eval_binary_op(&left_val, op, &right_val)
            }
        }
    }

    /// Evaluate a term
    fn eval_term(&self, term: &Term) -> Result<Value, EvalError> {
        match term {
            Term::Literal(lit) => self.eval_literal(lit),
            Term::Ident(ident) => self.eval_ident(ident),
            Term::SemanticIdent(sem) => self.eval_semantic_ident(sem),
            Term::Group(expr) => {
                // Group expressions are used for math blocks [expr]
                // For now, just evaluate the inner expression
                let mut temp_eval = Self {
                    variables: self.variables.clone(),
                    semantic_vars: self.semantic_vars.clone(),
                };
                temp_eval.eval_expr(expr)
            }
            Term::Math(math_expr) => {
                // Math blocks contain MathExpr which needs evaluation
                self.eval_math_expr(math_expr)
            }
            Term::FunctionCall { name, args } => {
                // Evaluate function call by dispatching to builtin
                let mut temp_eval = Self {
                    variables: self.variables.clone(),
                    semantic_vars: self.semantic_vars.clone(),
                };
                let args: Vec<Value> = args.iter().map(|arg| temp_eval.eval_expr(arg)).collect::<Result<_, _>>()?;
                let ctx = self.context();
                ctx.apply_builtin_by_name(&name.0, &args)
            }
        }
    }

    /// Evaluate a math expression
    fn eval_math_expr(&self, math: &MathExpr) -> Result<Value, EvalError> {
        match math {
            MathExpr::Atom(atom) => self.eval_math_atom(atom),
            MathExpr::Binary { left, op, right } => {
                let left_val = self.eval_math_expr(left)?;
                let right_val = self.eval_math_expr(right)?;
                self.eval_math_op(&left_val, op, &right_val)
            }
            MathExpr::Unary { op, operand } => {
                let val = self.eval_math_expr(operand)?;
                self.eval_math_unary_op(op, &val)
            }
        }
    }

    /// Evaluate a math atom
    fn eval_math_atom(&self, atom: &MathAtom) -> Result<Value, EvalError> {
        match atom {
            MathAtom::Number(n) => Ok(Value::Float(*n)),
            MathAtom::Ident(ident) => {
                // Check if it's a semantic identifier (contains ':')
                if ident.0.contains(':') {
                    let parts: Vec<&str> = ident.0.split(':').collect();
                    if parts.len() == 2 && parts[0].len() == 1 {
                        let prefix = parts[0].chars().next().unwrap();
                        self.get_semantic(prefix, parts[1])
                            .cloned()
                            .ok_or_else(|| EvalError::UndefinedVariable(ident.0.clone()))
                    } else {
                        self.eval_ident(ident)
                    }
                } else {
                    self.eval_ident(ident)
                }
            }
            MathAtom::Group(math) => self.eval_math_expr(math),
            MathAtom::Array(elements) => {
                // Evaluate array literal inside math block
                let mut values = Vec::new();
                for elem in elements {
                    values.push(self.eval_math_expr(elem)?);
                }
                Ok(Value::Array(values))
            }
        }
    }

    /// Evaluate a math binary operation
    fn eval_math_op(&self, left: &Value, op: &MathOp, right: &Value) -> Result<Value, EvalError> {
        match op {
            MathOp::Add => left.add(right),
            MathOp::Subtract => left.sub(right),
            MathOp::Multiply => left.mul(right),
            MathOp::Divide => left.div(right),
            MathOp::Power => left.pow(right),
            MathOp::Modulo => left.modulo(right),
            MathOp::Root => Err(EvalError::UnsupportedOperation(
                "Root operator not yet implemented".into(),
            )),
        }
    }

    /// Evaluate a math unary operation
    fn eval_math_unary_op(&self, op: &MathUnaryOp, val: &Value) -> Result<Value, EvalError> {
        match op {
            MathUnaryOp::Negate => val.negate(),
            MathUnaryOp::Plus => Ok(val.clone()),
        }
    }

    /// Evaluate a literal value
    fn eval_literal(&self, lit: &Literal) -> Result<Value, EvalError> {
        match lit {
            Literal::Number(n) => Ok(Value::Float(*n)),
            Literal::String(s) => Ok(Value::String(s.clone())),
            Literal::Bool(b) => Ok(Value::Scalar(if *b { 1.0 } else { 0.0 })),
            Literal::Array(exprs) => {
                let mut values = Vec::new();
                let mut temp_eval = Self {
                    variables: self.variables.clone(),
                    semantic_vars: self.semantic_vars.clone(),
                };
                for expr in exprs {
                    values.push(temp_eval.eval_expr(expr)?);
                }
                Ok(Value::Array(values))
            }
        }
    }

    /// Evaluate an identifier (variable lookup)
    fn eval_ident(&self, ident: &Ident) -> Result<Value, EvalError> {
        self.variables
            .get(&ident.0)
            .cloned()
            .ok_or_else(|| EvalError::UndefinedVariable(ident.0.clone()))
    }

    /// Evaluate a semantic identifier (T:name, V:velocity, etc.)
    fn eval_semantic_ident(&self, sem: &SemanticIdent) -> Result<Value, EvalError> {
        let key = format!("{}:{}", sem.prefix, sem.name.0);
        self.semantic_vars
            .get(&key)
            .cloned()
            .ok_or_else(|| EvalError::UndefinedVariable(key))
    }

    /// Evaluate a binary operation using RuneOp (structural operations only)
    /// Arithmetic operations are handled by MathOp within math blocks `[]`
    fn eval_binary_op(&self, left: &Value, op: &RuneOp, right: &Value) -> Result<Value, EvalError> {
        use RuneOp::*;

        match op {
            // Comparison operators
            Less => left.lt(right),
            LessEqual => left.le(right),
            Greater => left.gt(right),
            GreaterEqual => left.ge(right),
            Equal => Ok(Value::Bool(left == right)),

            // Structural operators (not for computation) - arithmetic handled by MathOp
            Descendant | Ancestor | Define | FlowRight | FlowLeft | Bind | Namespace | Alias
            | Parallel | Transform | SplitJoin | JoinSplit | AnchorDescend | BranchStabilize
            | RootStabilize | StabilizeRoot | SymmetricSplit | BranchAnchorBranch
            | Specializes | Match | Unify | FlowBidirectional | FlowConvergent
            | PipelineRight | PipelineLeft | Output | Input => {
                Err(EvalError::UnsupportedOperation(format!(
                    "Structural operator {:?} not implemented for computation. Use math blocks `[]` for arithmetic.",
                    op
                )))
            }
        }
    }

    /// Export current context
    pub fn context(&self) -> EvalContext {
        let mut ctx = EvalContext::new();
        for (name, value) in &self.variables {
            ctx.bind(name.clone(), value.clone());
        }
        // Add semantic variables from the evaluator into the context so builtins
        // can resolve semantic identifiers.
        for (k, v) in &self.semantic_vars {
            ctx.semantic_vars.insert(k.clone(), v.clone());
        }
        ctx
    }

    /// Evaluate a builtin by its textual name using the current context
    pub fn eval_builtin_by_name(
        &self,
        name: &str,
        args: &[Value],
    ) -> Result<Value, EvalError> {
        let ctx = self.context();
        ctx.apply_builtin_by_name(name, args)
    }
}

impl Default for Evaluator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::rune::parse;

    #[test]
    fn test_eval_literal_number() {
        let mut eval = Evaluator::new();
        let stmts = parse("42").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(42.0));
    }

    #[test]
    fn test_eval_arithmetic() {
        let mut eval = Evaluator::new();

        // Simple addition in math block
        let stmts = parse("[2 + 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(5.0));

        // Multiplication in math block
        let stmts = parse("[4 * 5]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(20.0));

        // Complex expression with precedence
        let stmts = parse("[2 + 3 * 4]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(14.0)); // Respects precedence

        // Division in math block
        let stmts = parse("[10 / 2]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(5.0));

        // Power in math block
        let stmts = parse("[2 ^ 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(8.0));

        // Modulo in math block
        let stmts = parse("[10 % 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(1.0));
    }

    #[test]
    fn test_eval_array_literal() {
        let mut eval = Evaluator::new();
        let stmts = parse("[1, 2, 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();

        match result {
            Value::Array(arr) => {
                assert_eq!(arr.len(), 3);
                assert_eq!(arr[0], Value::Float(1.0));
                assert_eq!(arr[1], Value::Float(2.0));
                assert_eq!(arr[2], Value::Float(3.0));
            }
            _ => panic!("Expected array value"),
        }
    }

    #[test]
    fn test_eval_array_operations() {
        let mut eval = Evaluator::new();

        // Array addition (element-wise) in math block
        let stmts = parse("[[1, 2, 3] + [4, 5, 6]]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();

        match result {
            Value::Array(arr) => {
                assert_eq!(arr.len(), 3);
                assert_eq!(arr[0], Value::Float(5.0));
                assert_eq!(arr[1], Value::Float(7.0));
                assert_eq!(arr[2], Value::Float(9.0));
            }
            _ => panic!("Expected array value"),
        }
    }

    #[test]
    fn test_eval_semantic_prefix() {
        let mut eval = Evaluator::new();

        // Set semantic variable
        eval.set_semantic('T', "Gf8", Value::Float(2.5));

        // Evaluate semantic expression in math block
        let stmts = parse("[T:Gf8 * 3]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(7.5));
    }

    #[test]
    fn test_eval_variables() {
        let mut eval = Evaluator::new();

        // Set variable
        eval.set_var("x", Value::Float(10.0));

        // Use in expression within math block
        let stmts = parse("[x + 5]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(15.0));
    }

    #[test]
    fn test_eval_nested_math() {
        let mut eval = Evaluator::new();

        // Math block with nested operations
        let stmts = parse("[[3, 3, 3] * [2, 2, 2]]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();

        match result {
            Value::Array(arr) => {
                assert_eq!(arr.len(), 3);
                assert_eq!(arr[0], Value::Float(6.0));
                assert_eq!(arr[1], Value::Float(6.0));
                assert_eq!(arr[2], Value::Float(6.0));
            }
            _ => panic!("Expected array value"),
        }
    }

    #[test]
    fn test_eval_comparison() {
        let mut eval = Evaluator::new();

        // Comparisons work with RuneOp outside math blocks
        let stmts = parse("5 > 3").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("2 = 2").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));
    }

    #[test]
    fn test_eval_unary_minus() {
        let mut eval = Evaluator::new();

        // Unary minus in math block
        let stmts = parse("[-5]").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Float(-5.0));
    }

    #[test]
    fn test_eval_comparison_operators() {
        let mut eval = Evaluator::new();

        // Test less than or equal
        let stmts = parse("3 <= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("5 <= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("7 <= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(false));

        // Test greater than or equal
        let stmts = parse("5 >= 3").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("5 >= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(true));

        let stmts = parse("3 >= 5").unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        assert_eq!(result, Value::Bool(false));
    }

    #[test]
    fn test_eval_builtin_by_name() {
        let eval = Evaluator::new();
        let a = crate::rune::hydron::values::Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let b = crate::rune::hydron::values::Value::Vec8([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        // Use static method eval_builtin_by_name to invoke S7Distance
        let result = eval.eval_builtin_by_name("S7Distance", &[a.clone(), b.clone()]).unwrap();
        assert!(matches!(result, crate::rune::hydron::values::Value::Scalar(_)));

        // Slerp interception
        let t = crate::rune::hydron::values::Value::Scalar(0.5);
        let interp = eval
            .eval_builtin_by_name("S7Slerp", &[a.clone(), b.clone(), t])
            .unwrap();
        assert!(matches!(interp, crate::rune::hydron::values::Value::Vec8(_)));
    }

    #[test]
    fn test_parse_typed_and_eval() {
        let mut eval = Evaluator::new();
        // parse typed statement
        let typed = crate::rune::parse_typed("[2 + 3]").unwrap();
        assert_eq!(typed.len(), 1);
        if let crate::rune::ast::StmtTyped::Expr(te) = &typed[0] {
            // Type should be Scalar
            assert_eq!(te.r#type, crate::rune::ast::RuneType::Scalar);
            let result = eval.eval_typed_stmt(&typed[0]).unwrap();
            assert_eq!(result, crate::rune::hydron::values::Value::Float(5.0));
        } else {
            panic!("Expected typed expr");
        }
    }

    #[test]
    fn test_eval_transform_builtin_slerp() {
        let mut eval = Evaluator::new();
        let script = "S7Slerp ~ [[1,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0], 0.5]";
        let stmts = crate::rune::parse(script).unwrap();
        let result = eval.eval_stmt(&stmts[0]).unwrap();
        // Expect Vec8 result
        assert!(matches!(result, crate::rune::hydron::values::Value::Vec8(_)));
    }
}

File: hydron\mod.rs
===================
//! Hydron - E8 Geometric Mathematics Engine
//!
//! Pure mathematical implementations of E8 lattice geometry with multi-geometric layers:
//! - Fisher information geometry (statistical manifolds)
//! - Symplectic T*E8 geometry (Hamiltonian dynamics)
//! - Hyperbolic H8 geometry (Poincaré ball model)
//! - Topological analysis (persistent homology)
//! - Lorentzian geometry (spacetime metrics)
//! - Quaternion algebra (rotations, SLERP)
//! - Spherical S7 geometry (unit sphere)
//!
//! All modules provide pure geometric operations. Application-specific extensions
//! (e.g., causal DAGs, event systems) are clearly separated.
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

#[cfg(feature = "cuda")]
pub mod cuda;
pub mod eval;
pub mod perception;
pub mod topology;
pub mod values;

// Re-export the hydron-core crate's math modules when the feature is enabled.
// This keeps the Rune crate's public API stable while the actual math is
// implemented in the `hydron-core` crate.
#[cfg(feature = "hydron")]
pub use hydron_core::{
    FisherLayer, Gf8, Gf8Tensor, HyperbolicLayer, LorentzianCausalLayer, LorentzianLayer,
    PersistencePair, QuaternionOps, SpacetimePoint, SphericalLayer, SymplecticLayer,
    TopologicalLayer, intrinsics_for_f32_width,
};

// When hydron feature is disabled, keep local types for the evaluator and values as-is.
// Re-export the runtime value types so code can always import `crate::rune::hydron::Value`.
pub use crate::rune::hydron::values::{EvalContext, EvalError, Octonion, Value};

File: hydron\topology.rs
========================
//! E8 Topology & Weyl Group Operations.
//!
//! # Hydron – Topology Module
//! ▫~•◦------------------------‣
//!
//! Provides adjacency (kissing) relations, Weyl reflections, and simple diffusion over
//! the E8 root lattice. Uses the static root table from hydron-core.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use hydron_core::get_e8_roots;

/// Returns the indices of the 56 nearest neighbors in the E8 lattice.
/// Roots are neighbors if their dot product is approximately 0.5 (60 degrees).
pub fn get_neighbors(root_idx: usize) -> Vec<u8> {
    let roots = get_e8_roots();
    if root_idx >= roots.len() {
        return vec![];
    }
    let target = roots[root_idx];
    let mut neighbors = Vec::with_capacity(56);

    for (i, root) in roots.iter().enumerate() {
        if i == root_idx {
            continue;
        }
        let dot: f32 = target.iter().zip(root.iter()).map(|(a, b)| a * b).sum();
        if (dot - 0.5).abs() < 1e-4 {
            neighbors.push(i as u8);
        }
    }
    neighbors
}

/// Performs a Weyl reflection of a vector `v` across the hyperplane orthogonal to root `r`.
/// Formula (unit roots): v' = v - 2 * <v, r> * r
pub fn weyl_reflect(vec: &[f32; 8], mirror_root: &[f32; 8]) -> [f32; 8] {
    let dot: f32 = vec.iter().zip(mirror_root.iter()).map(|(a, b)| a * b).sum();
    let mut result = [0.0; 8];
    for i in 0..8 {
        result[i] = vec[i] - 2.0 * dot * mirror_root[i];
    }
    result
}

/// Diffuse energy over the E8 lattice (swarm/attention style).
/// Keeps source energy and adds a fraction to neighbors.
pub fn diffuse_energy(energy: &[f32; 240], diffusion_rate: f32) -> [f32; 240] {
    let _roots = get_e8_roots();
    let mut new_field = *energy;

    for i in 0..240 {
        let e = energy[i];
        if e <= 1e-6 {
            continue;
        }
        let neighbors = get_neighbors(i);
        if neighbors.is_empty() {
            continue;
        }
        let flow = e * diffusion_rate;
        let flow_per = flow / neighbors.len() as f32;
        for n in neighbors {
            new_field[n as usize] += flow_per;
        }
    }

    new_field
}

File: parts\arrays.rs
=====================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;

#[cfg(not(feature = "hydron"))]
pub fn arrays() {
    println!("Hydron feature required for dynamic arrays");
}

#[cfg(feature = "hydron")]
pub fn arrays() {
    // Dynamic Array (Strings)
    let tags = Value::Array(vec![
        Value::String("admin".to_string()),
        Value::String("ops".to_string()),
        Value::String("dev".to_string()),
    ]);
    let out = encode_default(&tags).unwrap();
    println!("tags[3]: {out}");

    // Dynamic Array (Numbers)
    let nums = Value::Array(vec![
        Value::Integer(1),
        Value::Integer(2),
        Value::Integer(3),
        Value::Integer(4),
        Value::Integer(5),
    ]);
    let out = encode_default(&nums).unwrap();
    println!("\nnums[5]: {out}");

    // Dynamic Array (Mixed)
    let mixed = Value::Array(vec![
        Value::String("x".to_string()),
        Value::String("y".to_string()),
        Value::Bool(true),
        Value::Integer(10),
    ]);
    let out = encode_default(&mixed).unwrap();
    println!("\ndata[4]: {out}");
}

File: parts\arrays_of_arrays.rs
===============================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn arrays_of_arrays() {
    println!("Hydron feature required for dynamic arrays of arrays");
}

#[cfg(feature = "hydron")]
pub fn arrays_of_arrays() {
    // Dynamic Arrays of Arrays (Integers)
    let pair1 = Value::Array(vec![Value::Integer(1), Value::Integer(2)]);
    let pair2 = Value::Array(vec![Value::Integer(3), Value::Integer(4)]);
    let pairs_array = Value::Array(vec![pair1, pair2]);

    let mut pairs_map = HashMap::new();
    pairs_map.insert("pairs".to_string(), pairs_array);
    let pairs = Value::Map(pairs_map);

    let out = encode_default(&pairs).unwrap();
    println!("{out}");

    // Dynamic Arrays of Arrays (Strings)
    let spair1 = Value::Array(vec![
        Value::String("a".to_string()),
        Value::String("b".to_string()),
    ]);
    let spair2 = Value::Array(vec![
        Value::String("c".to_string()),
        Value::String("d".to_string()),
    ]);
    let spairs_array = Value::Array(vec![spair1, spair2]);

    let mut spairs_map = HashMap::new();
    spairs_map.insert("pairs".to_string(), spairs_array);
    let string_pairs = Value::Map(spairs_map);

    let out = encode_default(&string_pairs).unwrap();
    println!("\n{out}");

    // Dynamic Matrix
    let row1 = Value::Array(vec![
        Value::Float(1.0),
        Value::Float(2.0),
        Value::Float(3.0),
    ]);
    let row2 = Value::Array(vec![
        Value::Float(4.0),
        Value::Float(5.0),
        Value::Float(6.0),
    ]);
    let row3 = Value::Array(vec![
        Value::Float(7.0),
        Value::Float(8.0),
        Value::Float(9.0),
    ]);
    let matrix_array = Value::Array(vec![row1, row2, row3]);

    let mut matrix_map = HashMap::new();
    matrix_map.insert("matrix".to_string(), matrix_array);
    let matrix = Value::Map(matrix_map);

    let out = encode_default(&matrix).unwrap();
    println!("\n{out}");
}

File: parts\decode_strict.rs
============================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{DecodeOptions, decode};

#[cfg(not(feature = "hydron"))]
pub fn decode_strict() {
    println!("Hydron feature required for dynamic decode strict");
}

#[cfg(feature = "hydron")]
pub fn decode_strict() {
    // Malformed: header says 2 rows, but only 1 provided
    let malformed = "items[2]{id,name}:\n  1,Ada";

    let opts = DecodeOptions::new().with_strict(true);
    match decode::<Value>(malformed, &opts) {
        Ok(val) => println!("Unexpectedly decoded: {:?}", val),
        Err(err) => println!("Strict decode error: {err}"),
    }
}

File: hydron\perception.rs
==========================
/* src/rune/hydron/perception.rs */
//! Perception Engine: Signal (ByteLex) and Structure (Morphology) analysis.
//!
//! # Hydron – Perception Module
//!▫~•◦--------------------------‣
//!
//! This module provides the core mechanisms to convert raw text into geometric vectors
//! based on two distinct properties within the RUNE ecosystem, using zero external dependencies:
//!
//! 1.  **Signal (The Body):** Raw byte-level convolution using deterministic hashing.
//!     Captures "shape", typos, and non-linguistic patterns. Implemented via `signal_encode`.
//! 2.  **Structure (The Skeleton):** Morphological decomposition (Prefix/Root/Suffix).
//!     Captures linguistic logic and semantic composition. Implemented via `morph_analyze`.
//!
//! These vectors are designed to be fused (via `/\`) to create a lossless,
//! holographic embedding of the input.
//!
//! ### Key Capabilities
//! - **Signal Encoding:** Deterministic byte-stream convolution into normalized 8D vectors.
//! - **Morphological Analysis:** Greedy affix decomposition into geometric representations.
//! - **Root Recognition:** Common root validation against a curated lexicon for semantic anchoring.
//! - **Zero Dependencies:** All logic implemented using const-time hashing and static affix tables.
//!
//! ### Architectural Notes
//! This module is designed for integration with the broader RUNE/Hydron geometry pipeline.
//! Vectors produced here are normalized to the unit sphere (S7-compatible) and can be
//! composed using geometric algebra operations.
//!
//! ### Example
//! ```rust
//! use rune_format::rune::hydron::perception::{signal_encode, morph_analyze};
//!
//! let bytes = b"unbelievably";
//! let signal_vec = signal_encode(bytes);
//! let morph_vec = morph_analyze("unbelievably");
//!
//! // Both vectors are normalized and ready for geometric composition.
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

// --- 1. STATIC DATA (The Skeleton) ---
// High-coverage English affixes ported from the original lexicon architecture.
// These allow the engine to "see" word structure without a dictionary.

/// Comprehensive prefix table for morphological decomposition.
/// Ordered alphabetically for binary search compatibility.
/// Includes productive derivational and inflectional prefixes from Latin, Greek, and Germanic roots.
static PREFIXES: &[&str] = &[
    "a", "ab", "abs", "ac", "ad", "af", "ag", "al", "am", "an", "ante", "anti", "ap", "apo",
    "arch", "as", "at", "auto", "be", "bi", "bio", "cata", "circum", "cis", "co", "col", "com",
    "con", "contra", "cor", "counter", "de", "deca", "deci", "demi", "di", "dia", "dif", "dis",
    "down", "duo", "dys", "e", "ec", "eco", "ecto", "ef", "electro", "em", "en", "endo", "epi",
    "equi", "ex", "exo", "extra", "fore", "geo", "hemi", "hetero", "hexa", "homo", "hydro",
    "hyper", "hypo", "il", "im", "in", "infra", "inter", "intra", "intro", "ir", "iso", "kilo",
    "macro", "mal", "mega", "meta", "micro", "mid", "milli", "mini", "mis", "mono", "multi",
    "nano", "neo", "neuro", "non", "ob", "oc", "oct", "octa", "of", "omni", "op", "ortho", "out",
    "over", "paleo", "pan", "para", "penta", "per", "peri", "photo", "poly", "post", "pre",
    "preter", "pro", "proto", "pseudo", "pyro", "quadr", "quasi", "re", "retro", "self", "semi",
    "sept", "sex", "sub", "suc", "suf", "sug", "sum", "sup", "super", "sur", "sus", "sym", "syn",
    "tele", "tetra", "thermo", "trans", "tri", "twi", "ultra", "un", "under", "uni", "up", "vice",
];

/// Comprehensive suffix table for morphological decomposition.
/// Ordered alphabetically for binary search compatibility.
/// Includes productive derivational and inflectional suffixes across major word classes.
static SUFFIXES: &[&str] = &[
    "able",
    "ably",
    "ac",
    "aceous",
    "acious",
    "age",
    "al",
    "algia",
    "an",
    "ance",
    "ancy",
    "ant",
    "ar",
    "ard",
    "ary",
    "ase",
    "ate",
    "ation",
    "ative",
    "ator",
    "atory",
    "cide",
    "cracy",
    "crat",
    "cy",
    "dom",
    "dox",
    "ed",
    "ee",
    "eer",
    "en",
    "ence",
    "ency",
    "ent",
    "eous",
    "er",
    "ern",
    "ery",
    "es",
    "ese",
    "esque",
    "ess",
    "est",
    "etic",
    "ette",
    "ful",
    "fy",
    "gen",
    "genic",
    "gon",
    "gram",
    "graph",
    "graphy",
    "hood",
    "ia",
    "ial",
    "ian",
    "iasis",
    "iatric",
    "iatry",
    "ible",
    "ibly",
    "ic",
    "ical",
    "ically",
    "ice",
    "ician",
    "ics",
    "id",
    "ide",
    "ie",
    "ier",
    "iferous",
    "ific",
    "ification",
    "ify",
    "ile",
    "ine",
    "ing",
    "ion",
    "ior",
    "ious",
    "ish",
    "ism",
    "ist",
    "istic",
    "ite",
    "itis",
    "itive",
    "ity",
    "ium",
    "ive",
    "ize",
    "kin",
    "less",
    "let",
    "like",
    "ling",
    "logue",
    "logy",
    "ly",
    "lysis",
    "lyte",
    "lytic",
    "man",
    "mancy",
    "mania",
    "ment",
    "meter",
    "metry",
    "most",
    "ness",
    "oid",
    "ology",
    "oma",
    "or",
    "ory",
    "ose",
    "osis",
    "ous",
    "path",
    "pathy",
    "ped",
    "phage",
    "phagy",
    "phile",
    "philia",
    "phobe",
    "phobia",
    "phone",
    "phony",
    "phyte",
    "plasty",
    "pod",
    "polis",
    "proof",
    "ry",
    "s",
    "scope",
    "scopy",
    "sect",
    "ship",
    "sion",
    "sis",
    "some",
    "sophy",
    "ster",
    "th",
    "tion",
    "tomy",
    "tor",
    "tous",
    "trix",
    "tron",
    "tude",
    "ty",
    "ular",
    "ule",
    "ure",
    "ward",
    "wards",
    "wise",
    "woman",
    "worthy",
    "y",
    "yer",
];

/// Common etymological roots for semantic anchoring.
/// These high-frequency roots provide validation and boost morphological confidence.
/// Organized by semantic domain for future extensibility.
///
/// **Design Rationale:**
/// Rather than storing all possible roots (which would balloon the binary), we include
/// productive roots that appear across multiple derived forms. This allows the morphology
/// engine to recognize when a decomposition has landed on a "real" root vs. arbitrary residue.
static ROOTS: &[&str] = &[
    // --- Motion & Position ---
    "cede", "ceed", "cess", "cur", "curr", "curs", "duc", "duct", "fer", "gress", "ject", "miss",
    "mit", "mov", "mot", "pass", "ped", "pod", "port", "pos", "puls", "sequ", "spec", "spect",
    "sta", "stat", "tend", "tens", "tent", "tract", "vene", "vent", "vert", "vers", "via", "voy",
    // --- Perception & Cognition ---
    "audi", "audit", "cept", "ceive", "cogn", "cred", "dic", "dict", "log", "mem", "ment", "not",
    "path", "pens", "phon", "pict", "sci", "scrib", "script", "sens", "sent", "sign", "soph",
    "spec", "vid", "vis", // --- Action & Creation ---
    "cre", "creat", "fac", "fact", "fect", "fic", "fig", "form", "gen", "oper", "plic", "ply",
    "pon", "pos", "scrib", "struct", "tain", "ten", "volv",
    // --- Communication & Expression ---
    "claim", "clam", "loqu", "locut", "nounce", "nunce", "parl", "phan", "phone", "voc", "voic",
    "voke", // --- Measurement & Science ---
    "centr", "chron", "cycl", "dyna", "graph", "gram", "hydr", "log", "metr", "meter", "morph",
    "nym", "phys", "scop", "sphere", "techn", "therm", // --- Social & Legal ---
    "civ", "dem", "jud", "jur", "jus", "leg", "liber", "poli", "polit", "popul", "reg", "soci",
    // --- Life & Nature ---
    "anim", "anthrop", "bio", "corp", "geo", "herb", "viv", "zoo",
    // --- Emotion & Value ---
    "am", "amor", "bene", "bon", "fort", "grat", "mal", "magn", "misc", "pac", "pat", "phil",
    "vict", "vinc", // --- Quantity & Relation ---
    "equ", "fin", "fract", "frag", "grad", "gress", "medi", "min", "mit", "multi", "nom", "plen",
    "plu", "plus", "simil", "sing", "sol", "uni", "vac", "van", "void",
    // --- Time & Change ---
    "aev", "chron", "dur", "gener", "nov", "prim", "temp", "vest",
    // --- Quality & State ---
    "acer", "acr", "acu", "alb", "alt", "clar", "dign", "dur", "firm", "fort", "grav", "lev",
    "liber", "lucid", "nigr", "prob", "purg", "sacr", "san", "satis", "secur", "serv", "sever",
    "simpl", "stabil", "strict", "triv", "turb", "urb", "util", "vag", "val", "var", "ver",
    "vigil",
];

// --- 2. MATH KERNEL (Deterministic Hashing) ---

/// SplitMix64: Fast, dependency-free pseudo-random hashing.
/// Used to project arbitrary bytes into the 8D geometric space deterministically.
///
/// # Invariants
/// - Same input always produces same output (deterministic).
/// - Output has high avalanche properties (single-bit changes propagate).
///
/// # Arguments
/// * `x` - Seed value for the hash.
///
/// # Returns
/// * `u64` - The hashed value.
#[inline]
const fn splitmix64(mut x: u64) -> u64 {
    x = x.wrapping_add(0x9E3779B97F4A7C15);
    let mut z = x;
    z = (z ^ (z >> 30)).wrapping_mul(0xBF58476D1CE4E5B9);
    z = (z ^ (z >> 27)).wrapping_mul(0x94D049BB133111EB);
    z ^ (z >> 31)
}

/// Map a hash seed to a unit float within [-0.5, 0.5).
/// This centers the signal around the origin, ideal for geometric composition.
///
/// # Arguments
/// * `seed` - The hash seed to convert.
///
/// # Returns
/// * `f32` - A floating-point value in the range [-0.5, 0.5).
#[inline]
fn hash_to_float(seed: u64) -> f32 {
    let bits = splitmix64(seed);
    let as_f64 = (bits >> 11) as f64 * (1.0 / (1u64 << 53) as f64);
    (as_f64 as f32) - 0.5
}

// --- 3. SIGNAL ENCODING (The Body) ---

/// Encodes raw bytes into an 8D semantic vector using strided convolution.
///
/// This function treats the byte stream as a continuous signal, applying a local
/// convolution window and pooling the result into a normalized vector. Each byte
/// contributes to all 8 dimensions based on its value and position, creating a
/// holographic representation of the input.
///
/// # Algorithmic Details
/// - **Window Size:** Minimum of 4 or the input length, providing local context.
/// - **Position Encoding:** Modulo-based positional hashing ensures location-awareness.
/// - **Normalization:** Result is projected onto the unit sphere (L2 norm = 1.0).
///
/// # Arguments
/// * `bytes` - The raw input byte stream.
///
/// # Returns
/// * `[f32; 8]` - The normalized signal vector. Returns zero vector for empty input.
#[inline]
pub fn signal_encode(bytes: &[u8]) -> [f32; 8] {
    if bytes.is_empty() {
        return [0.0; 8];
    }

    let mut signal = [0.0f32; 8];
    let window_size = 4.min(bytes.len());

    for (i, &b) in bytes.iter().enumerate() {
        for dim in 0..8 {
            let seed = (b as u64)
                .wrapping_mul(31)
                .wrapping_add(dim as u64)
                .wrapping_add((i % window_size) as u64 * 1024);

            let val = hash_to_float(seed);
            signal[dim] += val;
        }
    }

    let norm_sq: f32 = signal.iter().map(|x| x * x).sum();
    if norm_sq > 1e-9 {
        let inv_norm = 1.0 / norm_sq.sqrt();
        for x in &mut signal {
            *x *= inv_norm;
        }
    }

    signal
}

// --- 4. STRUCTURE ANALYSIS (The Skeleton) ---

/// Validate if a potential root exists in the known root lexicon.
/// Uses binary search for O(log n) lookup.
///
/// # Arguments
/// * `candidate` - The root candidate to validate.
///
/// # Returns
/// * `bool` - True if the candidate is a recognized root.
#[inline]
fn is_valid_root(candidate: &str) -> bool {
    ROOTS.iter().any(|&r| r == candidate)
}

/// Analyze string morphology and return a structural hash vector.
///
/// This function decomposes a token into `<prefix>`, `<root>`, `<suffix>` using a
/// greedy longest-match algorithm against static affix tables. The root is validated
/// against a curated lexicon to ensure semantic anchoring. Each component is then
/// hashed into an 8D vector space with distinct seed offsets to prevent collisions.
///
/// # Enhanced Root Recognition
/// After affix stripping, the remaining root is checked against `ROOTS`. If the root
/// is unrecognized but longer than 3 characters, the algorithm attempts progressive
/// suffix stripping to find a valid root kernel. This handles cases like:
/// - "believe" → valid root (recognized)
/// - "believing" → "believ" + "ing" → fallback checks "belie", "beli", "bel" until match or exhaustion
///
/// # Arguments
/// * `token` - The input token to analyze.
///
/// # Returns
/// * `[f32; 8]` - The normalized morphology vector.
#[inline]
pub fn morph_analyze(token: &str) -> [f32; 8] {
    let clean = token
        .trim_matches(|c: char| !c.is_alphanumeric())
        .to_lowercase();

    if clean.is_empty() {
        return [0.0; 8];
    }

    let mut prefix = "";
    let mut suffix = "";
    let mut root = clean.as_str();

    // Identify prefix (greedy longest match)
    for &p in PREFIXES {
        if root.starts_with(p) && root.len() > p.len() + 2 {
            if p.len() > prefix.len() {
                prefix = p;
            }
        }
    }

    if !prefix.is_empty() {
        root = &root[prefix.len()..];
    }

    // Identify suffix (greedy longest match)
    for &s in SUFFIXES {
        if root.ends_with(s) && root.len() > s.len() + 2 {
            if s.len() > suffix.len() {
                suffix = s;
            }
        }
    }

    if !suffix.is_empty() {
        root = &root[..root.len() - suffix.len()];
    }

    // Root validation & progressive kernel extraction
    if !is_valid_root(root) && root.len() > 3 {
        // Attempt progressive stripping to find a valid root kernel
        // Example: "running" → root "run" after "n" → "ing" decomposition
        let mut candidate = root;
        while candidate.len() > 2 {
            if is_valid_root(candidate) {
                root = candidate;
                break;
            }
            // Strip one character from the end
            candidate = &candidate[..candidate.len() - 1];
        }
    }

    // Hash the components into the 8D vector
    let mut vec = [0.0f32; 8];

    let components = [
        (prefix, 100u64), // Prefix offset
        (root, 0u64),     // Root offset
        (suffix, 200u64), // Suffix offset
    ];

    for (str_part, seed_offset) in components {
        if str_part.is_empty() {
            continue;
        }

        for (i, &b) in str_part.as_bytes().iter().enumerate() {
            for dim in 0..8 {
                let seed = (b as u64)
                    .wrapping_add(dim as u64)
                    .wrapping_add(i as u64 * 31)
                    .wrapping_add(seed_offset);

                vec[dim] += hash_to_float(seed);
            }
        }
    }

    let norm_sq: f32 = vec.iter().map(|x| x * x).sum();
    if norm_sq > 1e-9 {
        let inv_norm = 1.0 / norm_sq.sqrt();
        for x in &mut vec {
            *x *= inv_norm;
        }
    }

    vec
}

#[cfg(test)]
mod tests {
    use super::{hash_to_float, is_valid_root, morph_analyze, signal_encode, splitmix64};

    #[test]
    fn test_signal_encode_determinism() {
        let input = b"hello world";
        let v1 = signal_encode(input);
        let v2 = signal_encode(input);
        assert_eq!(v1, v2, "Signal encoding must be deterministic");

        let v3 = signal_encode(b"hello worl");
        let dot: f32 = v1.iter().zip(v3.iter()).map(|(a, b)| a * b).sum();
        assert!(
            dot > 0.8,
            "Similar strings should have high signal correlation"
        );
        assert!(dot < 0.9999, "Distinct strings should not be identical");
    }

    #[test]
    fn test_signal_encode_empty_input() {
        let vec = signal_encode(b"");
        assert_eq!(vec, [0.0; 8], "Empty input should produce zero vector");
    }

    #[test]
    fn test_signal_encode_normalization() {
        let vec = signal_encode(b"test");
        let norm: f32 = vec.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!(
            (norm - 1.0).abs() < 1e-5,
            "Signal vector must be normalized"
        );
    }

    #[test]
    fn test_morph_analyze_decomposition() {
        let v1 = morph_analyze("unbelievably");
        let v2 = morph_analyze("believer");

        let dot: f32 = v1.iter().zip(v2.iter()).map(|(a, b)| a * b).sum();
        assert!(
            dot > 0.0,
            "Shared roots should produce positive correlation"
        );
    }

    #[test]
    fn test_morph_analyze_affix_handling() {
        let v_redo = morph_analyze("redo");
        let v_do = morph_analyze("do");

        assert_ne!(v_redo, v_do, "Prefix presence should alter the vector");
    }

    #[test]
    fn test_morph_analyze_empty_input() {
        let vec = morph_analyze("");
        assert_eq!(vec, [0.0; 8], "Empty input should produce zero vector");
    }

    #[test]
    fn test_morph_analyze_normalization() {
        let vec = morph_analyze("testing");
        let norm: f32 = vec.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!(
            (norm - 1.0).abs() < 1e-5,
            "Morphology vector must be normalized"
        );
    }

    #[test]
    fn test_morph_analyze_non_alphanumeric() {
        let vec1 = morph_analyze("test!");
        let vec2 = morph_analyze("test");
        assert_eq!(
            vec1, vec2,
            "Non-alphanumeric trimming should produce identical vectors"
        );
    }

    #[test]
    fn test_root_validation() {
        assert!(is_valid_root("dict"), "Known root 'dict' should validate");
        assert!(is_valid_root("spec"), "Known root 'spec' should validate");
        assert!(!is_valid_root("xyz123"), "Unknown root should not validate");
    }

    #[test]
    fn test_progressive_root_extraction() {
        // This is an implicit test via morph_analyze behavior
        // If we had "dictating" it should find root "dict"
        let _vec = morph_analyze("dictating");
        // The internal logic should strip "ing", leaving "dictat",
        // then progressively strip to find "dict" as a valid root
    }

    #[test]
    fn test_hash_to_float_range() {
        for seed in 0..1000 {
            let val = hash_to_float(seed);
            assert!(
                val >= -0.5 && val < 0.5,
                "hash_to_float must produce values in [-0.5, 0.5)"
            );
        }
    }

    #[test]
    fn test_splitmix64_determinism() {
        let seed = 42;
        let h1 = splitmix64(seed);
        let h2 = splitmix64(seed);
        assert_eq!(h1, h2, "splitmix64 must be deterministic");
    }

    #[test]
    fn test_splitmix64_avalanche() {
        let h1 = splitmix64(0);
        let h2 = splitmix64(1);
        assert_ne!(h1, h2, "splitmix64 must have avalanche properties");
    }
}

File: parts\delimiters.rs
=========================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{Delimiter, EncodeOptions, encode};
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn delimiters() {
    println!("Hydron feature required for dynamic delimiters");
}

#[cfg(feature = "hydron")]
pub fn delimiters() {
    // Dynamic Data
    let mut item1 = HashMap::new();
    item1.insert("sku".to_string(), Value::String("A1".to_string()));
    item1.insert("name".to_string(), Value::String("Widget".to_string()));
    item1.insert("qty".to_string(), Value::Integer(2));
    item1.insert("price".to_string(), Value::Float(9.99));

    let mut item2 = HashMap::new();
    item2.insert("sku".to_string(), Value::String("B2".to_string()));
    item2.insert("name".to_string(), Value::String("Gadget".to_string()));
    item2.insert("qty".to_string(), Value::Integer(1));
    item2.insert("price".to_string(), Value::Float(14.5));

    let items_array = Value::Array(vec![Value::Map(item1), Value::Map(item2)]);

    let mut data_map = HashMap::new();
    data_map.insert("items".to_string(), items_array);
    let data = Value::Map(data_map);

    // Tab delimiter (\t)
    let tab = encode(&data, &EncodeOptions::new().with_delimiter(Delimiter::Tab)).unwrap();
    println!("{tab}");

    // Pipe delimiter (|)
    let pipe = encode(&data, &EncodeOptions::new().with_delimiter(Delimiter::Pipe)).unwrap();
    println!("\n{pipe}");
}

File: hydron\values.rs
======================
//! RUNE Evaluation Engine - Runtime Value System
//!
//! Provides runtime evaluation for RUNE expressions, including:
//! - E8 geometric types (vectors, octonions)
//! - GF(8) Galois field arithmetic
//! - Context-aware evaluation based on root declarations
//! - Built-in operations that bridge RUNE into Hydron geometry layers
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use serde::{Deserialize, Serialize};
use std::collections::{HashMap, hash_map::Entry};
use std::fmt;
use std::sync::{Arc, Mutex, OnceLock};
use thiserror::Error;

// Hydron geometry layers from hydron-core
use hydron_core::{
    FisherLayer, Gf8, HyperbolicLayer, LorentzianCausalLayer, QuaternionOps, SpacetimePoint,
    SphericalLayer, SymplecticLayer, TopologicalLayer, gf8,
};

// Local SIMD implementations (fallback when feature is disabled)
pub fn gf8_add_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    // Simple scalar implementation
    let mut result = [0.0f32; 8];
    for i in 0..8 {
        result[i] = a[i] + b[i];
    }
    result
}

pub fn gf8_sub_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    // Simple scalar implementation
    let mut result = [0.0f32; 8];
    for i in 0..8 {
        result[i] = a[i] - b[i];
    }
    result
}

pub fn gf8_matvec_simd(matrix: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8] {
    // Matrix-vector multiplication
    let mut result = [0.0f32; 8];
    for i in 0..8 {
        for j in 0..8 {
            result[i] += matrix[i][j] * vec[j];
        }
    }
    result
}

pub fn gf8_norm2_simd(vec: &[f32; 8]) -> f32 {
    // Squared norm
    vec.iter().map(|x| x * x).sum()
}

pub fn gf8_dot_simd(a: &[f32; 8], b: &[f32; 8]) -> f32 {
    // Dot product
    let mut sum = 0.0f32;
    for i in 0..8 {
        sum += a[i] * b[i];
    }
    sum
}

pub fn get_available_f32_256_intrinsics() -> Vec<&'static str> {
    // Return empty vec when SIMD not available
    vec![]
}

pub fn print_simd_capabilities() {
    // No-op when SIMD not available
}

use rune_hex::hex as hex_model;

/// Runtime value types in the E8 ecosystem
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
#[serde(untagged)]
pub enum Value {
    /// Boolean value
    Bool(bool),

    /// Floating-point number (for RUNE expressions)
    Float(f64),

    /// String value
    String(String),

    /// Array of values
    Array(Vec<Value>),

    /// Scalar numeric value (f32)
    Scalar(f32),

    /// 8-dimensional geometric float (canonical Gf8)
    Gf8(hydron_core::Gf8),

    /// Geo-Semantic lattice frame (allowed E8 root indices)
    Frame(Vec<u8>),

    /// Spatially indexed associative memory (E8 root -> data)
    Atlas(HashMap<u8, Vec<Value>>),

    /// Spacetime point (Lorentzian coords)
    Spacetime(SpacetimePoint),

    /// DomR result (dominant E8 roots)
    DomR(hex_model::DomR),

    /// 8-dimensional vector in E8 lattice
    Vec8([f32; 8]),

    /// 16-dimensional phase space vector (position + momentum)
    Vec16([f32; 16]),

    /// Octonion (8-dimensional non-associative algebra)
    Octonion(Octonion),

    /// Quaternion (4D rotation)
    Quaternion([f32; 4]),

    /// Symbolic reference (unevaluated)
    Symbol(String),

    /// 8x8 matrix (Fisher information, etc.)
    Matrix8x8([[f32; 8]; 8]),

    /// Betti numbers (topological invariants)
    Betti([u32; 3]),

    /// Collection of Vec8 points (for point clouds)
    PointCloud(Vec<[f32; 8]>),

    // --- Extended Types ---
    Integer(i128),
    Byte(u8),
    Char(char),
    Map(HashMap<String, Value>),
    Bytes(Vec<u8>),
    Null,
    Complex([f64; 2]),

    // Advanced Types
    BigInt(Vec<u64>),   // Arbitrary precision integer parts
    Decimal(i128, u32), // Mantissa, Scale (Decimal = m * 10^-s)

    // Structural Types
    Object(RuneObject),
    Enum(String, String, Option<Box<Value>>), // EnumName, Variant, Payload
    Union(Box<Value>),                        // Type-erased union value
    Struct(String, Vec<Value>),               // StructName, Tuple-like fields
    Tuple(Vec<Value>),
    Set(Vec<Value>), // Using Vec for set to allow non-hashable values (linear scan)

    // Functional & Async
    Function(RuneFunction),
    Lambda(RuneLambda),
    #[serde(skip)]
    Future(RuneFuture),
    #[serde(skip)]
    Stream(RuneStream),
    Promise(RunePromise),
    Coroutine(RuneCoroutine),

    // System
    Pointer(usize),
    Interface(String),            // Interface name/ID
    Class(String),                // Class name/ID
    Generic(String, Vec<String>), // Name, TypeParams

    /// Error value
    Error(String),
}

// --- Advanced Type Implementations ---

/// Glyph-capable structural algebra over runtime values.
pub trait RuneGeometric {
    /// Split-join (midpoint / meet) glyph `/\`.
    fn meet(&self, other: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Join-split (antipodal midpoint) glyph `\/`.
    fn join(&self, other: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Projection glyph `|\`.
    fn project(&self, target: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Rejection glyph `\|` (component orthogonal to target).
    fn reject(&self, target: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Universal distance glyph `|/` returning a scalar distance.
    fn distance(&self, other: &Self) -> Result<f32, EvalError>
    where
        Self: Sized;

    /// Structural match check for filtering.
    fn matches_pattern(&self, pattern: &Self) -> bool;
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct RuneObject {
    pub class: String,
    pub fields: HashMap<String, Value>,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct RuneFunction {
    pub name: String,
    pub args: Vec<String>,
    pub body: String, // AST or Bytecode reference
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct RuneLambda {
    pub captures: HashMap<String, Value>,
    pub args: Vec<String>,
    pub body: String,
}

#[derive(Debug, Clone)]
pub struct RuneFuture {
    pub id: String,
    pub state: Arc<Mutex<FutureState>>,
}

impl PartialEq for RuneFuture {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

#[derive(Debug, Clone)]
pub enum FutureState {
    Pending,
    Resolved(Value),
    Rejected(String),
}

#[derive(Debug, Clone)]
pub struct RuneStream {
    pub id: String,
    pub buffer: Arc<Mutex<Vec<Value>>>,
}

impl PartialEq for RuneStream {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RunePromise {
    pub id: String,
    // Promise is the write-side of a Future
}

impl PartialEq for RunePromise {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RuneCoroutine {
    pub id: String,
    pub pc: usize, // Program counter
}

impl PartialEq for RuneCoroutine {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

/// Octonion representation: (scalar, 7 imaginary units)
#[derive(Debug, Clone, Copy, PartialEq, Serialize, Deserialize)]
pub struct Octonion {
    pub scalar: f32,
    pub i: [f32; 7], // e1, e2, e3, e4, e5, e6, e7
}

impl Octonion {
    /// Create a new octonion
    pub fn new(scalar: f32, i: [f32; 7]) -> Self {
        Self { scalar, i }
    }

    /// Create a real octonion (pure scalar)
    pub fn real(scalar: f32) -> Self {
        Self {
            scalar,
            i: [0.0; 7],
        }
    }

    /// Octonion multiplication (non-associative!)
    ///
    /// Implements full Fano-plane based multiplication:
    /// (a0 + a·e) * (b0 + b·e) =
    ///   (a0*b0 - a·b) + (a0*b + b0*a + a × b),
    /// where a × b is the G₂-invariant 7D cross product induced by the Fano plane.
    pub fn mul(&self, other: &Octonion) -> Octonion {
        let a0 = self.scalar;
        let b0 = other.scalar;
        let a = &self.i;
        let b = &other.i;

        // Scalar part: a0*b0 - a·b
        let mut scalar = a0 * b0;
        for k in 0..7 {
            scalar -= a[k] * b[k];
        }

        // Imaginary part: a0*b + b0*a + a × b
        let mut imag = [0.0f32; 7];

        // Linear terms a0*b + b0*a
        for k in 0..7 {
            imag[k] += a0 * b[k] + b0 * a[k];
        }

        // Cross product term a × b via Fano plane structure constants
        //
        // We encode the oriented Fano triples for the imaginary units e1..e7.
        // Indices 0..6 correspond to e1..e7.
        //
        // The triples below define:
        //   e_i * e_j =  e_k  if (i,j,k) in oriented triple
        //   e_j * e_i = -e_k  (anti-commutativity)
        //
        // The chosen convention is one standard G₂ / octonion orientation:
        //   (1,2,3), (1,4,5), (1,6,7),
        //   (2,4,6), (2,5,7), (3,4,7), (3,5,6)
        const FANO_TRIPLES: &[(usize, usize, usize)] = &[
            (0, 1, 2),
            (0, 3, 4),
            (0, 5, 6),
            (1, 3, 5),
            (1, 4, 6),
            (2, 3, 6),
            (2, 4, 5),
        ];

        // Helper: product of basis elements e_(i+1) * e_(j+1)
        // Returns (scalar_part, imag_basis) where imag_basis[k] is the coefficient of e_(k+1).
        fn basis_mul(i: usize, j: usize) -> (f32, [f32; 7]) {
            debug_assert!(i < 7 && j < 7);
            if i == j {
                // e_i * e_i = -1
                return (-1.0, [0.0; 7]);
            }

            for &(a, b, c) in FANO_TRIPLES.iter() {
                // e_a * e_b =  e_c, e_b * e_a = -e_c
                if i == a && j == b {
                    let mut v = [0.0f32; 7];
                    v[c] = 1.0;
                    return (0.0, v);
                }
                if i == b && j == a {
                    let mut v = [0.0f32; 7];
                    v[c] = -1.0;
                    return (0.0, v);
                }

                // e_b * e_c =  e_a, e_c * e_b = -e_a
                if i == b && j == c {
                    let mut v = [0.0f32; 7];
                    v[a] = 1.0;
                    return (0.0, v);
                }
                if i == c && j == b {
                    let mut v = [0.0f32; 7];
                    v[a] = -1.0;
                    return (0.0, v);
                }

                // e_c * e_a =  e_b, e_a * e_c = -e_b
                if i == c && j == a {
                    let mut v = [0.0f32; 7];
                    v[b] = 1.0;
                    return (0.0, v);
                }
                if i == a && j == c {
                    let mut v = [0.0f32; 7];
                    v[b] = -1.0;
                    return (0.0, v);
                }
            }

            // This should never be reached if FANO_TRIPLES covers all oriented pairs.
            (0.0, [0.0; 7])
        }

        // Accumulate a × b via bilinearity:
        // (∑ a_i e_i) * (∑ b_j e_j) = ∑_{i,j} a_i b_j (e_i * e_j)
        // We already handled the i == j scalar contribution above,
        // so here we only need i != j and only add imaginary parts.
        for i in 0..7 {
            if a[i] == 0.0 {
                continue;
            }
            for j in 0..7 {
                if b[j] == 0.0 || i == j {
                    continue;
                }
                let (_s_part, basis_vec) = basis_mul(i, j);
                let coeff = a[i] * b[j];

                // Only imaginary contributions are expected here (_s_part is 0.0 for i != j).
                for k in 0..7 {
                    imag[k] += coeff * basis_vec[k];
                }
            }
        }

        Octonion { scalar, i: imag }
    }

    /// Conjugate of octonion
    pub fn conjugate(&self) -> Octonion {
        let mut neg_i = self.i;
        for x in &mut neg_i {
            *x = -*x;
        }
        Octonion {
            scalar: self.scalar,
            i: neg_i,
        }
    }

    /// Norm (magnitude) of octonion
    pub fn norm(&self) -> f32 {
        let mut sum = self.scalar * self.scalar;
        for &x in &self.i {
            sum += x * x;
        }
        sum.sqrt()
    }
}

impl fmt::Display for Octonion {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.scalar)?;
        for (i, &val) in self.i.iter().enumerate() {
            if val != 0.0 {
                write!(f, " + {}e{}", val, i + 1)?;
            }
        }
        Ok(())
    }
}

// Shared causal layer for Rune runtime (Value payloads)
static CAUSAL_LAYER: OnceLock<Mutex<LorentzianCausalLayer<Value>>> = OnceLock::new();

fn causal_layer() -> &'static Mutex<LorentzianCausalLayer<Value>> {
    CAUSAL_LAYER.get_or_init(|| Mutex::new(LorentzianCausalLayer::new()))
}

// Gf8 is imported from hydron-core via the module re-exports
// (see src/rune/hydron/mod.rs)

impl Value {
    /// Insert data into an Atlas at the location defined by a vector.
    pub fn atlas_insert(&mut self, key_vector: &Value, data: Value) -> Result<(), EvalError> {
        match self {
            Value::Atlas(map) => {
                let gf8 = match key_vector {
                    Value::Gf8(g) => *g,
                    Value::Vec8(v) => hydron_core::Gf8::new(*v),
                    _ => return Err(EvalError::TypeMismatch("Atlas key must be a vector".into())),
                };

                let (idx, _root) = gf8.quantize();

                match map.entry(idx) {
                    Entry::Occupied(mut e) => {
                        e.get_mut().push(data);
                    }
                    Entry::Vacant(e) => {
                        e.insert(vec![data]);
                    }
                }
                Ok(())
            }
            _ => Err(EvalError::TypeMismatch("Target is not an Atlas".into())),
        }
    }

    /// Recall data from an Atlas near the location defined by a vector.
    pub fn atlas_recall(&self, query_vector: &Value) -> Result<Value, EvalError> {
        match self {
            Value::Atlas(map) => {
                let gf8 = match query_vector {
                    Value::Gf8(g) => *g,
                    Value::Vec8(v) => hydron_core::Gf8::new(*v),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Atlas query must be a vector".into(),
                        ));
                    }
                };

                let (idx, _root) = gf8.quantize();

                if let Some(items) = map.get(&idx) {
                    Ok(Value::Array(items.clone()))
                } else {
                    Ok(Value::Array(vec![]))
                }
            }
            _ => Err(EvalError::TypeMismatch("Target is not an Atlas".into())),
        }
    }
    /// Add two values
    pub fn add(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a + b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a + b)),

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot add arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.add(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = a[i] + b[i];
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(a), Value::Gf8(b)) => {
                #[cfg(feature = "simd")]
                {
                    let result_coords = gf8::gf8_add_simd(a.coords(), b.coords());
                    Ok(Value::Gf8(Gf8::new(result_coords)))
                }
                #[cfg(not(feature = "simd"))]
                {
                    Ok(Value::Gf8(*a + *b))
                }
            }

            (Value::Octonion(a), Value::Octonion(b)) => {
                let mut result_i = [0.0f32; 7];
                for (i, result) in result_i.iter_mut().enumerate() {
                    *result = a.i[i] + b.i[i];
                }
                Ok(Value::Octonion(Octonion {
                    scalar: a.scalar + b.scalar,
                    i: result_i,
                }))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot add {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Multiply two values
    pub fn mul(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a * b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a * b)),

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot multiply arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.mul(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Scalar(s), Value::Vec8(v)) | (Value::Vec8(v), Value::Scalar(s)) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = v[i] * s;
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(a), Value::Scalar(s)) | (Value::Scalar(s), Value::Gf8(a)) => {
                Ok(Value::Gf8(*a * *s))
            }

            (Value::Octonion(a), Value::Octonion(b)) => Ok(Value::Octonion(a.mul(b))),

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot multiply {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Subtract two values
    pub fn sub(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a - b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a - b)),

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot subtract arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.sub(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = a[i] - b[i];
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(a), Value::Gf8(b)) => Ok(Value::Gf8(*a - *b)),

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot subtract {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Divide two values
    pub fn div(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Float(a / b))
            }

            (Value::Scalar(a), Value::Scalar(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Scalar(a / b))
            }

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot divide arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.div(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Vec8(v), Value::Scalar(s)) => {
                if *s == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = v[i] / s;
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(_a), Value::Gf8(_b)) => {
                // Division for geometric Gf8 not directly supported
                Err(EvalError::TypeMismatch(
                    "Division not supported for Gf8 geometric types".to_string(),
                ))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot divide {:?} by {:?}",
                self, other
            ))),
        }
    }

    /// Power operation
    pub fn pow(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a.powf(*b))),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a.powf(*b))),

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot raise {:?} to power {:?}",
                self, other
            ))),
        }
    }

    /// Modulo operation
    pub fn modulo(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Float(a % b))
            }

            (Value::Scalar(a), Value::Scalar(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Scalar(a % b))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compute {:?} mod {:?}",
                self, other
            ))),
        }
    }

    /// Geometric midpoint (type-preserving where possible).
    /// Used by the `/\` and `/|` glyphs.
    pub fn geometric_midpoint(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            // Preserve Gf8 on the spherical manifold via SLERP at t = 0.5
            (Value::Gf8(a), Value::Gf8(b)) => Ok(Value::Gf8(a.spherical_slerp(b, 0.5))),

            // Quaternion midpoint via SLERP
            (Value::Quaternion(a), Value::Quaternion(b)) => {
                Ok(Value::Quaternion(QuaternionOps::slerp(a, b, 0.5)))
            }

            // Octonion linear average (vector space)
            (Value::Octonion(a), Value::Octonion(b)) => {
                let scalar = (a.scalar + b.scalar) * 0.5;
                let mut i = [0.0; 7];
                for k in 0..7 {
                    i[k] = (a.i[k] + b.i[k]) * 0.5;
                }
                Ok(Value::Octonion(Octonion { scalar, i }))
            }

            // Vec8 midpoint
            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut res = [0.0; 8];
                for k in 0..8 {
                    res[k] = (a[k] + b[k]) * 0.5;
                }
                Ok(Value::Vec8(res))
            }

            // Vec16 midpoint
            (Value::Vec16(a), Value::Vec16(b)) => {
                let mut res = [0.0; 16];
                for k in 0..16 {
                    res[k] = (a[k] + b[k]) * 0.5;
                }
                Ok(Value::Vec16(res))
            }

            // Scalar/float midpoint returned as Scalar (geometry is f32-based)
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar((a + b) * 0.5)),
            (Value::Float(a), Value::Float(b)) => Ok(Value::Scalar((*a as f32 + *b as f32) * 0.5)),
            (Value::Scalar(a), Value::Float(b)) | (Value::Float(b), Value::Scalar(a)) => {
                Ok(Value::Scalar((*a + *b as f32) * 0.5))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compute midpoint of {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Antipodal midpoint (mean then negate). Used by `\/`.
    pub fn geometric_antipode_midpoint(&self, other: &Value) -> Result<Value, EvalError> {
        let mid = self.geometric_midpoint(other)?;
        mid.negate()
    }

    /// Project `self` onto `target` (|\ glyph).
    pub fn geometric_project(&self, target: &Value) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Gf8(v), Value::Gf8(u)) => {
                let dot = v.dot(u.coords());
                let base = *u.coords();
                Ok(Value::Vec8(base.map(|x| x * dot)))
            }
            (Value::Vec8(v), Value::Vec8(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec8([0.0; 8]));
                }
                let scale = dot / norm_sq;
                Ok(Value::Vec8((*u).map(|x| x * scale)))
            }

            (Value::Vec16(v), Value::Vec16(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec16([0.0; 16]));
                }
                let scale = dot / norm_sq;
                Ok(Value::Vec16(u.map(|x| x * scale)))
            }
            _ => Err(EvalError::TypeMismatch(format!(
                "Projection requires compatible vector types: {:?} -> {:?}",
                self, target
            ))),
        }
    }

    /// Reject `self` from `target` (component orthogonal to target). Used by `\|`.
    pub fn geometric_reject(&self, target: &Value) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Gf8(v), Value::Gf8(u)) => {
                let v_coords = *v.coords();
                let u_coords = *u.coords();
                let dot = v.dot(u.coords());
                let norm_sq: f32 = u_coords.iter().map(|x| x * x).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec8(v_coords));
                }
                let scale = dot / norm_sq;
                let mut rej = [0.0f32; 8];
                for i in 0..8 {
                    rej[i] = v_coords[i] - u_coords[i] * scale;
                }
                Ok(Value::Vec8(rej))
            }
            (Value::Vec8(v), Value::Vec8(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec8(*v));
                }
                let scale = dot / norm_sq;
                let mut rej = [0.0f32; 8];
                for i in 0..8 {
                    rej[i] = v[i] - u[i] * scale;
                }
                Ok(Value::Vec8(rej))
            }

            (Value::Vec16(v), Value::Vec16(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec16(*v));
                }
                let scale = dot / norm_sq;
                let mut rej = [0.0f32; 16];
                for i in 0..16 {
                    rej[i] = v[i] - u[i] * scale;
                }
                Ok(Value::Vec16(rej))
            }
            _ => Err(EvalError::TypeMismatch(format!(
                "Rejection requires compatible vector types: {:?} ⟂ {:?}",
                self, target
            ))),
        }
    }

    /// Geometric distance (context-aware where possible). Used by `|/`.
    pub fn geometric_distance(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            // Spherical distance for Gf8
            (Value::Gf8(a), Value::Gf8(b)) => Ok(Value::Scalar(a.spherical_distance_to(b))),

            // Euclidean distance for Vec8
            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut sum = 0.0f32;
                for i in 0..8 {
                    let d = a[i] - b[i];
                    sum += d * d;
                }
                Ok(Value::Scalar(sum.sqrt()))
            }

            // Euclidean distance for Vec16
            (Value::Vec16(a), Value::Vec16(b)) => {
                let mut sum = 0.0f32;
                for i in 0..16 {
                    let d = a[i] - b[i];
                    sum += d * d;
                }
                Ok(Value::Scalar(sum.sqrt()))
            }

            // Scalar distance (absolute difference)
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar((a - b).abs())),
            (Value::Float(a), Value::Float(b)) => Ok(Value::Scalar((*a as f32 - *b as f32).abs())),
            (Value::Scalar(a), Value::Float(b)) | (Value::Float(b), Value::Scalar(a)) => {
                Ok(Value::Scalar((*a - *b as f32).abs()))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Distance requires compatible geometric types: {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Negate a value (unary minus)
    pub fn negate(&self) -> Result<Value, EvalError> {
        match self {
            Value::Float(a) => Ok(Value::Float(-a)),
            Value::Scalar(a) => Ok(Value::Scalar(-a)),

            Value::Array(a) => {
                let mut result = Vec::new();
                for val in a.iter() {
                    result.push(val.negate()?);
                }
                Ok(Value::Array(result))
            }

            Value::Vec8(v) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = -v[i];
                }
                Ok(Value::Vec8(result))
            }

            Value::Vec16(v) => {
                let mut result = [0.0; 16];
                for i in 0..16 {
                    result[i] = -v[i];
                }
                Ok(Value::Vec16(result))
            }

            Value::Quaternion(q) => Ok(Value::Quaternion([-q[0], -q[1], -q[2], -q[3]])),

            Value::Gf8(g) => Ok(Value::Gf8(-*g)),

            Value::Octonion(o) => Ok(Value::Octonion(Octonion {
                scalar: -o.scalar,
                i: o.i.map(|x| -x),
            })),

            Value::Map(m) => {
                let mut out = HashMap::with_capacity(m.len());
                for (k, v) in m {
                    out.insert(k.clone(), v.negate()?);
                }
                Ok(Value::Map(out))
            }

            Value::Object(obj) => {
                let mut fields = HashMap::with_capacity(obj.fields.len());
                for (k, v) in &obj.fields {
                    fields.insert(k.clone(), v.negate()?);
                }
                Ok(Value::Object(RuneObject {
                    class: obj.class.clone(),
                    fields,
                }))
            }

            Value::Tuple(vals) => {
                let mut out = Vec::with_capacity(vals.len());
                for v in vals {
                    out.push(v.negate()?);
                }
                Ok(Value::Tuple(out))
            }

            Value::Struct(name, vals) => {
                let mut out = Vec::with_capacity(vals.len());
                for v in vals {
                    out.push(v.negate()?);
                }
                Ok(Value::Struct(name.clone(), out))
            }

            _ => Err(EvalError::TypeMismatch(format!("Cannot negate {:?}", self))),
        }
    }

    /// Less than comparison
    pub fn lt(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a < b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a < b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} < {:?}",
                self, other
            ))),
        }
    }

    /// Less than or equal comparison
    pub fn le(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a <= b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a <= b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} <= {:?}",
                self, other
            ))),
        }
    }

    /// Greater than comparison
    pub fn gt(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a > b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a > b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} > {:?}",
                self, other
            ))),
        }
    }

    /// Greater than or equal comparison
    pub fn ge(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a >= b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a >= b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} >= {:?}",
                self, other
            ))),
        }
    }

    /// Logical AND
    pub fn and(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Bool(a), Value::Bool(b)) => Ok(Value::Bool(*a && *b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot apply AND to {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Logical OR
    pub fn or(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Bool(a), Value::Bool(b)) => Ok(Value::Bool(*a || *b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot apply OR to {:?} and {:?}",
                self, other
            ))),
        }
    }
}

impl RuneGeometric for Value {
    /// Structural containment check: returns true if `self` matches the pattern structurally.
    /// Arrays: all elements must match any element in pattern array? Here we require same length and per-index match.
    /// Maps/Objects: pattern keys must exist in self with matching substructure.
    fn matches_pattern(&self, pattern: &Value) -> bool {
        match (self, pattern) {
            (Value::Map(m), Value::Map(p)) => {
                for (k, pv) in p {
                    if let Some(v) = m.get(k) {
                        if !v.matches_pattern(pv) {
                            return false;
                        }
                    } else {
                        return false;
                    }
                }
                true
            }
            (Value::Object(o), Value::Object(p)) => {
                if o.class != p.class {
                    return false;
                }
                for (k, pv) in &p.fields {
                    if let Some(v) = o.fields.get(k) {
                        if !v.matches_pattern(pv) {
                            return false;
                        }
                    } else {
                        return false;
                    }
                }
                true
            }
            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b || a.len() != b.len() {
                    return false;
                }
                a.iter()
                    .zip(b.iter())
                    .all(|(va, vb)| va.matches_pattern(vb))
            }
            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return false;
                }
                a.iter()
                    .zip(b.iter())
                    .all(|(va, vb)| va.matches_pattern(vb))
            }
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return false;
                }
                a.iter()
                    .zip(b.iter())
                    .all(|(va, vb)| va.matches_pattern(vb))
            }
            // Primitive equality fallback
            _ => self == pattern,
        }
    }
    fn meet(&self, other: &Self) -> Result<Value, EvalError> {
        match (self, other) {
            // Structural recursion
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in structural glyph".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.meet(vb)?);
                }
                Ok(Value::Array(out))
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in structural glyph".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.meet(vb)?);
                }
                Ok(Value::Tuple(out))
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in structural glyph".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.meet(vb)?);
                }
                Ok(Value::Struct(name_a.clone(), out))
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut out = HashMap::new();
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        out.insert(k.clone(), va.meet(vb)?);
                    }
                }
                Ok(Value::Map(out))
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot merge different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut fields = HashMap::new();
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        fields.insert(k.clone(), va.meet(vb)?);
                    }
                }
                Ok(Value::Object(RuneObject {
                    class: a.class.clone(),
                    fields,
                }))
            }

            // Leaf path
            _ => self.geometric_midpoint(other),
        }
    }

    fn join(&self, other: &Self) -> Result<Value, EvalError> {
        let mid = self.meet(other)?;
        mid.negate()
    }

    fn project(&self, target: &Self) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in projection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.project(vb)?);
                }
                Ok(Value::Array(out))
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in projection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.project(vb)?);
                }
                Ok(Value::Tuple(out))
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in projection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.project(vb)?);
                }
                Ok(Value::Struct(name_a.clone(), out))
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut out = HashMap::new();
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        out.insert(k.clone(), va.project(vb)?);
                    }
                }
                Ok(Value::Map(out))
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot project different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut fields = HashMap::new();
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        fields.insert(k.clone(), va.project(vb)?);
                    }
                }
                Ok(Value::Object(RuneObject {
                    class: a.class.clone(),
                    fields,
                }))
            }

            _ => self.geometric_project(target),
        }
    }

    fn reject(&self, target: &Self) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in rejection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.reject(vb)?);
                }
                Ok(Value::Array(out))
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in rejection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.reject(vb)?);
                }
                Ok(Value::Tuple(out))
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in rejection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.reject(vb)?);
                }
                Ok(Value::Struct(name_a.clone(), out))
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut out = HashMap::new();
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        out.insert(k.clone(), va.reject(vb)?);
                    }
                }
                Ok(Value::Map(out))
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot reject across different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut fields = HashMap::new();
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        fields.insert(k.clone(), va.reject(vb)?);
                    }
                }
                Ok(Value::Object(RuneObject {
                    class: a.class.clone(),
                    fields,
                }))
            }

            _ => self.geometric_reject(target),
        }
    }

    fn distance(&self, other: &Self) -> Result<f32, EvalError> {
        match (self, other) {
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in distance".into(),
                    ));
                }
                let mut accum = 0.0f32;
                for (va, vb) in a.iter().zip(b.iter()) {
                    accum += va.distance(vb)?;
                }
                let n = a.len() as f32;
                Ok(if n > 0.0 { accum / n } else { 0.0 })
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in distance".into(),
                    ));
                }
                let mut accum = 0.0f32;
                for (va, vb) in a.iter().zip(b.iter()) {
                    accum += va.distance(vb)?;
                }
                let n = a.len() as f32;
                Ok(if n > 0.0 { accum / n } else { 0.0 })
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in distance".into(),
                    ));
                }
                let mut accum = 0.0f32;
                for (va, vb) in a.iter().zip(b.iter()) {
                    accum += va.distance(vb)?;
                }
                let n = a.len() as f32;
                Ok(if n > 0.0 { accum / n } else { 0.0 })
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut accum = 0.0f32;
                let mut count = 0usize;
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        accum += va.distance(vb)?;
                        count += 1;
                    }
                }
                Ok(if count > 0 { accum / count as f32 } else { 0.0 })
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot measure distance across different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut accum = 0.0f32;
                let mut count = 0usize;
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        accum += va.distance(vb)?;
                        count += 1;
                    }
                }
                Ok(if count > 0 { accum / count as f32 } else { 0.0 })
            }

            _ => match self.geometric_distance(other)? {
                Value::Scalar(s) => Ok(s),
                Value::Float(f) => Ok(f as f32),
                other => Err(EvalError::TypeMismatch(format!(
                    "Distance expected scalar, got {:?}",
                    other
                ))),
            },
        }
    }
}

impl fmt::Display for Value {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Value::Bool(b) => write!(f, "{}", b),
            Value::Float(v) => write!(f, "{}", v),
            Value::String(s) => write!(f, "{}", s),
            Value::Array(arr) => {
                write!(f, "[")?;
                for (i, val) in arr.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    write!(f, "{}", val)?;
                }
                write!(f, "]")
            }
            Value::Scalar(v) => write!(f, "{}", v),
            Value::Gf8(g) => write!(f, "Gf8({})", g.to_scalar()),
            Value::Vec8(v) => write!(
                f,
                "Vec8[{}, {}, {}, {}, {}, {}, {}, {}]",
                v[0], v[1], v[2], v[3], v[4], v[5], v[6], v[7]
            ),
            Value::Vec16(v) => write!(
                f,
                "Vec16[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]",
                v[0],
                v[1],
                v[2],
                v[3],
                v[4],
                v[5],
                v[6],
                v[7],
                v[8],
                v[9],
                v[10],
                v[11],
                v[12],
                v[13],
                v[14],
                v[15]
            ),
            Value::Octonion(o) => write!(f, "{}", o),
            Value::Quaternion(q) => write!(f, "Quat[{}, {}, {}, {}]", q[0], q[1], q[2], q[3]),
            Value::Spacetime(p) => write!(
                f,
                "Spacetime[t={}, x1={}, x2={}, x3={}, x4={}, x5={}, x6={}, x7={}]",
                p.coords[0],
                p.coords[1],
                p.coords[2],
                p.coords[3],
                p.coords[4],
                p.coords[5],
                p.coords[6],
                p.coords[7]
            ),
            Value::DomR(d) => write!(
                f,
                "DomR(roots={}, scores={})",
                d.roots.len(),
                d.scores.len()
            ),
            Value::Frame(indices) => write!(f, "Frame({} indices)", indices.len()),
            Value::Atlas(map) => write!(f, "Atlas({} roots)", map.len()),
            Value::Symbol(s) => write!(f, "{}", s),
            Value::Matrix8x8(_) => write!(f, "Matrix8x8[...]"),
            Value::Betti(b) => write!(f, "Betti[{}, {}, {}]", b[0], b[1], b[2]),
            Value::PointCloud(points) => write!(f, "PointCloud[{} points]", points.len()),

            // Extended Types Display
            Value::Integer(i) => write!(f, "{}", i),
            Value::Byte(b) => write!(f, "0x{:02X}", b),
            Value::Char(c) => write!(f, "'{}'", c),
            Value::Map(m) => {
                write!(f, "{{")?;
                for (i, (k, v)) in m.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    write!(f, "{}: {}", k, v)?;
                }
                write!(f, "}}")
            }
            Value::Bytes(b) => write!(f, "Bytes[{}]", b.len()),
            Value::Null => write!(f, "null"),
            Value::Complex(c) => write!(f, "{} + {}i", c[0], c[1]),

            // Advanced Types
            Value::BigInt(parts) => write!(f, "BigInt({:?})", parts),
            Value::Decimal(m, s) => write!(f, "Decimal({}e-{})", m, s),

            // Structural
            Value::Object(obj) => write!(f, "Object({})", obj.class),
            Value::Enum(name, variant, _) => write!(f, "{}::{}", name, variant),
            Value::Union(val) => write!(f, "Union({})", val),
            Value::Struct(name, _) => write!(f, "Struct({})", name),
            Value::Tuple(vals) => write!(f, "Tuple({})", vals.len()),
            Value::Set(vals) => write!(f, "Set({})", vals.len()),

            // Functional & Async
            Value::Function(func) => write!(f, "Fn({})", func.name),
            Value::Lambda(_) => write!(f, "Lambda"),
            Value::Future(fut) => write!(f, "Future({})", fut.id),
            Value::Stream(s) => write!(f, "Stream({})", s.id),
            Value::Promise(p) => write!(f, "Promise({})", p.id),
            Value::Coroutine(c) => write!(f, "Coroutine({})", c.id),

            // System
            Value::Pointer(p) => write!(f, "Ptr(0x{:x})", p),
            Value::Interface(i) => write!(f, "Interface({})", i),
            Value::Class(c) => write!(f, "Class({})", c),
            Value::Generic(n, _) => write!(f, "Generic({})", n),

            Value::Error(e) => write!(f, "Error: {}", e),
        }
    }
}

/// Evaluation context with variable bindings and root context
#[derive(Debug, Clone)]
pub struct EvalContext {
    /// Variable bindings
    pub variables: HashMap<String, Value>,

    /// Semantic variable bindings (prefix:name -> value)
    pub semantic_vars: HashMap<String, Value>,

    /// Current root context (affects interpretation)
    root: Option<String>,
}

impl EvalContext {
    /// Create a new evaluation context
    pub fn new() -> Self {
        Self {
            variables: HashMap::new(),
            semantic_vars: HashMap::new(),
            root: None,
        }
    }

    /// Set the root context
    pub fn set_root(&mut self, root: String) {
        self.root = Some(root);
    }

    /// Get the current root context
    pub fn root(&self) -> Option<&str> {
        self.root.as_deref()
    }

    /// Bind a variable to a value
    pub fn bind(&mut self, name: String, value: Value) {
        self.variables.insert(name, value);
    }

    /// Look up a variable
    pub fn lookup(&self, name: &str) -> Option<&Value> {
        self.variables.get(name)
    }
}

impl Default for EvalContext {
    fn default() -> Self {
        Self::new()
    }
}

/// Evaluation errors
#[derive(Debug, Error)]
pub enum EvalError {
    #[error("Type mismatch: {0}")]
    TypeMismatch(String),

    #[error("Undefined variable: {0}")]
    UndefinedVariable(String),

    #[error("Division by zero")]
    DivisionByZero,

    #[error("Invalid operation: {0}")]
    InvalidOperation(String),

    #[error("Unsupported operation: {0}")]
    UnsupportedOperation(String),

    #[error("Not implemented: {0}")]
    NotImplemented(String),
}

// ===================================
// From trait implementations - automatic Value wrapping
// ===================================

impl From<[f32; 8]> for Value {
    fn from(arr: [f32; 8]) -> Self {
        Value::Vec8(arr)
    }
}

impl From<[f32; 16]> for Value {
    fn from(arr: [f32; 16]) -> Self {
        Value::Vec16(arr)
    }
}

impl From<[f32; 4]> for Value {
    fn from(arr: [f32; 4]) -> Self {
        Value::Quaternion(arr)
    }
}

impl From<[u32; 3]> for Value {
    fn from(arr: [u32; 3]) -> Self {
        Value::Betti(arr)
    }
}

// ===================================
// RuneBuiltin - Geometric Operation Dispatch
// ===================================

/// Built-in geometric operations that bridge RUNE into Hydron
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RuneBuiltin {
    // Gf8 core operations
    Gf8Norm,      // [f32;8] → f32
    Gf8Normalize, // [f32;8] → [f32;8]
    Gf8Dot,       // [f32;8], [f32;8] → f32

    // Spherical (S7) operations
    S7Project,   // [f32;8] → [f32;8]
    S7Distance,  // [f32;8], [f32;8] → f32
    S7Slerp,     // [f32;8], [f32;8], f32 → [f32;8]
    S7Antipodal, // [f32;8] → [f32;8]
    S7Mean,      // [[f32;8]] → [f32;8]

    // Hyperbolic operations
    H8Distance,  // [f32;8], [f32;8] → f32
    H8MobiusAdd, // [f32;8], [f32;8] → [f32;8]

    // Fisher information geometry
    FisherDistance, // [f32;8], [f32;8] → f32
    FisherMatrix,   // [f32;8] → [[f32;8];8]
    KLDivergence,   // [f32;8], [f32;8] → f32
    FisherFilter,   // Array, threshold -> Array (novelty filter)

    // Quaternion operations
    QuatSlerp,     // [f32;4], [f32;4], f32 → [f32;4]
    QuatCompose,   // [f32;4], [f32;4] → [f32;4]
    QuatConjugate, // [f32;4] → [f32;4]

    // Symplectic operations
    SymHamiltonian, // [f32;16] → f32
    SymEvolveStep,  // [f32;16], f32 → [f32;16]

    // Lorentzian spacetime operations
    LorentzianCausal,   // [f32;8], [f32;8] → bool
    LorentzianDistance, // [f32;8], [f32;8] → f32
    CausalNow,          // () -> [f32;8]
    CausalEmit,         // any, optional root, optional causes -> event_id
    CausalLink,         // cause_id, effect_id -> ()
    CausalConePast,     // id -> [ids]
    CausalConeFuture,   // id -> [ids]
    CausalVerify,       // () -> bool
    Fold,               // [values], op -> value
    Filter,             // [values], pattern -> [values]
    AtlasNew,           // -> Atlas
    AtlasInsert,        // [Atlas, KeyVec, Data] -> Atlas
    AtlasRecall,        // [Atlas, QueryVec] -> Array
    Neighbors,          // Integer -> Array<Integer>
    Reflect,            // [Vec8, Vec8] -> Vec8 (Weyl reflection)
    Diffuse,            // [Array<f32;240], Scalar] -> Array<f32;240>

    // Topological operations
    TopoBetti,     // [[f32;8]] → [u32;3]
    TopoSignature, // [[f32;8]] → symbol

    // CUDA orchestration
    CudaVecDot,        // GPU row-wise dot
    CudaTopK,          // GPU top-k
    CudaDomR,          // GPU DomR (E8-native dominant roots)
    CudaArchetypeDomR, // Archetype dispatch for DomR

    // E8 graph/ontology helpers
    E8TypeI,      // Axes[] -> Vec<Vec8> (Type-I roots)
    E8TypeII,     // Axes[] -> Vec<Vec8> (Type-II spinors)
    E8EdgesWhere, // Vertices[] -> Edges[] (inner product rule)
    HexGraph,     // (vertices, edges, axes) -> Map graph

    // Perception operations
    Perceive, // String → Vec8 (Signal /\ Structure)
}

impl RuneBuiltin {
    /// Create a RuneBuiltin from a name string (case-insensitive).
    pub fn from_str(name: &str) -> Option<Self> {
        match name.to_lowercase().as_str() {
            // Perception operations
            "perceive" => Some(RuneBuiltin::Perceive),

            // E8 graph helpers
            "e8typei" => Some(RuneBuiltin::E8TypeI),
            "e8typeii" => Some(RuneBuiltin::E8TypeII),
            "e8edgeswhere" => Some(RuneBuiltin::E8EdgesWhere),
            "e8edges" => Some(RuneBuiltin::E8EdgesWhere),
            "HexGraph" => Some(RuneBuiltin::HexGraph),
            "t:HexGraph" => Some(RuneBuiltin::HexGraph),

            // Gf8 operations
            "gf8norm" => Some(RuneBuiltin::Gf8Norm),
            "gf8normalize" => Some(RuneBuiltin::Gf8Normalize),
            "gf8dot" => Some(RuneBuiltin::Gf8Dot),

            // Spherical operations
            "s7project" => Some(RuneBuiltin::S7Project),
            "s7distance" => Some(RuneBuiltin::S7Distance),
            "s7slerp" => Some(RuneBuiltin::S7Slerp),
            "s7antipodal" => Some(RuneBuiltin::S7Antipodal),
            "s7mean" => Some(RuneBuiltin::S7Mean),

            // Hyperbolic operations
            "h8distance" => Some(RuneBuiltin::H8Distance),
            "h8mobiusadd" => Some(RuneBuiltin::H8MobiusAdd),

            // Fisher geometry
            "fisherdistance" => Some(RuneBuiltin::FisherDistance),
            "fishermatrix" => Some(RuneBuiltin::FisherMatrix),
            "kldivergence" => Some(RuneBuiltin::KLDivergence),
            "fisherfilter" => Some(RuneBuiltin::FisherFilter),

            // Quaternion operations
            "quatslerp" => Some(RuneBuiltin::QuatSlerp),
            "quatcompose" => Some(RuneBuiltin::QuatCompose),
            "quatconjugate" => Some(RuneBuiltin::QuatConjugate),

            // Symplectic operations
            "symhamiltonian" => Some(RuneBuiltin::SymHamiltonian),
            "symevolvestep" => Some(RuneBuiltin::SymEvolveStep),

            // Lorentzian operations
            "lorentziancausal" => Some(RuneBuiltin::LorentzianCausal),
            "lorentziandistance" => Some(RuneBuiltin::LorentzianDistance),
            "causalnow" => Some(RuneBuiltin::CausalNow),
            "causalemit" => Some(RuneBuiltin::CausalEmit),
            "causallink" => Some(RuneBuiltin::CausalLink),
            "causalconepast" => Some(RuneBuiltin::CausalConePast),
            "causalconefuture" => Some(RuneBuiltin::CausalConeFuture),
            "causalverify" => Some(RuneBuiltin::CausalVerify),
            "fold" => Some(RuneBuiltin::Fold),
            "filter" => Some(RuneBuiltin::Filter),
            "atlasnew" => Some(RuneBuiltin::AtlasNew),
            "atlasinsert" => Some(RuneBuiltin::AtlasInsert),
            "atlasrecall" => Some(RuneBuiltin::AtlasRecall),
            "neighbors" => Some(RuneBuiltin::Neighbors),
            "reflect" => Some(RuneBuiltin::Reflect),
            "diffuse" => Some(RuneBuiltin::Diffuse),

            // Topological operations
            "topobetti" => Some(RuneBuiltin::TopoBetti),
            "toposignature" => Some(RuneBuiltin::TopoSignature),

            // CUDA builtins (feature-gated at execution)
            "cuda:vecdot" => Some(RuneBuiltin::CudaVecDot),
            "cuda:topk" => Some(RuneBuiltin::CudaTopK),
            "cuda:domr" => Some(RuneBuiltin::CudaDomR),
            "cuda:archetype:domr" => Some(RuneBuiltin::CudaArchetypeDomR),
            _ => None,
        }
    }
}

impl EvalContext {
    /// Apply a built-in geometric operation
    ///
    /// This is the bridge layer that makes RUNE expressions actually drive Hydron geometry.
    pub fn apply_builtin(&self, op: RuneBuiltin, args: &[Value]) -> Result<Value, EvalError> {
        match op {
            // Spherical S7 operations
            RuneBuiltin::S7Project => {
                let v = expect_vec8(args.first())?;
                let projected = SphericalLayer::project(&v);
                Ok(Value::Vec8(projected))
            }

            RuneBuiltin::S7Distance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = SphericalLayer::distance(&a, &b);
                Ok(Value::Scalar(dist))
            }

            RuneBuiltin::S7Slerp => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let t = expect_scalar(args.get(2))?;
                let result = SphericalLayer::slerp(&a, &b, t);
                Ok(Value::Vec8(result))
            }

            // Quaternion operations
            RuneBuiltin::QuatSlerp => {
                let a = expect_quat(args.first())?;
                let b = expect_quat(args.get(1))?;
                let t = expect_scalar(args.get(2))?;
                let result = QuaternionOps::slerp(&a, &b, t);
                Ok(Value::Quaternion(result))
            }

            // Symplectic operations
            RuneBuiltin::SymHamiltonian => {
                let state = expect_vec16(args.first())?;
                let (q, p) = split_phase_space(&state);
                let layer = SymplecticLayer::new();
                let h = layer.hamiltonian(&q, &p);
                Ok(Value::Scalar(h))
            }

            RuneBuiltin::SymEvolveStep => {
                let state = expect_vec16(args.first())?;
                let dt = expect_scalar(args.get(1))?;
                let (mut q, mut p) = split_phase_space(&state);
                let layer = SymplecticLayer::new();
                layer.evolve(&mut q, &mut p, dt);
                let evolved = merge_phase_space(&q, &p);
                Ok(Value::Vec16(evolved))
            }

            // Topological operations
            RuneBuiltin::TopoBetti => {
                let points = extract_point_cloud(args)?;
                let mut layer = TopologicalLayer::new();
                for point in points {
                    layer.add_point(point);
                }
                layer.compute_betti_numbers(2.0, 10); // max_radius=2.0, steps=10
                Ok(Value::Betti(layer.betti))
            }

            RuneBuiltin::TopoSignature => {
                let points = extract_point_cloud(args)?;
                let mut layer = TopologicalLayer::new();
                for point in points {
                    layer.add_point(point);
                }
                layer.compute_betti_numbers(2.0, 10);
                let sig = format!("β={:?}", layer.betti);
                Ok(Value::Symbol(sig))
            }

            // Gf8 core operations
            RuneBuiltin::Gf8Norm => {
                let v = expect_vec8(args.first())?;
                let norm = v.iter().map(|x| x * x).sum::<f32>().sqrt();
                Ok(Value::Scalar(norm))
            }

            RuneBuiltin::Gf8Normalize => {
                let v = expect_vec8(args.first())?;
                let norm = v.iter().map(|x| x * x).sum::<f32>().sqrt();
                if norm > 1e-10 {
                    let normalized = v.map(|x| x / norm);
                    Ok(Value::Vec8(normalized))
                } else {
                    Ok(Value::Vec8(v))
                }
            }

            RuneBuiltin::Gf8Dot => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dot = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum::<f32>();
                Ok(Value::Scalar(dot))
            }

            // Spherical operations
            RuneBuiltin::S7Antipodal => {
                let v = expect_vec8(args.first())?;
                let antipodal = v.map(|x| -x);
                Ok(Value::Vec8(antipodal))
            }

            RuneBuiltin::S7Mean => {
                let points = extract_point_cloud(args)?;
                if points.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "Cannot compute mean of empty point cloud".to_string(),
                    ));
                }
                let result = SphericalLayer::mean(&points);
                Ok(Value::Vec8(result))
            }

            // Hyperbolic operations
            RuneBuiltin::H8Distance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = HyperbolicLayer::distance(&a, &b);
                Ok(Value::Scalar(dist))
            }

            RuneBuiltin::H8MobiusAdd => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let result = HyperbolicLayer::mobius_add(&a, &b);
                Ok(Value::Vec8(result))
            }

            // Fisher information geometry
            RuneBuiltin::FisherDistance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = a
                    .iter()
                    .zip(b.iter())
                    .map(|(x, y)| (x - y).powi(2))
                    .sum::<f32>()
                    .sqrt();
                Ok(Value::Scalar(dist))
            }

            RuneBuiltin::FisherMatrix => {
                let flat: Vec<Value> = (0..64)
                    .map(|i| {
                        let diag = if i / 8 == i % 8 { 1.0 } else { 0.0 };
                        Value::Scalar(diag)
                    })
                    .collect();
                Ok(Value::Array(flat))
            }

            RuneBuiltin::KLDivergence => {
                let p = expect_vec8(args.first())?;
                let q = expect_vec8(args.get(1))?;
                let kl = FisherLayer::kl_divergence(&p, &q);
                Ok(Value::Scalar(kl))
            }

            // Quaternion operations
            RuneBuiltin::QuatCompose => {
                let a = expect_quat(args.first())?;
                let b = expect_quat(args.get(1))?;
                // Quaternion multiplication: (a0,a)(b0,b) = (a0*b0 - a·b, a0*b + b0*a + a×b)
                let result = [
                    a[0] * b[0] - (a[1] * b[1] + a[2] * b[2] + a[3] * b[3]),
                    a[0] * b[1] + b[0] * a[1] + (a[2] * b[3] - a[3] * b[2]),
                    a[0] * b[2] + b[0] * a[2] + (a[3] * b[1] - a[1] * b[3]),
                    a[0] * b[3] + b[0] * a[3] + (a[1] * b[2] - a[2] * b[1]),
                ];
                Ok(Value::Quaternion(result))
            }

            RuneBuiltin::QuatConjugate => {
                let q = expect_quat(args.first())?;
                let conj = [q[0], -q[1], -q[2], -q[3]];
                Ok(Value::Quaternion(conj))
            }

            // Lorentzian operations
            RuneBuiltin::LorentzianCausal => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let interval = a[0].powi(2)
                    - a[1..]
                        .iter()
                        .zip(&b[1..])
                        .map(|(x, y)| (x - y).powi(2))
                        .sum::<f32>();
                Ok(Value::Bool(interval > 0.0))
            }

            RuneBuiltin::LorentzianDistance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = (a[0] - b[0]).powi(2)
                    - a[1..]
                        .iter()
                        .zip(&b[1..])
                        .map(|(x, y)| (x - y).powi(2))
                        .sum::<f32>();
                Ok(Value::Scalar(dist.abs().sqrt()))
            }

            // E8 graph helpers -------------------------------------------------
            RuneBuiltin::E8TypeI => {
                // Expect axes array of maps with at least "index" (0..7) and optional "weight"
                let axes_val = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("E8TypeI expects axes array".into())
                })?;
                let axes = parse_axes(axes_val)?;
                if axes.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "E8TypeI requires at least two axes".into(),
                    ));
                }
                let mut verts = Vec::new();
                for a in 0..axes.len() {
                    for b in (a + 1)..axes.len() {
                        let (idx_a, w_a) = axes[a];
                        let (idx_b, w_b) = axes[b];
                        // four sign combinations
                        let signs = [(1.0, 1.0), (1.0, -1.0), (-1.0, 1.0), (-1.0, -1.0)];
                        for (sa, sb) in signs {
                            let mut v = [0.0f32; 8];
                            v[idx_a] = w_a * sa;
                            v[idx_b] = w_b * sb;
                            normalize_vec8(&mut v);
                            verts.push(Value::Vec8(v));
                        }
                    }
                }
                Ok(Value::Array(verts))
            }

            RuneBuiltin::E8TypeII => {
                let axes_val = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("E8TypeII expects axes array".into())
                })?;
                let axes = parse_axes(axes_val)?;
                if axes.len() != 8 {
                    return Err(EvalError::InvalidOperation(
                        "E8TypeII expects exactly 8 axes".into(),
                    ));
                }
                let mut verts = Vec::new();
                // 2^8 sign patterns, keep even number of negatives (128 spinors)
                for mask in 0u16..256 {
                    let negs = mask.count_ones();
                    if negs % 2 != 0 {
                        continue;
                    }
                    let mut v = [0.0f32; 8];
                    for (i, (idx, w)) in axes.iter().enumerate() {
                        let sign = if (mask & (1 << i)) != 0 { -0.5 } else { 0.5 };
                        v[*idx] = sign * *w;
                    }
                    normalize_vec8(&mut v);
                    verts.push(Value::Vec8(v));
                }
                Ok(Value::Array(verts))
            }

            RuneBuiltin::E8EdgesWhere => {
                // Args: vertices array (Vec8/Gf8), optional threshold (default 0.5), optional tolerance
                let verts_val = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("E8EdgesWhere expects vertices array".into())
                })?;
                let verts = parse_vec8_list(verts_val)?;
                let threshold = match args.get(1) {
                    Some(Value::Scalar(s)) => *s,
                    Some(Value::Float(f)) => *f as f32,
                    _ => 0.5f32,
                };
                let tol = match args.get(2) {
                    Some(Value::Scalar(s)) => s.abs(),
                    Some(Value::Float(f)) => (*f as f32).abs(),
                    _ => 1e-4f32,
                };
                let mut edges = Vec::new();
                for i in 0..verts.len() {
                    for j in (i + 1)..verts.len() {
                        let dot: f32 = verts[i]
                            .iter()
                            .zip(verts[j].iter())
                            .map(|(a, b)| a * b)
                            .sum();
                        if (dot - threshold).abs() <= tol {
                            let mut map = HashMap::new();
                            map.insert("u".to_string(), Value::Integer(i as i128));
                            map.insert("v".to_string(), Value::Integer(j as i128));
                            map.insert("strength".to_string(), Value::Scalar(dot));
                            map.insert("relationship".to_string(), Value::Symbol("Similar".into()));
                            edges.push(Value::Map(map));
                        }
                    }
                }
                Ok(Value::Array(edges))
            }

            RuneBuiltin::HexGraph => {
                // Accept tuple or array of three: (vertices, edges, axes)
                let pack = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("HexGraph expects (vertices, edges, axes)".into())
                })?;
                let (verts, edges, axes) = match pack {
                    Value::Tuple(v) if v.len() == 3 => (&v[0], &v[1], &v[2]),
                    Value::Array(v) if v.len() == 3 => (&v[0], &v[1], &v[2]),
                    _ => {
                        return Err(EvalError::InvalidOperation(
                            "HexGraph expects tuple/array of (vertices, edges, axes)".into(),
                        ));
                    }
                };
                let mut graph = HashMap::new();
                graph.insert("vertices".into(), verts.clone());
                graph.insert("edges".into(), edges.clone());
                graph.insert("axes".into(), axes.clone());
                graph.insert("domain_stats".into(), Value::Map(HashMap::new()));
                Ok(Value::Map(graph))
            }

            // Perception operations
            RuneBuiltin::Perceive => {
                let input = match args.first() {
                    Some(Value::String(s)) => s,
                    Some(Value::Symbol(s)) => s,
                    _ => return Err(EvalError::TypeMismatch("Perceive requires a string".into())),
                };

                let sig = crate::rune::hydron::perception::signal_encode(input.as_bytes());
                let morph = crate::rune::hydron::perception::morph_analyze(input);

                let v_sig = Value::Vec8(sig);
                let v_morph = Value::Vec8(morph);

                // Synthesis: Signal /\ Structure (Geometric Midpoint)
                v_sig.geometric_midpoint(&v_morph)
            }

            RuneBuiltin::CausalNow => {
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                let mut coords = [0.0f64; 8];
                coords[0] = guard.proper_time;
                Ok(Value::Spacetime(SpacetimePoint::new(coords)))
            }

            RuneBuiltin::CausalEmit => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "CausalEmit requires at least a payload".into(),
                    ));
                }
                let payload = args[0].clone();
                let mut idx = 1;
                let mut location: Option<SpacetimePoint> = None;
                let mut root: usize = 0;

                if let Some(arg1) = args.get(idx) {
                    if let Value::Spacetime(p) = arg1 {
                        location = Some(p.clone());
                        idx += 1;
                    } else if let Ok(r) = expect_scalar(Some(arg1)) {
                        root = r as usize;
                        idx += 1;
                    }
                }

                let causes: Vec<u64> = if let Some(cause_val) = args.get(idx) {
                    match cause_val {
                        Value::Array(arr) => {
                            let mut out = Vec::new();
                            for v in arr {
                                out.push(expect_id(v)?);
                            }
                            out
                        }
                        other => vec![expect_id(other)?],
                    }
                } else {
                    Vec::new()
                };

                let layer = causal_layer();
                let mut guard = layer.lock().unwrap();
                let id = guard.add_event(root, payload, &causes, location);
                Ok(Value::Integer(id as i128))
            }

            RuneBuiltin::CausalLink => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "CausalLink requires cause and effect ids".into(),
                    ));
                }
                let cause = expect_id(&args[0])?;
                let effect = expect_id(&args[1])?;
                let layer = causal_layer();
                let mut guard = layer.lock().unwrap();
                guard
                    .add_link(cause, effect)
                    .map_err(|e| EvalError::InvalidOperation(e.to_string()))?;
                Ok(Value::Null)
            }

            RuneBuiltin::CausalConePast => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "CausalConePast requires an event id".into(),
                    ));
                }
                let id = expect_id(&args[0])?;
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                let cone = guard.past_light_cone(id);
                Ok(Value::Array(
                    cone.into_iter()
                        .map(|i| Value::Integer(i as i128))
                        .collect(),
                ))
            }

            RuneBuiltin::CausalConeFuture => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "CausalConeFuture requires an event id".into(),
                    ));
                }
                let id = expect_id(&args[0])?;
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                let cone = guard.future_light_cone(id);
                Ok(Value::Array(
                    cone.into_iter()
                        .map(|i| Value::Integer(i as i128))
                        .collect(),
                ))
            }

            RuneBuiltin::CausalVerify => {
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                Ok(Value::Bool(guard.verify_consistency()))
            }

            RuneBuiltin::FisherFilter => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "FisherFilter expects [values], optional threshold".into(),
                    ));
                }
                let list = match &args[0] {
                    Value::Array(arr) => arr,
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "FisherFilter first argument must be Array".into(),
                        ));
                    }
                };
                let threshold = args
                    .get(1)
                    .map(|v| expect_scalar(Some(v)))
                    .transpose()?
                    .unwrap_or(0.1);

                if list.is_empty() {
                    return Ok(Value::Array(Vec::new()));
                }

                let mut filtered = Vec::new();
                let mut prev_dist: Option<Vec<f32>> = None;
                for item in list.iter() {
                    let dist = value_to_distribution(item)?;
                    let keep = if let Some(prev) = &prev_dist {
                        let len = dist.len().min(prev.len());
                        let kl = FisherLayer::kl_divergence(&dist[..len], &prev[..len]);
                        kl > threshold
                    } else {
                        true
                    };
                    if keep {
                        filtered.push(item.clone());
                        prev_dist = Some(dist);
                    }
                }

                Ok(Value::Array(filtered))
            }

            RuneBuiltin::Fold => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "Fold expects [values], operator".into(),
                    ));
                }
                let list = match &args[0] {
                    Value::Array(arr) => arr.clone(),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Fold first argument must be Array".into(),
                        ));
                    }
                };
                let op_name = match &args[1] {
                    Value::Symbol(s) | Value::String(s) => s.clone(),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Fold operator must be Symbol/String".into(),
                        ));
                    }
                };

                let mut iter = list.into_iter();
                let mut acc = match iter.next() {
                    Some(first) => first,
                    None => return Ok(args.get(2).cloned().unwrap_or(Value::Null)),
                };

                for item in iter {
                    acc = match op_name.as_str() {
                        "/\\" => acc.meet(&item)?,
                        "\\/" => acc.join(&item)?,
                        "\\|" => acc.reject(&item)?,
                        "|\\" => acc.project(&item)?,
                        _ => {
                            return Err(EvalError::InvalidOperation(format!(
                                "Unknown fold operator {}",
                                op_name
                            )));
                        }
                    };
                }
                Ok(acc)
            }

            RuneBuiltin::Filter => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "Filter expects [values], pattern".into(),
                    ));
                }
                let list = match &args[0] {
                    Value::Array(arr) => arr,
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Filter first argument must be Array".into(),
                        ));
                    }
                };
                let pattern = &args[1];
                let mut out = Vec::new();
                for item in list {
                    if item.matches_pattern(pattern) {
                        out.push(item.clone());
                    }
                }
                Ok(Value::Array(out))
            }

            RuneBuiltin::AtlasNew => Ok(Value::Atlas(HashMap::new())),

            RuneBuiltin::AtlasInsert => {
                if args.len() < 3 {
                    return Err(EvalError::InvalidOperation(
                        "AtlasInsert expects [Atlas, Vector, Data]".into(),
                    ));
                }
                let mut atlas = args[0].clone();
                let key_vec = &args[1];
                let data = args[2].clone();
                atlas.atlas_insert(key_vec, data)?;
                Ok(atlas)
            }

            RuneBuiltin::AtlasRecall => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "AtlasRecall expects [Atlas, Vector]".into(),
                    ));
                }
                let atlas = &args[0];
                let query = &args[1];
                atlas.atlas_recall(query)
            }

            RuneBuiltin::Neighbors => {
                let idx = match args.get(0) {
                    Some(Value::Integer(i)) => *i as usize,
                    Some(Value::Scalar(s)) => *s as usize,
                    Some(Value::Float(f)) => *f as usize,
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Neighbors expects a root index".into(),
                        ));
                    }
                };
                let neighbors = crate::rune::hydron::topology::get_neighbors(idx);
                let vals = neighbors
                    .into_iter()
                    .map(|i| Value::Integer(i as i128))
                    .collect();
                Ok(Value::Array(vals))
            }

            RuneBuiltin::Reflect => {
                let vec = expect_vec8(args.get(0))?;
                let mirror = expect_vec8(args.get(1))?;
                let reflected = crate::rune::hydron::topology::weyl_reflect(&vec, &mirror);
                Ok(Value::Vec8(reflected))
            }

            RuneBuiltin::Diffuse => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "Diffuse expects [Array(240), rate]".into(),
                    ));
                }
                let energy = match &args[0] {
                    Value::Array(arr) => {
                        if arr.len() != 240 {
                            return Err(EvalError::TypeMismatch(
                                "Diffuse energy array must have length 240".into(),
                            ));
                        }
                        let mut out = [0.0f32; 240];
                        for (i, v) in arr.iter().enumerate() {
                            out[i] = match v {
                                Value::Scalar(s) => *s,
                                Value::Float(f) => *f as f32,
                                _ => {
                                    return Err(EvalError::TypeMismatch(
                                        "Diffuse energy entries must be numeric".into(),
                                    ));
                                }
                            };
                        }
                        out
                    }
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Diffuse first argument must be Array".into(),
                        ));
                    }
                };

                let rate = expect_scalar(args.get(1).map(|v| v))?;
                let diffused = crate::rune::hydron::topology::diffuse_energy(&energy, rate);
                let vals = diffused
                    .iter()
                    .map(|f| Value::Scalar(*f))
                    .collect::<Vec<_>>();
                Ok(Value::Array(vals))
            }

            // CUDA builtins - use CUDA accelerator if available
            RuneBuiltin::CudaDomR | RuneBuiltin::CudaArchetypeDomR => {
                #[cfg(feature = "cuda")]
                {
                    match crate::rune::hydron::cuda::get_cuda_accelerator().execute_domr("CudaDomR", args) {
                        Ok(result) => return Ok(result),
                        Err(_) => {
                            // Fall through to CPU implementation below
                        }
                    }
                }

                // CPU implementation fallback
                let energy_vec = expect_energy(args.get(0))?;
                let n_dr = match args.get(1) {
                    Some(Value::Integer(i)) => *i as usize,
                    Some(Value::Scalar(s)) => *s as usize,
                    Some(Value::Float(f)) => *f as usize,
                    _ => 8usize, // default
                };

                let graph = hex_model::default_graph();
                let domr = hex_model::domr_cpu(graph, &energy_vec, n_dr)
                    .map_err(|e| EvalError::InvalidOperation(e.to_string()))?;
                Ok(Value::DomR(domr))
            }

            RuneBuiltin::CudaVecDot => Err(EvalError::UnsupportedOperation("CudaVecDot not implemented".into())),

            RuneBuiltin::CudaTopK => Err(EvalError::UnsupportedOperation("CudaTopK not implemented".into())),
        }
    }

    /// Apply a builtin by string name; returns Err if unknown name.
    pub fn apply_builtin_by_name(&self, name: &str, args: &[Value]) -> Result<Value, EvalError> {
        if let Some(b) = RuneBuiltin::from_str(name) {
            self.apply_builtin(b, args)
        } else {
            Err(EvalError::InvalidOperation(format!(
                "Unknown builtin: {}",
                name
            )))
        }
    }
}

// ===================================
// Helper functions for type extraction
// ===================================

fn expect_vec8(val: Option<&Value>) -> Result<[f32; 8], EvalError> {
    match val {
        Some(Value::Vec8(v)) => Ok(*v),
        Some(Value::Array(arr)) => {
            // Ensure array has length 8 and extract floats
            if arr.len() != 8 {
                return Err(EvalError::TypeMismatch(format!(
                    "Expected Vec8 (array of 8 floats), got array length {}",
                    arr.len()
                )));
            }
            let mut v = [0.0f32; 8];
            for (i, elem) in arr.iter().enumerate() {
                match elem {
                    Value::Float(f) => v[i] = *f as f32,
                    Value::Scalar(s) => v[i] = *s,
                    _ => {
                        return Err(EvalError::TypeMismatch(format!(
                            "Expected numeric values for Vec8, found {:?}",
                            elem
                        )));
                    }
                }
            }
            Ok(v)
        }
        Some(other) => Err(EvalError::TypeMismatch(format!(
            "Expected Vec8, got {}",
            match other {
                Value::Scalar(_) => "Scalar",
                Value::Vec16(_) => "Vec16",
                Value::Quaternion(_) => "Quaternion",
                Value::Gf8(_) => "Gf8",
                Value::Octonion(_) => "Octonion",
                Value::Symbol(_) => "Symbol",
                Value::Matrix8x8(_) => "Matrix8x8",
                Value::Betti(_) => "Betti",
                _ => "unknown",
            }
        ))),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_vec16(val: Option<&Value>) -> Result<[f32; 16], EvalError> {
    match val {
        Some(Value::Vec16(v)) => Ok(*v),
        Some(_) => Err(EvalError::TypeMismatch("Expected Vec16".to_string())),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_quat(val: Option<&Value>) -> Result<[f32; 4], EvalError> {
    match val {
        Some(Value::Quaternion(q)) => Ok(*q),
        Some(_) => Err(EvalError::TypeMismatch("Expected Quaternion".to_string())),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_scalar(val: Option<&Value>) -> Result<f32, EvalError> {
    match val {
        Some(Value::Scalar(s)) => Ok(*s),
        Some(Value::Float(f)) => Ok(*f as f32),
        Some(_) => Err(EvalError::TypeMismatch(
            "Expected Scalar or Float".to_string(),
        )),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_id(val: &Value) -> Result<u64, EvalError> {
    match val {
        Value::Integer(i) => Ok(*i as u64),
        Value::Scalar(s) => Ok(*s as u64),
        Value::Float(f) => Ok(*f as u64),
        _ => Err(EvalError::TypeMismatch("Expected event id".to_string())),
    }
}

fn expect_energy(val: Option<&Value>) -> Result<Vec<f32>, EvalError> {
    let arr = match val {
        Some(Value::Array(arr)) => arr,
        Some(_) => {
            return Err(EvalError::TypeMismatch(
                "Energy must be an Array of 240 numeric values".into(),
            ));
        }
        None => {
            return Err(EvalError::InvalidOperation(
                "Missing energy argument".into(),
            ));
        }
    };
    if arr.len() != 240 {
        return Err(EvalError::TypeMismatch(format!(
            "Energy array must have length 240, got {}",
            arr.len()
        )));
    }
    let mut out = Vec::with_capacity(240);
    for v in arr {
        match v {
            Value::Scalar(s) => out.push(*s),
            Value::Float(f) => out.push(*f as f32),
            Value::Integer(i) => out.push(*i as f32),
            _ => {
                return Err(EvalError::TypeMismatch(
                    "Energy entries must be numeric".into(),
                ));
            }
        }
    }
    Ok(out)
}

fn value_to_distribution(val: &Value) -> Result<Vec<f32>, EvalError> {
    let mut dist = match val {
        Value::Array(arr) => {
            let mut out = Vec::with_capacity(arr.len());
            for v in arr {
                match v {
                    Value::Scalar(s) => out.push(*s),
                    Value::Float(f) => out.push(*f as f32),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Array must contain numeric values for FisherFilter".into(),
                        ));
                    }
                }
            }
            out
        }
        Value::Vec8(v) => v.to_vec(),
        Value::Vec16(v) => v.to_vec(),
        Value::Gf8(g) => g.coords().to_vec(),
        Value::Quaternion(q) => q.to_vec(),
        Value::Scalar(s) => vec![*s],
        Value::Float(f) => vec![*f as f32],
        _ => {
            return Err(EvalError::TypeMismatch(
                "Unsupported value for FisherFilter distribution".into(),
            ));
        }
    };

    let sum: f32 = dist.iter().map(|x| x.abs()).sum();
    if sum > 1e-8 {
        for x in dist.iter_mut() {
            *x /= sum;
        }
    }
    Ok(dist)
}

fn extract_point_cloud(args: &[Value]) -> Result<Vec<[f32; 8]>, EvalError> {
    // Handle multiple argument formats:
    // 1. Single PointCloud value
    // 2. Single Vec16 (two packed points)
    // 3. Multiple Vec8 arguments

    if args.is_empty() {
        return Err(EvalError::InvalidOperation(
            "No points provided".to_string(),
        ));
    }

    // Case 1: PointCloud value
    if args.len() == 1 {
        if let Value::PointCloud(points) = &args[0] {
            return Ok(points.clone());
        }

        // Case 2: Vec16 (two packed points)
        if let Value::Vec16(v16) = &args[0] {
            let p1 = [
                v16[0], v16[1], v16[2], v16[3], v16[4], v16[5], v16[6], v16[7],
            ];
            let p2 = [
                v16[8], v16[9], v16[10], v16[11], v16[12], v16[13], v16[14], v16[15],
            ];
            return Ok(vec![p1, p2]);
        }
    }

    // Case 3: Multiple Vec8 arguments
    let mut points = Vec::new();
    for arg in args {
        match arg {
            Value::Vec8(v) => points.push(*v),
            Value::PointCloud(pc) => points.extend_from_slice(pc),
            _ => {
                return Err(EvalError::TypeMismatch(
                    "Expected Vec8, Vec16, or PointCloud for point cloud".to_string(),
                ));
            }
        }
    }
    Ok(points)
}

/// Normalize a mutable Vec8 in-place; no-op for near-zero norm.
fn normalize_vec8(v: &mut [f32; 8]) {
    let norm_sq: f32 = v.iter().map(|x| x * x).sum();
    if norm_sq > 1e-9 {
        let inv = 1.0 / norm_sq.sqrt();
        for x in v {
            *x *= inv;
        }
    }
}

/// Extract axes as (index, weight) pairs from a Value::Array of maps.
fn parse_axes(val: &Value) -> Result<Vec<(usize, f32)>, EvalError> {
    let mut axes = Vec::new();
    let arr = match val {
        Value::Array(a) => a,
        _ => return Err(EvalError::TypeMismatch("Axes must be an array".into())),
    };
    for item in arr {
        match item {
            Value::Map(m) => {
                let idx_val = m
                    .get("index")
                    .ok_or_else(|| EvalError::TypeMismatch("Axis missing 'index' field".into()))?;
                let idx = expect_id(idx_val)? as usize;
                let w = match m.get("weight") {
                    Some(Value::Scalar(s)) => *s,
                    Some(Value::Float(f)) => *f as f32,
                    _ => 1.0,
                };
                axes.push((idx, w));
            }
            _ => return Err(EvalError::TypeMismatch("Axis must be a map".into())),
        }
    }
    // Deterministic ordering
    axes.sort_by_key(|(idx, _)| *idx);
    Ok(axes)
}

/// Parse a list of 8D vectors from various value representations.
fn parse_vec8_list(val: &Value) -> Result<Vec<[f32; 8]>, EvalError> {
    match val {
        Value::Array(arr) => {
            let mut out = Vec::with_capacity(arr.len());
            for v in arr {
                out.push(expect_vec8(Some(v))?);
            }
            Ok(out)
        }
        Value::PointCloud(points) => Ok(points.clone()),
        _ => Err(EvalError::TypeMismatch(
            "Expected Array of Vec8 for vertices".into(),
        )),
    }
}

/// Split Vec16 phase space into position and momentum
fn split_phase_space(state: &[f32; 16]) -> ([f32; 8], [f32; 8]) {
    let mut q = [0.0f32; 8];
    let mut p = [0.0f32; 8];
    q.copy_from_slice(&state[..8]);
    p.copy_from_slice(&state[8..]);
    (q, p)
}

/// Merge position and momentum into Vec16 phase space
fn merge_phase_space(q: &[f32; 8], p: &[f32; 8]) -> [f32; 16] {
    let mut state = [0.0f32; 16];
    state[..8].copy_from_slice(q);
    state[8..].copy_from_slice(p);
    state
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_scalar_arithmetic() {
        let a = Value::Scalar(5.0);
        let b = Value::Scalar(3.0);

        assert_eq!(a.add(&b).unwrap(), Value::Scalar(8.0));
        assert_eq!(a.mul(&b).unwrap(), Value::Scalar(15.0));
        assert_eq!(a.sub(&b).unwrap(), Value::Scalar(2.0));
    }

    #[test]
    fn test_gf8_arithmetic() {
        use crate::rune::hydron::Gf8;

        // Test Gf8 addition (geometric addition on unit sphere)
        let gf_a = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let gf_b = Gf8::new([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        let a = Value::Gf8(gf_a);
        let b = Value::Gf8(gf_b);

        // Geometric Gf8 addition
        let result = a.add(&b).unwrap();
        assert!(matches!(result, Value::Gf8(_)));
    }

    #[test]
    fn test_octonion_multiplication() {
        let a = Octonion::real(2.0);
        let b = Octonion::real(3.0);
        let c = a.mul(&b);

        assert_eq!(c.scalar, 6.0);
    }

    #[test]
    fn test_vec8_operations() {
        let a = Value::Vec8([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]);
        let b = Value::Vec8([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]);

        let result = a.add(&b).unwrap();
        if let Value::Vec8(v) = result {
            assert_eq!(v[0], 2.0);
            assert_eq!(v[7], 9.0);
        }
    }

    // ===================================
    // Integration Tests: RUNE → Hydron Geometry
    // ===================================

    #[test]
    fn test_rune_drives_spherical_geometry() {
        let ctx = EvalContext::new();

        // Test S7 projection
        let v = Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let result = ctx.apply_builtin(RuneBuiltin::S7Project, &[v]).unwrap();

        if let Value::Vec8(projected) = result {
            // Should be normalized to unit sphere
            let norm: f32 = projected.iter().map(|x| x * x).sum::<f32>().sqrt();
            assert!((norm - 1.0).abs() < 1e-6, "S7 projection should normalize");
        } else {
            panic!("Expected Vec8 result from S7Project");
        }

        // Test S7 distance
        let a = Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let b = Value::Vec8([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let dist = ctx
            .apply_builtin(RuneBuiltin::S7Distance, &[a.clone(), b.clone()])
            .unwrap();

        if let Value::Scalar(d) = dist {
            assert!(
                d > 0.0,
                "Distance between distinct points should be positive"
            );
        }

        // Test S7 slerp
        let t = Value::Scalar(0.5);
        let interp = ctx.apply_builtin(RuneBuiltin::S7Slerp, &[a, b, t]).unwrap();

        assert!(matches!(interp, Value::Vec8(_)), "Slerp should return Vec8");
    }

    #[test]
    fn test_rune_drives_symplectic_geometry() {
        let ctx = EvalContext::new();

        // Create a symplectic state (position + momentum)
        let state = Value::Vec16([
            1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // position
            0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // momentum
        ]);

        // Test Hamiltonian computation
        let h = ctx
            .apply_builtin(RuneBuiltin::SymHamiltonian, &[state.clone()])
            .unwrap();

        if let Value::Scalar(energy) = h {
            assert!(energy >= 0.0, "Hamiltonian should be non-negative");
        } else {
            panic!("Expected Scalar from SymHamiltonian");
        }

        // Test symplectic evolution
        let dt = Value::Scalar(0.1);
        let evolved = ctx
            .apply_builtin(RuneBuiltin::SymEvolveStep, &[state, dt])
            .unwrap();

        assert!(
            matches!(evolved, Value::Vec16(_)),
            "Symplectic evolution should return Vec16"
        );
    }

    #[test]
    fn test_rune_drives_topological_analysis() {
        let ctx = EvalContext::new();

        // Create a point cloud (2 points packed into Vec16)
        let points = Value::Vec16([
            1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // point 1
            0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // point 2
        ]);

        // Test Betti number computation
        let betti = ctx
            .apply_builtin(RuneBuiltin::TopoBetti, &[points.clone()])
            .unwrap();

        if let Value::Betti([b0, b1, b2]) = betti {
            assert!(b0 > 0, "Should have at least one connected component");
            // b1, b2 depend on point cloud structure
            let _ = (b1, b2);
        } else {
            panic!("Expected Betti from TopoBetti");
        }

        // Test topological signature
        let sig = ctx
            .apply_builtin(RuneBuiltin::TopoSignature, &[points])
            .unwrap();

        assert!(
            matches!(sig, Value::Symbol(_)),
            "Topological signature should return Symbol"
        );
    }

    #[test]
    fn test_from_trait_conversions() {
        // Test automatic Value wrapping
        let v8: Value = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0].into();
        assert!(matches!(v8, Value::Vec8(_)));

        let v16: Value = [0.0; 16].into();
        assert!(matches!(v16, Value::Vec16(_)));

        let quat: Value = [1.0, 0.0, 0.0, 0.0].into();
        assert!(matches!(quat, Value::Quaternion(_)));

        let betti: Value = [1, 0, 0].into();
        assert!(matches!(betti, Value::Betti(_)));
    }
}

File: parts\empty_and_root.rs
=============================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn empty_and_root() {
    println!("Hydron feature required for dynamic empty and root");
}

#[cfg(feature = "hydron")]
pub fn empty_and_root() {
    // Dynamic Empty Container
    let empty_array = Value::Array(vec![]);
    let mut empty_map = HashMap::new();
    empty_map.insert("items".to_string(), empty_array);
    let empty_items = Value::Map(empty_map);
    println!("{}", encode_default(&empty_items).unwrap());

    // Dynamic Root Array
    let root_array = Value::Array(vec![
        Value::String("x".to_string()),
        Value::String("y".to_string()),
    ]);
    println!("\n{}", encode_default(&root_array).unwrap());

    // Dynamic Empty Object
    let empty_obj = Value::Map(HashMap::new());
    let out = encode_default(&empty_obj).unwrap();
    if out.is_empty() {
        println!("\n(empty output)");
    } else {
        println!("\n{out}");
    }
}

File: parts\mixed_arrays.rs
===========================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn mixed_arrays() {
    println!("Hydron feature required for dynamic mixed arrays");
}

#[cfg(feature = "hydron")]
pub fn mixed_arrays() {
    // Dynamic Mixed Array
    let mut obj = HashMap::new();
    obj.insert("a".to_string(), Value::Integer(1));

    let mixed_array = Value::Array(vec![
        Value::Integer(1),
        Value::Map(obj),
        Value::String("text".to_string()),
    ]);

    let mut mixed_map = HashMap::new();
    mixed_map.insert("items".to_string(), mixed_array);
    let mixed = Value::Map(mixed_map);

    println!("{}", encode_default(&mixed).unwrap());

    // Dynamic List of Objects
    let mut item1 = HashMap::new();
    item1.insert("id".to_string(), Value::Integer(1));
    item1.insert("name".to_string(), Value::String("First".to_string()));

    let mut item2 = HashMap::new();
    item2.insert("id".to_string(), Value::Integer(2));
    item2.insert("name".to_string(), Value::String("Second".to_string()));
    item2.insert("extra".to_string(), Value::Bool(true));

    let list_array = Value::Array(vec![Value::Map(item1), Value::Map(item2)]);

    let mut list_map = HashMap::new();
    list_map.insert("items".to_string(), list_array);
    let list_objects = Value::Map(list_map);

    println!("\n{}", encode_default(&list_objects).unwrap());
}

File: parts\mod.rs
==================
pub mod arrays;
pub mod arrays_of_arrays;
pub mod decode_strict;
pub mod delimiters;
pub mod empty_and_root;
pub mod mixed_arrays;
pub mod objects;
pub mod round_trip;
pub mod structs;
pub mod tabular;

File: parts\round_trip.rs
=========================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{decode_default, encode_default};
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn round_trip() {
    println!("Hydron feature required for dynamic round trip");
}

#[cfg(feature = "hydron")]
pub fn round_trip() {
    // Dynamic Round Trip (Value)
    let mut product_map = HashMap::new();
    product_map.insert("product".to_string(), Value::String("Widget".to_string()));
    product_map.insert("price".to_string(), Value::Float(29.99));
    product_map.insert("stock".to_string(), Value::Integer(100));

    let categories = Value::Array(vec![
        Value::String("tools".to_string()),
        Value::String("hardware".to_string()),
    ]);
    product_map.insert("categories".to_string(), categories);

    let original = Value::Map(product_map);

    let encoded = encode_default(&original).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();

    println!("Encoded:\n{encoded}",);
    println!("\nRound-trip equal: {}", original == decoded);
}

File: parts\objects.rs
======================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn objects() {
    println!("Hydron feature required for dynamic objects");
}

#[cfg(feature = "hydron")]
pub fn objects() {
    // Dynamic Object: Simple
    let mut simple_map = HashMap::new();
    simple_map.insert("id".to_string(), Value::Integer(123));
    simple_map.insert("name".to_string(), Value::String("Ada".to_string()));
    simple_map.insert("active".to_string(), Value::Bool(true));
    let simple = Value::Map(simple_map);

    let out = encode_default(&simple).unwrap();
    println!("{out}");

    // Dynamic Object: Nested
    let mut user_info = HashMap::new();
    user_info.insert("id".to_string(), Value::Integer(123));
    user_info.insert("name".to_string(), Value::String("Ada".to_string()));

    let mut nested_map = HashMap::new();
    nested_map.insert("user".to_string(), Value::Map(user_info));
    let nested = Value::Map(nested_map);

    let out_nested = encode_default(&nested).unwrap();
    println!("\n{out_nested}");

    // Dynamic Array of Objects
    let mut user1 = HashMap::new();
    user1.insert("id".to_string(), Value::Integer(1));
    user1.insert("name".to_string(), Value::String("Alice".to_string()));
    user1.insert(
        "email".to_string(),
        Value::String("alice@example.com".to_string()),
    );
    user1.insert("active".to_string(), Value::Bool(true));

    let mut user2 = HashMap::new();
    user2.insert("id".to_string(), Value::Integer(2));
    user2.insert("name".to_string(), Value::String("Bob".to_string()));
    user2.insert(
        "email".to_string(),
        Value::String("bob@example.com".to_string()),
    );
    user2.insert("active".to_string(), Value::Bool(true));

    let users = Value::Array(vec![Value::Map(user1), Value::Map(user2)]);

    let out = encode_default(&users).unwrap();
    println!("\n{out}");
}

File: parts\structs.rs
======================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{decode_default, encode_default};
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn serde_structs() {
    println!("Hydron feature required for dynamic structs");
}

#[cfg(feature = "hydron")]
pub fn serde_structs() {
    // Dynamic Struct (User)
    let mut user_map = HashMap::new();
    user_map.insert("name".to_string(), Value::String("Alice".to_string()));
    user_map.insert("age".to_string(), Value::Integer(30));
    user_map.insert(
        "email".to_string(),
        Value::String("alice@example.com".to_string()),
    );
    user_map.insert("active".to_string(), Value::Bool(true));
    let user = Value::Map(user_map);

    let toon = encode_default(&user).unwrap();
    println!("{toon}");

    let decoded: Value = decode_default(&toon).unwrap();
    assert_eq!(user, decoded);

    // Dynamic Nested Struct (Product)
    let mut metadata_map = HashMap::new();
    metadata_map.insert("category".to_string(), Value::String("Tech".to_string()));
    metadata_map.insert("in_stock".to_string(), Value::Bool(true));

    let tags = Value::Array(vec![
        Value::String("electronics".to_string()),
        Value::String("computers".to_string()),
    ]);

    let mut product_map = HashMap::new();
    product_map.insert("id".to_string(), Value::Integer(42));
    product_map.insert("name".to_string(), Value::String("Laptop".to_string()));
    product_map.insert("price".to_string(), Value::Float(999.99));
    product_map.insert("tags".to_string(), tags);
    product_map.insert("metadata".to_string(), Value::Map(metadata_map));
    let product = Value::Map(product_map);

    let toon = encode_default(&product).unwrap();
    println!("\n{toon}");

    let decoded: Value = decode_default(&toon).unwrap();
    assert_eq!(product, decoded);
}

File: parts\tabular.rs
======================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn tabular() {
    println!("Hydron feature required for dynamic tabular data");
}

#[cfg(feature = "hydron")]
pub fn tabular() {
    // Dynamic Tabular Data
    let mut item1 = HashMap::new();
    item1.insert("sku".to_string(), Value::String("A1".to_string()));
    item1.insert("qty".to_string(), Value::Integer(2));
    item1.insert("price".to_string(), Value::Float(9.99));

    let mut item2 = HashMap::new();
    item2.insert("sku".to_string(), Value::String("B2".to_string()));
    item2.insert("qty".to_string(), Value::Integer(1));
    item2.insert("price".to_string(), Value::Float(14.5));

    let items_array = Value::Array(vec![Value::Map(item1), Value::Map(item2)]);

    let mut items_map = HashMap::new();
    items_map.insert("items".to_string(), items_array);
    let items = Value::Map(items_map);

    let out = encode_default(&items).unwrap();
    println!("{out}");

    // Dynamic Nested Tabular Data
    let mut user1 = HashMap::new();
    user1.insert("id".to_string(), Value::Integer(1));
    user1.insert("name".to_string(), Value::String("Ada".to_string()));

    let mut user2 = HashMap::new();
    user2.insert("id".to_string(), Value::Integer(2));
    user2.insert("name".to_string(), Value::String("Bob".to_string()));

    let users_array = Value::Array(vec![Value::Map(user1), Value::Map(user2)]);

    let mut container = HashMap::new();
    container.insert("users".to_string(), users_array);
    container.insert("status".to_string(), Value::String("active".to_string()));

    let items_array_nested = Value::Array(vec![Value::Map(container)]);

    let mut nested_map = HashMap::new();
    nested_map.insert("items".to_string(), items_array_nested);
    let nested = Value::Map(nested_map);

    let out_nested = encode_default(&nested).unwrap();
    println!("\n{out_nested}");
}

File: tests\archetype_integration.rs
====================================
//! Integration test for RUNE-ArchetypeEngine bridge
//!
//! Tests the end-to-end flow: RUNE kernel declaration -> ArchetypeEngine compilation -> PTX generation

use rune_format::rune::hydron::eval::Evaluator;
use rune_format::rune::parse;
use std::fs;
use std::path::Path;

#[cfg(feature = "cuda")]
#[test]
fn test_archetype_kernel_compilation() {
    // Define RUNE script with kernel declaration
    let script = r#"
Kernel:MyRowDot := CUDA:Archetype:RowDot(D: 8) and MyData -> MyRowDot
"#;

    // Parse the script
    let stmts = parse(script).expect("Failed to parse RUNE script");

    // Set up evaluator with initial data
    let mut eval = Evaluator::new();
    eval.set_var("MyData", rune_format::rune::hydron::values::Value::Array(vec![
        rune_format::rune::hydron::values::Value::Vec8([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]),
        rune_format::rune::hydron::values::Value::Vec8([2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]),
    ]));

    // Evaluate the kernel declaration
    let result = eval.eval_stmt(&stmts[0]);
    assert!(result.is_ok(), "Kernel declaration evaluation failed");
    assert_eq!(result.unwrap(), rune_format::rune::hydron::values::Value::Null);

    // Check that PTX file was created
    let cache_dir = Path::new("target").join("rune").join("cache");
    assert!(cache_dir.exists(), "Cache directory should exist");

    // Find PTX files in cache directory
    let ptx_files: Vec<_> = fs::read_dir(&cache_dir)
        .expect("Failed to read cache directory")
        .filter_map(|entry| entry.ok())
        .map(|entry| entry.path())
        .filter(|path| path.extension().map_or(false, |ext| ext == "ptx"))
        .collect();

    assert!(!ptx_files.is_empty(), "At least one PTX file should be generated");
}

#[cfg(not(feature = "cuda"))]
#[test]
fn test_archetype_kernel_compilation_no_cuda() {
    // Define RUNE script with kernel declaration
    let script = r#"
Kernel:MyRowDot := CUDA:Archetype:RowDot(D: 8) and MyData -> MyRowDot
"#;

    // Parse the script
    let stmts = parse(script).expect("Failed to parse RUNE script");

    // Set up evaluator
    let mut eval = Evaluator::new();

    // Evaluate the kernel declaration - should fail without CUDA
    let result = eval.eval_stmt(&stmts[0]);
    assert!(result.is_err(), "Kernel declaration should fail without CUDA feature");

    if let Err(err) = result {
        assert!(err.to_string().contains("CUDA feature not enabled"));
    }
}

File: src\rune\hydron\perception.rs
===================================
/* src/rune/hydron/perception.rs */
//! Perception Engine: Signal (ByteLex) and Structure (Morphology) analysis.
//!
//! # Hydron – Perception Module
//!▫~•◦--------------------------‣
//!
//! This module provides the core mechanisms to convert raw text into geometric vectors
//! based on two distinct properties within the RUNE ecosystem, using zero external dependencies:
//!
//! 1.  **Signal (The Body):** Raw byte-level convolution using deterministic hashing.
//!     Captures "shape", typos, and non-linguistic patterns. Implemented via `signal_encode`.
//! 2.  **Structure (The Skeleton):** Morphological decomposition (Prefix/Root/Suffix).
//!     Captures linguistic logic and semantic composition. Implemented via `morph_analyze`.
//!
//! These vectors are designed to be fused (via `/\`) to create a lossless,
//! holographic embedding of the input.
//!
//! ### Key Capabilities
//! - **Signal Encoding:** Deterministic byte-stream convolution into normalized 8D vectors.
//! - **Morphological Analysis:** Greedy affix decomposition into geometric representations.
//! - **Root Recognition:** Common root validation against a curated lexicon for semantic anchoring.
//! - **Zero Dependencies:** All logic implemented using const-time hashing and static affix tables.
//!
//! ### Architectural Notes
//! This module is designed for integration with the broader RUNE/Hydron geometry pipeline.
//! Vectors produced here are normalized to the unit sphere (S7-compatible) and can be
//! composed using geometric algebra operations.
//!
//! ### Example
//! ```rust
//! use rune_format::rune::hydron::perception::{signal_encode, morph_analyze};
//!
//! let bytes = b"unbelievably";
//! let signal_vec = signal_encode(bytes);
//! let morph_vec = morph_analyze("unbelievably");
//!
//! // Both vectors are normalized and ready for geometric composition.
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

// --- 1. STATIC DATA (The Skeleton) ---
// High-coverage English affixes ported from the original lexicon architecture.
// These allow the engine to "see" word structure without a dictionary.

/// Comprehensive prefix table for morphological decomposition.
/// Ordered alphabetically for binary search compatibility.
/// Includes productive derivational and inflectional prefixes from Latin, Greek, and Germanic roots.
static PREFIXES: &[&str] = &[
    "a", "ab", "abs", "ac", "ad", "af", "ag", "al", "am", "an", "ante", "anti", "ap", "apo",
    "arch", "as", "at", "auto", "be", "bi", "bio", "cata", "circum", "cis", "co", "col", "com",
    "con", "contra", "cor", "counter", "de", "deca", "deci", "demi", "di", "dia", "dif", "dis",
    "down", "duo", "dys", "e", "ec", "eco", "ecto", "ef", "electro", "em", "en", "endo", "epi",
    "equi", "ex", "exo", "extra", "fore", "geo", "hemi", "hetero", "hexa", "homo", "hydro",
    "hyper", "hypo", "il", "im", "in", "infra", "inter", "intra", "intro", "ir", "iso", "kilo",
    "macro", "mal", "mega", "meta", "micro", "mid", "milli", "mini", "mis", "mono", "multi",
    "nano", "neo", "neuro", "non", "ob", "oc", "oct", "octa", "of", "omni", "op", "ortho", "out",
    "over", "paleo", "pan", "para", "penta", "per", "peri", "photo", "poly", "post", "pre",
    "preter", "pro", "proto", "pseudo", "pyro", "quadr", "quasi", "re", "retro", "self", "semi",
    "sept", "sex", "sub", "suc", "suf", "sug", "sum", "sup", "super", "sur", "sus", "sym", "syn",
    "tele", "tetra", "thermo", "trans", "tri", "twi", "ultra", "un", "under", "uni", "up", "vice",
];

/// Comprehensive suffix table for morphological decomposition.
/// Ordered alphabetically for binary search compatibility.
/// Includes productive derivational and inflectional suffixes across major word classes.
static SUFFIXES: &[&str] = &[
    "able",
    "ably",
    "ac",
    "aceous",
    "acious",
    "age",
    "al",
    "algia",
    "an",
    "ance",
    "ancy",
    "ant",
    "ar",
    "ard",
    "ary",
    "ase",
    "ate",
    "ation",
    "ative",
    "ator",
    "atory",
    "cide",
    "cracy",
    "crat",
    "cy",
    "dom",
    "dox",
    "ed",
    "ee",
    "eer",
    "en",
    "ence",
    "ency",
    "ent",
    "eous",
    "er",
    "ern",
    "ery",
    "es",
    "ese",
    "esque",
    "ess",
    "est",
    "etic",
    "ette",
    "ful",
    "fy",
    "gen",
    "genic",
    "gon",
    "gram",
    "graph",
    "graphy",
    "hood",
    "ia",
    "ial",
    "ian",
    "iasis",
    "iatric",
    "iatry",
    "ible",
    "ibly",
    "ic",
    "ical",
    "ically",
    "ice",
    "ician",
    "ics",
    "id",
    "ide",
    "ie",
    "ier",
    "iferous",
    "ific",
    "ification",
    "ify",
    "ile",
    "ine",
    "ing",
    "ion",
    "ior",
    "ious",
    "ish",
    "ism",
    "ist",
    "istic",
    "ite",
    "itis",
    "itive",
    "ity",
    "ium",
    "ive",
    "ize",
    "kin",
    "less",
    "let",
    "like",
    "ling",
    "logue",
    "logy",
    "ly",
    "lysis",
    "lyte",
    "lytic",
    "man",
    "mancy",
    "mania",
    "ment",
    "meter",
    "metry",
    "most",
    "ness",
    "oid",
    "ology",
    "oma",
    "or",
    "ory",
    "ose",
    "osis",
    "ous",
    "path",
    "pathy",
    "ped",
    "phage",
    "phagy",
    "phile",
    "philia",
    "phobe",
    "phobia",
    "phone",
    "phony",
    "phyte",
    "plasty",
    "pod",
    "polis",
    "proof",
    "ry",
    "s",
    "scope",
    "scopy",
    "sect",
    "ship",
    "sion",
    "sis",
    "some",
    "sophy",
    "ster",
    "th",
    "tion",
    "tomy",
    "tor",
    "tous",
    "trix",
    "tron",
    "tude",
    "ty",
    "ular",
    "ule",
    "ure",
    "ward",
    "wards",
    "wise",
    "woman",
    "worthy",
    "y",
    "yer",
];

/// Common etymological roots for semantic anchoring.
/// These high-frequency roots provide validation and boost morphological confidence.
/// Organized by semantic domain for future extensibility.
///
/// **Design Rationale:**
/// Rather than storing all possible roots (which would balloon the binary), we include
/// productive roots that appear across multiple derived forms. This allows the morphology
/// engine to recognize when a decomposition has landed on a "real" root vs. arbitrary residue.
static ROOTS: &[&str] = &[
    // --- Motion & Position ---
    "cede", "ceed", "cess", "cur", "curr", "curs", "duc", "duct", "fer", "gress", "ject", "miss",
    "mit", "mov", "mot", "pass", "ped", "pod", "port", "pos", "puls", "sequ", "spec", "spect",
    "sta", "stat", "tend", "tens", "tent", "tract", "vene", "vent", "vert", "vers", "via", "voy",
    // --- Perception & Cognition ---
    "audi", "audit", "cept", "ceive", "cogn", "cred", "dic", "dict", "log", "mem", "ment", "not",
    "path", "pens", "phon", "pict", "sci", "scrib", "script", "sens", "sent", "sign", "soph",
    "spec", "vid", "vis", // --- Action & Creation ---
    "cre", "creat", "fac", "fact", "fect", "fic", "fig", "form", "gen", "oper", "plic", "ply",
    "pon", "pos", "scrib", "struct", "tain", "ten", "volv",
    // --- Communication & Expression ---
    "claim", "clam", "loqu", "locut", "nounce", "nunce", "parl", "phan", "phone", "voc", "voic",
    "voke", // --- Measurement & Science ---
    "centr", "chron", "cycl", "dyna", "graph", "gram", "hydr", "log", "metr", "meter", "morph",
    "nym", "phys", "scop", "sphere", "techn", "therm", // --- Social & Legal ---
    "civ", "dem", "jud", "jur", "jus", "leg", "liber", "poli", "polit", "popul", "reg", "soci",
    // --- Life & Nature ---
    "anim", "anthrop", "bio", "corp", "geo", "herb", "viv", "zoo",
    // --- Emotion & Value ---
    "am", "amor", "bene", "bon", "fort", "grat", "mal", "magn", "misc", "pac", "pat", "phil",
    "vict", "vinc", // --- Quantity & Relation ---
    "equ", "fin", "fract", "frag", "grad", "gress", "medi", "min", "mit", "multi", "nom", "plen",
    "plu", "plus", "simil", "sing", "sol", "uni", "vac", "van", "void",
    // --- Time & Change ---
    "aev", "chron", "dur", "gener", "nov", "prim", "temp", "vest",
    // --- Quality & State ---
    "acer", "acr", "acu", "alb", "alt", "clar", "dign", "dur", "firm", "fort", "grav", "lev",
    "liber", "lucid", "nigr", "prob", "purg", "sacr", "san", "satis", "secur", "serv", "sever",
    "simpl", "stabil", "strict", "triv", "turb", "urb", "util", "vag", "val", "var", "ver",
    "vigil",
];

// --- 2. MATH KERNEL (Deterministic Hashing) ---

/// SplitMix64: Fast, dependency-free pseudo-random hashing.
/// Used to project arbitrary bytes into the 8D geometric space deterministically.
///
/// # Invariants
/// - Same input always produces same output (deterministic).
/// - Output has high avalanche properties (single-bit changes propagate).
///
/// # Arguments
/// * `x` - Seed value for the hash.
///
/// # Returns
/// * `u64` - The hashed value.
#[inline]
const fn splitmix64(mut x: u64) -> u64 {
    x = x.wrapping_add(0x9E3779B97F4A7C15);
    let mut z = x;
    z = (z ^ (z >> 30)).wrapping_mul(0xBF58476D1CE4E5B9);
    z = (z ^ (z >> 27)).wrapping_mul(0x94D049BB133111EB);
    z ^ (z >> 31)
}

/// Map a hash seed to a unit float within [-0.5, 0.5).
/// This centers the signal around the origin, ideal for geometric composition.
///
/// # Arguments
/// * `seed` - The hash seed to convert.
///
/// # Returns
/// * `f32` - A floating-point value in the range [-0.5, 0.5).
#[inline]
fn hash_to_float(seed: u64) -> f32 {
    let bits = splitmix64(seed);
    let as_f64 = (bits >> 11) as f64 * (1.0 / (1u64 << 53) as f64);
    (as_f64 as f32) - 0.5
}

// --- 3. SIGNAL ENCODING (The Body) ---

/// Encodes raw bytes into an 8D semantic vector using strided convolution.
///
/// This function treats the byte stream as a continuous signal, applying a local
/// convolution window and pooling the result into a normalized vector. Each byte
/// contributes to all 8 dimensions based on its value and position, creating a
/// holographic representation of the input.
///
/// # Algorithmic Details
/// - **Window Size:** Minimum of 4 or the input length, providing local context.
/// - **Position Encoding:** Modulo-based positional hashing ensures location-awareness.
/// - **Normalization:** Result is projected onto the unit sphere (L2 norm = 1.0).
///
/// # Arguments
/// * `bytes` - The raw input byte stream.
///
/// # Returns
/// * `[f32; 8]` - The normalized signal vector. Returns zero vector for empty input.
#[inline]
pub fn signal_encode(bytes: &[u8]) -> [f32; 8] {
    if bytes.is_empty() {
        return [0.0; 8];
    }

    let mut signal = [0.0f32; 8];
    let window_size = 4.min(bytes.len());

    for (i, &b) in bytes.iter().enumerate() {
        for dim in 0..8 {
            let seed = (b as u64)
                .wrapping_mul(31)
                .wrapping_add(dim as u64)
                .wrapping_add((i % window_size) as u64 * 1024);

            let val = hash_to_float(seed);
            signal[dim] += val;
        }
    }

    let norm_sq: f32 = signal.iter().map(|x| x * x).sum();
    if norm_sq > 1e-9 {
        let inv_norm = 1.0 / norm_sq.sqrt();
        for x in &mut signal {
            *x *= inv_norm;
        }
    }

    signal
}

// --- 4. STRUCTURE ANALYSIS (The Skeleton) ---

/// Validate if a potential root exists in the known root lexicon.
/// Uses binary search for O(log n) lookup.
///
/// # Arguments
/// * `candidate` - The root candidate to validate.
///
/// # Returns
/// * `bool` - True if the candidate is a recognized root.
#[inline]
fn is_valid_root(candidate: &str) -> bool {
    ROOTS.iter().any(|&r| r == candidate)
}

/// Analyze string morphology and return a structural hash vector.
///
/// This function decomposes a token into `<prefix>`, `<root>`, `<suffix>` using a
/// greedy longest-match algorithm against static affix tables. The root is validated
/// against a curated lexicon to ensure semantic anchoring. Each component is then
/// hashed into an 8D vector space with distinct seed offsets to prevent collisions.
///
/// # Enhanced Root Recognition
/// After affix stripping, the remaining root is checked against `ROOTS`. If the root
/// is unrecognized but longer than 3 characters, the algorithm attempts progressive
/// suffix stripping to find a valid root kernel. This handles cases like:
/// - "believe" → valid root (recognized)
/// - "believing" → "believ" + "ing" → fallback checks "belie", "beli", "bel" until match or exhaustion
///
/// # Arguments
/// * `token` - The input token to analyze.
///
/// # Returns
/// * `[f32; 8]` - The normalized morphology vector.
#[inline]
pub fn morph_analyze(token: &str) -> [f32; 8] {
    let clean = token
        .trim_matches(|c: char| !c.is_alphanumeric())
        .to_lowercase();

    if clean.is_empty() {
        return [0.0; 8];
    }

    let mut prefix = "";
    let mut suffix = "";
    let mut root = clean.as_str();

    // Identify prefix (greedy longest match)
    for &p in PREFIXES {
        if root.starts_with(p) && root.len() > p.len() + 2 {
            if p.len() > prefix.len() {
                prefix = p;
            }
        }
    }

    if !prefix.is_empty() {
        root = &root[prefix.len()..];
    }

    // Identify suffix (greedy longest match)
    for &s in SUFFIXES {
        if root.ends_with(s) && root.len() > s.len() + 2 {
            if s.len() > suffix.len() {
                suffix = s;
            }
        }
    }

    if !suffix.is_empty() {
        root = &root[..root.len() - suffix.len()];
    }

    // Root validation & progressive kernel extraction
    if !is_valid_root(root) && root.len() > 3 {
        // Attempt progressive stripping to find a valid root kernel
        // Example: "running" → root "run" after "n" → "ing" decomposition
        let mut candidate = root;
        while candidate.len() > 2 {
            if is_valid_root(candidate) {
                root = candidate;
                break;
            }
            // Strip one character from the end
            candidate = &candidate[..candidate.len() - 1];
        }
    }

    // Hash the components into the 8D vector
    let mut vec = [0.0f32; 8];

    let components = [
        (prefix, 100u64), // Prefix offset
        (root, 0u64),     // Root offset
        (suffix, 200u64), // Suffix offset
    ];

    for (str_part, seed_offset) in components {
        if str_part.is_empty() {
            continue;
        }

        for (i, &b) in str_part.as_bytes().iter().enumerate() {
            for dim in 0..8 {
                let seed = (b as u64)
                    .wrapping_add(dim as u64)
                    .wrapping_add(i as u64 * 31)
                    .wrapping_add(seed_offset);

                vec[dim] += hash_to_float(seed);
            }
        }
    }

    let norm_sq: f32 = vec.iter().map(|x| x * x).sum();
    if norm_sq > 1e-9 {
        let inv_norm = 1.0 / norm_sq.sqrt();
        for x in &mut vec {
            *x *= inv_norm;
        }
    }

    vec
}

#[cfg(test)]
mod tests {
    use super::{hash_to_float, is_valid_root, morph_analyze, signal_encode, splitmix64};

    #[test]
    fn test_signal_encode_determinism() {
        let input = b"hello world";
        let v1 = signal_encode(input);
        let v2 = signal_encode(input);
        assert_eq!(v1, v2, "Signal encoding must be deterministic");

        let v3 = signal_encode(b"hello worl");
        let dot: f32 = v1.iter().zip(v3.iter()).map(|(a, b)| a * b).sum();
        assert!(
            dot > 0.8,
            "Similar strings should have high signal correlation"
        );
        assert!(dot < 0.9999, "Distinct strings should not be identical");
    }

    #[test]
    fn test_signal_encode_empty_input() {
        let vec = signal_encode(b"");
        assert_eq!(vec, [0.0; 8], "Empty input should produce zero vector");
    }

    #[test]
    fn test_signal_encode_normalization() {
        let vec = signal_encode(b"test");
        let norm: f32 = vec.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!(
            (norm - 1.0).abs() < 1e-5,
            "Signal vector must be normalized"
        );
    }

    #[test]
    fn test_morph_analyze_decomposition() {
        let v1 = morph_analyze("unbelievably");
        let v2 = morph_analyze("believer");

        let dot: f32 = v1.iter().zip(v2.iter()).map(|(a, b)| a * b).sum();
        assert!(
            dot > 0.0,
            "Shared roots should produce positive correlation"
        );
    }

    #[test]
    fn test_morph_analyze_affix_handling() {
        let v_redo = morph_analyze("redo");
        let v_do = morph_analyze("do");

        assert_ne!(v_redo, v_do, "Prefix presence should alter the vector");
    }

    #[test]
    fn test_morph_analyze_empty_input() {
        let vec = morph_analyze("");
        assert_eq!(vec, [0.0; 8], "Empty input should produce zero vector");
    }

    #[test]
    fn test_morph_analyze_normalization() {
        let vec = morph_analyze("testing");
        let norm: f32 = vec.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!(
            (norm - 1.0).abs() < 1e-5,
            "Morphology vector must be normalized"
        );
    }

    #[test]
    fn test_morph_analyze_non_alphanumeric() {
        let vec1 = morph_analyze("test!");
        let vec2 = morph_analyze("test");
        assert_eq!(
            vec1, vec2,
            "Non-alphanumeric trimming should produce identical vectors"
        );
    }

    #[test]
    fn test_root_validation() {
        assert!(is_valid_root("dict"), "Known root 'dict' should validate");
        assert!(is_valid_root("spec"), "Known root 'spec' should validate");
        assert!(!is_valid_root("xyz123"), "Unknown root should not validate");
    }

    #[test]
    fn test_progressive_root_extraction() {
        // This is an implicit test via morph_analyze behavior
        // If we had "dictating" it should find root "dict"
        let _vec = morph_analyze("dictating");
        // The internal logic should strip "ing", leaving "dictat",
        // then progressively strip to find "dict" as a valid root
    }

    #[test]
    fn test_hash_to_float_range() {
        for seed in 0..1000 {
            let val = hash_to_float(seed);
            assert!(
                val >= -0.5 && val < 0.5,
                "hash_to_float must produce values in [-0.5, 0.5)"
            );
        }
    }

    #[test]
    fn test_splitmix64_determinism() {
        let seed = 42;
        let h1 = splitmix64(seed);
        let h2 = splitmix64(seed);
        assert_eq!(h1, h2, "splitmix64 must be deterministic");
    }

    #[test]
    fn test_splitmix64_avalanche() {
        let h1 = splitmix64(0);
        let h2 = splitmix64(1);
        assert_ne!(h1, h2, "splitmix64 must have avalanche properties");
    }
}

File: src\rune\parts\arrays_of_arrays.rs
========================================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn arrays_of_arrays() {
    println!("Hydron feature required for dynamic arrays of arrays");
}

#[cfg(feature = "hydron")]
pub fn arrays_of_arrays() {
    // Dynamic Arrays of Arrays (Integers)
    let pair1 = Value::Array(vec![Value::Integer(1), Value::Integer(2)]);
    let pair2 = Value::Array(vec![Value::Integer(3), Value::Integer(4)]);
    let pairs_array = Value::Array(vec![pair1, pair2]);

    let mut pairs_map = HashMap::new();
    pairs_map.insert("pairs".to_string(), pairs_array);
    let pairs = Value::Map(pairs_map);

    let out = encode_default(&pairs).unwrap();
    println!("{out}");

    // Dynamic Arrays of Arrays (Strings)
    let spair1 = Value::Array(vec![
        Value::String("a".to_string()),
        Value::String("b".to_string()),
    ]);
    let spair2 = Value::Array(vec![
        Value::String("c".to_string()),
        Value::String("d".to_string()),
    ]);
    let spairs_array = Value::Array(vec![spair1, spair2]);

    let mut spairs_map = HashMap::new();
    spairs_map.insert("pairs".to_string(), spairs_array);
    let string_pairs = Value::Map(spairs_map);

    let out = encode_default(&string_pairs).unwrap();
    println!("\n{out}");

    // Dynamic Matrix
    let row1 = Value::Array(vec![
        Value::Float(1.0),
        Value::Float(2.0),
        Value::Float(3.0),
    ]);
    let row2 = Value::Array(vec![
        Value::Float(4.0),
        Value::Float(5.0),
        Value::Float(6.0),
    ]);
    let row3 = Value::Array(vec![
        Value::Float(7.0),
        Value::Float(8.0),
        Value::Float(9.0),
    ]);
    let matrix_array = Value::Array(vec![row1, row2, row3]);

    let mut matrix_map = HashMap::new();
    matrix_map.insert("matrix".to_string(), matrix_array);
    let matrix = Value::Map(matrix_map);

    let out = encode_default(&matrix).unwrap();
    println!("\n{out}");
}

File: src\rune\hydron\topology.rs
=================================
//! E8 Topology & Weyl Group Operations.
//!
//! # Hydron – Topology Module
//! ▫~•◦------------------------‣
//!
//! Provides adjacency (kissing) relations, Weyl reflections, and simple diffusion over
//! the E8 root lattice. Uses the static root table from hydron-core.
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use hydron_core::get_e8_roots;

/// Returns the indices of the 56 nearest neighbors in the E8 lattice.
/// Roots are neighbors if their dot product is approximately 0.5 (60 degrees).
pub fn get_neighbors(root_idx: usize) -> Vec<u8> {
    let roots = get_e8_roots();
    if root_idx >= roots.len() {
        return vec![];
    }
    let target = roots[root_idx];
    let mut neighbors = Vec::with_capacity(56);

    for (i, root) in roots.iter().enumerate() {
        if i == root_idx {
            continue;
        }
        let dot: f32 = target.iter().zip(root.iter()).map(|(a, b)| a * b).sum();
        if (dot - 0.5).abs() < 1e-4 {
            neighbors.push(i as u8);
        }
    }
    neighbors
}

/// Performs a Weyl reflection of a vector `v` across the hyperplane orthogonal to root `r`.
/// Formula (unit roots): v' = v - 2 * <v, r> * r
pub fn weyl_reflect(vec: &[f32; 8], mirror_root: &[f32; 8]) -> [f32; 8] {
    let dot: f32 = vec.iter().zip(mirror_root.iter()).map(|(a, b)| a * b).sum();
    let mut result = [0.0; 8];
    for i in 0..8 {
        result[i] = vec[i] - 2.0 * dot * mirror_root[i];
    }
    result
}

/// Diffuse energy over the E8 lattice (swarm/attention style).
/// Keeps source energy and adds a fraction to neighbors.
pub fn diffuse_energy(energy: &[f32; 240], diffusion_rate: f32) -> [f32; 240] {
    let _roots = get_e8_roots();
    let mut new_field = *energy;

    for i in 0..240 {
        let e = energy[i];
        if e <= 1e-6 {
            continue;
        }
        let neighbors = get_neighbors(i);
        if neighbors.is_empty() {
            continue;
        }
        let flow = e * diffusion_rate;
        let flow_per = flow / neighbors.len() as f32;
        for n in neighbors {
            new_field[n as usize] += flow_per;
        }
    }

    new_field
}

File: src\rune\hydron\values.rs
===============================
//! RUNE Evaluation Engine - Runtime Value System
//!
//! Provides runtime evaluation for RUNE expressions, including:
//! - E8 geometric types (vectors, octonions)
//! - GF(8) Galois field arithmetic
//! - Context-aware evaluation based on root declarations
//! - Built-in operations that bridge RUNE into Hydron geometry layers
//!
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use serde::{Deserialize, Serialize};
use std::collections::{HashMap, hash_map::Entry};
use std::fmt;
use std::sync::{Arc, Mutex, OnceLock};
use thiserror::Error;

// Hydron geometry layers from hydron-core
use hydron_core::{
    FisherLayer, HyperbolicLayer, LorentzianCausalLayer, QuaternionOps, SpacetimePoint,
    SphericalLayer, SymplecticLayer, TopologicalLayer,
};

// Local SIMD implementations (fallback when feature is disabled)
pub fn gf8_add_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    // Simple scalar implementation
    let mut result = [0.0f32; 8];
    for i in 0..8 {
        result[i] = a[i] + b[i];
    }
    result
}

pub fn gf8_sub_simd(a: &[f32; 8], b: &[f32; 8]) -> [f32; 8] {
    // Simple scalar implementation
    let mut result = [0.0f32; 8];
    for i in 0..8 {
        result[i] = a[i] - b[i];
    }
    result
}

pub fn gf8_matvec_simd(matrix: &[[f32; 8]; 8], vec: &[f32; 8]) -> [f32; 8] {
    // Matrix-vector multiplication
    let mut result = [0.0f32; 8];
    for i in 0..8 {
        for j in 0..8 {
            result[i] += matrix[i][j] * vec[j];
        }
    }
    result
}

pub fn gf8_norm2_simd(vec: &[f32; 8]) -> f32 {
    // Squared norm
    vec.iter().map(|x| x * x).sum()
}

pub fn gf8_dot_simd(a: &[f32; 8], b: &[f32; 8]) -> f32 {
    // Dot product
    let mut sum = 0.0f32;
    for i in 0..8 {
        sum += a[i] * b[i];
    }
    sum
}

pub fn get_available_f32_256_intrinsics() -> Vec<&'static str> {
    // Return empty vec when SIMD not available
    vec![]
}

pub fn print_simd_capabilities() {
    // No-op when SIMD not available
}

use rune_hex::hex as hex_model;

/// Runtime value types in the E8 ecosystem
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
#[serde(untagged)]
pub enum Value {
    /// Boolean value
    Bool(bool),

    /// Floating-point number (for RUNE expressions)
    Float(f64),

    /// String value
    String(String),

    /// Array of values
    Array(Vec<Value>),

    /// Scalar numeric value (f32)
    Scalar(f32),

    /// 8-dimensional geometric float (canonical Gf8)
    Gf8(hydron_core::Gf8),

    /// Geo-Semantic lattice frame (allowed E8 root indices)
    Frame(Vec<u8>),

    /// Spatially indexed associative memory (E8 root -> data)
    Atlas(HashMap<u8, Vec<Value>>),

    /// Spacetime point (Lorentzian coords)
    Spacetime(SpacetimePoint),

    /// DomR result (dominant E8 roots)
    DomR(hex_model::DomR),

    /// 8-dimensional vector in E8 lattice
    Vec8([f32; 8]),

    /// 16-dimensional phase space vector (position + momentum)
    Vec16([f32; 16]),

    /// Octonion (8-dimensional non-associative algebra)
    Octonion(Octonion),

    /// Quaternion (4D rotation)
    Quaternion([f32; 4]),

    /// Symbolic reference (unevaluated)
    Symbol(String),

    /// 8x8 matrix (Fisher information, etc.)
    Matrix8x8([[f32; 8]; 8]),

    /// Betti numbers (topological invariants)
    Betti([u32; 3]),

    /// Collection of Vec8 points (for point clouds)
    PointCloud(Vec<[f32; 8]>),

    // --- Extended Types ---
    Integer(i128),
    Byte(u8),
    Char(char),
    Map(HashMap<String, Value>),
    Bytes(Vec<u8>),
    Null,
    Complex([f64; 2]),

    // Advanced Types
    BigInt(Vec<u64>),   // Arbitrary precision integer parts
    Decimal(i128, u32), // Mantissa, Scale (Decimal = m * 10^-s)

    // Structural Types
    Object(RuneObject),
    Enum(String, String, Option<Box<Value>>), // EnumName, Variant, Payload
    Union(Box<Value>),                        // Type-erased union value
    Struct(String, Vec<Value>),               // StructName, Tuple-like fields
    Tuple(Vec<Value>),
    Set(Vec<Value>), // Using Vec for set to allow non-hashable values (linear scan)

    // Functional & Async
    Function(RuneFunction),
    Lambda(RuneLambda),
    #[serde(skip)]
    Future(RuneFuture),
    #[serde(skip)]
    Stream(RuneStream),
    Promise(RunePromise),
    Coroutine(RuneCoroutine),

    // System
    Pointer(usize),
    Interface(String),            // Interface name/ID
    Class(String),                // Class name/ID
    Generic(String, Vec<String>), // Name, TypeParams

    /// Error value
    Error(String),
}

// --- Advanced Type Implementations ---

/// Glyph-capable structural algebra over runtime values.
pub trait RuneGeometric {
    /// Split-join (midpoint / meet) glyph `/\`.
    fn meet(&self, other: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Join-split (antipodal midpoint) glyph `\/`.
    fn join(&self, other: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Projection glyph `|\`.
    fn project(&self, target: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Rejection glyph `\|` (component orthogonal to target).
    fn reject(&self, target: &Self) -> Result<Value, EvalError>
    where
        Self: Sized;

    /// Universal distance glyph `|/` returning a scalar distance.
    fn distance(&self, other: &Self) -> Result<f32, EvalError>
    where
        Self: Sized;

    /// Structural match check for filtering.
    fn matches_pattern(&self, pattern: &Self) -> bool;
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct RuneObject {
    pub class: String,
    pub fields: HashMap<String, Value>,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct RuneFunction {
    pub name: String,
    pub args: Vec<String>,
    pub body: String, // AST or Bytecode reference
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct RuneLambda {
    pub captures: HashMap<String, Value>,
    pub args: Vec<String>,
    pub body: String,
}

#[derive(Debug, Clone)]
pub struct RuneFuture {
    pub id: String,
    pub state: Arc<Mutex<FutureState>>,
}

impl PartialEq for RuneFuture {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

#[derive(Debug, Clone)]
pub enum FutureState {
    Pending,
    Resolved(Value),
    Rejected(String),
}

#[derive(Debug, Clone)]
pub struct RuneStream {
    pub id: String,
    pub buffer: Arc<Mutex<Vec<Value>>>,
}

impl PartialEq for RuneStream {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RunePromise {
    pub id: String,
    // Promise is the write-side of a Future
}

impl PartialEq for RunePromise {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RuneCoroutine {
    pub id: String,
    pub pc: usize, // Program counter
}

impl PartialEq for RuneCoroutine {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

/// Octonion representation: (scalar, 7 imaginary units)
#[derive(Debug, Clone, Copy, PartialEq, Serialize, Deserialize)]
pub struct Octonion {
    pub scalar: f32,
    pub i: [f32; 7], // e1, e2, e3, e4, e5, e6, e7
}

impl Octonion {
    /// Create a new octonion
    pub fn new(scalar: f32, i: [f32; 7]) -> Self {
        Self { scalar, i }
    }

    /// Create a real octonion (pure scalar)
    pub fn real(scalar: f32) -> Self {
        Self {
            scalar,
            i: [0.0; 7],
        }
    }

    /// Octonion multiplication (non-associative!)
    ///
    /// Implements full Fano-plane based multiplication:
    /// (a0 + a·e) * (b0 + b·e) =
    ///   (a0*b0 - a·b) + (a0*b + b0*a + a × b),
    /// where a × b is the G₂-invariant 7D cross product induced by the Fano plane.
    pub fn mul(&self, other: &Octonion) -> Octonion {
        let a0 = self.scalar;
        let b0 = other.scalar;
        let a = &self.i;
        let b = &other.i;

        // Scalar part: a0*b0 - a·b
        let mut scalar = a0 * b0;
        for k in 0..7 {
            scalar -= a[k] * b[k];
        }

        // Imaginary part: a0*b + b0*a + a × b
        let mut imag = [0.0f32; 7];

        // Linear terms a0*b + b0*a
        for k in 0..7 {
            imag[k] += a0 * b[k] + b0 * a[k];
        }

        // Cross product term a × b via Fano plane structure constants
        //
        // We encode the oriented Fano triples for the imaginary units e1..e7.
        // Indices 0..6 correspond to e1..e7.
        //
        // The triples below define:
        //   e_i * e_j =  e_k  if (i,j,k) in oriented triple
        //   e_j * e_i = -e_k  (anti-commutativity)
        //
        // The chosen convention is one standard G₂ / octonion orientation:
        //   (1,2,3), (1,4,5), (1,6,7),
        //   (2,4,6), (2,5,7), (3,4,7), (3,5,6)
        const FANO_TRIPLES: &[(usize, usize, usize)] = &[
            (0, 1, 2),
            (0, 3, 4),
            (0, 5, 6),
            (1, 3, 5),
            (1, 4, 6),
            (2, 3, 6),
            (2, 4, 5),
        ];

        // Helper: product of basis elements e_(i+1) * e_(j+1)
        // Returns (scalar_part, imag_basis) where imag_basis[k] is the coefficient of e_(k+1).
        fn basis_mul(i: usize, j: usize) -> (f32, [f32; 7]) {
            debug_assert!(i < 7 && j < 7);
            if i == j {
                // e_i * e_i = -1
                return (-1.0, [0.0; 7]);
            }

            for &(a, b, c) in FANO_TRIPLES.iter() {
                // e_a * e_b =  e_c, e_b * e_a = -e_c
                if i == a && j == b {
                    let mut v = [0.0f32; 7];
                    v[c] = 1.0;
                    return (0.0, v);
                }
                if i == b && j == a {
                    let mut v = [0.0f32; 7];
                    v[c] = -1.0;
                    return (0.0, v);
                }

                // e_b * e_c =  e_a, e_c * e_b = -e_a
                if i == b && j == c {
                    let mut v = [0.0f32; 7];
                    v[a] = 1.0;
                    return (0.0, v);
                }
                if i == c && j == b {
                    let mut v = [0.0f32; 7];
                    v[a] = -1.0;
                    return (0.0, v);
                }

                // e_c * e_a =  e_b, e_a * e_c = -e_b
                if i == c && j == a {
                    let mut v = [0.0f32; 7];
                    v[b] = 1.0;
                    return (0.0, v);
                }
                if i == a && j == c {
                    let mut v = [0.0f32; 7];
                    v[b] = -1.0;
                    return (0.0, v);
                }
            }

            // This should never be reached if FANO_TRIPLES covers all oriented pairs.
            (0.0, [0.0; 7])
        }

        // Accumulate a × b via bilinearity:
        // (∑ a_i e_i) * (∑ b_j e_j) = ∑_{i,j} a_i b_j (e_i * e_j)
        // We already handled the i == j scalar contribution above,
        // so here we only need i != j and only add imaginary parts.
        for i in 0..7 {
            if a[i] == 0.0 {
                continue;
            }
            for j in 0..7 {
                if b[j] == 0.0 || i == j {
                    continue;
                }
                let (_s_part, basis_vec) = basis_mul(i, j);
                let coeff = a[i] * b[j];

                // Only imaginary contributions are expected here (_s_part is 0.0 for i != j).
                for k in 0..7 {
                    imag[k] += coeff * basis_vec[k];
                }
            }
        }

        Octonion { scalar, i: imag }
    }

    /// Conjugate of octonion
    pub fn conjugate(&self) -> Octonion {
        let mut neg_i = self.i;
        for x in &mut neg_i {
            *x = -*x;
        }
        Octonion {
            scalar: self.scalar,
            i: neg_i,
        }
    }

    /// Norm (magnitude) of octonion
    pub fn norm(&self) -> f32 {
        let mut sum = self.scalar * self.scalar;
        for &x in &self.i {
            sum += x * x;
        }
        sum.sqrt()
    }
}

impl fmt::Display for Octonion {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.scalar)?;
        for (i, &val) in self.i.iter().enumerate() {
            if val != 0.0 {
                write!(f, " + {}e{}", val, i + 1)?;
            }
        }
        Ok(())
    }
}

// Shared causal layer for Rune runtime (Value payloads)
static CAUSAL_LAYER: OnceLock<Mutex<LorentzianCausalLayer<Value>>> = OnceLock::new();

fn causal_layer() -> &'static Mutex<LorentzianCausalLayer<Value>> {
    CAUSAL_LAYER.get_or_init(|| Mutex::new(LorentzianCausalLayer::new()))
}

// Gf8 is imported from hydron-core via the module re-exports
// (see src/rune/hydron/mod.rs)

impl Value {
    /// Insert data into an Atlas at the location defined by a vector.
    pub fn atlas_insert(&mut self, key_vector: &Value, data: Value) -> Result<(), EvalError> {
        match self {
            Value::Atlas(map) => {
                let gf8 = match key_vector {
                    Value::Gf8(g) => *g,
                    Value::Vec8(v) => hydron_core::Gf8::new(*v),
                    _ => return Err(EvalError::TypeMismatch("Atlas key must be a vector".into())),
                };

                let (idx, _root) = gf8.quantize();

                match map.entry(idx) {
                    Entry::Occupied(mut e) => {
                        e.get_mut().push(data);
                    }
                    Entry::Vacant(e) => {
                        e.insert(vec![data]);
                    }
                }
                Ok(())
            }
            _ => Err(EvalError::TypeMismatch("Target is not an Atlas".into())),
        }
    }

    /// Recall data from an Atlas near the location defined by a vector.
    pub fn atlas_recall(&self, query_vector: &Value) -> Result<Value, EvalError> {
        match self {
            Value::Atlas(map) => {
                let gf8 = match query_vector {
                    Value::Gf8(g) => *g,
                    Value::Vec8(v) => hydron_core::Gf8::new(*v),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Atlas query must be a vector".into(),
                        ));
                    }
                };

                let (idx, _root) = gf8.quantize();

                if let Some(items) = map.get(&idx) {
                    Ok(Value::Array(items.clone()))
                } else {
                    Ok(Value::Array(vec![]))
                }
            }
            _ => Err(EvalError::TypeMismatch("Target is not an Atlas".into())),
        }
    }
    /// Add two values
    pub fn add(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a + b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a + b)),

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot add arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.add(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = a[i] + b[i];
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(a), Value::Gf8(b)) => {
                #[cfg(feature = "simd")]
                {
                    let result_coords = gf8::gf8_add_simd(a.coords(), b.coords());
                    Ok(Value::Gf8(Gf8::new(result_coords)))
                }
                #[cfg(not(feature = "simd"))]
                {
                    Ok(Value::Gf8(*a + *b))
                }
            }

            (Value::Octonion(a), Value::Octonion(b)) => {
                let mut result_i = [0.0f32; 7];
                for (i, result) in result_i.iter_mut().enumerate() {
                    *result = a.i[i] + b.i[i];
                }
                Ok(Value::Octonion(Octonion {
                    scalar: a.scalar + b.scalar,
                    i: result_i,
                }))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot add {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Multiply two values
    pub fn mul(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a * b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a * b)),

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot multiply arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.mul(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Scalar(s), Value::Vec8(v)) | (Value::Vec8(v), Value::Scalar(s)) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = v[i] * s;
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(a), Value::Scalar(s)) | (Value::Scalar(s), Value::Gf8(a)) => {
                Ok(Value::Gf8(*a * *s))
            }

            (Value::Octonion(a), Value::Octonion(b)) => Ok(Value::Octonion(a.mul(b))),

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot multiply {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Subtract two values
    pub fn sub(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a - b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a - b)),

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot subtract arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.sub(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = a[i] - b[i];
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(a), Value::Gf8(b)) => Ok(Value::Gf8(*a - *b)),

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot subtract {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Divide two values
    pub fn div(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Float(a / b))
            }

            (Value::Scalar(a), Value::Scalar(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Scalar(a / b))
            }

            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot divide arrays of different lengths: {} and {}",
                        a.len(),
                        b.len()
                    )));
                }
                let mut result = Vec::new();
                for (va, vb) in a.iter().zip(b.iter()) {
                    result.push(va.div(vb)?);
                }
                Ok(Value::Array(result))
            }

            (Value::Vec8(v), Value::Scalar(s)) => {
                if *s == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = v[i] / s;
                }
                Ok(Value::Vec8(result))
            }

            (Value::Gf8(_a), Value::Gf8(_b)) => {
                // Division for geometric Gf8 not directly supported
                Err(EvalError::TypeMismatch(
                    "Division not supported for Gf8 geometric types".to_string(),
                ))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot divide {:?} by {:?}",
                self, other
            ))),
        }
    }

    /// Power operation
    pub fn pow(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a.powf(*b))),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar(a.powf(*b))),

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot raise {:?} to power {:?}",
                self, other
            ))),
        }
    }

    /// Modulo operation
    pub fn modulo(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Float(a % b))
            }

            (Value::Scalar(a), Value::Scalar(b)) => {
                if *b == 0.0 {
                    return Err(EvalError::DivisionByZero);
                }
                Ok(Value::Scalar(a % b))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compute {:?} mod {:?}",
                self, other
            ))),
        }
    }

    /// Geometric midpoint (type-preserving where possible).
    /// Used by the `/\` and `/|` glyphs.
    pub fn geometric_midpoint(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            // Preserve Gf8 on the spherical manifold via SLERP at t = 0.5
            (Value::Gf8(a), Value::Gf8(b)) => Ok(Value::Gf8(a.spherical_slerp(b, 0.5))),

            // Quaternion midpoint via SLERP
            (Value::Quaternion(a), Value::Quaternion(b)) => {
                Ok(Value::Quaternion(QuaternionOps::slerp(a, b, 0.5)))
            }

            // Octonion linear average (vector space)
            (Value::Octonion(a), Value::Octonion(b)) => {
                let scalar = (a.scalar + b.scalar) * 0.5;
                let mut i = [0.0; 7];
                for k in 0..7 {
                    i[k] = (a.i[k] + b.i[k]) * 0.5;
                }
                Ok(Value::Octonion(Octonion { scalar, i }))
            }

            // Vec8 midpoint
            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut res = [0.0; 8];
                for k in 0..8 {
                    res[k] = (a[k] + b[k]) * 0.5;
                }
                Ok(Value::Vec8(res))
            }

            // Vec16 midpoint
            (Value::Vec16(a), Value::Vec16(b)) => {
                let mut res = [0.0; 16];
                for k in 0..16 {
                    res[k] = (a[k] + b[k]) * 0.5;
                }
                Ok(Value::Vec16(res))
            }

            // Scalar/float midpoint returned as Scalar (geometry is f32-based)
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar((a + b) * 0.5)),
            (Value::Float(a), Value::Float(b)) => Ok(Value::Scalar((*a as f32 + *b as f32) * 0.5)),
            (Value::Scalar(a), Value::Float(b)) | (Value::Float(b), Value::Scalar(a)) => {
                Ok(Value::Scalar((*a + *b as f32) * 0.5))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compute midpoint of {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Antipodal midpoint (mean then negate). Used by `\/`.
    pub fn geometric_antipode_midpoint(&self, other: &Value) -> Result<Value, EvalError> {
        let mid = self.geometric_midpoint(other)?;
        mid.negate()
    }

    /// Project `self` onto `target` (|\ glyph).
    pub fn geometric_project(&self, target: &Value) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Gf8(v), Value::Gf8(u)) => {
                let dot = v.dot(u.coords());
                let base = *u.coords();
                Ok(Value::Vec8(base.map(|x| x * dot)))
            }
            (Value::Vec8(v), Value::Vec8(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec8([0.0; 8]));
                }
                let scale = dot / norm_sq;
                Ok(Value::Vec8((*u).map(|x| x * scale)))
            }

            (Value::Vec16(v), Value::Vec16(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec16([0.0; 16]));
                }
                let scale = dot / norm_sq;
                Ok(Value::Vec16(u.map(|x| x * scale)))
            }
            _ => Err(EvalError::TypeMismatch(format!(
                "Projection requires compatible vector types: {:?} -> {:?}",
                self, target
            ))),
        }
    }

    /// Reject `self` from `target` (component orthogonal to target). Used by `\|`.
    pub fn geometric_reject(&self, target: &Value) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Gf8(v), Value::Gf8(u)) => {
                let v_coords = *v.coords();
                let u_coords = *u.coords();
                let dot = v.dot(u.coords());
                let norm_sq: f32 = u_coords.iter().map(|x| x * x).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec8(v_coords));
                }
                let scale = dot / norm_sq;
                let mut rej = [0.0f32; 8];
                for i in 0..8 {
                    rej[i] = v_coords[i] - u_coords[i] * scale;
                }
                Ok(Value::Vec8(rej))
            }
            (Value::Vec8(v), Value::Vec8(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec8(*v));
                }
                let scale = dot / norm_sq;
                let mut rej = [0.0f32; 8];
                for i in 0..8 {
                    rej[i] = v[i] - u[i] * scale;
                }
                Ok(Value::Vec8(rej))
            }

            (Value::Vec16(v), Value::Vec16(u)) => {
                let dot: f32 = v.iter().zip(u.iter()).map(|(a, b)| a * b).sum();
                let norm_sq: f32 = u.iter().map(|a| a * a).sum();
                if norm_sq < 1e-9 {
                    return Ok(Value::Vec16(*v));
                }
                let scale = dot / norm_sq;
                let mut rej = [0.0f32; 16];
                for i in 0..16 {
                    rej[i] = v[i] - u[i] * scale;
                }
                Ok(Value::Vec16(rej))
            }
            _ => Err(EvalError::TypeMismatch(format!(
                "Rejection requires compatible vector types: {:?} ⟂ {:?}",
                self, target
            ))),
        }
    }

    /// Geometric distance (context-aware where possible). Used by `|/`.
    pub fn geometric_distance(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            // Spherical distance for Gf8
            (Value::Gf8(a), Value::Gf8(b)) => Ok(Value::Scalar(a.spherical_distance_to(b))),

            // Euclidean distance for Vec8
            (Value::Vec8(a), Value::Vec8(b)) => {
                let mut sum = 0.0f32;
                for i in 0..8 {
                    let d = a[i] - b[i];
                    sum += d * d;
                }
                Ok(Value::Scalar(sum.sqrt()))
            }

            // Euclidean distance for Vec16
            (Value::Vec16(a), Value::Vec16(b)) => {
                let mut sum = 0.0f32;
                for i in 0..16 {
                    let d = a[i] - b[i];
                    sum += d * d;
                }
                Ok(Value::Scalar(sum.sqrt()))
            }

            // Scalar distance (absolute difference)
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Scalar((a - b).abs())),
            (Value::Float(a), Value::Float(b)) => Ok(Value::Scalar((*a as f32 - *b as f32).abs())),
            (Value::Scalar(a), Value::Float(b)) | (Value::Float(b), Value::Scalar(a)) => {
                Ok(Value::Scalar((*a - *b as f32).abs()))
            }

            _ => Err(EvalError::TypeMismatch(format!(
                "Distance requires compatible geometric types: {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Negate a value (unary minus)
    pub fn negate(&self) -> Result<Value, EvalError> {
        match self {
            Value::Float(a) => Ok(Value::Float(-a)),
            Value::Scalar(a) => Ok(Value::Scalar(-a)),

            Value::Array(a) => {
                let mut result = Vec::new();
                for val in a.iter() {
                    result.push(val.negate()?);
                }
                Ok(Value::Array(result))
            }

            Value::Vec8(v) => {
                let mut result = [0.0; 8];
                for i in 0..8 {
                    result[i] = -v[i];
                }
                Ok(Value::Vec8(result))
            }

            Value::Vec16(v) => {
                let mut result = [0.0; 16];
                for i in 0..16 {
                    result[i] = -v[i];
                }
                Ok(Value::Vec16(result))
            }

            Value::Quaternion(q) => Ok(Value::Quaternion([-q[0], -q[1], -q[2], -q[3]])),

            Value::Gf8(g) => Ok(Value::Gf8(-*g)),

            Value::Octonion(o) => Ok(Value::Octonion(Octonion {
                scalar: -o.scalar,
                i: o.i.map(|x| -x),
            })),

            Value::Map(m) => {
                let mut out = HashMap::with_capacity(m.len());
                for (k, v) in m {
                    out.insert(k.clone(), v.negate()?);
                }
                Ok(Value::Map(out))
            }

            Value::Object(obj) => {
                let mut fields = HashMap::with_capacity(obj.fields.len());
                for (k, v) in &obj.fields {
                    fields.insert(k.clone(), v.negate()?);
                }
                Ok(Value::Object(RuneObject {
                    class: obj.class.clone(),
                    fields,
                }))
            }

            Value::Tuple(vals) => {
                let mut out = Vec::with_capacity(vals.len());
                for v in vals {
                    out.push(v.negate()?);
                }
                Ok(Value::Tuple(out))
            }

            Value::Struct(name, vals) => {
                let mut out = Vec::with_capacity(vals.len());
                for v in vals {
                    out.push(v.negate()?);
                }
                Ok(Value::Struct(name.clone(), out))
            }

            _ => Err(EvalError::TypeMismatch(format!("Cannot negate {:?}", self))),
        }
    }

    /// Less than comparison
    pub fn lt(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a < b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a < b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} < {:?}",
                self, other
            ))),
        }
    }

    /// Less than or equal comparison
    pub fn le(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a <= b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a <= b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} <= {:?}",
                self, other
            ))),
        }
    }

    /// Greater than comparison
    pub fn gt(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a > b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a > b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} > {:?}",
                self, other
            ))),
        }
    }

    /// Greater than or equal comparison
    pub fn ge(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Float(a), Value::Float(b)) => Ok(Value::Bool(a >= b)),
            (Value::Scalar(a), Value::Scalar(b)) => Ok(Value::Bool(a >= b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot compare {:?} >= {:?}",
                self, other
            ))),
        }
    }

    /// Logical AND
    pub fn and(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Bool(a), Value::Bool(b)) => Ok(Value::Bool(*a && *b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot apply AND to {:?} and {:?}",
                self, other
            ))),
        }
    }

    /// Logical OR
    pub fn or(&self, other: &Value) -> Result<Value, EvalError> {
        match (self, other) {
            (Value::Bool(a), Value::Bool(b)) => Ok(Value::Bool(*a || *b)),
            _ => Err(EvalError::TypeMismatch(format!(
                "Cannot apply OR to {:?} and {:?}",
                self, other
            ))),
        }
    }
}

impl RuneGeometric for Value {
    /// Structural containment check: returns true if `self` matches the pattern structurally.
    /// Arrays: all elements must match any element in pattern array? Here we require same length and per-index match.
    /// Maps/Objects: pattern keys must exist in self with matching substructure.
    fn matches_pattern(&self, pattern: &Value) -> bool {
        match (self, pattern) {
            (Value::Map(m), Value::Map(p)) => {
                for (k, pv) in p {
                    if let Some(v) = m.get(k) {
                        if !v.matches_pattern(pv) {
                            return false;
                        }
                    } else {
                        return false;
                    }
                }
                true
            }
            (Value::Object(o), Value::Object(p)) => {
                if o.class != p.class {
                    return false;
                }
                for (k, pv) in &p.fields {
                    if let Some(v) = o.fields.get(k) {
                        if !v.matches_pattern(pv) {
                            return false;
                        }
                    } else {
                        return false;
                    }
                }
                true
            }
            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b || a.len() != b.len() {
                    return false;
                }
                a.iter()
                    .zip(b.iter())
                    .all(|(va, vb)| va.matches_pattern(vb))
            }
            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return false;
                }
                a.iter()
                    .zip(b.iter())
                    .all(|(va, vb)| va.matches_pattern(vb))
            }
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return false;
                }
                a.iter()
                    .zip(b.iter())
                    .all(|(va, vb)| va.matches_pattern(vb))
            }
            // Primitive equality fallback
            _ => self == pattern,
        }
    }
    fn meet(&self, other: &Self) -> Result<Value, EvalError> {
        match (self, other) {
            // Structural recursion
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in structural glyph".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.meet(vb)?);
                }
                Ok(Value::Array(out))
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in structural glyph".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.meet(vb)?);
                }
                Ok(Value::Tuple(out))
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in structural glyph".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.meet(vb)?);
                }
                Ok(Value::Struct(name_a.clone(), out))
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut out = HashMap::new();
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        out.insert(k.clone(), va.meet(vb)?);
                    }
                }
                Ok(Value::Map(out))
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot merge different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut fields = HashMap::new();
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        fields.insert(k.clone(), va.meet(vb)?);
                    }
                }
                Ok(Value::Object(RuneObject {
                    class: a.class.clone(),
                    fields,
                }))
            }

            // Leaf path
            _ => self.geometric_midpoint(other),
        }
    }

    fn join(&self, other: &Self) -> Result<Value, EvalError> {
        let mid = self.meet(other)?;
        mid.negate()
    }

    fn project(&self, target: &Self) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in projection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.project(vb)?);
                }
                Ok(Value::Array(out))
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in projection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.project(vb)?);
                }
                Ok(Value::Tuple(out))
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in projection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.project(vb)?);
                }
                Ok(Value::Struct(name_a.clone(), out))
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut out = HashMap::new();
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        out.insert(k.clone(), va.project(vb)?);
                    }
                }
                Ok(Value::Map(out))
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot project different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut fields = HashMap::new();
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        fields.insert(k.clone(), va.project(vb)?);
                    }
                }
                Ok(Value::Object(RuneObject {
                    class: a.class.clone(),
                    fields,
                }))
            }

            _ => self.geometric_project(target),
        }
    }

    fn reject(&self, target: &Self) -> Result<Value, EvalError> {
        match (self, target) {
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in rejection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.reject(vb)?);
                }
                Ok(Value::Array(out))
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in rejection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.reject(vb)?);
                }
                Ok(Value::Tuple(out))
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in rejection".into(),
                    ));
                }
                let mut out = Vec::with_capacity(a.len());
                for (va, vb) in a.iter().zip(b.iter()) {
                    out.push(va.reject(vb)?);
                }
                Ok(Value::Struct(name_a.clone(), out))
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut out = HashMap::new();
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        out.insert(k.clone(), va.reject(vb)?);
                    }
                }
                Ok(Value::Map(out))
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot reject across different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut fields = HashMap::new();
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        fields.insert(k.clone(), va.reject(vb)?);
                    }
                }
                Ok(Value::Object(RuneObject {
                    class: a.class.clone(),
                    fields,
                }))
            }

            _ => self.geometric_reject(target),
        }
    }

    fn distance(&self, other: &Self) -> Result<f32, EvalError> {
        match (self, other) {
            (Value::Array(a), Value::Array(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Array length mismatch in distance".into(),
                    ));
                }
                let mut accum = 0.0f32;
                for (va, vb) in a.iter().zip(b.iter()) {
                    accum += va.distance(vb)?;
                }
                let n = a.len() as f32;
                Ok(if n > 0.0 { accum / n } else { 0.0 })
            }

            (Value::Tuple(a), Value::Tuple(b)) => {
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Tuple length mismatch in distance".into(),
                    ));
                }
                let mut accum = 0.0f32;
                for (va, vb) in a.iter().zip(b.iter()) {
                    accum += va.distance(vb)?;
                }
                let n = a.len() as f32;
                Ok(if n > 0.0 { accum / n } else { 0.0 })
            }

            (Value::Struct(name_a, a), Value::Struct(name_b, b)) => {
                if name_a != name_b {
                    return Err(EvalError::TypeMismatch(format!(
                        "Struct name mismatch: {} vs {}",
                        name_a, name_b
                    )));
                }
                if a.len() != b.len() {
                    return Err(EvalError::TypeMismatch(
                        "Struct field arity mismatch in distance".into(),
                    ));
                }
                let mut accum = 0.0f32;
                for (va, vb) in a.iter().zip(b.iter()) {
                    accum += va.distance(vb)?;
                }
                let n = a.len() as f32;
                Ok(if n > 0.0 { accum / n } else { 0.0 })
            }

            (Value::Map(a), Value::Map(b)) => {
                let mut accum = 0.0f32;
                let mut count = 0usize;
                for (k, va) in a {
                    if let Some(vb) = b.get(k) {
                        accum += va.distance(vb)?;
                        count += 1;
                    }
                }
                Ok(if count > 0 { accum / count as f32 } else { 0.0 })
            }

            (Value::Object(a), Value::Object(b)) => {
                if a.class != b.class {
                    return Err(EvalError::TypeMismatch(format!(
                        "Cannot measure distance across different classes: {} and {}",
                        a.class, b.class
                    )));
                }
                let mut accum = 0.0f32;
                let mut count = 0usize;
                for (k, va) in &a.fields {
                    if let Some(vb) = b.fields.get(k) {
                        accum += va.distance(vb)?;
                        count += 1;
                    }
                }
                Ok(if count > 0 { accum / count as f32 } else { 0.0 })
            }

            _ => match self.geometric_distance(other)? {
                Value::Scalar(s) => Ok(s),
                Value::Float(f) => Ok(f as f32),
                other => Err(EvalError::TypeMismatch(format!(
                    "Distance expected scalar, got {:?}",
                    other
                ))),
            },
        }
    }
}

impl fmt::Display for Value {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Value::Bool(b) => write!(f, "{}", b),
            Value::Float(v) => write!(f, "{}", v),
            Value::String(s) => write!(f, "{}", s),
            Value::Array(arr) => {
                write!(f, "[")?;
                for (i, val) in arr.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    write!(f, "{}", val)?;
                }
                write!(f, "]")
            }
            Value::Scalar(v) => write!(f, "{}", v),
            Value::Gf8(g) => write!(f, "Gf8({})", g.to_scalar()),
            Value::Vec8(v) => write!(
                f,
                "Vec8[{}, {}, {}, {}, {}, {}, {}, {}]",
                v[0], v[1], v[2], v[3], v[4], v[5], v[6], v[7]
            ),
            Value::Vec16(v) => write!(
                f,
                "Vec16[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]",
                v[0],
                v[1],
                v[2],
                v[3],
                v[4],
                v[5],
                v[6],
                v[7],
                v[8],
                v[9],
                v[10],
                v[11],
                v[12],
                v[13],
                v[14],
                v[15]
            ),
            Value::Octonion(o) => write!(f, "{}", o),
            Value::Quaternion(q) => write!(f, "Quat[{}, {}, {}, {}]", q[0], q[1], q[2], q[3]),
            Value::Spacetime(p) => write!(
                f,
                "Spacetime[t={}, x1={}, x2={}, x3={}, x4={}, x5={}, x6={}, x7={}]",
                p.coords[0],
                p.coords[1],
                p.coords[2],
                p.coords[3],
                p.coords[4],
                p.coords[5],
                p.coords[6],
                p.coords[7]
            ),
            Value::DomR(d) => write!(
                f,
                "DomR(roots={}, scores={})",
                d.roots.len(),
                d.scores.len()
            ),
            Value::Frame(indices) => write!(f, "Frame({} indices)", indices.len()),
            Value::Atlas(map) => write!(f, "Atlas({} roots)", map.len()),
            Value::Symbol(s) => write!(f, "{}", s),
            Value::Matrix8x8(_) => write!(f, "Matrix8x8[...]"),
            Value::Betti(b) => write!(f, "Betti[{}, {}, {}]", b[0], b[1], b[2]),
            Value::PointCloud(points) => write!(f, "PointCloud[{} points]", points.len()),

            // Extended Types Display
            Value::Integer(i) => write!(f, "{}", i),
            Value::Byte(b) => write!(f, "0x{:02X}", b),
            Value::Char(c) => write!(f, "'{}'", c),
            Value::Map(m) => {
                write!(f, "{{")?;
                for (i, (k, v)) in m.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    write!(f, "{}: {}", k, v)?;
                }
                write!(f, "}}")
            }
            Value::Bytes(b) => write!(f, "Bytes[{}]", b.len()),
            Value::Null => write!(f, "null"),
            Value::Complex(c) => write!(f, "{} + {}i", c[0], c[1]),

            // Advanced Types
            Value::BigInt(parts) => write!(f, "BigInt({:?})", parts),
            Value::Decimal(m, s) => write!(f, "Decimal({}e-{})", m, s),

            // Structural
            Value::Object(obj) => write!(f, "Object({})", obj.class),
            Value::Enum(name, variant, _) => write!(f, "{}::{}", name, variant),
            Value::Union(val) => write!(f, "Union({})", val),
            Value::Struct(name, _) => write!(f, "Struct({})", name),
            Value::Tuple(vals) => write!(f, "Tuple({})", vals.len()),
            Value::Set(vals) => write!(f, "Set({})", vals.len()),

            // Functional & Async
            Value::Function(func) => write!(f, "Fn({})", func.name),
            Value::Lambda(_) => write!(f, "Lambda"),
            Value::Future(fut) => write!(f, "Future({})", fut.id),
            Value::Stream(s) => write!(f, "Stream({})", s.id),
            Value::Promise(p) => write!(f, "Promise({})", p.id),
            Value::Coroutine(c) => write!(f, "Coroutine({})", c.id),

            // System
            Value::Pointer(p) => write!(f, "Ptr(0x{:x})", p),
            Value::Interface(i) => write!(f, "Interface({})", i),
            Value::Class(c) => write!(f, "Class({})", c),
            Value::Generic(n, _) => write!(f, "Generic({})", n),

            Value::Error(e) => write!(f, "Error: {}", e),
        }
    }
}

/// Evaluation context with variable bindings and root context
#[derive(Debug, Clone)]
pub struct EvalContext {
    /// Variable bindings
    pub variables: HashMap<String, Value>,

    /// Semantic variable bindings (prefix:name -> value)
    pub semantic_vars: HashMap<String, Value>,

    /// Current root context (affects interpretation)
    root: Option<String>,
}

impl EvalContext {
    /// Create a new evaluation context
    pub fn new() -> Self {
        Self {
            variables: HashMap::new(),
            semantic_vars: HashMap::new(),
            root: None,
        }
    }

    /// Set the root context
    pub fn set_root(&mut self, root: String) {
        self.root = Some(root);
    }

    /// Get the current root context
    pub fn root(&self) -> Option<&str> {
        self.root.as_deref()
    }

    /// Bind a variable to a value
    pub fn bind(&mut self, name: String, value: Value) {
        self.variables.insert(name, value);
    }

    /// Look up a variable
    pub fn lookup(&self, name: &str) -> Option<&Value> {
        self.variables.get(name)
    }
}

impl Default for EvalContext {
    fn default() -> Self {
        Self::new()
    }
}

/// Evaluation errors
#[derive(Debug, Error)]
pub enum EvalError {
    #[error("Type mismatch: {0}")]
    TypeMismatch(String),

    #[error("Undefined variable: {0}")]
    UndefinedVariable(String),

    #[error("Division by zero")]
    DivisionByZero,

    #[error("Invalid operation: {0}")]
    InvalidOperation(String),

    #[error("Unsupported operation: {0}")]
    UnsupportedOperation(String),

    #[error("Not implemented: {0}")]
    NotImplemented(String),
}

// ===================================
// From trait implementations - automatic Value wrapping
// ===================================

impl From<[f32; 8]> for Value {
    fn from(arr: [f32; 8]) -> Self {
        Value::Vec8(arr)
    }
}

impl From<[f32; 16]> for Value {
    fn from(arr: [f32; 16]) -> Self {
        Value::Vec16(arr)
    }
}

impl From<[f32; 4]> for Value {
    fn from(arr: [f32; 4]) -> Self {
        Value::Quaternion(arr)
    }
}

impl From<[u32; 3]> for Value {
    fn from(arr: [u32; 3]) -> Self {
        Value::Betti(arr)
    }
}

// ===================================
// RuneBuiltin - Geometric Operation Dispatch
// ===================================

/// Built-in geometric operations that bridge RUNE into Hydron
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RuneBuiltin {
    // Gf8 core operations
    Gf8Norm,      // [f32;8] → f32
    Gf8Normalize, // [f32;8] → [f32;8]
    Gf8Dot,       // [f32;8], [f32;8] → f32

    // Spherical (S7) operations
    S7Project,   // [f32;8] → [f32;8]
    S7Distance,  // [f32;8], [f32;8] → f32
    S7Slerp,     // [f32;8], [f32;8], f32 → [f32;8]
    S7Antipodal, // [f32;8] → [f32;8]
    S7Mean,      // [[f32;8]] → [f32;8]

    // Hyperbolic operations
    H8Distance,  // [f32;8], [f32;8] → f32
    H8MobiusAdd, // [f32;8], [f32;8] → [f32;8]

    // Fisher information geometry
    FisherDistance, // [f32;8], [f32;8] → f32
    FisherMatrix,   // [f32;8] → [[f32;8];8]
    KLDivergence,   // [f32;8], [f32;8] → f32
    FisherFilter,   // Array, threshold -> Array (novelty filter)

    // Quaternion operations
    QuatSlerp,     // [f32;4], [f32;4], f32 → [f32;4]
    QuatCompose,   // [f32;4], [f32;4] → [f32;4]
    QuatConjugate, // [f32;4] → [f32;4]

    // Symplectic operations
    SymHamiltonian, // [f32;16] → f32
    SymEvolveStep,  // [f32;16], f32 → [f32;16]

    // Lorentzian spacetime operations
    LorentzianCausal,   // [f32;8], [f32;8] → bool
    LorentzianDistance, // [f32;8], [f32;8] → f32
    CausalNow,          // () -> [f32;8]
    CausalEmit,         // any, optional root, optional causes -> event_id
    CausalLink,         // cause_id, effect_id -> ()
    CausalConePast,     // id -> [ids]
    CausalConeFuture,   // id -> [ids]
    CausalVerify,       // () -> bool
    Fold,               // [values], op -> value
    Filter,             // [values], pattern -> [values]
    AtlasNew,           // -> Atlas
    AtlasInsert,        // [Atlas, KeyVec, Data] -> Atlas
    AtlasRecall,        // [Atlas, QueryVec] -> Array
    Neighbors,          // Integer -> Array<Integer>
    Reflect,            // [Vec8, Vec8] -> Vec8 (Weyl reflection)
    Diffuse,            // [Array<f32;240], Scalar] -> Array<f32;240>

    // Topological operations
    TopoBetti,     // [[f32;8]] → [u32;3]
    TopoSignature, // [[f32;8]] → symbol

    // CUDA orchestration
    CudaVecDot,        // GPU row-wise dot
    CudaTopK,          // GPU top-k
    CudaDomR,          // GPU DomR (E8-native dominant roots)
    CudaArchetypeDomR, // Archetype dispatch for DomR

    // E8 graph/ontology helpers
    E8TypeI,      // Axes[] -> Vec<Vec8> (Type-I roots)
    E8TypeII,     // Axes[] -> Vec<Vec8> (Type-II spinors)
    E8EdgesWhere, // Vertices[] -> Edges[] (inner product rule)
    HexGraph,     // (vertices, edges, axes) -> Map graph

    // Perception operations
    Perceive, // String → Vec8 (Signal /\ Structure)
}

impl RuneBuiltin {
    /// Create a RuneBuiltin from a name string (case-insensitive).
    pub fn from_str(name: &str) -> Option<Self> {
        match name.to_lowercase().as_str() {
            // Perception operations
            "perceive" => Some(RuneBuiltin::Perceive),

            // E8 graph helpers
            "e8typei" => Some(RuneBuiltin::E8TypeI),
            "e8typeii" => Some(RuneBuiltin::E8TypeII),
            "e8edgeswhere" => Some(RuneBuiltin::E8EdgesWhere),
            "e8edges" => Some(RuneBuiltin::E8EdgesWhere),
            "HexGraph" => Some(RuneBuiltin::HexGraph),
            "t:HexGraph" => Some(RuneBuiltin::HexGraph),

            // Gf8 operations
            "gf8norm" => Some(RuneBuiltin::Gf8Norm),
            "gf8normalize" => Some(RuneBuiltin::Gf8Normalize),
            "gf8dot" => Some(RuneBuiltin::Gf8Dot),

            // Spherical operations
            "s7project" => Some(RuneBuiltin::S7Project),
            "s7distance" => Some(RuneBuiltin::S7Distance),
            "s7slerp" => Some(RuneBuiltin::S7Slerp),
            "s7antipodal" => Some(RuneBuiltin::S7Antipodal),
            "s7mean" => Some(RuneBuiltin::S7Mean),

            // Hyperbolic operations
            "h8distance" => Some(RuneBuiltin::H8Distance),
            "h8mobiusadd" => Some(RuneBuiltin::H8MobiusAdd),

            // Fisher geometry
            "fisherdistance" => Some(RuneBuiltin::FisherDistance),
            "fishermatrix" => Some(RuneBuiltin::FisherMatrix),
            "kldivergence" => Some(RuneBuiltin::KLDivergence),
            "fisherfilter" => Some(RuneBuiltin::FisherFilter),

            // Quaternion operations
            "quatslerp" => Some(RuneBuiltin::QuatSlerp),
            "quatcompose" => Some(RuneBuiltin::QuatCompose),
            "quatconjugate" => Some(RuneBuiltin::QuatConjugate),

            // Symplectic operations
            "symhamiltonian" => Some(RuneBuiltin::SymHamiltonian),
            "symevolvestep" => Some(RuneBuiltin::SymEvolveStep),

            // Lorentzian operations
            "lorentziancausal" => Some(RuneBuiltin::LorentzianCausal),
            "lorentziandistance" => Some(RuneBuiltin::LorentzianDistance),
            "causalnow" => Some(RuneBuiltin::CausalNow),
            "causalemit" => Some(RuneBuiltin::CausalEmit),
            "causallink" => Some(RuneBuiltin::CausalLink),
            "causalconepast" => Some(RuneBuiltin::CausalConePast),
            "causalconefuture" => Some(RuneBuiltin::CausalConeFuture),
            "causalverify" => Some(RuneBuiltin::CausalVerify),
            "fold" => Some(RuneBuiltin::Fold),
            "filter" => Some(RuneBuiltin::Filter),
            "atlasnew" => Some(RuneBuiltin::AtlasNew),
            "atlasinsert" => Some(RuneBuiltin::AtlasInsert),
            "atlasrecall" => Some(RuneBuiltin::AtlasRecall),
            "neighbors" => Some(RuneBuiltin::Neighbors),
            "reflect" => Some(RuneBuiltin::Reflect),
            "diffuse" => Some(RuneBuiltin::Diffuse),

            // Topological operations
            "topobetti" => Some(RuneBuiltin::TopoBetti),
            "toposignature" => Some(RuneBuiltin::TopoSignature),

            // CUDA builtins (feature-gated at execution)
            "cuda:vecdot" => Some(RuneBuiltin::CudaVecDot),
            "cuda:topk" => Some(RuneBuiltin::CudaTopK),
            "cuda:domr" => Some(RuneBuiltin::CudaDomR),
            "cuda:archetype:domr" => Some(RuneBuiltin::CudaArchetypeDomR),
            _ => None,
        }
    }
}

impl EvalContext {
    /// Apply a built-in geometric operation
    ///
    /// This is the bridge layer that makes RUNE expressions actually drive Hydron geometry.
    pub fn apply_builtin(&self, op: RuneBuiltin, args: &[Value]) -> Result<Value, EvalError> {
        match op {
            // Spherical S7 operations
            RuneBuiltin::S7Project => {
                let v = expect_vec8(args.first())?;
                let projected = SphericalLayer::project(&v);
                Ok(Value::Vec8(projected))
            }

            RuneBuiltin::S7Distance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = SphericalLayer::distance(&a, &b);
                Ok(Value::Scalar(dist))
            }

            RuneBuiltin::S7Slerp => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let t = expect_scalar(args.get(2))?;
                let result = SphericalLayer::slerp(&a, &b, t);
                Ok(Value::Vec8(result))
            }

            // Quaternion operations
            RuneBuiltin::QuatSlerp => {
                let a = expect_quat(args.first())?;
                let b = expect_quat(args.get(1))?;
                let t = expect_scalar(args.get(2))?;
                let result = QuaternionOps::slerp(&a, &b, t);
                Ok(Value::Quaternion(result))
            }

            // Symplectic operations
            RuneBuiltin::SymHamiltonian => {
                let state = expect_vec16(args.first())?;
                let (q, p) = split_phase_space(&state);
                let layer = SymplecticLayer::new();
                let h = layer.hamiltonian(&q, &p);
                Ok(Value::Scalar(h))
            }

            RuneBuiltin::SymEvolveStep => {
                let state = expect_vec16(args.first())?;
                let dt = expect_scalar(args.get(1))?;
                let (mut q, mut p) = split_phase_space(&state);
                let layer = SymplecticLayer::new();
                layer.evolve(&mut q, &mut p, dt);
                let evolved = merge_phase_space(&q, &p);
                Ok(Value::Vec16(evolved))
            }

            // Topological operations
            RuneBuiltin::TopoBetti => {
                let points = extract_point_cloud(args)?;
                let mut layer = TopologicalLayer::new();
                for point in points {
                    layer.add_point(point);
                }
                layer.compute_betti_numbers(2.0, 10); // max_radius=2.0, steps=10
                Ok(Value::Betti(layer.betti))
            }

            RuneBuiltin::TopoSignature => {
                let points = extract_point_cloud(args)?;
                let mut layer = TopologicalLayer::new();
                for point in points {
                    layer.add_point(point);
                }
                layer.compute_betti_numbers(2.0, 10);
                let sig = format!("β={:?}", layer.betti);
                Ok(Value::Symbol(sig))
            }

            // Gf8 core operations
            RuneBuiltin::Gf8Norm => {
                let v = expect_vec8(args.first())?;
                let norm = v.iter().map(|x| x * x).sum::<f32>().sqrt();
                Ok(Value::Scalar(norm))
            }

            RuneBuiltin::Gf8Normalize => {
                let v = expect_vec8(args.first())?;
                let norm = v.iter().map(|x| x * x).sum::<f32>().sqrt();
                if norm > 1e-10 {
                    let normalized = v.map(|x| x / norm);
                    Ok(Value::Vec8(normalized))
                } else {
                    Ok(Value::Vec8(v))
                }
            }

            RuneBuiltin::Gf8Dot => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dot = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum::<f32>();
                Ok(Value::Scalar(dot))
            }

            // Spherical operations
            RuneBuiltin::S7Antipodal => {
                let v = expect_vec8(args.first())?;
                let antipodal = v.map(|x| -x);
                Ok(Value::Vec8(antipodal))
            }

            RuneBuiltin::S7Mean => {
                let points = extract_point_cloud(args)?;
                if points.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "Cannot compute mean of empty point cloud".to_string(),
                    ));
                }
                let result = SphericalLayer::mean(&points);
                Ok(Value::Vec8(result))
            }

            // Hyperbolic operations
            RuneBuiltin::H8Distance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = HyperbolicLayer::distance(&a, &b);
                Ok(Value::Scalar(dist))
            }

            RuneBuiltin::H8MobiusAdd => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let result = HyperbolicLayer::mobius_add(&a, &b);
                Ok(Value::Vec8(result))
            }

            // Fisher information geometry
            RuneBuiltin::FisherDistance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = a
                    .iter()
                    .zip(b.iter())
                    .map(|(x, y)| (x - y).powi(2))
                    .sum::<f32>()
                    .sqrt();
                Ok(Value::Scalar(dist))
            }

            RuneBuiltin::FisherMatrix => {
                let flat: Vec<Value> = (0..64)
                    .map(|i| {
                        let diag = if i / 8 == i % 8 { 1.0 } else { 0.0 };
                        Value::Scalar(diag)
                    })
                    .collect();
                Ok(Value::Array(flat))
            }

            RuneBuiltin::KLDivergence => {
                let p = expect_vec8(args.first())?;
                let q = expect_vec8(args.get(1))?;
                let kl = FisherLayer::kl_divergence(&p, &q);
                Ok(Value::Scalar(kl))
            }

            // Quaternion operations
            RuneBuiltin::QuatCompose => {
                let a = expect_quat(args.first())?;
                let b = expect_quat(args.get(1))?;
                // Quaternion multiplication: (a0,a)(b0,b) = (a0*b0 - a·b, a0*b + b0*a + a×b)
                let result = [
                    a[0] * b[0] - (a[1] * b[1] + a[2] * b[2] + a[3] * b[3]),
                    a[0] * b[1] + b[0] * a[1] + (a[2] * b[3] - a[3] * b[2]),
                    a[0] * b[2] + b[0] * a[2] + (a[3] * b[1] - a[1] * b[3]),
                    a[0] * b[3] + b[0] * a[3] + (a[1] * b[2] - a[2] * b[1]),
                ];
                Ok(Value::Quaternion(result))
            }

            RuneBuiltin::QuatConjugate => {
                let q = expect_quat(args.first())?;
                let conj = [q[0], -q[1], -q[2], -q[3]];
                Ok(Value::Quaternion(conj))
            }

            // Lorentzian operations
            RuneBuiltin::LorentzianCausal => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let interval = a[0].powi(2)
                    - a[1..]
                        .iter()
                        .zip(&b[1..])
                        .map(|(x, y)| (x - y).powi(2))
                        .sum::<f32>();
                Ok(Value::Bool(interval > 0.0))
            }

            RuneBuiltin::LorentzianDistance => {
                let a = expect_vec8(args.first())?;
                let b = expect_vec8(args.get(1))?;
                let dist = (a[0] - b[0]).powi(2)
                    - a[1..]
                        .iter()
                        .zip(&b[1..])
                        .map(|(x, y)| (x - y).powi(2))
                        .sum::<f32>();
                Ok(Value::Scalar(dist.abs().sqrt()))
            }

            // E8 graph helpers -------------------------------------------------
            RuneBuiltin::E8TypeI => {
                // Expect axes array of maps with at least "index" (0..7) and optional "weight"
                let axes_val = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("E8TypeI expects axes array".into())
                })?;
                let axes = parse_axes(axes_val)?;
                if axes.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "E8TypeI requires at least two axes".into(),
                    ));
                }
                let mut verts = Vec::new();
                for a in 0..axes.len() {
                    for b in (a + 1)..axes.len() {
                        let (idx_a, w_a) = axes[a];
                        let (idx_b, w_b) = axes[b];
                        // four sign combinations
                        let signs = [(1.0, 1.0), (1.0, -1.0), (-1.0, 1.0), (-1.0, -1.0)];
                        for (sa, sb) in signs {
                            let mut v = [0.0f32; 8];
                            v[idx_a] = w_a * sa;
                            v[idx_b] = w_b * sb;
                            normalize_vec8(&mut v);
                            verts.push(Value::Vec8(v));
                        }
                    }
                }
                Ok(Value::Array(verts))
            }

            RuneBuiltin::E8TypeII => {
                let axes_val = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("E8TypeII expects axes array".into())
                })?;
                let axes = parse_axes(axes_val)?;
                if axes.len() != 8 {
                    return Err(EvalError::InvalidOperation(
                        "E8TypeII expects exactly 8 axes".into(),
                    ));
                }
                let mut verts = Vec::new();
                // 2^8 sign patterns, keep even number of negatives (128 spinors)
                for mask in 0u16..256 {
                    let negs = mask.count_ones();
                    if negs % 2 != 0 {
                        continue;
                    }
                    let mut v = [0.0f32; 8];
                    for (i, (idx, w)) in axes.iter().enumerate() {
                        let sign = if (mask & (1 << i)) != 0 { -0.5 } else { 0.5 };
                        v[*idx] = sign * *w;
                    }
                    normalize_vec8(&mut v);
                    verts.push(Value::Vec8(v));
                }
                Ok(Value::Array(verts))
            }

            RuneBuiltin::E8EdgesWhere => {
                // Args: vertices array (Vec8/Gf8), optional threshold (default 0.5), optional tolerance
                let verts_val = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("E8EdgesWhere expects vertices array".into())
                })?;
                let verts = parse_vec8_list(verts_val)?;
                let threshold = match args.get(1) {
                    Some(Value::Scalar(s)) => *s,
                    Some(Value::Float(f)) => *f as f32,
                    _ => 0.5f32,
                };
                let tol = match args.get(2) {
                    Some(Value::Scalar(s)) => s.abs(),
                    Some(Value::Float(f)) => (*f as f32).abs(),
                    _ => 1e-4f32,
                };
                let mut edges = Vec::new();
                for i in 0..verts.len() {
                    for j in (i + 1)..verts.len() {
                        let dot: f32 = verts[i]
                            .iter()
                            .zip(verts[j].iter())
                            .map(|(a, b)| a * b)
                            .sum();
                        if (dot - threshold).abs() <= tol {
                            let mut map = HashMap::new();
                            map.insert("u".to_string(), Value::Integer(i as i128));
                            map.insert("v".to_string(), Value::Integer(j as i128));
                            map.insert("strength".to_string(), Value::Scalar(dot));
                            map.insert("relationship".to_string(), Value::Symbol("Similar".into()));
                            edges.push(Value::Map(map));
                        }
                    }
                }
                Ok(Value::Array(edges))
            }

            RuneBuiltin::HexGraph => {
                // Accept tuple or array of three: (vertices, edges, axes)
                let pack = args.get(0).ok_or_else(|| {
                    EvalError::InvalidOperation("HexGraph expects (vertices, edges, axes)".into())
                })?;
                let (verts, edges, axes) = match pack {
                    Value::Tuple(v) if v.len() == 3 => (&v[0], &v[1], &v[2]),
                    Value::Array(v) if v.len() == 3 => (&v[0], &v[1], &v[2]),
                    _ => {
                        return Err(EvalError::InvalidOperation(
                            "HexGraph expects tuple/array of (vertices, edges, axes)".into(),
                        ));
                    }
                };
                let mut graph = HashMap::new();
                graph.insert("vertices".into(), verts.clone());
                graph.insert("edges".into(), edges.clone());
                graph.insert("axes".into(), axes.clone());
                graph.insert("domain_stats".into(), Value::Map(HashMap::new()));
                Ok(Value::Map(graph))
            }

            // Perception operations
            RuneBuiltin::Perceive => {
                let input = match args.first() {
                    Some(Value::String(s)) => s,
                    Some(Value::Symbol(s)) => s,
                    _ => return Err(EvalError::TypeMismatch("Perceive requires a string".into())),
                };

                let sig = crate::rune::hydron::perception::signal_encode(input.as_bytes());
                let morph = crate::rune::hydron::perception::morph_analyze(input);

                let v_sig = Value::Vec8(sig);
                let v_morph = Value::Vec8(morph);

                // Synthesis: Signal /\ Structure (Geometric Midpoint)
                v_sig.geometric_midpoint(&v_morph)
            }

            RuneBuiltin::CausalNow => {
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                let mut coords = [0.0f64; 8];
                coords[0] = guard.proper_time;
                Ok(Value::Spacetime(SpacetimePoint::new(coords)))
            }

            RuneBuiltin::CausalEmit => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "CausalEmit requires at least a payload".into(),
                    ));
                }
                let payload = args[0].clone();
                let mut idx = 1;
                let mut location: Option<SpacetimePoint> = None;
                let mut root: usize = 0;

                if let Some(arg1) = args.get(idx) {
                    if let Value::Spacetime(p) = arg1 {
                        location = Some(p.clone());
                        idx += 1;
                    } else if let Ok(r) = expect_scalar(Some(arg1)) {
                        root = r as usize;
                        idx += 1;
                    }
                }

                let causes: Vec<u64> = if let Some(cause_val) = args.get(idx) {
                    match cause_val {
                        Value::Array(arr) => {
                            let mut out = Vec::new();
                            for v in arr {
                                out.push(expect_id(v)?);
                            }
                            out
                        }
                        other => vec![expect_id(other)?],
                    }
                } else {
                    Vec::new()
                };

                let layer = causal_layer();
                let mut guard = layer.lock().unwrap();
                let id = guard.add_event(root, payload, &causes, location);
                Ok(Value::Integer(id as i128))
            }

            RuneBuiltin::CausalLink => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "CausalLink requires cause and effect ids".into(),
                    ));
                }
                let cause = expect_id(&args[0])?;
                let effect = expect_id(&args[1])?;
                let layer = causal_layer();
                let mut guard = layer.lock().unwrap();
                guard
                    .add_link(cause, effect)
                    .map_err(|e| EvalError::InvalidOperation(e.to_string()))?;
                Ok(Value::Null)
            }

            RuneBuiltin::CausalConePast => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "CausalConePast requires an event id".into(),
                    ));
                }
                let id = expect_id(&args[0])?;
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                let cone = guard.past_light_cone(id);
                Ok(Value::Array(
                    cone.into_iter()
                        .map(|i| Value::Integer(i as i128))
                        .collect(),
                ))
            }

            RuneBuiltin::CausalConeFuture => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "CausalConeFuture requires an event id".into(),
                    ));
                }
                let id = expect_id(&args[0])?;
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                let cone = guard.future_light_cone(id);
                Ok(Value::Array(
                    cone.into_iter()
                        .map(|i| Value::Integer(i as i128))
                        .collect(),
                ))
            }

            RuneBuiltin::CausalVerify => {
                let layer = causal_layer();
                let guard = layer.lock().unwrap();
                Ok(Value::Bool(guard.verify_consistency()))
            }

            RuneBuiltin::FisherFilter => {
                if args.is_empty() {
                    return Err(EvalError::InvalidOperation(
                        "FisherFilter expects [values], optional threshold".into(),
                    ));
                }
                let list = match &args[0] {
                    Value::Array(arr) => arr,
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "FisherFilter first argument must be Array".into(),
                        ));
                    }
                };
                let threshold = args
                    .get(1)
                    .map(|v| expect_scalar(Some(v)))
                    .transpose()?
                    .unwrap_or(0.1);

                if list.is_empty() {
                    return Ok(Value::Array(Vec::new()));
                }

                let mut filtered = Vec::new();
                let mut prev_dist: Option<Vec<f32>> = None;
                for item in list.iter() {
                    let dist = value_to_distribution(item)?;
                    let keep = if let Some(prev) = &prev_dist {
                        let len = dist.len().min(prev.len());
                        let kl = FisherLayer::kl_divergence(&dist[..len], &prev[..len]);
                        kl > threshold
                    } else {
                        true
                    };
                    if keep {
                        filtered.push(item.clone());
                        prev_dist = Some(dist);
                    }
                }

                Ok(Value::Array(filtered))
            }

            RuneBuiltin::Fold => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "Fold expects [values], operator".into(),
                    ));
                }
                let list = match &args[0] {
                    Value::Array(arr) => arr.clone(),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Fold first argument must be Array".into(),
                        ));
                    }
                };
                let op_name = match &args[1] {
                    Value::Symbol(s) | Value::String(s) => s.clone(),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Fold operator must be Symbol/String".into(),
                        ));
                    }
                };

                let mut iter = list.into_iter();
                let mut acc = match iter.next() {
                    Some(first) => first,
                    None => return Ok(args.get(2).cloned().unwrap_or(Value::Null)),
                };

                for item in iter {
                    acc = match op_name.as_str() {
                        "/\\" => acc.meet(&item)?,
                        "\\/" => acc.join(&item)?,
                        "\\|" => acc.reject(&item)?,
                        "|\\" => acc.project(&item)?,
                        _ => {
                            return Err(EvalError::InvalidOperation(format!(
                                "Unknown fold operator {}",
                                op_name
                            )));
                        }
                    };
                }
                Ok(acc)
            }

            RuneBuiltin::Filter => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "Filter expects [values], pattern".into(),
                    ));
                }
                let list = match &args[0] {
                    Value::Array(arr) => arr,
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Filter first argument must be Array".into(),
                        ));
                    }
                };
                let pattern = &args[1];
                let mut out = Vec::new();
                for item in list {
                    if item.matches_pattern(pattern) {
                        out.push(item.clone());
                    }
                }
                Ok(Value::Array(out))
            }

            RuneBuiltin::AtlasNew => Ok(Value::Atlas(HashMap::new())),

            RuneBuiltin::AtlasInsert => {
                if args.len() < 3 {
                    return Err(EvalError::InvalidOperation(
                        "AtlasInsert expects [Atlas, Vector, Data]".into(),
                    ));
                }
                let mut atlas = args[0].clone();
                let key_vec = &args[1];
                let data = args[2].clone();
                atlas.atlas_insert(key_vec, data)?;
                Ok(atlas)
            }

            RuneBuiltin::AtlasRecall => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "AtlasRecall expects [Atlas, Vector]".into(),
                    ));
                }
                let atlas = &args[0];
                let query = &args[1];
                atlas.atlas_recall(query)
            }

            RuneBuiltin::Neighbors => {
                let idx = match args.get(0) {
                    Some(Value::Integer(i)) => *i as usize,
                    Some(Value::Scalar(s)) => *s as usize,
                    Some(Value::Float(f)) => *f as usize,
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Neighbors expects a root index".into(),
                        ));
                    }
                };
                let neighbors = crate::rune::hydron::topology::get_neighbors(idx);
                let vals = neighbors
                    .into_iter()
                    .map(|i| Value::Integer(i as i128))
                    .collect();
                Ok(Value::Array(vals))
            }

            RuneBuiltin::Reflect => {
                let vec = expect_vec8(args.get(0))?;
                let mirror = expect_vec8(args.get(1))?;
                let reflected = crate::rune::hydron::topology::weyl_reflect(&vec, &mirror);
                Ok(Value::Vec8(reflected))
            }

            RuneBuiltin::Diffuse => {
                if args.len() < 2 {
                    return Err(EvalError::InvalidOperation(
                        "Diffuse expects [Array(240), rate]".into(),
                    ));
                }
                let energy = match &args[0] {
                    Value::Array(arr) => {
                        if arr.len() != 240 {
                            return Err(EvalError::TypeMismatch(
                                "Diffuse energy array must have length 240".into(),
                            ));
                        }
                        let mut out = [0.0f32; 240];
                        for (i, v) in arr.iter().enumerate() {
                            out[i] = match v {
                                Value::Scalar(s) => *s,
                                Value::Float(f) => *f as f32,
                                _ => {
                                    return Err(EvalError::TypeMismatch(
                                        "Diffuse energy entries must be numeric".into(),
                                    ));
                                }
                            };
                        }
                        out
                    }
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Diffuse first argument must be Array".into(),
                        ));
                    }
                };

                let rate = expect_scalar(args.get(1).map(|v| v))?;
                let diffused = crate::rune::hydron::topology::diffuse_energy(&energy, rate);
                let vals = diffused
                    .iter()
                    .map(|f| Value::Scalar(*f))
                    .collect::<Vec<_>>();
                Ok(Value::Array(vals))
            }

            // CUDA builtins - use CUDA accelerator if available
            RuneBuiltin::CudaDomR | RuneBuiltin::CudaArchetypeDomR => {
                #[cfg(feature = "cuda")]
                {
                    match crate::rune::hydron::cuda::get_cuda_accelerator().execute_domr("CudaDomR", args) {
                        Ok(result) => return Ok(result),
                        Err(_) => {
                            // Fall through to CPU implementation below
                        }
                    }
                }

                // CPU implementation fallback
                let energy_vec = expect_energy(args.get(0))?;
                let n_dr = match args.get(1) {
                    Some(Value::Integer(i)) => *i as usize,
                    Some(Value::Scalar(s)) => *s as usize,
                    Some(Value::Float(f)) => *f as usize,
                    _ => 8usize, // default
                };

                let graph = hex_model::default_graph();
                let domr = hex_model::domr_cpu(graph, &energy_vec, n_dr)
                    .map_err(|e| EvalError::InvalidOperation(e.to_string()))?;
                Ok(Value::DomR(domr))
            }

            RuneBuiltin::CudaVecDot => Err(EvalError::UnsupportedOperation("CudaVecDot not implemented".into())),

            RuneBuiltin::CudaTopK => Err(EvalError::UnsupportedOperation("CudaTopK not implemented".into())),
        }
    }

    /// Apply a builtin by string name; returns Err if unknown name.
    pub fn apply_builtin_by_name(&self, name: &str, args: &[Value]) -> Result<Value, EvalError> {
        if let Some(b) = RuneBuiltin::from_str(name) {
            self.apply_builtin(b, args)
        } else {
            Err(EvalError::InvalidOperation(format!(
                "Unknown builtin: {}",
                name
            )))
        }
    }
}

// ===================================
// Helper functions for type extraction
// ===================================

fn expect_vec8(val: Option<&Value>) -> Result<[f32; 8], EvalError> {
    match val {
        Some(Value::Vec8(v)) => Ok(*v),
        Some(Value::Array(arr)) => {
            // Ensure array has length 8 and extract floats
            if arr.len() != 8 {
                return Err(EvalError::TypeMismatch(format!(
                    "Expected Vec8 (array of 8 floats), got array length {}",
                    arr.len()
                )));
            }
            let mut v = [0.0f32; 8];
            for (i, elem) in arr.iter().enumerate() {
                match elem {
                    Value::Float(f) => v[i] = *f as f32,
                    Value::Scalar(s) => v[i] = *s,
                    _ => {
                        return Err(EvalError::TypeMismatch(format!(
                            "Expected numeric values for Vec8, found {:?}",
                            elem
                        )));
                    }
                }
            }
            Ok(v)
        }
        Some(other) => Err(EvalError::TypeMismatch(format!(
            "Expected Vec8, got {}",
            match other {
                Value::Scalar(_) => "Scalar",
                Value::Vec16(_) => "Vec16",
                Value::Quaternion(_) => "Quaternion",
                Value::Gf8(_) => "Gf8",
                Value::Octonion(_) => "Octonion",
                Value::Symbol(_) => "Symbol",
                Value::Matrix8x8(_) => "Matrix8x8",
                Value::Betti(_) => "Betti",
                _ => "unknown",
            }
        ))),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_vec16(val: Option<&Value>) -> Result<[f32; 16], EvalError> {
    match val {
        Some(Value::Vec16(v)) => Ok(*v),
        Some(_) => Err(EvalError::TypeMismatch("Expected Vec16".to_string())),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_quat(val: Option<&Value>) -> Result<[f32; 4], EvalError> {
    match val {
        Some(Value::Quaternion(q)) => Ok(*q),
        Some(_) => Err(EvalError::TypeMismatch("Expected Quaternion".to_string())),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_scalar(val: Option<&Value>) -> Result<f32, EvalError> {
    match val {
        Some(Value::Scalar(s)) => Ok(*s),
        Some(Value::Float(f)) => Ok(*f as f32),
        Some(_) => Err(EvalError::TypeMismatch(
            "Expected Scalar or Float".to_string(),
        )),
        None => Err(EvalError::InvalidOperation("Missing argument".to_string())),
    }
}

fn expect_id(val: &Value) -> Result<u64, EvalError> {
    match val {
        Value::Integer(i) => Ok(*i as u64),
        Value::Scalar(s) => Ok(*s as u64),
        Value::Float(f) => Ok(*f as u64),
        _ => Err(EvalError::TypeMismatch("Expected event id".to_string())),
    }
}

fn expect_energy(val: Option<&Value>) -> Result<Vec<f32>, EvalError> {
    let arr = match val {
        Some(Value::Array(arr)) => arr,
        Some(_) => {
            return Err(EvalError::TypeMismatch(
                "Energy must be an Array of 240 numeric values".into(),
            ));
        }
        None => {
            return Err(EvalError::InvalidOperation(
                "Missing energy argument".into(),
            ));
        }
    };
    if arr.len() != 240 {
        return Err(EvalError::TypeMismatch(format!(
            "Energy array must have length 240, got {}",
            arr.len()
        )));
    }
    let mut out = Vec::with_capacity(240);
    for v in arr {
        match v {
            Value::Scalar(s) => out.push(*s),
            Value::Float(f) => out.push(*f as f32),
            Value::Integer(i) => out.push(*i as f32),
            _ => {
                return Err(EvalError::TypeMismatch(
                    "Energy entries must be numeric".into(),
                ));
            }
        }
    }
    Ok(out)
}

fn value_to_distribution(val: &Value) -> Result<Vec<f32>, EvalError> {
    let mut dist = match val {
        Value::Array(arr) => {
            let mut out = Vec::with_capacity(arr.len());
            for v in arr {
                match v {
                    Value::Scalar(s) => out.push(*s),
                    Value::Float(f) => out.push(*f as f32),
                    _ => {
                        return Err(EvalError::TypeMismatch(
                            "Array must contain numeric values for FisherFilter".into(),
                        ));
                    }
                }
            }
            out
        }
        Value::Vec8(v) => v.to_vec(),
        Value::Vec16(v) => v.to_vec(),
        Value::Gf8(g) => g.coords().to_vec(),
        Value::Quaternion(q) => q.to_vec(),
        Value::Scalar(s) => vec![*s],
        Value::Float(f) => vec![*f as f32],
        _ => {
            return Err(EvalError::TypeMismatch(
                "Unsupported value for FisherFilter distribution".into(),
            ));
        }
    };

    let sum: f32 = dist.iter().map(|x| x.abs()).sum();
    if sum > 1e-8 {
        for x in dist.iter_mut() {
            *x /= sum;
        }
    }
    Ok(dist)
}

fn extract_point_cloud(args: &[Value]) -> Result<Vec<[f32; 8]>, EvalError> {
    // Handle multiple argument formats:
    // 1. Single PointCloud value
    // 2. Single Vec16 (two packed points)
    // 3. Multiple Vec8 arguments

    if args.is_empty() {
        return Err(EvalError::InvalidOperation(
            "No points provided".to_string(),
        ));
    }

    // Case 1: PointCloud value
    if args.len() == 1 {
        if let Value::PointCloud(points) = &args[0] {
            return Ok(points.clone());
        }

        // Case 2: Vec16 (two packed points)
        if let Value::Vec16(v16) = &args[0] {
            let p1 = [
                v16[0], v16[1], v16[2], v16[3], v16[4], v16[5], v16[6], v16[7],
            ];
            let p2 = [
                v16[8], v16[9], v16[10], v16[11], v16[12], v16[13], v16[14], v16[15],
            ];
            return Ok(vec![p1, p2]);
        }
    }

    // Case 3: Multiple Vec8 arguments
    let mut points = Vec::new();
    for arg in args {
        match arg {
            Value::Vec8(v) => points.push(*v),
            Value::PointCloud(pc) => points.extend_from_slice(pc),
            _ => {
                return Err(EvalError::TypeMismatch(
                    "Expected Vec8, Vec16, or PointCloud for point cloud".to_string(),
                ));
            }
        }
    }
    Ok(points)
}

/// Normalize a mutable Vec8 in-place; no-op for near-zero norm.
fn normalize_vec8(v: &mut [f32; 8]) {
    let norm_sq: f32 = v.iter().map(|x| x * x).sum();
    if norm_sq > 1e-9 {
        let inv = 1.0 / norm_sq.sqrt();
        for x in v {
            *x *= inv;
        }
    }
}

/// Extract axes as (index, weight) pairs from a Value::Array of maps.
fn parse_axes(val: &Value) -> Result<Vec<(usize, f32)>, EvalError> {
    let mut axes = Vec::new();
    let arr = match val {
        Value::Array(a) => a,
        _ => return Err(EvalError::TypeMismatch("Axes must be an array".into())),
    };
    for item in arr {
        match item {
            Value::Map(m) => {
                let idx_val = m
                    .get("index")
                    .ok_or_else(|| EvalError::TypeMismatch("Axis missing 'index' field".into()))?;
                let idx = expect_id(idx_val)? as usize;
                let w = match m.get("weight") {
                    Some(Value::Scalar(s)) => *s,
                    Some(Value::Float(f)) => *f as f32,
                    _ => 1.0,
                };
                axes.push((idx, w));
            }
            _ => return Err(EvalError::TypeMismatch("Axis must be a map".into())),
        }
    }
    // Deterministic ordering
    axes.sort_by_key(|(idx, _)| *idx);
    Ok(axes)
}

/// Parse a list of 8D vectors from various value representations.
fn parse_vec8_list(val: &Value) -> Result<Vec<[f32; 8]>, EvalError> {
    match val {
        Value::Array(arr) => {
            let mut out = Vec::with_capacity(arr.len());
            for v in arr {
                out.push(expect_vec8(Some(v))?);
            }
            Ok(out)
        }
        Value::PointCloud(points) => Ok(points.clone()),
        _ => Err(EvalError::TypeMismatch(
            "Expected Array of Vec8 for vertices".into(),
        )),
    }
}

/// Split Vec16 phase space into position and momentum
fn split_phase_space(state: &[f32; 16]) -> ([f32; 8], [f32; 8]) {
    let mut q = [0.0f32; 8];
    let mut p = [0.0f32; 8];
    q.copy_from_slice(&state[..8]);
    p.copy_from_slice(&state[8..]);
    (q, p)
}

/// Merge position and momentum into Vec16 phase space
fn merge_phase_space(q: &[f32; 8], p: &[f32; 8]) -> [f32; 16] {
    let mut state = [0.0f32; 16];
    state[..8].copy_from_slice(q);
    state[8..].copy_from_slice(p);
    state
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_scalar_arithmetic() {
        let a = Value::Scalar(5.0);
        let b = Value::Scalar(3.0);

        assert_eq!(a.add(&b).unwrap(), Value::Scalar(8.0));
        assert_eq!(a.mul(&b).unwrap(), Value::Scalar(15.0));
        assert_eq!(a.sub(&b).unwrap(), Value::Scalar(2.0));
    }

    #[test]
    fn test_gf8_arithmetic() {
        use crate::rune::hydron::Gf8;

        // Test Gf8 addition (geometric addition on unit sphere)
        let gf_a = Gf8::new([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let gf_b = Gf8::new([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);

        let a = Value::Gf8(gf_a);
        let b = Value::Gf8(gf_b);

        // Geometric Gf8 addition
        let result = a.add(&b).unwrap();
        assert!(matches!(result, Value::Gf8(_)));
    }

    #[test]
    fn test_octonion_multiplication() {
        let a = Octonion::real(2.0);
        let b = Octonion::real(3.0);
        let c = a.mul(&b);

        assert_eq!(c.scalar, 6.0);
    }

    #[test]
    fn test_vec8_operations() {
        let a = Value::Vec8([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]);
        let b = Value::Vec8([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]);

        let result = a.add(&b).unwrap();
        if let Value::Vec8(v) = result {
            assert_eq!(v[0], 2.0);
            assert_eq!(v[7], 9.0);
        }
    }

    // ===================================
    // Integration Tests: RUNE → Hydron Geometry
    // ===================================

    #[test]
    fn test_rune_drives_spherical_geometry() {
        let ctx = EvalContext::new();

        // Test S7 projection
        let v = Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let result = ctx.apply_builtin(RuneBuiltin::S7Project, &[v]).unwrap();

        if let Value::Vec8(projected) = result {
            // Should be normalized to unit sphere
            let norm: f32 = projected.iter().map(|x| x * x).sum::<f32>().sqrt();
            assert!((norm - 1.0).abs() < 1e-6, "S7 projection should normalize");
        } else {
            panic!("Expected Vec8 result from S7Project");
        }

        // Test S7 distance
        let a = Value::Vec8([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let b = Value::Vec8([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let dist = ctx
            .apply_builtin(RuneBuiltin::S7Distance, &[a.clone(), b.clone()])
            .unwrap();

        if let Value::Scalar(d) = dist {
            assert!(
                d > 0.0,
                "Distance between distinct points should be positive"
            );
        }

        // Test S7 slerp
        let t = Value::Scalar(0.5);
        let interp = ctx.apply_builtin(RuneBuiltin::S7Slerp, &[a, b, t]).unwrap();

        assert!(matches!(interp, Value::Vec8(_)), "Slerp should return Vec8");
    }

    #[test]
    fn test_rune_drives_symplectic_geometry() {
        let ctx = EvalContext::new();

        // Create a symplectic state (position + momentum)
        let state = Value::Vec16([
            1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // position
            0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // momentum
        ]);

        // Test Hamiltonian computation
        let h = ctx
            .apply_builtin(RuneBuiltin::SymHamiltonian, &[state.clone()])
            .unwrap();

        if let Value::Scalar(energy) = h {
            assert!(energy >= 0.0, "Hamiltonian should be non-negative");
        } else {
            panic!("Expected Scalar from SymHamiltonian");
        }

        // Test symplectic evolution
        let dt = Value::Scalar(0.1);
        let evolved = ctx
            .apply_builtin(RuneBuiltin::SymEvolveStep, &[state, dt])
            .unwrap();

        assert!(
            matches!(evolved, Value::Vec16(_)),
            "Symplectic evolution should return Vec16"
        );
    }

    #[test]
    fn test_rune_drives_topological_analysis() {
        let ctx = EvalContext::new();

        // Create a point cloud (2 points packed into Vec16)
        let points = Value::Vec16([
            1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // point 1
            0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, // point 2
        ]);

        // Test Betti number computation
        let betti = ctx
            .apply_builtin(RuneBuiltin::TopoBetti, &[points.clone()])
            .unwrap();

        if let Value::Betti([b0, b1, b2]) = betti {
            assert!(b0 > 0, "Should have at least one connected component");
            // b1, b2 depend on point cloud structure
            let _ = (b1, b2);
        } else {
            panic!("Expected Betti from TopoBetti");
        }

        // Test topological signature
        let sig = ctx
            .apply_builtin(RuneBuiltin::TopoSignature, &[points])
            .unwrap();

        assert!(
            matches!(sig, Value::Symbol(_)),
            "Topological signature should return Symbol"
        );
    }

    #[test]
    fn test_from_trait_conversions() {
        // Test automatic Value wrapping
        let v8: Value = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0].into();
        assert!(matches!(v8, Value::Vec8(_)));

        let v16: Value = [0.0; 16].into();
        assert!(matches!(v16, Value::Vec16(_)));

        let quat: Value = [1.0, 0.0, 0.0, 0.0].into();
        assert!(matches!(quat, Value::Quaternion(_)));

        let betti: Value = [1, 0, 0].into();
        assert!(matches!(betti, Value::Betti(_)));
    }
}

File: src\rune\parts\delimiters.rs
==================================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{Delimiter, EncodeOptions, encode};
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn delimiters() {
    println!("Hydron feature required for dynamic delimiters");
}

#[cfg(feature = "hydron")]
pub fn delimiters() {
    // Dynamic Data
    let mut item1 = HashMap::new();
    item1.insert("sku".to_string(), Value::String("A1".to_string()));
    item1.insert("name".to_string(), Value::String("Widget".to_string()));
    item1.insert("qty".to_string(), Value::Integer(2));
    item1.insert("price".to_string(), Value::Float(9.99));

    let mut item2 = HashMap::new();
    item2.insert("sku".to_string(), Value::String("B2".to_string()));
    item2.insert("name".to_string(), Value::String("Gadget".to_string()));
    item2.insert("qty".to_string(), Value::Integer(1));
    item2.insert("price".to_string(), Value::Float(14.5));

    let items_array = Value::Array(vec![Value::Map(item1), Value::Map(item2)]);

    let mut data_map = HashMap::new();
    data_map.insert("items".to_string(), items_array);
    let data = Value::Map(data_map);

    // Tab delimiter (\t)
    let tab = encode(&data, &EncodeOptions::new().with_delimiter(Delimiter::Tab)).unwrap();
    println!("{tab}");

    // Pipe delimiter (|)
    let pipe = encode(&data, &EncodeOptions::new().with_delimiter(Delimiter::Pipe)).unwrap();
    println!("\n{pipe}");
}

File: src\rune\parts\arrays.rs
==============================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;

#[cfg(not(feature = "hydron"))]
pub fn arrays() {
    println!("Hydron feature required for dynamic arrays");
}

#[cfg(feature = "hydron")]
pub fn arrays() {
    // Dynamic Array (Strings)
    let tags = Value::Array(vec![
        Value::String("admin".to_string()),
        Value::String("ops".to_string()),
        Value::String("dev".to_string()),
    ]);
    let out = encode_default(&tags).unwrap();
    println!("tags[3]: {out}");

    // Dynamic Array (Numbers)
    let nums = Value::Array(vec![
        Value::Integer(1),
        Value::Integer(2),
        Value::Integer(3),
        Value::Integer(4),
        Value::Integer(5),
    ]);
    let out = encode_default(&nums).unwrap();
    println!("\nnums[5]: {out}");

    // Dynamic Array (Mixed)
    let mixed = Value::Array(vec![
        Value::String("x".to_string()),
        Value::String("y".to_string()),
        Value::Bool(true),
        Value::Integer(10),
    ]);
    let out = encode_default(&mixed).unwrap();
    println!("\ndata[4]: {out}");
}

File: src\rune\parts\decode_strict.rs
=====================================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{DecodeOptions, decode};

#[cfg(not(feature = "hydron"))]
pub fn decode_strict() {
    println!("Hydron feature required for dynamic decode strict");
}

#[cfg(feature = "hydron")]
pub fn decode_strict() {
    // Malformed: header says 2 rows, but only 1 provided
    let malformed = "items[2]{id,name}:\n  1,Ada";

    let opts = DecodeOptions::new().with_strict(true);
    match decode::<Value>(malformed, &opts) {
        Ok(val) => println!("Unexpectedly decoded: {:?}", val),
        Err(err) => println!("Strict decode error: {err}"),
    }
}

File: src\rune\parts\mixed_arrays.rs
====================================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn mixed_arrays() {
    println!("Hydron feature required for dynamic mixed arrays");
}

#[cfg(feature = "hydron")]
pub fn mixed_arrays() {
    // Dynamic Mixed Array
    let mut obj = HashMap::new();
    obj.insert("a".to_string(), Value::Integer(1));

    let mixed_array = Value::Array(vec![
        Value::Integer(1),
        Value::Map(obj),
        Value::String("text".to_string()),
    ]);

    let mut mixed_map = HashMap::new();
    mixed_map.insert("items".to_string(), mixed_array);
    let mixed = Value::Map(mixed_map);

    println!("{}", encode_default(&mixed).unwrap());

    // Dynamic List of Objects
    let mut item1 = HashMap::new();
    item1.insert("id".to_string(), Value::Integer(1));
    item1.insert("name".to_string(), Value::String("First".to_string()));

    let mut item2 = HashMap::new();
    item2.insert("id".to_string(), Value::Integer(2));
    item2.insert("name".to_string(), Value::String("Second".to_string()));
    item2.insert("extra".to_string(), Value::Bool(true));

    let list_array = Value::Array(vec![Value::Map(item1), Value::Map(item2)]);

    let mut list_map = HashMap::new();
    list_map.insert("items".to_string(), list_array);
    let list_objects = Value::Map(list_map);

    println!("\n{}", encode_default(&list_objects).unwrap());
}

File: src\rune\parts\empty_and_root.rs
======================================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn empty_and_root() {
    println!("Hydron feature required for dynamic empty and root");
}

#[cfg(feature = "hydron")]
pub fn empty_and_root() {
    // Dynamic Empty Container
    let empty_array = Value::Array(vec![]);
    let mut empty_map = HashMap::new();
    empty_map.insert("items".to_string(), empty_array);
    let empty_items = Value::Map(empty_map);
    println!("{}", encode_default(&empty_items).unwrap());

    // Dynamic Root Array
    let root_array = Value::Array(vec![
        Value::String("x".to_string()),
        Value::String("y".to_string()),
    ]);
    println!("\n{}", encode_default(&root_array).unwrap());

    // Dynamic Empty Object
    let empty_obj = Value::Map(HashMap::new());
    let out = encode_default(&empty_obj).unwrap();
    if out.is_empty() {
        println!("\n(empty output)");
    } else {
        println!("\n{out}");
    }
}

File: src\rune\parts\objects.rs
===============================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn objects() {
    println!("Hydron feature required for dynamic objects");
}

#[cfg(feature = "hydron")]
pub fn objects() {
    // Dynamic Object: Simple
    let mut simple_map = HashMap::new();
    simple_map.insert("id".to_string(), Value::Integer(123));
    simple_map.insert("name".to_string(), Value::String("Ada".to_string()));
    simple_map.insert("active".to_string(), Value::Bool(true));
    let simple = Value::Map(simple_map);

    let out = encode_default(&simple).unwrap();
    println!("{out}");

    // Dynamic Object: Nested
    let mut user_info = HashMap::new();
    user_info.insert("id".to_string(), Value::Integer(123));
    user_info.insert("name".to_string(), Value::String("Ada".to_string()));

    let mut nested_map = HashMap::new();
    nested_map.insert("user".to_string(), Value::Map(user_info));
    let nested = Value::Map(nested_map);

    let out_nested = encode_default(&nested).unwrap();
    println!("\n{out_nested}");

    // Dynamic Array of Objects
    let mut user1 = HashMap::new();
    user1.insert("id".to_string(), Value::Integer(1));
    user1.insert("name".to_string(), Value::String("Alice".to_string()));
    user1.insert(
        "email".to_string(),
        Value::String("alice@example.com".to_string()),
    );
    user1.insert("active".to_string(), Value::Bool(true));

    let mut user2 = HashMap::new();
    user2.insert("id".to_string(), Value::Integer(2));
    user2.insert("name".to_string(), Value::String("Bob".to_string()));
    user2.insert(
        "email".to_string(),
        Value::String("bob@example.com".to_string()),
    );
    user2.insert("active".to_string(), Value::Bool(true));

    let users = Value::Array(vec![Value::Map(user1), Value::Map(user2)]);

    let out = encode_default(&users).unwrap();
    println!("\n{out}");
}

File: src\rune\parts\mod.rs
===========================
pub mod arrays;
pub mod arrays_of_arrays;
pub mod decode_strict;
pub mod delimiters;
pub mod empty_and_root;
pub mod mixed_arrays;
pub mod objects;
pub mod round_trip;
pub mod structs;
pub mod tabular;

File: src\rune\parts\round_trip.rs
==================================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{decode_default, encode_default};
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn round_trip() {
    println!("Hydron feature required for dynamic round trip");
}

#[cfg(feature = "hydron")]
pub fn round_trip() {
    // Dynamic Round Trip (Value)
    let mut product_map = HashMap::new();
    product_map.insert("product".to_string(), Value::String("Widget".to_string()));
    product_map.insert("price".to_string(), Value::Float(29.99));
    product_map.insert("stock".to_string(), Value::Integer(100));

    let categories = Value::Array(vec![
        Value::String("tools".to_string()),
        Value::String("hardware".to_string()),
    ]);
    product_map.insert("categories".to_string(), categories);

    let original = Value::Map(product_map);

    let encoded = encode_default(&original).unwrap();
    let decoded: Value = decode_default(&encoded).unwrap();

    println!("Encoded:\n{encoded}",);
    println!("\nRound-trip equal: {}", original == decoded);
}

File: src\rune\parts\structs.rs
===============================
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use crate::{decode_default, encode_default};
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn serde_structs() {
    println!("Hydron feature required for dynamic structs");
}

#[cfg(feature = "hydron")]
pub fn serde_structs() {
    // Dynamic Struct (User)
    let mut user_map = HashMap::new();
    user_map.insert("name".to_string(), Value::String("Alice".to_string()));
    user_map.insert("age".to_string(), Value::Integer(30));
    user_map.insert(
        "email".to_string(),
        Value::String("alice@example.com".to_string()),
    );
    user_map.insert("active".to_string(), Value::Bool(true));
    let user = Value::Map(user_map);

    let toon = encode_default(&user).unwrap();
    println!("{toon}");

    let decoded: Value = decode_default(&toon).unwrap();
    assert_eq!(user, decoded);

    // Dynamic Nested Struct (Product)
    let mut metadata_map = HashMap::new();
    metadata_map.insert("category".to_string(), Value::String("Tech".to_string()));
    metadata_map.insert("in_stock".to_string(), Value::Bool(true));

    let tags = Value::Array(vec![
        Value::String("electronics".to_string()),
        Value::String("computers".to_string()),
    ]);

    let mut product_map = HashMap::new();
    product_map.insert("id".to_string(), Value::Integer(42));
    product_map.insert("name".to_string(), Value::String("Laptop".to_string()));
    product_map.insert("price".to_string(), Value::Float(999.99));
    product_map.insert("tags".to_string(), tags);
    product_map.insert("metadata".to_string(), Value::Map(metadata_map));
    let product = Value::Map(product_map);

    let toon = encode_default(&product).unwrap();
    println!("\n{toon}");

    let decoded: Value = decode_default(&toon).unwrap();
    assert_eq!(product, decoded);
}

File: src\rune\parts\tabular.rs
===============================
#[cfg(feature = "hydron")]
use crate::encode_default;
#[cfg(feature = "hydron")]
use crate::rune::hydron::values::Value;
#[cfg(feature = "hydron")]
use std::collections::HashMap;

#[cfg(not(feature = "hydron"))]
pub fn tabular() {
    println!("Hydron feature required for dynamic tabular data");
}

#[cfg(feature = "hydron")]
pub fn tabular() {
    // Dynamic Tabular Data
    let mut item1 = HashMap::new();
    item1.insert("sku".to_string(), Value::String("A1".to_string()));
    item1.insert("qty".to_string(), Value::Integer(2));
    item1.insert("price".to_string(), Value::Float(9.99));

    let mut item2 = HashMap::new();
    item2.insert("sku".to_string(), Value::String("B2".to_string()));
    item2.insert("qty".to_string(), Value::Integer(1));
    item2.insert("price".to_string(), Value::Float(14.5));

    let items_array = Value::Array(vec![Value::Map(item1), Value::Map(item2)]);

    let mut items_map = HashMap::new();
    items_map.insert("items".to_string(), items_array);
    let items = Value::Map(items_map);

    let out = encode_default(&items).unwrap();
    println!("{out}");

    // Dynamic Nested Tabular Data
    let mut user1 = HashMap::new();
    user1.insert("id".to_string(), Value::Integer(1));
    user1.insert("name".to_string(), Value::String("Ada".to_string()));

    let mut user2 = HashMap::new();
    user2.insert("id".to_string(), Value::Integer(2));
    user2.insert("name".to_string(), Value::String("Bob".to_string()));

    let users_array = Value::Array(vec![Value::Map(user1), Value::Map(user2)]);

    let mut container = HashMap::new();
    container.insert("users".to_string(), users_array);
    container.insert("status".to_string(), Value::String("active".to_string()));

    let items_array_nested = Value::Array(vec![Value::Map(container)]);

    let mut nested_map = HashMap::new();
    nested_map.insert("items".to_string(), items_array_nested);
    let nested = Value::Map(nested_map);

    let out_nested = encode_default(&nested).unwrap();
    println!("\n{out_nested}");
}

File: src\rune\tests\archetype_integration.rs
=============================================
//! Integration test for RUNE-ArchetypeEngine bridge
//!
//! Tests the end-to-end flow: RUNE kernel declaration -> ArchetypeEngine compilation -> PTX generation

use rune_format::rune::hydron::eval::Evaluator;
use rune_format::rune::parse;
use std::fs;
use std::path::Path;

#[cfg(feature = "cuda")]
#[test]
fn test_archetype_kernel_compilation() {
    // Define RUNE script with kernel declaration
    let script = r#"
Kernel:MyRowDot := CUDA:Archetype:RowDot(D: 8) and MyData -> MyRowDot
"#;

    // Parse the script
    let stmts = parse(script).expect("Failed to parse RUNE script");

    // Set up evaluator with initial data
    let mut eval = Evaluator::new();
    eval.set_var("MyData", rune_format::rune::hydron::values::Value::Array(vec![
        rune_format::rune::hydron::values::Value::Vec8([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]),
        rune_format::rune::hydron::values::Value::Vec8([2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]),
    ]));

    // Evaluate the kernel declaration
    let result = eval.eval_stmt(&stmts[0]);
    assert!(result.is_ok(), "Kernel declaration evaluation failed");
    assert_eq!(result.unwrap(), rune_format::rune::hydron::values::Value::Null);

    // Check that PTX file was created
    let cache_dir = Path::new("target").join("rune").join("cache");
    assert!(cache_dir.exists(), "Cache directory should exist");

    // Find PTX files in cache directory
    let ptx_files: Vec<_> = fs::read_dir(&cache_dir)
        .expect("Failed to read cache directory")
        .filter_map(|entry| entry.ok())
        .map(|entry| entry.path())
        .filter(|path| path.extension().map_or(false, |ext| ext == "ptx"))
        .collect();

    assert!(!ptx_files.is_empty(), "At least one PTX file should be generated");
}

#[cfg(not(feature = "cuda"))]
#[test]
fn test_archetype_kernel_compilation_no_cuda() {
    // Define RUNE script with kernel declaration
    let script = r#"
Kernel:MyRowDot := CUDA:Archetype:RowDot(D: 8) and MyData -> MyRowDot
"#;

    // Parse the script
    let stmts = parse(script).expect("Failed to parse RUNE script");

    // Set up evaluator
    let mut eval = Evaluator::new();

    // Evaluate the kernel declaration - should fail without CUDA
    let result = eval.eval_stmt(&stmts[0]);
    assert!(result.is_err(), "Kernel declaration should fail without CUDA feature");

    if let Err(err) = result {
        assert!(err.to_string().contains("CUDA feature not enabled"));
    }
}

File: src\tui\components\confirmation_dialog.rs
===============================================
/* src/tui/components/confirmation_dialog.rs */
//! Terminal UI confirmation dialog component for user interactions.
//!
//! # TOON-RUNE – Confirmation Dialog Component
//!▫~•◦-----------------------------------------‣
//!
//! This module provides a modal confirmation dialog component for the TOON-RUNE
//! terminal user interface, handling user confirmations for destructive actions.
//!
//! ### Key Capabilities
//! - **Modal Display**: Renders centered confirmation dialogs with styled borders and content.
//! - **Action Variants**: Supports different confirmation types (New File, Quit, Delete File).
//! - **Keyboard Navigation**: Visual cues for Y/N/Esc key bindings.
//! - **Responsive Layout**: Automatically centers and sizes dialog within terminal viewport.
//!
//! ### Architectural Notes
//! This component integrates with the `AppState` type's `ConfirmationAction` enum and
//! works alongside other TUI components like editors and file browsers. Dialog rendering
//! uses Ratatui's layout system for consistent positioning and styling.
//!
//! ### Example
//! ```rust
//! use rune_format::tui::components::confirmation_dialog::ConfirmationDialog;
//! use rune_format::tui::state::app_state::ConfirmationAction;
//! use ratatui::{Frame, layout::Rect};
//!
//! let action = ConfirmationAction::DeleteFile;
//! // In your TUI rendering loop:
//! // confirmation_dialog::render(&mut frame, dialog_area, action);
//!
//! // The dialog renders with appropriate title and message for the delete action.
//! ```
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    style::{Color, Modifier, Style},
    text::{Line, Span},
    widgets::{Block, Borders, Clear, Paragraph, Wrap},
};

use crate::tui::state::app_state::ConfirmationAction;

pub struct ConfirmationDialog;

impl ConfirmationDialog {
    pub fn render(frame: &mut Frame, area: Rect, action: ConfirmationAction) {
        let (title, message) = match action {
            ConfirmationAction::NewFile => (
                "New File",
                "Current file has unsaved changes. Create new file anyway?",
            ),
            ConfirmationAction::Quit => ("Quit", "Current file has unsaved changes. Quit anyway?"),
            ConfirmationAction::DeleteFile => (
                "Delete File",
                "Are you sure you want to delete this file? This cannot be undone.",
            ),
            ConfirmationAction::None => return,
        };

        // Create centered modal
        let popup_area = Self::centered_rect(50, 30, area);

        // Clear the area
        frame.render_widget(Clear, popup_area);

        // Create layout
        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Length(3), // Title
                Constraint::Min(3),    // Message
                Constraint::Length(3), // Buttons
            ])
            .split(popup_area);

        // Render border
        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(Style::default().fg(Color::Yellow))
            .title(title)
            .title_alignment(Alignment::Center);
        frame.render_widget(block, popup_area);

        // Render message
        let message_paragraph = Paragraph::new(message)
            .style(Style::default().fg(Color::White))
            .alignment(Alignment::Center)
            .wrap(Wrap { trim: true });
        frame.render_widget(message_paragraph, chunks[1]);

        // Render buttons
        let buttons = Line::from(vec![
            Span::styled(
                "[Y]",
                Style::default()
                    .fg(Color::Green)
                    .add_modifier(Modifier::BOLD),
            ),
            Span::raw(" Yes    "),
            Span::styled(
                "[N]",
                Style::default().fg(Color::Red).add_modifier(Modifier::BOLD),
            ),
            Span::raw(" No    "),
            Span::styled("[ESC]", Style::default().fg(Color::Gray)),
            Span::raw(" Cancel"),
        ]);
        let buttons_paragraph = Paragraph::new(buttons).alignment(Alignment::Center);
        frame.render_widget(buttons_paragraph, chunks[2]);
    }

    fn centered_rect(percent_x: u16, percent_y: u16, r: Rect) -> Rect {
        let popup_layout = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Percentage((100 - percent_y) / 2),
                Constraint::Percentage(percent_y),
                Constraint::Percentage((100 - percent_y) / 2),
            ])
            .split(r);

        Layout::default()
            .direction(Direction::Horizontal)
            .constraints([
                Constraint::Percentage((100 - percent_x) / 2),
                Constraint::Percentage(percent_x),
                Constraint::Percentage((100 - percent_x) / 2),
            ])
            .split(popup_layout[1])[1]
    }
}

File: src\tui\components\help_screen.rs
=======================================
//! Help screen showing keyboard shortcuts.

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, List, ListItem, Paragraph},
};

use crate::tui::{keybindings::KeyBindings, theme::Theme};

pub struct HelpScreen;

impl HelpScreen {
    pub fn render(f: &mut Frame, area: Rect, theme: &Theme) {
        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(true))
            .title(" Help - Press F1 or Esc to close ")
            .title_alignment(Alignment::Center);

        let inner = block.inner(area);
        f.render_widget(block, area);

        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Length(3),
                Constraint::Min(10),
                Constraint::Length(5),
            ])
            .split(inner);

        let title = Paragraph::new(vec![
            Line::from(Span::styled(
                "TOON Format - Interactive TUI",
                theme.title_style(),
            )),
            Line::from(Span::styled(
                "Token-Oriented Object Notation",
                theme.info_style(),
            )),
        ])
        .alignment(Alignment::Center);
        f.render_widget(title, chunks[0]);

        let shortcuts = KeyBindings::shortcuts();
        let items: Vec<ListItem> = shortcuts
            .iter()
            .map(|(key, desc)| {
                ListItem::new(Line::from(vec![
                    Span::styled(format!("  {key:18} "), theme.info_style()),
                    Span::styled(*desc, theme.normal_style()),
                ]))
            })
            .collect();

        let list = List::new(items).block(
            Block::default()
                .borders(Borders::ALL)
                .border_style(theme.border_style(false))
                .title(" Keyboard Shortcuts "),
        );
        f.render_widget(list, chunks[1]);

        let footer = Paragraph::new(vec![
            Line::from(Span::styled(
                "TOON is a compact, human-readable format for passing structured data to LLMs",
                theme.normal_style(),
            )),
            Line::from(vec![
                Span::styled("Repository: ", theme.line_number_style()),
                Span::styled("github.com/toon-format/toon-rust", theme.info_style()),
            ]),
        ])
        .alignment(Alignment::Center);
        f.render_widget(footer, chunks[2]);
    }
}

File: src\tui\components\mod.rs
===============================
//! UI components for the TUI.

pub mod confirmation_dialog;
pub mod diff_viewer;
pub mod editor;
pub mod file_browser;
pub mod help_screen;
pub mod history_panel;
pub mod repl_panel;
pub mod settings_panel;
pub mod stats_bar;
pub mod status_bar;

pub use confirmation_dialog::ConfirmationDialog;
pub use diff_viewer::DiffViewer;
pub use editor::EditorComponent;
pub use file_browser::FileBrowser;
pub use help_screen::HelpScreen;
pub use history_panel::HistoryPanel;
pub use repl_panel::ReplPanel;
pub use settings_panel::SettingsPanel;
pub use stats_bar::StatsBar;
pub use status_bar::StatusBar;

File: src\tui\components\editor.rs
==================================
//! Input and output editor panels.

use ratatui::{
    Frame,
    layout::Rect,
    widgets::{Block, Borders},
};

use crate::tui::{state::AppState, theme::Theme};

pub struct EditorComponent;

impl EditorComponent {
    pub fn render(
        f: &mut Frame,
        input_area: Rect,
        output_area: Rect,
        app: &mut AppState,
        theme: &Theme,
    ) {
        let input_active = app.editor.is_input_active();
        let input_title = format!(
            " Input ({}) {} ",
            match app.mode {
                crate::tui::state::app_state::Mode::Encode => "JSON",
                crate::tui::state::app_state::Mode::Decode => "TOON",
                crate::tui::state::app_state::Mode::Rune => "RUNE",
            },
            if input_active { "●" } else { "" }
        );

        let input_block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(input_active))
            .title(input_title)
            .style(theme.normal_style());

        app.editor.input.set_block(input_block);
        app.editor
            .input
            .set_cursor_line_style(theme.selection_style());
        app.editor.input.set_style(theme.normal_style());

        f.render_widget(&app.editor.input, input_area);

        let output_active = app.editor.is_output_active();
        let output_title = format!(
            " Output ({}) {} ",
            match app.mode {
                crate::tui::state::app_state::Mode::Encode => "TOON",
                crate::tui::state::app_state::Mode::Decode => "JSON",
                crate::tui::state::app_state::Mode::Rune => "Results",
            },
            if output_active { "●" } else { "" }
        );

        let output_block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(output_active))
            .title(output_title)
            .style(theme.normal_style());

        app.editor.output.set_block(output_block);
        app.editor
            .output
            .set_cursor_line_style(theme.selection_style());
        app.editor.output.set_style(theme.normal_style());

        f.render_widget(&app.editor.output, output_area);
    }
}

File: src\tui\components\file_browser.rs
========================================
//! File browser for opening JSON/TOON files.

use std::fs;

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, List, ListItem, Paragraph},
};

use crate::tui::{state::AppState, theme::Theme};

/// File browser state and rendering.
pub struct FileBrowser {
    pub selected_index: usize,
    pub scroll_offset: usize,
}

impl FileBrowser {
    pub fn new() -> Self {
        Self {
            selected_index: 0,
            scroll_offset: 0,
        }
    }

    pub fn move_up(&mut self) {
        if self.selected_index > 0 {
            self.selected_index -= 1;
            if self.selected_index < self.scroll_offset {
                self.scroll_offset = self.selected_index;
            }
        }
    }

    pub fn move_down(&mut self, max: usize) {
        if self.selected_index < max.saturating_sub(1) {
            self.selected_index += 1;
        }
    }

    pub fn get_selected_entry(&self, dir: &std::path::Path) -> Option<std::path::PathBuf> {
        let entries = self.get_directory_entries(dir);
        if self.selected_index < entries.len() {
            let (name, _is_dir, _, _) = &entries[self.selected_index];
            if name == ".." {
                dir.parent().map(|p| p.to_path_buf())
            } else {
                Some(dir.join(name))
            }
        } else {
            None
        }
    }

    pub fn get_entry_count(&self, dir: &std::path::Path) -> usize {
        self.get_directory_entries(dir).len()
    }

    pub fn render(&mut self, f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(true))
            .title(" File Browser - Press Esc to close ")
            .title_alignment(Alignment::Center);

        let inner = block.inner(area);
        f.render_widget(block, area);

        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Length(2),
                Constraint::Min(10),
                Constraint::Length(3),
            ])
            .split(inner);

        let current_dir = Paragraph::new(Line::from(vec![
            Span::styled("Current: ", theme.line_number_style()),
            Span::styled(
                app.file_state.current_dir.display().to_string(),
                theme.info_style(),
            ),
        ]));
        f.render_widget(current_dir, chunks[0]);

        let entries = self.get_directory_entries(&app.file_state.current_dir);
        let items: Vec<ListItem> = entries
            .iter()
            .enumerate()
            .map(|(idx, (name, is_dir, is_json, is_toon))| {
                let icon = if *is_dir {
                    "📁"
                } else if *is_json {
                    "📄"
                } else if *is_toon {
                    "📋"
                } else {
                    "📃"
                };

                let style = if idx == self.selected_index {
                    theme.selection_style()
                } else if *is_json || *is_toon {
                    theme.highlight_style()
                } else {
                    theme.normal_style()
                };

                ListItem::new(Line::from(vec![
                    Span::styled(format!("  {icon} "), style),
                    Span::styled(name, style),
                ]))
            })
            .collect();

        let list = List::new(items);
        f.render_widget(list, chunks[1]);

        let instructions = Paragraph::new(Line::from(vec![
            Span::styled("↑↓", theme.info_style()),
            Span::styled(" Navigate | ", theme.line_number_style()),
            Span::styled("Enter", theme.info_style()),
            Span::styled(" Open | ", theme.line_number_style()),
            Span::styled("Space", theme.info_style()),
            Span::styled(" Select | ", theme.line_number_style()),
            Span::styled("Esc", theme.info_style()),
            Span::styled(" Close", theme.line_number_style()),
        ]))
        .alignment(Alignment::Center);
        f.render_widget(instructions, chunks[2]);
    }

    fn get_directory_entries(&self, dir: &std::path::Path) -> Vec<(String, bool, bool, bool)> {
        let mut entries = vec![("..".to_string(), true, false, false)];

        if let Ok(read_dir) = fs::read_dir(dir) {
            let mut files: Vec<_> = read_dir
                .filter_map(|entry| entry.ok())
                .filter_map(|entry| {
                    let path = entry.path();
                    let name = path.file_name()?.to_str()?.to_string();
                    let is_dir = path.is_dir();
                    let is_json =
                        !is_dir && path.extension().and_then(|e| e.to_str()) == Some("json");
                    let is_toon =
                        !is_dir && path.extension().and_then(|e| e.to_str()) == Some("toon");
                    Some((name, is_dir, is_json, is_toon))
                })
                .collect();

            files.sort_by(|a, b| {
                if a.1 == b.1 {
                    a.0.cmp(&b.0)
                } else {
                    b.1.cmp(&a.1)
                }
            });

            entries.extend(files);
        }

        entries
    }
}

impl Default for FileBrowser {
    fn default() -> Self {
        Self::new()
    }
}

File: src\tui\components\diff_viewer.rs
=======================================
//! Side-by-side diff viewer for input/output comparison.

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, Paragraph, Wrap},
};

use crate::tui::{state::AppState, theme::Theme};

pub struct DiffViewer;

impl DiffViewer {
    pub fn render(f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(true))
            .title(" Side-by-Side Comparison - Press Esc to close ")
            .title_alignment(Alignment::Center);

        let inner = block.inner(area);
        f.render_widget(block, area);

        let chunks = Layout::default()
            .direction(Direction::Horizontal)
            .constraints([Constraint::Percentage(50), Constraint::Percentage(50)])
            .split(inner);

        let input_text = app.editor.get_input();
        let input_title = match app.mode {
            crate::tui::state::app_state::Mode::Encode => "JSON Input",
            crate::tui::state::app_state::Mode::Decode => "TOON Input",
            crate::tui::state::app_state::Mode::Rune => "RUNE Input",
        };

        let input_lines: Vec<Line> = input_text
            .lines()
            .enumerate()
            .map(|(idx, line)| {
                Line::from(vec![
                    Span::styled(format!("{:4} ", idx + 1), theme.line_number_style()),
                    Span::styled(line, theme.normal_style()),
                ])
            })
            .collect();

        let input_para = Paragraph::new(input_lines)
            .block(
                Block::default()
                    .borders(Borders::ALL)
                    .border_style(theme.border_style(false))
                    .title(format!(" {input_title} ")),
            )
            .wrap(Wrap { trim: false });

        f.render_widget(input_para, chunks[0]);

        let output_text = app.editor.get_output();
        let output_title = match app.mode {
            crate::tui::state::app_state::Mode::Encode => "TOON Output",
            crate::tui::state::app_state::Mode::Decode => "JSON Output",
            crate::tui::state::app_state::Mode::Rune => "Parsed Results",
        };

        let output_lines: Vec<Line> = output_text
            .lines()
            .enumerate()
            .map(|(idx, line)| {
                Line::from(vec![
                    Span::styled(format!("{:4} ", idx + 1), theme.line_number_style()),
                    Span::styled(line, theme.normal_style()),
                ])
            })
            .collect();

        let output_para = Paragraph::new(output_lines)
            .block(
                Block::default()
                    .borders(Borders::ALL)
                    .border_style(theme.border_style(false))
                    .title(format!(" {output_title} ")),
            )
            .wrap(Wrap { trim: false });

        f.render_widget(output_para, chunks[1]);
    }
}

File: src\tui\components\history_panel.rs
=========================================
//! Conversion history panel.

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, List, ListItem, Paragraph},
};

use crate::tui::{state::AppState, theme::Theme};

pub struct HistoryPanel;

impl HistoryPanel {
    pub fn render(f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(true))
            .title(" Conversion History - Press Esc to close ")
            .title_alignment(Alignment::Center);

        let inner = block.inner(area);
        f.render_widget(block, area);

        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([Constraint::Length(2), Constraint::Min(10)])
            .split(inner);

        let title = Paragraph::new(Line::from(Span::styled(
            format!("Total conversions: {}", app.file_state.history.len()),
            theme.info_style(),
        )))
        .alignment(Alignment::Center);
        f.render_widget(title, chunks[0]);

        if app.file_state.history.is_empty() {
            let empty = Paragraph::new(Line::from(Span::styled(
                "No conversion history yet",
                theme.line_number_style(),
            )))
            .alignment(Alignment::Center);
            f.render_widget(empty, chunks[1]);
        } else {
            let items: Vec<ListItem> = app
                .file_state
                .history
                .iter()
                .rev()
                .map(|entry| {
                    let time_str = entry.timestamp.format("%H:%M:%S").to_string();
                    let file_str = entry
                        .input_file
                        .as_ref()
                        .and_then(|p| p.file_name())
                        .and_then(|n| n.to_str())
                        .unwrap_or("stdin");

                    ListItem::new(Line::from(vec![
                        Span::styled(format!("  {time_str} "), theme.line_number_style()),
                        Span::styled(format!("[{}] ", entry.mode), theme.info_style()),
                        Span::styled(file_str, theme.normal_style()),
                        Span::styled(
                            format!(" → {:.1}% saved", entry.token_savings),
                            if entry.token_savings > 0.0 {
                                theme.success_style()
                            } else {
                                theme.warning_style()
                            },
                        ),
                    ]))
                })
                .collect();

            let list = List::new(items);
            f.render_widget(list, chunks[1]);
        }
    }
}

File: src\tui\components\repl_panel.rs
======================================
use ratatui::{
    Frame,
    layout::{Constraint, Direction, Layout, Margin, Rect},
    style::{Color, Modifier, Style},
    text::{Line, Span},
    widgets::{Block, Borders, Paragraph, Scrollbar, ScrollbarOrientation, ScrollbarState, Wrap},
};

use crate::tui::state::{AppState, ReplLineKind};

pub struct ReplPanel;

impl ReplPanel {
    pub fn render(f: &mut Frame, area: Rect, app: &mut AppState) {
        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([Constraint::Min(10), Constraint::Length(3)])
            .split(area);

        Self::render_output(f, chunks[0], app);
        Self::render_input(f, chunks[1], app);
    }

    fn render_output(f: &mut Frame, area: Rect, app: &AppState) {
        let lines: Vec<Line> = app
            .repl
            .output
            .iter()
            .skip(app.repl.scroll_offset)
            .map(|line| {
                let style = match line.kind {
                    ReplLineKind::Prompt => Style::default().fg(Color::Cyan),
                    ReplLineKind::Success => Style::default().fg(Color::Green),
                    ReplLineKind::Error => Style::default().fg(Color::Red),
                    ReplLineKind::Info => Style::default().fg(Color::Yellow),
                };
                Line::from(Span::styled(&line.content, style))
            })
            .collect();

        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(Style::default().fg(Color::Cyan))
            .title(" REPL Session (Ctrl+R to toggle, Esc to close) ");

        let paragraph = Paragraph::new(lines)
            .block(block)
            .wrap(Wrap { trim: false });

        f.render_widget(paragraph, area);

        if app.repl.output.len() > (area.height as usize - 2) {
            let scrollbar = Scrollbar::new(ScrollbarOrientation::VerticalRight)
                .begin_symbol(Some("↑"))
                .end_symbol(Some("↓"));

            let mut scrollbar_state =
                ScrollbarState::new(app.repl.output.len()).position(app.repl.scroll_offset);

            f.render_stateful_widget(
                scrollbar,
                area.inner(Margin {
                    vertical: 1,
                    horizontal: 0,
                }),
                &mut scrollbar_state,
            );
        }
    }

    fn render_input(f: &mut Frame, area: Rect, app: &AppState) {
        let prompt = Span::styled(
            "> ",
            Style::default()
                .fg(Color::Cyan)
                .add_modifier(Modifier::BOLD),
        );

        let input_text = Span::raw(&app.repl.input);
        let cursor = Span::styled("█", Style::default().fg(Color::White));

        let line = Line::from(vec![prompt, input_text, cursor]);

        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(Style::default().fg(Color::Cyan));

        let paragraph = Paragraph::new(line).block(block);

        f.render_widget(paragraph, area);
    }
}

File: src\tui\components\stats_bar.rs
=====================================
//! Statistics bar showing token and byte savings.

use ratatui::{
    Frame,
    layout::Rect,
    text::{Line, Span},
    widgets::{Block, Borders, Paragraph},
};

use crate::tui::{state::AppState, theme::Theme};

pub struct StatsBar;

impl StatsBar {
    pub fn render(f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
        if let Some(ref stats) = app.stats {
            let spans = vec![
                Span::styled(" Stats: ", theme.title_style()),
                Span::raw("Tokens: "),
                Span::styled(
                    format!("{}→{}", stats.json_tokens, stats.toon_tokens),
                    theme.info_style(),
                ),
                Span::styled(
                    format!(" ({:.1}%)", stats.token_savings),
                    if stats.token_savings > 0.0 {
                        theme.success_style()
                    } else {
                        theme.error_style()
                    },
                ),
                Span::raw(" | Bytes: "),
                Span::styled(
                    format!("{}→{}", stats.json_bytes, stats.toon_bytes),
                    theme.info_style(),
                ),
                Span::styled(
                    format!(" ({:.1}%)", stats.byte_savings),
                    if stats.byte_savings > 0.0 {
                        theme.success_style()
                    } else {
                        theme.error_style()
                    },
                ),
            ];

            let line = Line::from(spans);
            let paragraph = Paragraph::new(line).block(
                Block::default()
                    .borders(Borders::ALL)
                    .border_style(theme.border_style(false))
                    .title(" Statistics "),
            );

            f.render_widget(paragraph, area);
        } else {
            let paragraph = Paragraph::new(Line::from(vec![Span::styled(
                " No statistics available yet ",
                theme.line_number_style(),
            )]))
            .block(
                Block::default()
                    .borders(Borders::ALL)
                    .border_style(theme.border_style(false))
                    .title(" Statistics "),
            );

            f.render_widget(paragraph, area);
        }
    }
}

File: src\tui\components\settings_panel.rs
==========================================
//! Settings panel for configuring encode/decode options.

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, List, ListItem, Paragraph},
};

use crate::{
    tui::{state::AppState, theme::Theme},
    types::{Delimiter, Indent, KeyFoldingMode, PathExpansionMode},
};

pub struct SettingsPanel;

impl SettingsPanel {
    pub fn render(f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
        let block = Block::default()
            .borders(Borders::ALL)
            .border_style(theme.border_style(true))
            .title(" Settings - Press Ctrl+P or Esc to close ")
            .title_alignment(Alignment::Center);

        let inner = block.inner(area);
        f.render_widget(block, area);

        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Length(3),
                Constraint::Min(10),
                Constraint::Length(3),
            ])
            .split(inner);

        let title = Paragraph::new(Line::from(Span::styled(
            format!("Current Mode: {}", app.mode.as_str()),
            theme.title_style(),
        )))
        .alignment(Alignment::Center);
        f.render_widget(title, chunks[0]);

        let mut items = vec![];

        items.push(ListItem::new(Line::from(Span::styled(
            "═══ Encode Settings (JSON → TOON) ═══",
            theme.title_style(),
        ))));

        let delimiter_str = match app.encode_options.delimiter {
            Delimiter::Comma => "Comma (,)",
            Delimiter::Tab => "Tab (\\t)",
            Delimiter::Pipe => "Pipe (|)",
        };
        items.push(ListItem::new(Line::from(vec![
            Span::styled("  Delimiter:       ", theme.info_style()),
            Span::styled(delimiter_str, theme.normal_style()),
            Span::styled("  [Press 'd' to cycle]", theme.line_number_style()),
        ])));

        let Indent::Spaces(indent_spaces) = app.encode_options.indent;
        items.push(ListItem::new(Line::from(vec![
            Span::styled("  Indentation:     ", theme.info_style()),
            Span::styled(format!("{indent_spaces} spaces"), theme.normal_style()),
            Span::styled("  [+/- to adjust]", theme.line_number_style()),
        ])));

        let fold_keys = match app.encode_options.key_folding {
            KeyFoldingMode::Off => "Off",
            KeyFoldingMode::Safe => "On (Safe)",
        };
        items.push(ListItem::new(Line::from(vec![
            Span::styled("  Key Folding:     ", theme.info_style()),
            Span::styled(fold_keys, theme.normal_style()),
            Span::styled("  [Press 'f' to toggle]", theme.line_number_style()),
        ])));

        if app.encode_options.key_folding != KeyFoldingMode::Off {
            items.push(ListItem::new(Line::from(vec![
                Span::styled("  Flatten Depth:   ", theme.info_style()),
                Span::styled(
                    if app.encode_options.flatten_depth == usize::MAX {
                        "Unlimited".to_string()
                    } else {
                        format!("{}", app.encode_options.flatten_depth)
                    },
                    theme.normal_style(),
                ),
                Span::styled(
                    "  [[/] to adjust, [u] for unlimited]",
                    theme.line_number_style(),
                ),
            ])));
        }

        items.push(ListItem::new(Line::from("")));

        items.push(ListItem::new(Line::from(Span::styled(
            "═══ Decode Settings (TOON → JSON) ═══",
            theme.title_style(),
        ))));

        items.push(ListItem::new(Line::from(vec![
            Span::styled("  Strict Mode:     ", theme.info_style()),
            Span::styled(
                if app.decode_options.strict {
                    "On"
                } else {
                    "Off"
                },
                theme.normal_style(),
            ),
            Span::styled("  [Press 's' to toggle]", theme.line_number_style()),
        ])));

        items.push(ListItem::new(Line::from(vec![
            Span::styled("  Type Coercion:   ", theme.info_style()),
            Span::styled(
                if app.decode_options.coerce_types {
                    "On"
                } else {
                    "Off"
                },
                theme.normal_style(),
            ),
            Span::styled("  [Press 'c' to toggle]", theme.line_number_style()),
        ])));

        let expand_paths = match app.decode_options.expand_paths {
            PathExpansionMode::Off => "Off",
            PathExpansionMode::Safe => "On (Safe)",
        };
        items.push(ListItem::new(Line::from(vec![
            Span::styled("  Path Expansion:  ", theme.info_style()),
            Span::styled(expand_paths, theme.normal_style()),
            Span::styled("  [Press 'p' to toggle]", theme.line_number_style()),
        ])));

        let list = List::new(items);
        f.render_widget(list, chunks[1]);

        let instructions = Paragraph::new(Line::from(vec![
            Span::styled("Press ", theme.line_number_style()),
            Span::styled("Ctrl+E", theme.info_style()),
            Span::styled(" to toggle mode | ", theme.line_number_style()),
            Span::styled("Ctrl+R", theme.info_style()),
            Span::styled(" to refresh conversion", theme.line_number_style()),
        ]))
        .alignment(Alignment::Center);
        f.render_widget(instructions, chunks[2]);
    }
}

File: src\tui\state\app_state.rs
================================
//! Main application state.

use super::{EditorState, FileState, ReplState};
use crate::tui::message::Msg;
#[cfg(feature = "hydron")]
use crate::rune::hydron::eval::Evaluator;
use crate::{
    tui::theme::Theme,
    types::{DecodeOptions, Delimiter, EncodeOptions, Indent, KeyFoldingMode, PathExpansionMode},
};

/// Conversion mode (encode/decode/parse).
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Mode {
    Encode, // JSON → TOON
    Decode, // TOON → JSON
    Rune,   // RUNE → Parsed AST + TOON blocks
}

impl Mode {
    pub fn toggle(&self) -> Self {
        match self {
            Mode::Encode => Mode::Decode,
            Mode::Decode => Mode::Rune,
            Mode::Rune => Mode::Encode,
        }
    }

    pub fn as_str(&self) -> &'static str {
        match self {
            Mode::Encode => "Encode (JSON → TOON)",
            Mode::Decode => "Decode (TOON → JSON)",
            Mode::Rune => "Parse (RUNE → Results)",
        }
    }

    pub fn short_name(&self) -> &'static str {
        match self {
            Mode::Encode => "Encode",
            Mode::Decode => "Decode",
            Mode::Rune => "RUNE",
        }
    }
}

/// Statistics from the last conversion.
#[derive(Debug, Clone)]
pub struct ConversionStats {
    pub json_tokens: usize,
    pub toon_tokens: usize,
    pub json_bytes: usize,
    pub toon_bytes: usize,
    pub token_savings: f64,
    pub byte_savings: f64,
}

/// Central application state containing all UI and conversion state.
pub struct AppState<'a> {
    pub mode: Mode,
    pub editor: EditorState<'a>,
    pub file_state: FileState,
    pub repl: ReplState,
    #[cfg(feature = "hydron")]
    pub rune_eval: Evaluator,
    pub theme: Theme,
    pub encode_options: EncodeOptions,
    pub decode_options: DecodeOptions,
    pub show_settings: bool,
    pub show_help: bool,
    pub show_file_browser: bool,
    pub show_history: bool,
    pub show_diff: bool,
    pub show_confirmation: bool,
    pub confirmation_action: ConfirmationAction,
    pub error_message: Option<String>,
    pub status_message: Option<String>,
    pub stats: Option<ConversionStats>,
    pub should_quit: bool,
}

/// Actions that require user confirmation
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum ConfirmationAction {
    None,
    NewFile,
    Quit,
    DeleteFile,
}

impl<'a> AppState<'a> {
    pub fn new() -> Self {
        Self {
            mode: Mode::Encode,
            editor: EditorState::new(),
            file_state: FileState::new(),
            repl: ReplState::new(),
            #[cfg(feature = "hydron")]
            rune_eval: Evaluator::new(),
            theme: Theme::default(),

            encode_options: EncodeOptions::default(),
            decode_options: DecodeOptions::default(),

            show_settings: false,
            show_help: false,
            show_file_browser: false,
            show_history: false,
            show_diff: false,
            show_confirmation: false,
            confirmation_action: ConfirmationAction::None,

            error_message: None,
            status_message: None,
            stats: None,

            should_quit: false,
        }
    }

    pub fn toggle_mode(&mut self) {
        self.mode = self.mode.toggle();
        self.clear_error();
        self.clear_status();
    }

    pub fn toggle_theme(&mut self) {
        self.theme = self.theme.toggle();
        self.set_status("Theme toggled".to_string());
    }

    pub fn set_error(&mut self, msg: String) {
        self.error_message = Some(msg);
        self.status_message = None;
    }

    pub fn set_status(&mut self, msg: String) {
        self.status_message = Some(msg);
        self.error_message = None;
    }

    pub fn clear_error(&mut self) {
        self.error_message = None;
    }

    pub fn clear_status(&mut self) {
        self.status_message = None;
    }

    pub fn quit(&mut self) {
        self.should_quit = true;
    }

    pub fn toggle_settings(&mut self) {
        self.show_settings = !self.show_settings;
        if self.show_settings {
            self.show_help = false;
            self.show_file_browser = false;
            self.show_history = false;
            self.show_diff = false;
        }
    }

    pub fn toggle_help(&mut self) {
        self.show_help = !self.show_help;
        if self.show_help {
            self.show_settings = false;
            self.show_file_browser = false;
            self.show_history = false;
            self.show_diff = false;
        }
    }

    pub fn toggle_file_browser(&mut self) {
        self.show_file_browser = !self.show_file_browser;
        if self.show_file_browser {
            self.show_settings = false;
            self.show_help = false;
            self.show_history = false;
            self.show_diff = false;
        }
    }

    pub fn toggle_history(&mut self) {
        self.show_history = !self.show_history;
        if self.show_history {
            self.show_settings = false;
            self.show_help = false;
            self.show_file_browser = false;
            self.show_diff = false;
        }
    }

    pub fn toggle_diff(&mut self) {
        self.show_diff = !self.show_diff;
        if self.show_diff {
            self.show_settings = false;
            self.show_help = false;
            self.show_file_browser = false;
            self.show_history = false;
        }
    }

    pub fn cycle_delimiter(&mut self) {
        self.encode_options =
            self.encode_options
                .clone()
                .with_delimiter(match self.encode_options.delimiter {
                    Delimiter::Comma => Delimiter::Tab,
                    Delimiter::Tab => Delimiter::Pipe,
                    Delimiter::Pipe => Delimiter::Comma,
                });
    }

    pub fn increase_indent(&mut self) {
        let Indent::Spaces(current) = self.encode_options.indent;
        if current < 8 {
            self.encode_options = self
                .encode_options
                .clone()
                .with_indent(Indent::Spaces(current + 1));
        }
    }

    pub fn decrease_indent(&mut self) {
        let Indent::Spaces(current) = self.encode_options.indent;
        if current > 1 {
            self.encode_options = self
                .encode_options
                .clone()
                .with_indent(Indent::Spaces(current - 1));
        }
    }

    pub fn toggle_fold_keys(&mut self) {
        self.encode_options =
            self.encode_options
                .clone()
                .with_key_folding(match self.encode_options.key_folding {
                    KeyFoldingMode::Off => KeyFoldingMode::Safe,
                    KeyFoldingMode::Safe => KeyFoldingMode::Off,
                });
    }

    pub fn increase_flatten_depth(&mut self) {
        if self.encode_options.flatten_depth == usize::MAX {
            self.encode_options = self.encode_options.clone().with_flatten_depth(2);
        } else if self.encode_options.flatten_depth < 10 {
            self.encode_options = self
                .encode_options
                .clone()
                .with_flatten_depth(self.encode_options.flatten_depth + 1);
        }
    }

    pub fn decrease_flatten_depth(&mut self) {
        if self.encode_options.flatten_depth == 2 {
            self.encode_options = self.encode_options.clone().with_flatten_depth(usize::MAX);
        } else if self.encode_options.flatten_depth > 2
            && self.encode_options.flatten_depth != usize::MAX
        {
            self.encode_options = self
                .encode_options
                .clone()
                .with_flatten_depth(self.encode_options.flatten_depth - 1);
        }
    }

    pub fn toggle_flatten_depth(&mut self) {
        if self.encode_options.flatten_depth == usize::MAX {
            self.encode_options = self.encode_options.clone().with_flatten_depth(2);
        } else {
            self.encode_options = self.encode_options.clone().with_flatten_depth(usize::MAX);
        }
    }

    pub fn toggle_expand_paths(&mut self) {
        self.decode_options =
            self.decode_options
                .clone()
                .with_expand_paths(match self.decode_options.expand_paths {
                    PathExpansionMode::Off => PathExpansionMode::Safe,
                    PathExpansionMode::Safe => PathExpansionMode::Off,
                });
    }

    pub fn toggle_strict(&mut self) {
        let strict = !self.decode_options.strict;
        self.decode_options = self.decode_options.clone().with_strict(strict);
    }

    pub fn toggle_coerce_types(&mut self) {
        let coerce = !self.decode_options.coerce_types;
        self.decode_options = self.decode_options.clone().with_coerce_types(coerce);
    }

    /// Central message handler for TUI actions (Elm-style update).
    pub fn update(&mut self, msg: Msg) -> Option<Msg> {
        match msg {
            Msg::Quit => {
                self.quit();
                None
            }
            Msg::ToggleMode => {
                self.toggle_mode();
                None
            }
            Msg::ToggleSettings => {
                self.toggle_settings();
                None
            }
            Msg::ToggleHelp => {
                self.toggle_help();
                None
            }
            Msg::ToggleFileBrowser => {
                self.toggle_file_browser();
                None
            }
            Msg::ToggleHistory => {
                self.toggle_history();
                None
            }
            Msg::ToggleDiff => {
                self.toggle_diff();
                None
            }
            Msg::ToggleTheme => {
                self.toggle_theme();
                None
            }
            Msg::SetError(e) => {
                self.set_error(e);
                None
            }
            Msg::SetStatus(s) => {
                self.set_status(s);
                None
            }
            Msg::ClearError => {
                self.clear_error();
                None
            }
            Msg::ClearStatus => {
                self.clear_status();
                None
            }
            _ => None, // Not yet handled messages
        }
    }
}

impl<'a> Default for AppState<'a> {
    fn default() -> Self {
        Self::new()
    }
}

File: src\tui\components\status_bar.rs
======================================
//! Status bar showing mode, file, and key commands.

use ratatui::{
    Frame,
    layout::{Alignment, Constraint, Direction, Layout, Rect},
    text::{Line, Span},
    widgets::{Block, Borders, Paragraph},
};

use crate::tui::{state::AppState, theme::Theme};

pub struct StatusBar;

impl StatusBar {
    pub fn render(f: &mut Frame, area: Rect, app: &AppState, theme: &Theme) {
        let chunks = Layout::default()
            .direction(Direction::Horizontal)
            .constraints([Constraint::Percentage(70), Constraint::Percentage(30)])
            .split(area);

        let mut left_spans = vec![];

        left_spans.push(Span::styled(
            format!("{} ", app.mode.short_name()),
            theme.info_style(),
        ));

        left_spans.push(Span::raw("| "));

        if let Some(ref path) = app.file_state.current_file {
            let file_name = path
                .file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("Untitled");
            left_spans.push(Span::styled(file_name, theme.normal_style()));

            if app.file_state.is_modified {
                left_spans.push(Span::styled(" [Modified]", theme.warning_style()));
            }
        } else {
            left_spans.push(Span::styled("No file", theme.line_number_style()));
        }

        left_spans.push(Span::raw(" | "));

        if let Some(ref error) = app.error_message {
            left_spans.push(Span::styled(format!("✗ {error} "), theme.error_style()));
        } else if let Some(ref status) = app.status_message {
            left_spans.push(Span::styled(format!("✓ {status} "), theme.success_style()));
        } else {
            left_spans.push(Span::styled("Ready ", theme.normal_style()));
        }

        left_spans.push(Span::raw("| "));
        let theme_name = match theme {
            Theme::Dark => "Dark",
            Theme::Light => "Light",
        };
        left_spans.push(Span::styled(
            theme_name.to_string(),
            theme.line_number_style(),
        ));

        let left_line = Line::from(left_spans);
        let left_paragraph =
            Paragraph::new(left_line).block(Block::default().borders(Borders::ALL));

        let key_commands = vec![
            Span::styled("F1", theme.info_style()),
            Span::raw(" Help | "),
            Span::styled("Ctrl+C", theme.info_style()),
            Span::raw(" Quit"),
        ];

        let right_line = Line::from(key_commands);
        let right_paragraph = Paragraph::new(right_line)
            .block(Block::default().borders(Borders::ALL))
            .alignment(Alignment::Right);

        f.render_widget(left_paragraph, chunks[0]);
        f.render_widget(right_paragraph, chunks[1]);
    }
}

File: src\tui\state\editor_state.rs
===================================
//! Editor state for input/output text areas.

use tui_textarea::TextArea;

/// Which panel is currently active.
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum EditorMode {
    Input,
    Output,
}

/// State for input and output text areas.
pub struct EditorState<'a> {
    pub input: TextArea<'a>,
    pub output: TextArea<'a>,
    pub active: EditorMode,
}

impl<'a> EditorState<'a> {
    pub fn new() -> Self {
        let mut input = TextArea::default();
        input.set_placeholder_text("Enter JSON here or open a file (Ctrl+O)");

        let mut output = TextArea::default();
        output.set_placeholder_text("TOON output will appear here");

        Self {
            input,
            output,
            active: EditorMode::Input,
        }
    }

    pub fn set_input(&mut self, text: String) {
        let lines: Vec<String> = text.lines().map(|l| l.to_string()).collect();
        self.input = TextArea::from(lines);
    }

    pub fn set_output(&mut self, text: String) {
        let lines: Vec<String> = text.lines().map(|l| l.to_string()).collect();
        self.output = TextArea::from(lines);
    }

    pub fn get_input(&self) -> String {
        self.input.lines().join("\n")
    }

    pub fn get_output(&self) -> String {
        self.output.lines().join("\n")
    }

    pub fn clear_input(&mut self) {
        self.input = TextArea::default();
        self.input
            .set_placeholder_text("Enter JSON here or open a file (Ctrl+O)");
    }

    pub fn clear_output(&mut self) {
        self.output = TextArea::default();
        self.output
            .set_placeholder_text("TOON output will appear here");
    }

    pub fn toggle_active(&mut self) {
        self.active = match self.active {
            EditorMode::Input => EditorMode::Output,
            EditorMode::Output => EditorMode::Input,
        };
    }

    pub fn is_input_active(&self) -> bool {
        self.active == EditorMode::Input
    }

    pub fn is_output_active(&self) -> bool {
        self.active == EditorMode::Output
    }
}

impl<'a> Default for EditorState<'a> {
    fn default() -> Self {
        Self::new()
    }
}

File: src\tui\state\file_state.rs
=================================
//! File management and conversion history.

use std::path::PathBuf;

use chrono::{DateTime, Local};

/// A file or directory entry.
#[derive(Debug, Clone)]
pub struct FileEntry {
    pub path: PathBuf,
    pub is_dir: bool,
    pub size: u64,
    pub modified: Option<DateTime<Local>>,
}

impl FileEntry {
    pub fn name(&self) -> String {
        self.path
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("")
            .to_string()
    }

    pub fn is_json(&self) -> bool {
        !self.is_dir && self.path.extension().and_then(|e| e.to_str()) == Some("json")
    }

    pub fn is_toon(&self) -> bool {
        !self.is_dir && self.path.extension().and_then(|e| e.to_str()) == Some("toon")
    }
}

/// Record of a conversion operation.
#[derive(Debug, Clone)]
pub struct ConversionHistory {
    pub timestamp: DateTime<Local>,
    pub mode: String,
    pub input_file: Option<PathBuf>,
    pub output_file: Option<PathBuf>,
    pub token_savings: f64,
    pub byte_savings: f64,
}

/// File browser and conversion history state.
pub struct FileState {
    pub current_file: Option<PathBuf>,
    pub current_dir: PathBuf,
    pub selected_files: Vec<PathBuf>,
    pub history: Vec<ConversionHistory>,
    pub is_modified: bool,
}

impl FileState {
    pub fn new() -> Self {
        Self {
            current_file: None,
            current_dir: std::env::current_dir().unwrap_or_else(|_| PathBuf::from(".")),
            selected_files: Vec::new(),
            history: Vec::new(),
            is_modified: false,
        }
    }

    pub fn set_current_file(&mut self, path: PathBuf) {
        self.current_file = Some(path.clone());
        self.current_dir = path
            .parent()
            .map(|p| p.to_path_buf())
            .unwrap_or_else(|| std::env::current_dir().unwrap_or_else(|_| PathBuf::from(".")));
        self.is_modified = false;
    }

    pub fn clear_current_file(&mut self) {
        self.current_file = None;
        self.is_modified = false;
    }

    pub fn mark_modified(&mut self) {
        self.is_modified = true;
    }

    pub fn add_to_history(&mut self, entry: ConversionHistory) {
        self.history.push(entry);
        if self.history.len() > 50 {
            self.history.remove(0);
        }
    }

    pub fn toggle_file_selection(&mut self, path: PathBuf) {
        if let Some(pos) = self.selected_files.iter().position(|p| p == &path) {
            self.selected_files.remove(pos);
        } else {
            self.selected_files.push(path);
        }
    }

    pub fn clear_selection(&mut self) {
        self.selected_files.clear();
    }

    pub fn is_selected(&self, path: &PathBuf) -> bool {
        self.selected_files.contains(path)
    }
}

impl Default for FileState {
    fn default() -> Self {
        Self::new()
    }
}

File: src\tui\state\mod.rs
==========================
//! Application state management.

pub mod app_state;
pub mod editor_state;
pub mod file_state;
pub mod repl_state;

pub use app_state::{AppState, ConversionStats, Mode};
pub use editor_state::{EditorMode, EditorState};
pub use file_state::{ConversionHistory, FileState};
pub use repl_state::{ReplLine, ReplLineKind, ReplState};

File: src\tui\state\repl_state.rs
=================================
//! REPL state - separate from command mode

use std::collections::HashMap;

/// REPL session state
#[derive(Debug, Clone)]
pub struct ReplState {
    /// Whether REPL is active
    pub active: bool,
    /// Current input line
    pub input: String,
    /// Session history (output lines)
    pub output: Vec<ReplLine>,
    /// Variables stored in session
    pub variables: HashMap<String, String>,
    /// Command history
    pub history: Vec<String>,
    /// History index for navigation
    pub history_index: Option<usize>,
    /// Last result (for _ variable)
    pub last_result: Option<String>,
    /// Scroll offset for output
    pub scroll_offset: usize,
}

/// A line in the REPL output
#[derive(Debug, Clone)]
pub struct ReplLine {
    pub kind: ReplLineKind,
    pub content: String,
}

#[derive(Debug, Clone, PartialEq)]
pub enum ReplLineKind {
    Prompt,
    Success,
    Error,
    Info,
}

impl ReplState {
    pub fn new() -> Self {
        Self {
            active: false,
            input: String::new(),
            output: vec![ReplLine {
                kind: ReplLineKind::Info,
                content: "TOON REPL - Type 'help' for commands, 'exit' to close".to_string(),
            }],
            variables: HashMap::new(),
            history: Vec::new(),
            history_index: None,
            last_result: None,
            scroll_offset: 0,
        }
    }

    pub fn activate(&mut self) {
        self.active = true;
        self.input.clear();
        self.history_index = None;
    }

    pub fn deactivate(&mut self) {
        self.active = false;
        self.input.clear();
        self.history_index = None;
    }

    pub fn add_prompt(&mut self, cmd: &str) {
        self.output.push(ReplLine {
            kind: ReplLineKind::Prompt,
            content: format!("> {cmd}"),
        });
    }

    pub fn add_success(&mut self, msg: String) {
        for line in msg.lines() {
            self.output.push(ReplLine {
                kind: ReplLineKind::Success,
                content: line.to_string(),
            });
        }
    }

    pub fn add_error(&mut self, msg: String) {
        self.output.push(ReplLine {
            kind: ReplLineKind::Error,
            content: format!("✗ {msg}"),
        });
    }

    pub fn add_info(&mut self, msg: String) {
        let content = if msg.is_empty() || msg.starts_with("  ") || msg.starts_with("📖") {
            msg
        } else {
            format!("✓ {msg}")
        };

        self.output.push(ReplLine {
            kind: ReplLineKind::Info,
            content,
        });
    }

    pub fn add_to_history(&mut self, cmd: String) {
        if cmd.trim().is_empty() {
            return;
        }
        if self.history.last() == Some(&cmd) {
            return;
        }
        self.history.push(cmd);
        if self.history.len() > 100 {
            self.history.remove(0);
        }
    }

    pub fn history_up(&mut self) {
        if self.history.is_empty() {
            return;
        }
        let new_index = match self.history_index {
            None => Some(self.history.len() - 1),
            Some(0) => Some(0),
            Some(i) => Some(i - 1),
        };
        if let Some(idx) = new_index {
            self.input = self.history[idx].clone();
            self.history_index = new_index;
        }
    }

    pub fn history_down(&mut self) {
        match self.history_index {
            None => (),
            Some(i) if i >= self.history.len() - 1 => {
                self.input.clear();
                self.history_index = None;
            }
            Some(i) => {
                let new_idx = i + 1;
                self.input = self.history[new_idx].clone();
                self.history_index = Some(new_idx);
            }
        }
    }

    pub fn scroll_up(&mut self) {
        if self.scroll_offset > 0 {
            self.scroll_offset -= 1;
        }
    }

    pub fn scroll_down(&mut self, visible_lines: usize) {
        let max_scroll = self.output.len().saturating_sub(visible_lines);
        if self.scroll_offset < max_scroll {
            self.scroll_offset += 1;
        }
    }

    pub fn scroll_to_bottom(&mut self) {
        if self.output.len() <= 30 {
            self.scroll_offset = 0;
        } else {
            self.scroll_offset = self.output.len().saturating_sub(30);
        }
    }
}

impl Default for ReplState {
    fn default() -> Self {
        Self::new()
    }
}

File: tools\rune-vscode-theme\syntaxes\rune.tmLanguage.json
===========================================================
{
  "scopeName": "source.rune",
  "patterns": [
    { "name": "comment.line.rune", "match": "#.*$" },
    { "name": "string.quoted.rune", "match": "\"(?:\\.|[^\"])*\"" },
    { "name": "constant.numeric.rune", "match": "-?\\b\\d+(?:\\.\\d+)?\\b" },
    { "name": "variable.language.rune.semantic.prefix.a", "match": "\\bA:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.b", "match": "\\bB:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.c", "match": "\\bC:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.d", "match": "\\bD:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.e", "match": "\\bE:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.f", "match": "\\bF:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.g", "match": "\\bG:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.h", "match": "\\bH:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.i", "match": "\\bI:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.j", "match": "\\bJ:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.k", "match": "\\bK:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.l", "match": "\\bL:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.m", "match": "\\bM:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.n", "match": "\\bN:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.o", "match": "\\bO:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.p", "match": "\\bP:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.q", "match": "\\bQ:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.r", "match": "\\bR:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.s", "match": "\\bS:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.t", "match": "\\bT:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.u", "match": "\\bU:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.v", "match": "\\bV:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.w", "match": "\\bW:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.x", "match": "\\bX:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.y", "match": "\\bY:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic.prefix.z", "match": "\\bZ:(?=[A-Za-z_])" },
    { "name": "variable.language.rune.semantic", "match": "\\b[A-Z]:[A-Za-z_][A-Za-z0-9_]*\\b" },

    { "name": "keyword.operator.rune.flow", "match": "<->|>-<|->|<-" },
    { "name": "keyword.operator.rune.split", "match": "\\\\\\|/|/\\|\\\\|/\\\\|\\\\/" },
    { "name": "keyword.operator.rune.stabilize", "match": "\\|/|/\\||\\\\\\||\\|\\\\" },
    { "name": "keyword.operator.rune.pipeline", "match": "\\|>|<\\|" },
    { "name": "keyword.operator.rune.bind", "match": ":=|:>|<:|:" },
    { "name": "keyword.operator.rune.namespace", "match": "::" },
    { "name": "keyword.operator.rune.compare", "match": "<=|>=|=|<|>" },
    { "name": "keyword.operator.rune.transform", "match": "~" },

    { "name": "support.function.rune", "match": "\\b[A-Za-z_][A-Za-z0-9_]*\\s*(?=\\()" }
  ]
}

File: tools\rune-vscode-theme\themes\rune-color-theme.json
==========================================================
{
  "name": "RUNE Theme",
  "type": "dark",
  "colors": {},
  "tokenColors": [
    { "scope": "comment.line.rune", "settings": { "foreground": "#70829ca4", "fontStyle": "italic" } },
    { "scope": "string.quoted.rune", "settings": { "foreground": "#8bdcba" } },
    { "scope": "constant.numeric.rune", "settings": { "foreground": "#d4c0ffcb" } },
    { "scope": "variable.language.rune.semantic", "settings": { "foreground": "#cd69ecd7", "fontStyle": "bold" } },

    { "scope": "variable.language.rune.semantic.prefix.a", "settings": { "foreground": "#ff0000" } },
    { "scope": "variable.language.rune.semantic.prefix.b", "settings": { "foreground": "#ff3b00" } },
    { "scope": "variable.language.rune.semantic.prefix.c", "settings": { "foreground": "#ff7700" } },
    { "scope": "variable.language.rune.semantic.prefix.d", "settings": { "foreground": "#ffb200" } },
    { "scope": "variable.language.rune.semantic.prefix.e", "settings": { "foreground": "#ffe600" } },
    { "scope": "variable.language.rune.semantic.prefix.f", "settings": { "foreground": "#d4ff00" } },
    { "scope": "variable.language.rune.semantic.prefix.g", "settings": { "foreground": "#99ff00" } },
    { "scope": "variable.language.rune.semantic.prefix.h", "settings": { "foreground": "#5dff00" } },
    { "scope": "variable.language.rune.semantic.prefix.i", "settings": { "foreground": "#22ff00" } },
    { "scope": "variable.language.rune.semantic.prefix.j", "settings": { "foreground": "#00ff2a" } },
    { "scope": "variable.language.rune.semantic.prefix.k", "settings": { "foreground": "#00ff66" } },
    { "scope": "variable.language.rune.semantic.prefix.l", "settings": { "foreground": "#00ffa2" } },
    { "scope": "variable.language.rune.semantic.prefix.m", "settings": { "foreground": "#00ffdd" } },
    { "scope": "variable.language.rune.semantic.prefix.n", "settings": { "foreground": "#00c3ff" } },
    { "scope": "variable.language.rune.semantic.prefix.o", "settings": { "foreground": "#007fff" } },
    { "scope": "variable.language.rune.semantic.prefix.p", "settings": { "foreground": "#0044ff" } },
    { "scope": "variable.language.rune.semantic.prefix.q", "settings": { "foreground": "#0009ff" } },
    { "scope": "variable.language.rune.semantic.prefix.r", "settings": { "foreground": "#2b00ff" } },
    { "scope": "variable.language.rune.semantic.prefix.s", "settings": { "foreground": "#6600ff" } },
    { "scope": "variable.language.rune.semantic.prefix.t", "settings": { "foreground": "#a100ff" } },
    { "scope": "variable.language.rune.semantic.prefix.u", "settings": { "foreground": "#dc00ff" } },
    { "scope": "variable.language.rune.semantic.prefix.v", "settings": { "foreground": "#ff00e0" } },
    { "scope": "variable.language.rune.semantic.prefix.w", "settings": { "foreground": "#ff00a5" } },
    { "scope": "variable.language.rune.semantic.prefix.x", "settings": { "foreground": "#ff0069" } },
    { "scope": "variable.language.rune.semantic.prefix.y", "settings": { "foreground": "#ff002e" } },
    { "scope": "variable.language.rune.semantic.prefix.z", "settings": { "foreground": "#ff005f" } },

    { "scope": "keyword.operator.rune.flow", "settings": { "foreground": "#3A6FF7" } },
    { "scope": "keyword.operator.rune.split", "settings": { "foreground": "#B28CFF" } },
    { "scope": "keyword.operator.rune.stabilize", "settings": { "foreground": "#6FD1FF" } },
    { "scope": "keyword.operator.rune.pipeline", "settings": { "foreground": "#5DD6C2" } },
    { "scope": "keyword.operator.rune.bind", "settings": { "foreground": "#7A3FF2" } },
    { "scope": "keyword.operator.rune.namespace", "settings": { "foreground": "#6FD1FF" } },
    { "scope": "keyword.operator.rune.compare", "settings": { "foreground": "#F28F3B" } },
    { "scope": "keyword.operator.rune.transform", "settings": { "foreground": "#39C6B0" } },

    { "scope": "support.function.rune", "settings": { "foreground": "#7CD4FF" } },
    { "scope": "entity.name.type.rune", "settings": { "foreground": "#F2C17D" } }
  ]
}

File: hydron-ffi\www\index.html
===============================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>hydron-ffi example</title>
  </head>
  <body>
    <h1>hydron-ffi WebAssembly Example</h1>
    <p id="output">Loading...</p>
    <script type="module">
      import init, { s7_distance_js } from "./pkg/hydron_ffi.js";

      async function run() {
        await init();

        // Two orthogonal unit vectors on S7
        const a = new Float32Array([1,0,0,0,0,0,0,0]);
        const b = new Float32Array([0,1,0,0,0,0,0,0]);
        const d = s7_distance_js(a, b);
        document.getElementById('output').innerText = `S7 distance = ${d}`;
        console.log('S7 distance:', d);
      }

      run().catch(console.error);
    </script>
  </body>
</html>

File: index.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hydron Geometric Engine - Interactive Demo</title>
    <style>
        :root {
            --primary: #2563eb;
            --bg: #f8fafc;
            --card: #ffffff;
            --text: #1e293b;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: var(--bg);
            color: var(--text);
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
            line-height: 1.5;
        }
        h1 { margin-bottom: 0.5rem; }
        .subtitle { color: #64748b; margin-bottom: 2rem; }

        .card {
            background: var(--card);
            padding: 2rem;
            border-radius: 12px;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);
            margin-bottom: 2rem;
        }

        .vector-group { margin-bottom: 1.5rem; }
        .vector-group h3 { margin-bottom: 0.5rem; font-size: 1rem; color: #475569; }

        .inputs {
            display: grid;
            grid-template-columns: repeat(8, 1fr);
            gap: 0.5rem;
        }

        input {
            width: 100%;
            padding: 0.5rem;
            border: 1px solid #cbd5e1;
            border-radius: 6px;
            text-align: center;
            font-family: monospace;
        }
        input:focus {
            outline: 2px solid var(--primary);
            border-color: transparent;
        }

        button {
            background: var(--primary);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 6px;
            font-weight: 600;
            cursor: pointer;
            transition: background 0.2s;
            width: 100%;
            font-size: 1.1rem;
        }
        button:hover { background: #1d4ed8; }
        button:disabled { opacity: 0.7; cursor: wait; }

        #result-area {
            margin-top: 2rem;
            padding: 1.5rem;
            background: #f1f5f9;
            border-radius: 8px;
            text-align: center;
            display: none;
        }
        .result-value {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--primary);
            font-family: monospace;
        }
        .result-meta { color: #64748b; margin-top: 0.5rem; font-size: 0.9rem; }

        .status {
            position: fixed;
            bottom: 1rem;
            right: 1rem;
            padding: 0.5rem 1rem;
            background: #10b981;
            color: white;
            border-radius: 999px;
            font-size: 0.875rem;
            opacity: 0;
            transition: opacity 0.3s;
        }
        .status.visible { opacity: 1; }
    </style>
</head>
<body>
    <h1>Hydron Geometric Engine</h1>
    <p class="subtitle">High-performance S<sup>7</sup> spherical geometry in WebAssembly</p>

    <div class="card">
        <div class="vector-group">
            <h3>Vector A (8D)</h3>
            <div class="inputs" id="vec-a">
                <input type="number" value="1.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
            </div>
        </div>

        <div class="vector-group">
            <h3>Vector B (8D)</h3>
            <div class="inputs" id="vec-b">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="1.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
                <input type="number" value="0.0" step="0.1">
            </div>
        </div>

        <button id="calc-btn">Calculate Spherical Distance</button>

        <div id="result-area">
            <div class="result-label">Geodesic Distance (radians)</div>
            <div class="result-value" id="distance-val">--</div>
            <div class="result-meta" id="perf-val"></div>
        </div>
    </div>

    <div id="status-badge" class="status">Wasm Engine Ready</div>

    <script type="module">
        import init, { s7_distance } from './hydron-ffi/pkg/hydron_ffi.js';

        const btn = document.getElementById('calc-btn');
        const resultArea = document.getElementById('result-area');
        const distanceVal = document.getElementById('distance-val');
        const perfVal = document.getElementById('perf-val');
        const statusBadge = document.getElementById('status-badge');

        async function initialize() {
            try {
                await init();
                statusBadge.classList.add('visible');

                // Auto-calculate on load
                calculate();
            } catch (e) {
                console.error(e);
                btn.textContent = "Error Loading Wasm Engine";
                btn.disabled = true;
                btn.style.background = "#ef4444";
            }
        }

        function getVector(id) {
            const inputs = document.querySelectorAll(`#${id} input`);
            return new Float32Array(Array.from(inputs).map(i => parseFloat(i.value) || 0));
        }

        function calculate() {
            const vecA = getVector('vec-a');
            const vecB = getVector('vec-b');

            const start = performance.now();
            const distance = s7_distance(vecA, vecB);
            const end = performance.now();

            resultArea.style.display = 'block';
            distanceVal.textContent = distance.toFixed(8);

            const isPiOver2 = Math.abs(distance - Math.PI/2) < 1e-6;
            const note = isPiOver2 ? " (≈ π/2)" : "";

            perfVal.textContent = `Computed in ${(end - start).toFixed(3)}ms${note}`;
        }

        btn.addEventListener('click', calculate);

        // Initialize
        initialize();
    </script>
</body>
</html>
